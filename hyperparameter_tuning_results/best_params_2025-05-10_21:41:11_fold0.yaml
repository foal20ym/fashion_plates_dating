batch_size: 8
dense_layers: 2
dense_units: 512
dropout: 0.4
fine_tune_layers: 5
l2_regularization: 0.0001
learning_rate: 7.373698566110249e-05
val_loss: !!python/object/apply:numpy._core.multiarray.scalar
- !!python/object/apply:numpy.dtype
  args:
  - f8
  - false
  - true
  state: !!python/tuple
  - 3
  - <
  - null
  - null
  - null
  - -1
  - -1
  - 0
- !!binary |
  AAAAQBoyDEA=
