task: regression

model:
  # name: NASNetMobile
  name: InceptionV3
  # name: ResNet101
  # name: EfficientNetB3
  # name: "ConvNeXtTiny"
  # name: "EfficientNetV2S"
  hybrid: false
  normalize_years: false
  normalization_method: "standardize" # Options: "minmax", "standardize", "scale_to_range"
  include_top: false
  fine_tune:
    layers: 9
    use: true
  save_model: false
  l2_regularization:
    value: 1e-5
    use: true
  dropout:
    value: 0.4
    use: true
  dense_layers: 2
  dense_units: 256

training:
  batch_size: 8
  epochs: 1
  learning_rate: 0.00025973809360934377
  early_stopping_patience: 16
  reduce_lr_patience: 8
  class_balancing:
    enabled: false
    method: "balanced"

cross_validation: false

hyperparameter_tuning:
  enabled: false
  method: "bayesian" # Options: "random", "bayesian", "hyperband"
  max_trials: 10
  executions_per_trial: 1
  directory: "hyperparameter_tuning"
  project_name: "fashion_plates_dating"
  parameters:
    dropout:
      min: 0.1
      max: 0.5
      step: 0.1
      tune: true
    learning_rate:
      min: 0.0000001
      max: 0.01
      sampling: "log"
      tune: true
    batch_size:
      values: [8, 16, 32, 64, 128]
      tune: true
    l2_regularization:
      values: [0.0, 1e-5, 1e-4, 1e-3, 1e-2]
      tune: true
    fine_tune_layers:
      min: 0
      max: 10
      step: 1
      tune: true
    dense_units:
      values: [32, 64, 128, 256, 512]
      default: 128
      tune: true
    dense_layers:
      min: 1
      max: 3
      step: 1
      default: 1
      tune: true

null_hypothesis_testing:
  use: true
  model_1: InceptionV3
  model_2: NASNetMobile