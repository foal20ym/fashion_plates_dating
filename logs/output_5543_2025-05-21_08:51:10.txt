TensorFlow Version: 2.20.0-dev20250508
Num GPUs Available: 1
Physical devices cannot be modified after being initialized

=== Using model: ConvNeXtTiny. ===
RUN ID: 2025-05-21_08:51:14
Task: Classification
Test fold: 0

===== Fine Tuning 7 layers! =====
Epoch 1/300
1413/1413 - 306s - 217ms/step - accuracy: 0.1279 - loss: 4.5191 - val_accuracy: 0.0884 - val_loss: 3.8226 - learning_rate: 1.6200e-04
Epoch 2/300
1413/1413 - 232s - 164ms/step - accuracy: 0.1982 - loss: 3.9988 - val_accuracy: 0.1935 - val_loss: 4.4706 - learning_rate: 1.6200e-04
Epoch 3/300
1413/1413 - 235s - 166ms/step - accuracy: 0.2246 - loss: 3.8322 - val_accuracy: 0.2524 - val_loss: 4.0259 - learning_rate: 1.6200e-04
Epoch 4/300
1413/1413 - 227s - 161ms/step - accuracy: 0.2520 - loss: 3.6784 - val_accuracy: 0.2619 - val_loss: 4.1980 - learning_rate: 1.6200e-04
Epoch 5/300
1413/1413 - 234s - 166ms/step - accuracy: 0.2583 - loss: 3.5995 - val_accuracy: 0.3416 - val_loss: 3.1546 - learning_rate: 1.6200e-04
Epoch 6/300
1413/1413 - 231s - 164ms/step - accuracy: 0.2686 - loss: 3.5217 - val_accuracy: 0.2006 - val_loss: 4.9555 - learning_rate: 1.6200e-04
Epoch 7/300
1413/1413 - 236s - 167ms/step - accuracy: 0.2805 - loss: 3.4787 - val_accuracy: 0.3551 - val_loss: 3.2804 - learning_rate: 1.6200e-04
Epoch 8/300
1413/1413 - 233s - 165ms/step - accuracy: 0.2827 - loss: 3.4394 - val_accuracy: 0.2699 - val_loss: 3.2868 - learning_rate: 1.6200e-04
Epoch 9/300
1413/1413 - 226s - 160ms/step - accuracy: 0.2916 - loss: 3.4258 - val_accuracy: 0.3264 - val_loss: 3.5607 - learning_rate: 1.6200e-04
Epoch 10/300
1413/1413 - 235s - 167ms/step - accuracy: 0.3011 - loss: 3.3470 - val_accuracy: 0.2803 - val_loss: 4.6112 - learning_rate: 1.6200e-04
Epoch 11/300
1413/1413 - 236s - 167ms/step - accuracy: 0.3059 - loss: 3.3269 - val_accuracy: 0.3662 - val_loss: 2.8327 - learning_rate: 1.6200e-04
Epoch 12/300
1413/1413 - 228s - 161ms/step - accuracy: 0.3091 - loss: 3.3176 - val_accuracy: 0.2914 - val_loss: 4.9030 - learning_rate: 1.6200e-04
Epoch 13/300
1413/1413 - 230s - 163ms/step - accuracy: 0.3086 - loss: 3.2987 - val_accuracy: 0.3678 - val_loss: 3.0187 - learning_rate: 1.6200e-04
Epoch 14/300
1413/1413 - 229s - 162ms/step - accuracy: 0.3161 - loss: 3.2823 - val_accuracy: 0.3073 - val_loss: 3.0636 - learning_rate: 1.6200e-04
Epoch 15/300
1413/1413 - 229s - 162ms/step - accuracy: 0.3194 - loss: 3.2352 - val_accuracy: 0.4538 - val_loss: 2.7366 - learning_rate: 1.6200e-04
Epoch 16/300
1413/1413 - 230s - 163ms/step - accuracy: 0.3212 - loss: 3.2658 - val_accuracy: 0.3973 - val_loss: 3.1222 - learning_rate: 1.6200e-04
Epoch 17/300
1413/1413 - 225s - 159ms/step - accuracy: 0.3272 - loss: 3.2055 - val_accuracy: 0.4459 - val_loss: 2.6336 - learning_rate: 1.6200e-04
Epoch 18/300
1413/1413 - 231s - 163ms/step - accuracy: 0.3307 - loss: 3.1948 - val_accuracy: 0.4021 - val_loss: 3.2080 - learning_rate: 1.6200e-04
Epoch 19/300
1413/1413 - 232s - 164ms/step - accuracy: 0.3333 - loss: 3.1699 - val_accuracy: 0.4379 - val_loss: 2.5292 - learning_rate: 1.6200e-04
Epoch 20/300
1413/1413 - 230s - 163ms/step - accuracy: 0.3384 - loss: 3.1746 - val_accuracy: 0.4108 - val_loss: 3.0042 - learning_rate: 1.6200e-04
Epoch 21/300
1413/1413 - 229s - 162ms/step - accuracy: 0.3366 - loss: 3.1625 - val_accuracy: 0.4642 - val_loss: 2.7194 - learning_rate: 1.6200e-04
Epoch 22/300
1413/1413 - 229s - 162ms/step - accuracy: 0.3352 - loss: 3.1401 - val_accuracy: 0.4634 - val_loss: 2.7283 - learning_rate: 1.6200e-04
Epoch 23/300
1413/1413 - 228s - 161ms/step - accuracy: 0.3411 - loss: 3.1242 - val_accuracy: 0.3909 - val_loss: 2.6689 - learning_rate: 1.6200e-04
Epoch 24/300
1413/1413 - 230s - 163ms/step - accuracy: 0.3489 - loss: 3.1122 - val_accuracy: 0.3002 - val_loss: 3.6624 - learning_rate: 1.6200e-04
Epoch 25/300
1413/1413 - 260s - 184ms/step - accuracy: 0.3431 - loss: 3.1104 - val_accuracy: 0.4411 - val_loss: 2.4953 - learning_rate: 1.6200e-04
Epoch 26/300
1413/1413 - 229s - 162ms/step - accuracy: 0.3593 - loss: 3.0563 - val_accuracy: 0.3893 - val_loss: 4.4109 - learning_rate: 1.6200e-04
Epoch 27/300
1413/1413 - 228s - 162ms/step - accuracy: 0.3532 - loss: 3.0765 - val_accuracy: 0.4252 - val_loss: 2.8937 - learning_rate: 1.6200e-04
Epoch 28/300
1413/1413 - 233s - 165ms/step - accuracy: 0.3526 - loss: 3.0646 - val_accuracy: 0.3822 - val_loss: 3.5021 - learning_rate: 1.6200e-04
Epoch 29/300
1413/1413 - 227s - 161ms/step - accuracy: 0.3519 - loss: 3.0625 - val_accuracy: 0.3639 - val_loss: 3.7061 - learning_rate: 1.6200e-04
Epoch 30/300
1413/1413 - 226s - 160ms/step - accuracy: 0.3615 - loss: 3.0206 - val_accuracy: 0.4594 - val_loss: 2.5119 - learning_rate: 1.6200e-04
Epoch 31/300
1413/1413 - 230s - 163ms/step - accuracy: 0.3599 - loss: 3.0280 - val_accuracy: 0.4936 - val_loss: 2.4293 - learning_rate: 1.6200e-04
Epoch 32/300
1413/1413 - 224s - 158ms/step - accuracy: 0.3611 - loss: 3.0355 - val_accuracy: 0.5104 - val_loss: 2.4405 - learning_rate: 1.6200e-04
Epoch 33/300
1413/1413 - 230s - 163ms/step - accuracy: 0.3628 - loss: 3.0336 - val_accuracy: 0.4490 - val_loss: 3.0180 - learning_rate: 1.6200e-04
Epoch 34/300
1413/1413 - 231s - 163ms/step - accuracy: 0.3625 - loss: 3.0183 - val_accuracy: 0.4984 - val_loss: 2.3133 - learning_rate: 1.6200e-04
Epoch 35/300
1413/1413 - 226s - 160ms/step - accuracy: 0.3683 - loss: 2.9672 - val_accuracy: 0.3495 - val_loss: 3.3976 - learning_rate: 1.6200e-04
Epoch 36/300
1413/1413 - 230s - 163ms/step - accuracy: 0.3663 - loss: 2.9913 - val_accuracy: 0.5072 - val_loss: 2.2482 - learning_rate: 1.6200e-04
Epoch 37/300
1413/1413 - 225s - 159ms/step - accuracy: 0.3705 - loss: 2.9697 - val_accuracy: 0.3981 - val_loss: 3.6012 - learning_rate: 1.6200e-04
Epoch 38/300
1413/1413 - 226s - 160ms/step - accuracy: 0.3701 - loss: 2.9428 - val_accuracy: 0.4371 - val_loss: 2.8562 - learning_rate: 1.6200e-04
Epoch 39/300
1413/1413 - 227s - 161ms/step - accuracy: 0.3788 - loss: 2.9466 - val_accuracy: 0.5247 - val_loss: 2.1938 - learning_rate: 1.6200e-04
Epoch 40/300
1413/1413 - 226s - 160ms/step - accuracy: 0.3743 - loss: 2.9615 - val_accuracy: 0.3575 - val_loss: 3.9538 - learning_rate: 1.6200e-04
Epoch 41/300
1413/1413 - 226s - 160ms/step - accuracy: 0.3742 - loss: 2.9403 - val_accuracy: 0.5255 - val_loss: 2.2866 - learning_rate: 1.6200e-04
Epoch 42/300
1413/1413 - 227s - 161ms/step - accuracy: 0.3718 - loss: 2.9726 - val_accuracy: 0.5295 - val_loss: 2.2485 - learning_rate: 1.6200e-04
Epoch 43/300
1413/1413 - 225s - 159ms/step - accuracy: 0.3782 - loss: 2.9246 - val_accuracy: 0.4403 - val_loss: 2.8686 - learning_rate: 1.6200e-04
Epoch 44/300
1413/1413 - 234s - 166ms/step - accuracy: 0.3791 - loss: 2.9131 - val_accuracy: 0.4427 - val_loss: 2.7087 - learning_rate: 1.6200e-04
Epoch 45/300
1413/1413 - 226s - 160ms/step - accuracy: 0.3830 - loss: 2.9279 - val_accuracy: 0.5366 - val_loss: 2.1265 - learning_rate: 1.6200e-04
Epoch 46/300
1413/1413 - 227s - 160ms/step - accuracy: 0.3831 - loss: 2.9203 - val_accuracy: 0.5287 - val_loss: 2.1754 - learning_rate: 1.6200e-04
Epoch 47/300
1413/1413 - 234s - 165ms/step - accuracy: 0.3841 - loss: 2.8966 - val_accuracy: 0.5764 - val_loss: 1.9780 - learning_rate: 1.6200e-04
Epoch 48/300
1413/1413 - 228s - 162ms/step - accuracy: 0.3823 - loss: 2.8981 - val_accuracy: 0.5669 - val_loss: 2.0536 - learning_rate: 1.6200e-04
Epoch 49/300
1413/1413 - 222s - 157ms/step - accuracy: 0.3862 - loss: 2.9008 - val_accuracy: 0.4777 - val_loss: 2.8675 - learning_rate: 1.6200e-04
Epoch 50/300
1413/1413 - 234s - 166ms/step - accuracy: 0.3859 - loss: 2.8838 - val_accuracy: 0.4920 - val_loss: 2.4543 - learning_rate: 1.6200e-04
Epoch 51/300
1413/1413 - 227s - 161ms/step - accuracy: 0.3806 - loss: 2.8890 - val_accuracy: 0.5637 - val_loss: 2.1075 - learning_rate: 1.6200e-04
Epoch 52/300
1413/1413 - 226s - 160ms/step - accuracy: 0.3935 - loss: 2.8471 - val_accuracy: 0.4904 - val_loss: 2.8611 - learning_rate: 1.6200e-04
Epoch 53/300
1413/1413 - 225s - 159ms/step - accuracy: 0.3837 - loss: 2.8865 - val_accuracy: 0.5422 - val_loss: 2.1622 - learning_rate: 1.6200e-04
Epoch 54/300
1413/1413 - 225s - 159ms/step - accuracy: 0.3911 - loss: 2.8627 - val_accuracy: 0.5565 - val_loss: 1.9134 - learning_rate: 1.6200e-04
Epoch 55/300
1413/1413 - 227s - 161ms/step - accuracy: 0.3976 - loss: 2.8609 - val_accuracy: 0.5581 - val_loss: 2.1600 - learning_rate: 1.6200e-04
Epoch 56/300
1413/1413 - 226s - 160ms/step - accuracy: 0.3900 - loss: 2.8775 - val_accuracy: 0.5924 - val_loss: 1.9807 - learning_rate: 1.6200e-04
Epoch 57/300
1413/1413 - 226s - 160ms/step - accuracy: 0.3931 - loss: 2.8543 - val_accuracy: 0.5573 - val_loss: 2.0366 - learning_rate: 1.6200e-04
Epoch 58/300
1413/1413 - 240s - 170ms/step - accuracy: 0.3969 - loss: 2.8414 - val_accuracy: 0.5255 - val_loss: 2.1291 - learning_rate: 1.6200e-04
Epoch 59/300
1413/1413 - 241s - 171ms/step - accuracy: 0.3912 - loss: 2.8512 - val_accuracy: 0.5748 - val_loss: 2.0822 - learning_rate: 1.6200e-04
Epoch 60/300
1413/1413 - 239s - 169ms/step - accuracy: 0.3980 - loss: 2.8365 - val_accuracy: 0.5215 - val_loss: 2.3102 - learning_rate: 1.6200e-04
Epoch 61/300
1413/1413 - 235s - 166ms/step - accuracy: 0.3941 - loss: 2.8229 - val_accuracy: 0.5629 - val_loss: 2.0929 - learning_rate: 1.6200e-04
Epoch 62/300

Epoch 62: ReduceLROnPlateau reducing learning rate to 8.099817205220461e-05.
1413/1413 - 239s - 169ms/step - accuracy: 0.3960 - loss: 2.8358 - val_accuracy: 0.5247 - val_loss: 2.2236 - learning_rate: 1.6200e-04
Epoch 63/300
1413/1413 - 239s - 169ms/step - accuracy: 0.4101 - loss: 2.7701 - val_accuracy: 0.5725 - val_loss: 1.9187 - learning_rate: 8.0998e-05
Epoch 64/300
1413/1413 - 234s - 165ms/step - accuracy: 0.4093 - loss: 2.7649 - val_accuracy: 0.6139 - val_loss: 1.9015 - learning_rate: 8.0998e-05
Epoch 65/300
1413/1413 - 233s - 165ms/step - accuracy: 0.4177 - loss: 2.7506 - val_accuracy: 0.6274 - val_loss: 1.7788 - learning_rate: 8.0998e-05
Epoch 66/300
1413/1413 - 237s - 167ms/step - accuracy: 0.4184 - loss: 2.7281 - val_accuracy: 0.6107 - val_loss: 1.8273 - learning_rate: 8.0998e-05
Epoch 67/300
1413/1413 - 236s - 167ms/step - accuracy: 0.4157 - loss: 2.7180 - val_accuracy: 0.6051 - val_loss: 1.9301 - learning_rate: 8.0998e-05
Epoch 68/300
1413/1413 - 237s - 167ms/step - accuracy: 0.4198 - loss: 2.7126 - val_accuracy: 0.5565 - val_loss: 2.2835 - learning_rate: 8.0998e-05
Epoch 69/300
1413/1413 - 227s - 161ms/step - accuracy: 0.4250 - loss: 2.7234 - val_accuracy: 0.6131 - val_loss: 1.7881 - learning_rate: 8.0998e-05
Epoch 70/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4164 - loss: 2.7166 - val_accuracy: 0.5955 - val_loss: 1.8822 - learning_rate: 8.0998e-05
Epoch 71/300
1413/1413 - 235s - 166ms/step - accuracy: 0.4237 - loss: 2.7055 - val_accuracy: 0.6154 - val_loss: 1.8061 - learning_rate: 8.0998e-05
Epoch 72/300
1413/1413 - 239s - 169ms/step - accuracy: 0.4206 - loss: 2.7101 - val_accuracy: 0.6194 - val_loss: 1.7761 - learning_rate: 8.0998e-05
Epoch 73/300
1413/1413 - 234s - 165ms/step - accuracy: 0.4220 - loss: 2.7267 - val_accuracy: 0.6011 - val_loss: 1.8439 - learning_rate: 8.0998e-05
Epoch 74/300
1413/1413 - 237s - 168ms/step - accuracy: 0.4245 - loss: 2.7015 - val_accuracy: 0.6194 - val_loss: 1.7981 - learning_rate: 8.0998e-05
Epoch 75/300
1413/1413 - 235s - 167ms/step - accuracy: 0.4202 - loss: 2.6910 - val_accuracy: 0.5947 - val_loss: 1.8712 - learning_rate: 8.0998e-05
Epoch 76/300
1413/1413 - 235s - 166ms/step - accuracy: 0.4175 - loss: 2.7307 - val_accuracy: 0.6131 - val_loss: 1.7742 - learning_rate: 8.0998e-05
Epoch 77/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4221 - loss: 2.6994 - val_accuracy: 0.5876 - val_loss: 1.9142 - learning_rate: 8.0998e-05
Epoch 78/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4228 - loss: 2.7312 - val_accuracy: 0.6202 - val_loss: 1.8675 - learning_rate: 8.0998e-05
Epoch 79/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4218 - loss: 2.6869 - val_accuracy: 0.6258 - val_loss: 1.7216 - learning_rate: 8.0998e-05
Epoch 80/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4263 - loss: 2.6874 - val_accuracy: 0.6123 - val_loss: 1.8500 - learning_rate: 8.0998e-05
Epoch 81/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4278 - loss: 2.6824 - val_accuracy: 0.6083 - val_loss: 1.7073 - learning_rate: 8.0998e-05
Epoch 82/300
1413/1413 - 231s - 163ms/step - accuracy: 0.4339 - loss: 2.6562 - val_accuracy: 0.6131 - val_loss: 1.8614 - learning_rate: 8.0998e-05
Epoch 83/300
1413/1413 - 227s - 161ms/step - accuracy: 0.4235 - loss: 2.6797 - val_accuracy: 0.6115 - val_loss: 1.8063 - learning_rate: 8.0998e-05
Epoch 84/300
1413/1413 - 221s - 157ms/step - accuracy: 0.4292 - loss: 2.6762 - val_accuracy: 0.6075 - val_loss: 1.8461 - learning_rate: 8.0998e-05
Epoch 85/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4363 - loss: 2.6661 - val_accuracy: 0.6361 - val_loss: 1.7531 - learning_rate: 8.0998e-05
Epoch 86/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4342 - loss: 2.6652 - val_accuracy: 0.6361 - val_loss: 1.6592 - learning_rate: 8.0998e-05
Epoch 87/300
1413/1413 - 234s - 165ms/step - accuracy: 0.4290 - loss: 2.6714 - val_accuracy: 0.5955 - val_loss: 1.8448 - learning_rate: 8.0998e-05
Epoch 88/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4306 - loss: 2.6690 - val_accuracy: 0.6298 - val_loss: 1.7260 - learning_rate: 8.0998e-05
Epoch 89/300
1413/1413 - 227s - 160ms/step - accuracy: 0.4305 - loss: 2.6460 - val_accuracy: 0.5709 - val_loss: 1.9368 - learning_rate: 8.0998e-05
Epoch 90/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4248 - loss: 2.6957 - val_accuracy: 0.6194 - val_loss: 1.8851 - learning_rate: 8.0998e-05
Epoch 91/300
1413/1413 - 233s - 165ms/step - accuracy: 0.4376 - loss: 2.6463 - val_accuracy: 0.5971 - val_loss: 1.8186 - learning_rate: 8.0998e-05
Epoch 92/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4336 - loss: 2.6355 - val_accuracy: 0.6258 - val_loss: 1.7117 - learning_rate: 8.0998e-05
Epoch 93/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4351 - loss: 2.6665 - val_accuracy: 0.6091 - val_loss: 1.8558 - learning_rate: 8.0998e-05
Epoch 94/300
1413/1413 - 224s - 159ms/step - accuracy: 0.4339 - loss: 2.6331 - val_accuracy: 0.6433 - val_loss: 1.6304 - learning_rate: 8.0998e-05
Epoch 95/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4339 - loss: 2.6330 - val_accuracy: 0.5740 - val_loss: 1.9286 - learning_rate: 8.0998e-05
Epoch 96/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4315 - loss: 2.6668 - val_accuracy: 0.6011 - val_loss: 1.7338 - learning_rate: 8.0998e-05
Epoch 97/300
1413/1413 - 236s - 167ms/step - accuracy: 0.4330 - loss: 2.6584 - val_accuracy: 0.6194 - val_loss: 1.8262 - learning_rate: 8.0998e-05
Epoch 98/300
1413/1413 - 238s - 168ms/step - accuracy: 0.4345 - loss: 2.6314 - val_accuracy: 0.5756 - val_loss: 1.9865 - learning_rate: 8.0998e-05
Epoch 99/300
1413/1413 - 237s - 168ms/step - accuracy: 0.4333 - loss: 2.6365 - val_accuracy: 0.6035 - val_loss: 1.8568 - learning_rate: 8.0998e-05
Epoch 100/300
1413/1413 - 241s - 170ms/step - accuracy: 0.4355 - loss: 2.6548 - val_accuracy: 0.6306 - val_loss: 1.7004 - learning_rate: 8.0998e-05
Epoch 101/300
1413/1413 - 235s - 167ms/step - accuracy: 0.4329 - loss: 2.6414 - val_accuracy: 0.6027 - val_loss: 1.9142 - learning_rate: 8.0998e-05
Epoch 102/300

Epoch 102: ReduceLROnPlateau reducing learning rate to 4.0499086026102304e-05.
1413/1413 - 226s - 160ms/step - accuracy: 0.4410 - loss: 2.6367 - val_accuracy: 0.6346 - val_loss: 1.6357 - learning_rate: 8.0998e-05
Epoch 103/300
1413/1413 - 230s - 163ms/step - accuracy: 0.4496 - loss: 2.5836 - val_accuracy: 0.6513 - val_loss: 1.6358 - learning_rate: 4.0499e-05
Epoch 104/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4426 - loss: 2.5881 - val_accuracy: 0.6584 - val_loss: 1.6691 - learning_rate: 4.0499e-05
Epoch 105/300
1413/1413 - 239s - 169ms/step - accuracy: 0.4419 - loss: 2.5771 - val_accuracy: 0.6449 - val_loss: 1.5795 - learning_rate: 4.0499e-05
Epoch 106/300
1413/1413 - 236s - 167ms/step - accuracy: 0.4463 - loss: 2.5861 - val_accuracy: 0.6433 - val_loss: 1.6430 - learning_rate: 4.0499e-05
Epoch 107/300
1413/1413 - 239s - 169ms/step - accuracy: 0.4479 - loss: 2.6088 - val_accuracy: 0.6688 - val_loss: 1.5679 - learning_rate: 4.0499e-05
Epoch 108/300
1413/1413 - 240s - 170ms/step - accuracy: 0.4488 - loss: 2.5827 - val_accuracy: 0.6553 - val_loss: 1.6353 - learning_rate: 4.0499e-05
Epoch 109/300
1413/1413 - 234s - 165ms/step - accuracy: 0.4497 - loss: 2.5480 - val_accuracy: 0.6616 - val_loss: 1.5679 - learning_rate: 4.0499e-05
Epoch 110/300
1413/1413 - 228s - 161ms/step - accuracy: 0.4456 - loss: 2.5714 - val_accuracy: 0.6640 - val_loss: 1.5320 - learning_rate: 4.0499e-05
Epoch 111/300
1413/1413 - 237s - 168ms/step - accuracy: 0.4493 - loss: 2.5801 - val_accuracy: 0.6584 - val_loss: 1.5506 - learning_rate: 4.0499e-05
Epoch 112/300
1413/1413 - 236s - 167ms/step - accuracy: 0.4517 - loss: 2.5572 - val_accuracy: 0.6537 - val_loss: 1.5759 - learning_rate: 4.0499e-05
Epoch 113/300
1413/1413 - 239s - 169ms/step - accuracy: 0.4476 - loss: 2.5805 - val_accuracy: 0.6417 - val_loss: 1.6695 - learning_rate: 4.0499e-05
Epoch 114/300
1413/1413 - 238s - 169ms/step - accuracy: 0.4484 - loss: 2.5640 - val_accuracy: 0.6648 - val_loss: 1.6290 - learning_rate: 4.0499e-05
Epoch 115/300
1413/1413 - 235s - 167ms/step - accuracy: 0.4458 - loss: 2.5900 - val_accuracy: 0.6505 - val_loss: 1.5864 - learning_rate: 4.0499e-05
Epoch 116/300
1413/1413 - 234s - 165ms/step - accuracy: 0.4616 - loss: 2.5201 - val_accuracy: 0.6425 - val_loss: 1.6285 - learning_rate: 4.0499e-05
Epoch 117/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4527 - loss: 2.5467 - val_accuracy: 0.6322 - val_loss: 1.6958 - learning_rate: 4.0499e-05
Epoch 118/300

Epoch 118: ReduceLROnPlateau reducing learning rate to 2.0249543013051152e-05.
1413/1413 - 225s - 159ms/step - accuracy: 0.4516 - loss: 2.5644 - val_accuracy: 0.6537 - val_loss: 1.6119 - learning_rate: 4.0499e-05
Epoch 119/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4507 - loss: 2.5784 - val_accuracy: 0.6712 - val_loss: 1.5371 - learning_rate: 2.0250e-05
Epoch 120/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4609 - loss: 2.5227 - val_accuracy: 0.6561 - val_loss: 1.5587 - learning_rate: 2.0250e-05
Epoch 121/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4586 - loss: 2.5301 - val_accuracy: 0.6736 - val_loss: 1.5018 - learning_rate: 2.0250e-05
Epoch 122/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4588 - loss: 2.5446 - val_accuracy: 0.6696 - val_loss: 1.5436 - learning_rate: 2.0250e-05
Epoch 123/300
1413/1413 - 227s - 160ms/step - accuracy: 0.4615 - loss: 2.5004 - val_accuracy: 0.6680 - val_loss: 1.6239 - learning_rate: 2.0250e-05
Epoch 124/300
1413/1413 - 224s - 159ms/step - accuracy: 0.4658 - loss: 2.5201 - val_accuracy: 0.6664 - val_loss: 1.5191 - learning_rate: 2.0250e-05
Epoch 125/300
1413/1413 - 227s - 161ms/step - accuracy: 0.4623 - loss: 2.5272 - val_accuracy: 0.6656 - val_loss: 1.5661 - learning_rate: 2.0250e-05
Epoch 126/300
1413/1413 - 224s - 158ms/step - accuracy: 0.4651 - loss: 2.5121 - val_accuracy: 0.6600 - val_loss: 1.5439 - learning_rate: 2.0250e-05
Epoch 127/300
1413/1413 - 228s - 162ms/step - accuracy: 0.4624 - loss: 2.5147 - val_accuracy: 0.6752 - val_loss: 1.5258 - learning_rate: 2.0250e-05
Epoch 128/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4598 - loss: 2.5154 - val_accuracy: 0.6688 - val_loss: 1.5423 - learning_rate: 2.0250e-05
Epoch 129/300

Epoch 129: ReduceLROnPlateau reducing learning rate to 1.0124771506525576e-05.
1413/1413 - 224s - 159ms/step - accuracy: 0.4611 - loss: 2.5299 - val_accuracy: 0.6616 - val_loss: 1.5655 - learning_rate: 2.0250e-05
Epoch 130/300
1413/1413 - 228s - 161ms/step - accuracy: 0.4620 - loss: 2.5058 - val_accuracy: 0.6775 - val_loss: 1.5153 - learning_rate: 1.0125e-05
Epoch 131/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4686 - loss: 2.5034 - val_accuracy: 0.6775 - val_loss: 1.5224 - learning_rate: 1.0125e-05
Epoch 132/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4712 - loss: 2.4712 - val_accuracy: 0.6624 - val_loss: 1.5143 - learning_rate: 1.0125e-05
Epoch 133/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4608 - loss: 2.5031 - val_accuracy: 0.6752 - val_loss: 1.4991 - learning_rate: 1.0125e-05
Epoch 134/300
1413/1413 - 224s - 159ms/step - accuracy: 0.4622 - loss: 2.5056 - val_accuracy: 0.6752 - val_loss: 1.5119 - learning_rate: 1.0125e-05
Epoch 135/300
1413/1413 - 244s - 173ms/step - accuracy: 0.4711 - loss: 2.4637 - val_accuracy: 0.6807 - val_loss: 1.5336 - learning_rate: 1.0125e-05
Epoch 136/300
1413/1413 - 240s - 170ms/step - accuracy: 0.4647 - loss: 2.4860 - val_accuracy: 0.6783 - val_loss: 1.4752 - learning_rate: 1.0125e-05
Epoch 137/300
1413/1413 - 233s - 165ms/step - accuracy: 0.4626 - loss: 2.5114 - val_accuracy: 0.6847 - val_loss: 1.5112 - learning_rate: 1.0125e-05
Epoch 138/300
1413/1413 - 241s - 171ms/step - accuracy: 0.4652 - loss: 2.4966 - val_accuracy: 0.6799 - val_loss: 1.4885 - learning_rate: 1.0125e-05
Epoch 139/300
1413/1413 - 236s - 167ms/step - accuracy: 0.4658 - loss: 2.4728 - val_accuracy: 0.6855 - val_loss: 1.5113 - learning_rate: 1.0125e-05
Epoch 140/300
1413/1413 - 239s - 169ms/step - accuracy: 0.4630 - loss: 2.5047 - val_accuracy: 0.6783 - val_loss: 1.4845 - learning_rate: 1.0125e-05
Epoch 141/300
1413/1413 - 234s - 166ms/step - accuracy: 0.4673 - loss: 2.5010 - val_accuracy: 0.6855 - val_loss: 1.4752 - learning_rate: 1.0125e-05
Epoch 142/300
1413/1413 - 238s - 169ms/step - accuracy: 0.4615 - loss: 2.4840 - val_accuracy: 0.6744 - val_loss: 1.5196 - learning_rate: 1.0125e-05
Epoch 143/300
1413/1413 - 240s - 170ms/step - accuracy: 0.4649 - loss: 2.4793 - val_accuracy: 0.6775 - val_loss: 1.5078 - learning_rate: 1.0125e-05
Epoch 144/300

Epoch 144: ReduceLROnPlateau reducing learning rate to 5.062385753262788e-06.
1413/1413 - 236s - 167ms/step - accuracy: 0.4690 - loss: 2.4756 - val_accuracy: 0.6799 - val_loss: 1.4895 - learning_rate: 1.0125e-05
Epoch 145/300
1413/1413 - 237s - 168ms/step - accuracy: 0.4649 - loss: 2.4906 - val_accuracy: 0.6775 - val_loss: 1.4734 - learning_rate: 5.0624e-06
Epoch 146/300
1413/1413 - 237s - 168ms/step - accuracy: 0.4695 - loss: 2.4678 - val_accuracy: 0.6863 - val_loss: 1.4670 - learning_rate: 5.0624e-06
Epoch 147/300
1413/1413 - 236s - 167ms/step - accuracy: 0.4686 - loss: 2.4772 - val_accuracy: 0.6807 - val_loss: 1.4893 - learning_rate: 5.0624e-06
Epoch 148/300
1413/1413 - 237s - 168ms/step - accuracy: 0.4726 - loss: 2.4800 - val_accuracy: 0.6768 - val_loss: 1.4726 - learning_rate: 5.0624e-06
Epoch 149/300
1413/1413 - 224s - 159ms/step - accuracy: 0.4661 - loss: 2.4558 - val_accuracy: 0.6839 - val_loss: 1.4726 - learning_rate: 5.0624e-06
Epoch 150/300
1413/1413 - 220s - 156ms/step - accuracy: 0.4655 - loss: 2.4835 - val_accuracy: 0.6783 - val_loss: 1.4876 - learning_rate: 5.0624e-06
Epoch 151/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4778 - loss: 2.4695 - val_accuracy: 0.6815 - val_loss: 1.4661 - learning_rate: 5.0624e-06
Epoch 152/300
1413/1413 - 224s - 159ms/step - accuracy: 0.4682 - loss: 2.4757 - val_accuracy: 0.6847 - val_loss: 1.4697 - learning_rate: 5.0624e-06
Epoch 153/300
1413/1413 - 231s - 164ms/step - accuracy: 0.4664 - loss: 2.4794 - val_accuracy: 0.6871 - val_loss: 1.4977 - learning_rate: 5.0624e-06
Epoch 154/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4704 - loss: 2.4470 - val_accuracy: 0.6799 - val_loss: 1.5075 - learning_rate: 5.0624e-06
Epoch 155/300
1413/1413 - 228s - 161ms/step - accuracy: 0.4657 - loss: 2.4677 - val_accuracy: 0.6815 - val_loss: 1.4702 - learning_rate: 5.0624e-06
Epoch 156/300
1413/1413 - 231s - 164ms/step - accuracy: 0.4672 - loss: 2.4944 - val_accuracy: 0.6831 - val_loss: 1.4715 - learning_rate: 5.0624e-06
Epoch 157/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4729 - loss: 2.4625 - val_accuracy: 0.6736 - val_loss: 1.5296 - learning_rate: 5.0624e-06
Epoch 158/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4695 - loss: 2.4840 - val_accuracy: 0.6807 - val_loss: 1.4696 - learning_rate: 5.0624e-06
Epoch 159/300

Epoch 159: ReduceLROnPlateau reducing learning rate to 2.531192876631394e-06.
1413/1413 - 224s - 158ms/step - accuracy: 0.4719 - loss: 2.4786 - val_accuracy: 0.6863 - val_loss: 1.4670 - learning_rate: 5.0624e-06
Epoch 160/300
1413/1413 - 228s - 162ms/step - accuracy: 0.4786 - loss: 2.4470 - val_accuracy: 0.6807 - val_loss: 1.4625 - learning_rate: 2.5312e-06
Epoch 161/300
1413/1413 - 227s - 161ms/step - accuracy: 0.4710 - loss: 2.4553 - val_accuracy: 0.6823 - val_loss: 1.4636 - learning_rate: 2.5312e-06
Epoch 162/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4741 - loss: 2.4728 - val_accuracy: 0.6823 - val_loss: 1.4697 - learning_rate: 2.5312e-06
Epoch 163/300
1413/1413 - 268s - 189ms/step - accuracy: 0.4660 - loss: 2.4872 - val_accuracy: 0.6839 - val_loss: 1.4570 - learning_rate: 2.5312e-06
Epoch 164/300
1413/1413 - 221s - 157ms/step - accuracy: 0.4662 - loss: 2.4622 - val_accuracy: 0.6863 - val_loss: 1.4757 - learning_rate: 2.5312e-06
Epoch 165/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4639 - loss: 2.4921 - val_accuracy: 0.6775 - val_loss: 1.4845 - learning_rate: 2.5312e-06
Epoch 166/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4750 - loss: 2.4686 - val_accuracy: 0.6847 - val_loss: 1.4660 - learning_rate: 2.5312e-06
Epoch 167/300
1413/1413 - 224s - 159ms/step - accuracy: 0.4690 - loss: 2.4872 - val_accuracy: 0.6831 - val_loss: 1.4576 - learning_rate: 2.5312e-06
Epoch 168/300
1413/1413 - 228s - 161ms/step - accuracy: 0.4691 - loss: 2.4770 - val_accuracy: 0.6823 - val_loss: 1.4684 - learning_rate: 2.5312e-06
Epoch 169/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4743 - loss: 2.4597 - val_accuracy: 0.6839 - val_loss: 1.4643 - learning_rate: 2.5312e-06
Epoch 170/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4670 - loss: 2.4910 - val_accuracy: 0.6847 - val_loss: 1.4524 - learning_rate: 2.5312e-06
Epoch 171/300
1413/1413 - 227s - 160ms/step - accuracy: 0.4666 - loss: 2.4885 - val_accuracy: 0.6847 - val_loss: 1.4782 - learning_rate: 2.5312e-06
Epoch 172/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4731 - loss: 2.4610 - val_accuracy: 0.6871 - val_loss: 1.4788 - learning_rate: 2.5312e-06
Epoch 173/300
1413/1413 - 228s - 161ms/step - accuracy: 0.4731 - loss: 2.4745 - val_accuracy: 0.6863 - val_loss: 1.4701 - learning_rate: 2.5312e-06
Epoch 174/300
1413/1413 - 228s - 161ms/step - accuracy: 0.4731 - loss: 2.4623 - val_accuracy: 0.6911 - val_loss: 1.4574 - learning_rate: 2.5312e-06
Epoch 175/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4758 - loss: 2.4420 - val_accuracy: 0.6823 - val_loss: 1.4597 - learning_rate: 2.5312e-06
Epoch 176/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4721 - loss: 2.4617 - val_accuracy: 0.6887 - val_loss: 1.4581 - learning_rate: 2.5312e-06
Epoch 177/300
1413/1413 - 221s - 156ms/step - accuracy: 0.4729 - loss: 2.4606 - val_accuracy: 0.6823 - val_loss: 1.4690 - learning_rate: 2.5312e-06
Epoch 178/300

Epoch 178: ReduceLROnPlateau reducing learning rate to 1.265596438315697e-06.
1413/1413 - 224s - 158ms/step - accuracy: 0.4705 - loss: 2.4643 - val_accuracy: 0.6831 - val_loss: 1.4751 - learning_rate: 2.5312e-06
Epoch 179/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4777 - loss: 2.4489 - val_accuracy: 0.6855 - val_loss: 1.4582 - learning_rate: 1.2656e-06
Epoch 180/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4693 - loss: 2.4376 - val_accuracy: 0.6839 - val_loss: 1.4605 - learning_rate: 1.2656e-06
Epoch 181/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4675 - loss: 2.4879 - val_accuracy: 0.6871 - val_loss: 1.4615 - learning_rate: 1.2656e-06
Epoch 182/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4739 - loss: 2.4447 - val_accuracy: 0.6911 - val_loss: 1.4608 - learning_rate: 1.2656e-06
Epoch 183/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4737 - loss: 2.4759 - val_accuracy: 0.6823 - val_loss: 1.4566 - learning_rate: 1.2656e-06
Epoch 184/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4675 - loss: 2.4585 - val_accuracy: 0.6847 - val_loss: 1.4541 - learning_rate: 1.2656e-06
Epoch 185/300
1413/1413 - 227s - 161ms/step - accuracy: 0.4697 - loss: 2.4394 - val_accuracy: 0.6879 - val_loss: 1.4630 - learning_rate: 1.2656e-06
Epoch 186/300

Epoch 186: ReduceLROnPlateau reducing learning rate to 1e-06.
1413/1413 - 226s - 160ms/step - accuracy: 0.4693 - loss: 2.4898 - val_accuracy: 0.6871 - val_loss: 1.4662 - learning_rate: 1.2656e-06
Epoch 186: early stopping
Restoring model weights from the end of the best epoch: 170.
Fold 0 Evaluation results: [1.4531687498092651, 0.6847133636474609]
              precision    recall  f1-score   support

        1820       0.83      0.84      0.83        62
        1821       0.87      0.91      0.89        57
        1822       0.00      0.00      0.00         1
        1823       0.00      0.00      0.00         1
        1824       0.00      0.00      0.00         1
        1825       0.00      0.00      0.00         3
        1826       0.00      0.00      0.00         2
        1827       0.92      0.88      0.90        25
        1828       0.00      0.00      0.00         1
        1829       0.50      0.80      0.62         5
        1830       0.86      0.68      0.76        56
        1831       0.86      0.90      0.88       134
        1832       0.76      0.81      0.78        67
        1833       0.89      0.89      0.89        19
        1834       0.56      0.76      0.65        29
        1835       0.00      0.00      0.00         2
        1836       0.20      0.25      0.22         4
        1837       0.31      0.67      0.42         6
        1838       0.50      0.67      0.57         3
        1839       0.00      0.00      0.00         1
        1840       0.78      0.72      0.75        43
        1841       0.84      0.62      0.71       108
        1842       0.50      0.67      0.57         6
        1843       0.50      0.33      0.40         6
        1844       0.00      0.00      0.00         1
        1845       0.00      0.00      0.00         1
        1846       0.22      0.33      0.27         6
        1847       1.00      0.50      0.67         2
        1848       0.57      0.80      0.67         5
        1849       0.29      0.33      0.31         6
        1850       0.50      0.50      0.50        48
        1851       0.74      0.78      0.76        77
        1852       0.67      0.29      0.40         7
        1853       0.20      0.14      0.17         7
        1854       0.50      0.67      0.57         3
        1855       0.59      0.57      0.58        23
        1856       0.89      0.67      0.76        12
        1857       0.58      0.70      0.64        30
        1858       0.00      0.00      0.00         2
        1859       0.00      0.00      0.00         2
        1860       0.39      0.49      0.44        65
        1861       0.82      0.82      0.82        85
        1862       0.38      0.47      0.42        19
        1863       0.67      0.63      0.65        19
        1864       0.53      0.53      0.53        17
        1865       0.40      0.57      0.47         7
        1866       0.17      0.20      0.18         5
        1867       0.38      0.73      0.50        11
        1868       0.00      0.00      0.00         7
        1869       0.25      0.20      0.22         5
        1870       0.55      0.55      0.55        31
        1871       0.71      0.82      0.76        49
        1872       0.67      0.57      0.62         7
        1873       0.00      0.00      0.00        10
        1874       0.50      0.40      0.44         5
        1875       0.50      0.21      0.30        14
        1876       0.70      0.70      0.70        10
        1877       0.57      0.80      0.67         5
        1878       0.44      0.44      0.44         9
        1879       0.00      0.00      0.00         2

    accuracy                           0.68      1256
   macro avg       0.43      0.45      0.43      1256
weighted avg       0.68      0.68      0.68      1256

Matthews Correlation Coefficient: 0.670
Macro avg F1: 0.431
Weighted avg F1: 0.679
Micro avg F1: 0.685
Top-3 Accuracy: 0.878
Top-5 Accuracy: 0.923
Micro ROC AUC  = 0.99
Macro ROC AUC (present classes) = 0.98
Classification MAE (in years): 2.67

Fold 0 Misclassification Analysis:
Near misses (within 2 years): 115 out of 396 misclassifications (29.04%)
Big misses (greater than 10 years): 178
MAE with outliers: 2.67
MAE without outliers: 1.74 (improvement: 0.92)

10 Worst misclassifications:
Image: data/datasets/public/1820/1820_036met.jpg, True: 1820, Predicted: 1873, Error: 53
Image: data/datasets/private/1870/1871_85etsy.jpg, True: 1871, Predicted: 1821, Error: 50
Image: data/datasets/public/1820/1820_030met.jpg, True: 1820, Predicted: 1867, Error: 47
Image: data/datasets/public/1870/1876_455vna.jpg, True: 1876, Predicted: 1832, Error: 44
Image: data/datasets/public/1820/1820_050met.jpg, True: 1820, Predicted: 1863, Error: 43
Image: data/datasets/public/1820/1820_026met.jpg, True: 1820, Predicted: 1861, Error: 41
Image: data/datasets/public/1820/1820_046met.jpg, True: 1820, Predicted: 1860, Error: 40
Image: data/datasets/private/1860/1860_123et.jpg, True: 1860, Predicted: 1820, Error: 40
Image: data/datasets/public/1860/1860_010met.jpg, True: 1860, Predicted: 1820, Error: 40
Image: data/datasets/public/1870/1878_030met.jpg, True: 1878, Predicted: 1838, Error: 40
Metrics: {'accuracy': 0.6847133636474609, 'mae_years': np.float64(2.6679936305732483), 'mcc': np.float64(0.6695106084280439)}

=== Total running time: 11 hours, 55 minutes, 24 seconds ===

