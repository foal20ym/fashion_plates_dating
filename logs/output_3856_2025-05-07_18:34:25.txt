TensorFlow Version: 2.6.0
Num GPUs Available: 1
Using GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')
Using model: InceptionV3.
RUN ID: 2025-05-07_18:34:29
Test fold: 0
Fine Tuning!
Epoch 1/100
707/707 - 167s - loss: 7.3845 - accuracy: 0.3759 - val_loss: 7.8246 - val_accuracy: 0.3360
Epoch 2/100
707/707 - 152s - loss: 6.8081 - accuracy: 0.4610 - val_loss: 9.3887 - val_accuracy: 0.2850
Epoch 3/100
707/707 - 152s - loss: 6.8080 - accuracy: 0.5080 - val_loss: 8.2796 - val_accuracy: 0.3997
Epoch 4/100
707/707 - 148s - loss: 6.6795 - accuracy: 0.5274 - val_loss: 9.2122 - val_accuracy: 0.3623
Epoch 5/100
707/707 - 149s - loss: 6.6622 - accuracy: 0.5363 - val_loss: 8.3694 - val_accuracy: 0.4498

Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.
Epoch 6/100
707/707 - 149s - loss: 2.9794 - accuracy: 0.6788 - val_loss: 4.8567 - val_accuracy: 0.5080
Epoch 7/100
707/707 - 150s - loss: 2.4848 - accuracy: 0.6901 - val_loss: 4.7963 - val_accuracy: 0.5104
Epoch 8/100
707/707 - 148s - loss: 2.2755 - accuracy: 0.6995 - val_loss: 4.3917 - val_accuracy: 0.5207
Epoch 9/100
707/707 - 151s - loss: 2.1419 - accuracy: 0.7005 - val_loss: 4.2025 - val_accuracy: 0.5207
Epoch 10/100
707/707 - 151s - loss: 2.0583 - accuracy: 0.7035 - val_loss: 3.9862 - val_accuracy: 0.5358
Epoch 11/100
707/707 - 151s - loss: 2.0051 - accuracy: 0.7088 - val_loss: 4.0923 - val_accuracy: 0.5318
Epoch 12/100
707/707 - 148s - loss: 1.8731 - accuracy: 0.7139 - val_loss: 3.7763 - val_accuracy: 0.5263
Epoch 13/100
707/707 - 150s - loss: 1.8664 - accuracy: 0.7143 - val_loss: 3.7658 - val_accuracy: 0.5287
Epoch 14/100
707/707 - 149s - loss: 1.7654 - accuracy: 0.7188 - val_loss: 3.9450 - val_accuracy: 0.5358
Epoch 15/100
707/707 - 149s - loss: 1.6860 - accuracy: 0.7281 - val_loss: 3.7492 - val_accuracy: 0.5271
Epoch 16/100
707/707 - 147s - loss: 1.6609 - accuracy: 0.7228 - val_loss: 3.8356 - val_accuracy: 0.5326
Epoch 17/100
707/707 - 146s - loss: 1.6747 - accuracy: 0.7207 - val_loss: 3.6654 - val_accuracy: 0.5422
Epoch 18/100
707/707 - 147s - loss: 1.5641 - accuracy: 0.7356 - val_loss: 3.5588 - val_accuracy: 0.5533
Epoch 19/100
707/707 - 149s - loss: 1.5647 - accuracy: 0.7303 - val_loss: 3.3920 - val_accuracy: 0.5541
Epoch 20/100
707/707 - 149s - loss: 1.5275 - accuracy: 0.7341 - val_loss: 3.3230 - val_accuracy: 0.5669
Epoch 21/100
707/707 - 135s - loss: 1.4702 - accuracy: 0.7415 - val_loss: 3.3456 - val_accuracy: 0.5557
Epoch 22/100
707/707 - 134s - loss: 1.4592 - accuracy: 0.7394 - val_loss: 3.3880 - val_accuracy: 0.5398
Epoch 23/100
707/707 - 136s - loss: 1.4412 - accuracy: 0.7418 - val_loss: 3.3807 - val_accuracy: 0.5446
Epoch 24/100
707/707 - 137s - loss: 1.4333 - accuracy: 0.7402 - val_loss: 3.4888 - val_accuracy: 0.5358

Epoch 00024: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.
Epoch 25/100
707/707 - 138s - loss: 1.1912 - accuracy: 0.7711 - val_loss: 3.1130 - val_accuracy: 0.5605
Epoch 26/100
707/707 - 153s - loss: 1.1525 - accuracy: 0.7717 - val_loss: 3.0744 - val_accuracy: 0.5764
Epoch 27/100
707/707 - 153s - loss: 1.1187 - accuracy: 0.7815 - val_loss: 3.0625 - val_accuracy: 0.5645
Epoch 28/100
707/707 - 154s - loss: 1.1369 - accuracy: 0.7811 - val_loss: 3.0505 - val_accuracy: 0.5685
Epoch 29/100
707/707 - 154s - loss: 1.1170 - accuracy: 0.7736 - val_loss: 3.0834 - val_accuracy: 0.5693
Epoch 30/100
707/707 - 151s - loss: 1.1204 - accuracy: 0.7789 - val_loss: 3.0668 - val_accuracy: 0.5653
Epoch 31/100
707/707 - 148s - loss: 1.1273 - accuracy: 0.7709 - val_loss: 3.0377 - val_accuracy: 0.5709
Epoch 32/100
707/707 - 149s - loss: 1.1220 - accuracy: 0.7809 - val_loss: 3.0049 - val_accuracy: 0.5756
Epoch 33/100
707/707 - 141s - loss: 1.1015 - accuracy: 0.7797 - val_loss: 3.0162 - val_accuracy: 0.5701
Epoch 34/100
707/707 - 134s - loss: 1.1161 - accuracy: 0.7761 - val_loss: 3.0402 - val_accuracy: 0.5693
Epoch 35/100
707/707 - 131s - loss: 1.0919 - accuracy: 0.7824 - val_loss: 3.0139 - val_accuracy: 0.5717
Epoch 36/100
707/707 - 133s - loss: 1.1073 - accuracy: 0.7770 - val_loss: 2.9878 - val_accuracy: 0.5748
Epoch 37/100
707/707 - 132s - loss: 1.1103 - accuracy: 0.7817 - val_loss: 3.0277 - val_accuracy: 0.5748
Epoch 38/100
707/707 - 132s - loss: 1.0710 - accuracy: 0.7810 - val_loss: 3.0244 - val_accuracy: 0.5693
Epoch 39/100
707/707 - 133s - loss: 1.0905 - accuracy: 0.7830 - val_loss: 3.0120 - val_accuracy: 0.5645
Epoch 40/100
707/707 - 151s - loss: 1.0927 - accuracy: 0.7821 - val_loss: 2.9613 - val_accuracy: 0.5740
Epoch 41/100
707/707 - 149s - loss: 1.0756 - accuracy: 0.7818 - val_loss: 2.9750 - val_accuracy: 0.5796
Epoch 42/100
707/707 - 148s - loss: 1.0663 - accuracy: 0.7832 - val_loss: 2.9626 - val_accuracy: 0.5780
Epoch 43/100
707/707 - 150s - loss: 1.0806 - accuracy: 0.7802 - val_loss: 2.9270 - val_accuracy: 0.5740
Epoch 44/100
707/707 - 148s - loss: 1.0663 - accuracy: 0.7840 - val_loss: 2.9540 - val_accuracy: 0.5812
Epoch 45/100
707/707 - 149s - loss: 1.0574 - accuracy: 0.7866 - val_loss: 2.9122 - val_accuracy: 0.5717
Epoch 46/100
707/707 - 149s - loss: 1.0574 - accuracy: 0.7815 - val_loss: 2.9700 - val_accuracy: 0.5796
Epoch 47/100
707/707 - 147s - loss: 1.0698 - accuracy: 0.7838 - val_loss: 2.9620 - val_accuracy: 0.5756
Epoch 48/100
707/707 - 151s - loss: 1.0654 - accuracy: 0.7824 - val_loss: 2.9432 - val_accuracy: 0.5732
Epoch 49/100
707/707 - 149s - loss: 1.0766 - accuracy: 0.7844 - val_loss: 2.9603 - val_accuracy: 0.5661

Epoch 00049: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.
Epoch 50/100
707/707 - 149s - loss: 1.0202 - accuracy: 0.7880 - val_loss: 2.9479 - val_accuracy: 0.5748
Epoch 51/100
707/707 - 147s - loss: 1.0229 - accuracy: 0.7928 - val_loss: 2.9338 - val_accuracy: 0.5788
Epoch 52/100
707/707 - 148s - loss: 1.0228 - accuracy: 0.7897 - val_loss: 2.9236 - val_accuracy: 0.5764
Epoch 53/100
707/707 - 149s - loss: 1.0544 - accuracy: 0.7809 - val_loss: 2.9253 - val_accuracy: 0.5772

Epoch 00053: ReduceLROnPlateau reducing learning rate to 1e-06.
Epoch 54/100
707/707 - 147s - loss: 1.0189 - accuracy: 0.7928 - val_loss: 2.9256 - val_accuracy: 0.5772
Epoch 55/100
707/707 - 146s - loss: 1.0372 - accuracy: 0.7847 - val_loss: 2.9251 - val_accuracy: 0.5764
Restoring model weights from the end of the best epoch.
Epoch 00055: early stopping
Fold 0 Evaluation results: [2.9122183322906494, 0.5716560482978821]
              precision    recall  f1-score   support

        1820       0.68      0.69      0.69        62
        1821       0.90      0.91      0.90        57
        1822       0.00      0.00      0.00         1
        1823       0.50      1.00      0.67         1
        1824       0.00      0.00      0.00         1
        1825       0.67      0.67      0.67         3
        1826       0.00      0.00      0.00         2
        1827       0.65      0.68      0.67        25
        1828       0.00      0.00      0.00         1
        1829       1.00      0.20      0.33         5
        1830       0.47      0.68      0.56        56
        1831       0.91      0.77      0.83       134
        1832       0.68      0.73      0.71        67
        1833       1.00      0.74      0.85        19
        1834       0.44      0.69      0.54        29
        1835       0.00      0.00      0.00         2
        1836       1.00      0.25      0.40         4
        1837       0.83      0.83      0.83         6
        1838       0.50      0.33      0.40         3
        1839       1.00      1.00      1.00         1
        1840       0.54      0.47      0.50        43
        1841       0.65      0.62      0.64       108
        1842       0.57      0.67      0.62         6
        1843       0.40      0.33      0.36         6
        1844       0.00      0.00      0.00         1
        1845       0.00      0.00      0.00         1
        1846       0.00      0.00      0.00         6
        1847       0.00      0.00      0.00         2
        1848       0.17      0.20      0.18         5
        1849       0.33      0.17      0.22         6
        1850       0.40      0.44      0.42        48
        1851       0.64      0.73      0.68        77
        1852       0.33      0.29      0.31         7
        1853       0.00      0.00      0.00         7
        1854       0.00      0.00      0.00         3
        1855       0.34      0.48      0.40        23
        1856       0.89      0.67      0.76        12
        1857       0.37      0.43      0.40        30
        1858       0.00      0.00      0.00         2
        1859       0.00      0.00      0.00         2
        1860       0.20      0.17      0.18        65
        1861       0.66      0.76      0.71        85
        1862       0.06      0.05      0.06        19
        1863       0.39      0.37      0.38        19
        1864       0.21      0.24      0.22        17
        1865       0.40      0.29      0.33         7
        1866       0.14      0.20      0.17         5
        1867       0.29      0.18      0.22        11
        1868       0.20      0.14      0.17         7
        1869       0.14      0.20      0.17         5
        1870       0.38      0.48      0.43        31
        1871       0.77      0.67      0.72        49
        1872       0.33      0.14      0.20         7
        1873       0.20      0.10      0.13        10
        1874       0.50      0.40      0.44         5
        1875       0.25      0.29      0.27        14
        1876       1.00      0.80      0.89        10
        1877       0.33      0.20      0.25         5
        1878       0.29      0.44      0.35         9
        1879       0.00      0.00      0.00         2

    accuracy                           0.57      1256
   macro avg       0.39      0.36      0.36      1256
weighted avg       0.57      0.57      0.57      1256

Macro avg F1: 0.364
Weighted avg F1: 0.566
Micro avg F1: 0.572
Top-3 Accuracy: 0.787
Top-5 Accuracy: 0.865
Micro ROC AUC  = 0.97
Macro ROC AUC (present classes) = 0.95
Classification MAE (in years): 4.20
Metrics: {'accuracy': 0.5716560482978821, 'mae_years': 4.199044585987261}
Total running time: 2 hours, 18 minutes, 51 seconds
