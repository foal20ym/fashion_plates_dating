TensorFlow Version: 2.20.0-dev20250425
Num GPUs Available: 1
Physical devices cannot be modified after being initialized

=== Using model: InceptionV3. ===
RUN ID: 2025-05-22_17:26:07
Task: Classification

===== Running 5x2 Cross-Validation for Model Comparison =====
Base model using dataset from: data/datasets/
Alternative model using dataset from: data/datasets_cleaned/
Using models specified in config: InceptionV3 vs InceptionV3
Comparing: Base model (InceptionV3) vs. Alternative model (InceptionV3)

===== Iteration 1/5 =====
=== Training Base Model ===

===== Fine Tuning 9 layers! =====
Epoch 1/300
785/785 - 148s - 189ms/step - accuracy: 0.1258 - loss: 4.4673 - val_accuracy: 0.2083 - val_loss: 4.1281 - learning_rate: 2.5974e-04
Epoch 2/300
785/785 - 87s - 111ms/step - accuracy: 0.1793 - loss: 4.1498 - val_accuracy: 0.2314 - val_loss: 3.6247 - learning_rate: 2.5974e-04
Epoch 3/300
785/785 - 88s - 112ms/step - accuracy: 0.2061 - loss: 3.9017 - val_accuracy: 0.3209 - val_loss: 3.3713 - learning_rate: 2.5974e-04
Epoch 4/300
785/785 - 87s - 110ms/step - accuracy: 0.2322 - loss: 3.7840 - val_accuracy: 0.2798 - val_loss: 3.2311 - learning_rate: 2.5974e-04
Epoch 5/300
785/785 - 86s - 109ms/step - accuracy: 0.2502 - loss: 3.6819 - val_accuracy: 0.3360 - val_loss: 3.2895 - learning_rate: 2.5974e-04
Epoch 6/300
785/785 - 92s - 118ms/step - accuracy: 0.2604 - loss: 3.6271 - val_accuracy: 0.3623 - val_loss: 3.0816 - learning_rate: 2.5974e-04
Epoch 7/300
785/785 - 87s - 111ms/step - accuracy: 0.2664 - loss: 3.5941 - val_accuracy: 0.3755 - val_loss: 2.9769 - learning_rate: 2.5974e-04
Epoch 8/300
785/785 - 88s - 112ms/step - accuracy: 0.2725 - loss: 3.5175 - val_accuracy: 0.4083 - val_loss: 2.8309 - learning_rate: 2.5974e-04
Epoch 9/300
785/785 - 86s - 110ms/step - accuracy: 0.2856 - loss: 3.4661 - val_accuracy: 0.4315 - val_loss: 2.7845 - learning_rate: 2.5974e-04
Epoch 10/300
785/785 - 86s - 109ms/step - accuracy: 0.2817 - loss: 3.4221 - val_accuracy: 0.4322 - val_loss: 2.7508 - learning_rate: 2.5974e-04
Epoch 11/300
785/785 - 87s - 111ms/step - accuracy: 0.2994 - loss: 3.3576 - val_accuracy: 0.4217 - val_loss: 2.6540 - learning_rate: 2.5974e-04
Epoch 12/300
785/785 - 87s - 111ms/step - accuracy: 0.3085 - loss: 3.3606 - val_accuracy: 0.4201 - val_loss: 2.6845 - learning_rate: 2.5974e-04
Epoch 13/300
785/785 - 87s - 111ms/step - accuracy: 0.3160 - loss: 3.3236 - val_accuracy: 0.4662 - val_loss: 2.6543 - learning_rate: 2.5974e-04
Epoch 14/300
785/785 - 93s - 119ms/step - accuracy: 0.3254 - loss: 3.2781 - val_accuracy: 0.4575 - val_loss: 2.5370 - learning_rate: 2.5974e-04
Epoch 15/300
785/785 - 92s - 117ms/step - accuracy: 0.3214 - loss: 3.2651 - val_accuracy: 0.4760 - val_loss: 2.5229 - learning_rate: 2.5974e-04
Epoch 16/300
785/785 - 97s - 124ms/step - accuracy: 0.3316 - loss: 3.2262 - val_accuracy: 0.4500 - val_loss: 2.6010 - learning_rate: 2.5974e-04
Epoch 17/300
785/785 - 92s - 117ms/step - accuracy: 0.3279 - loss: 3.2121 - val_accuracy: 0.4691 - val_loss: 2.4640 - learning_rate: 2.5974e-04
Epoch 18/300
785/785 - 92s - 117ms/step - accuracy: 0.3338 - loss: 3.2155 - val_accuracy: 0.4866 - val_loss: 2.4903 - learning_rate: 2.5974e-04
Epoch 19/300
785/785 - 92s - 117ms/step - accuracy: 0.3376 - loss: 3.1854 - val_accuracy: 0.4887 - val_loss: 2.4253 - learning_rate: 2.5974e-04
Epoch 20/300
785/785 - 94s - 120ms/step - accuracy: 0.3421 - loss: 3.1729 - val_accuracy: 0.4826 - val_loss: 2.4122 - learning_rate: 2.5974e-04
Epoch 21/300
785/785 - 92s - 118ms/step - accuracy: 0.3486 - loss: 3.1352 - val_accuracy: 0.4978 - val_loss: 2.3848 - learning_rate: 2.5974e-04
Epoch 22/300
785/785 - 91s - 116ms/step - accuracy: 0.3521 - loss: 3.1541 - val_accuracy: 0.4951 - val_loss: 2.4433 - learning_rate: 2.5974e-04
Epoch 23/300
785/785 - 93s - 118ms/step - accuracy: 0.3502 - loss: 3.1650 - val_accuracy: 0.4882 - val_loss: 2.3468 - learning_rate: 2.5974e-04
Epoch 24/300
785/785 - 90s - 115ms/step - accuracy: 0.3590 - loss: 3.1100 - val_accuracy: 0.4939 - val_loss: 2.3643 - learning_rate: 2.5974e-04
Epoch 25/300
785/785 - 93s - 118ms/step - accuracy: 0.3430 - loss: 3.0792 - val_accuracy: 0.5040 - val_loss: 2.3422 - learning_rate: 2.5974e-04
Epoch 26/300
785/785 - 94s - 120ms/step - accuracy: 0.3521 - loss: 3.1020 - val_accuracy: 0.5005 - val_loss: 2.3102 - learning_rate: 2.5974e-04
Epoch 27/300
785/785 - 92s - 118ms/step - accuracy: 0.3577 - loss: 3.0716 - val_accuracy: 0.5107 - val_loss: 2.2909 - learning_rate: 2.5974e-04
Epoch 28/300
785/785 - 93s - 118ms/step - accuracy: 0.3510 - loss: 3.1111 - val_accuracy: 0.5010 - val_loss: 2.3274 - learning_rate: 2.5974e-04
Epoch 29/300
785/785 - 92s - 118ms/step - accuracy: 0.3596 - loss: 3.0504 - val_accuracy: 0.5183 - val_loss: 2.2737 - learning_rate: 2.5974e-04
Epoch 30/300
785/785 - 90s - 115ms/step - accuracy: 0.3622 - loss: 3.0450 - val_accuracy: 0.4997 - val_loss: 2.3153 - learning_rate: 2.5974e-04
Epoch 31/300
785/785 - 92s - 117ms/step - accuracy: 0.3566 - loss: 3.0676 - val_accuracy: 0.5076 - val_loss: 2.2351 - learning_rate: 2.5974e-04
Epoch 32/300
785/785 - 92s - 118ms/step - accuracy: 0.3700 - loss: 3.0222 - val_accuracy: 0.5217 - val_loss: 2.2712 - learning_rate: 2.5974e-04
Epoch 33/300
785/785 - 93s - 119ms/step - accuracy: 0.3695 - loss: 2.9708 - val_accuracy: 0.5232 - val_loss: 2.2443 - learning_rate: 2.5974e-04
Epoch 34/300
785/785 - 90s - 115ms/step - accuracy: 0.3638 - loss: 3.0357 - val_accuracy: 0.5154 - val_loss: 2.2060 - learning_rate: 2.5974e-04
Epoch 35/300
785/785 - 93s - 118ms/step - accuracy: 0.3731 - loss: 2.9996 - val_accuracy: 0.5102 - val_loss: 2.1928 - learning_rate: 2.5974e-04
Epoch 36/300
785/785 - 91s - 116ms/step - accuracy: 0.3690 - loss: 2.9890 - val_accuracy: 0.5201 - val_loss: 2.1955 - learning_rate: 2.5974e-04
Epoch 37/300
785/785 - 89s - 114ms/step - accuracy: 0.3754 - loss: 2.9986 - val_accuracy: 0.5256 - val_loss: 2.1710 - learning_rate: 2.5974e-04
Epoch 38/300
785/785 - 93s - 119ms/step - accuracy: 0.3700 - loss: 2.9541 - val_accuracy: 0.5038 - val_loss: 2.2100 - learning_rate: 2.5974e-04
Epoch 39/300
785/785 - 92s - 117ms/step - accuracy: 0.3814 - loss: 2.9765 - val_accuracy: 0.5242 - val_loss: 2.1753 - learning_rate: 2.5974e-04
Epoch 40/300
785/785 - 92s - 117ms/step - accuracy: 0.3822 - loss: 2.9843 - val_accuracy: 0.5209 - val_loss: 2.1582 - learning_rate: 2.5974e-04
Epoch 41/300
785/785 - 92s - 117ms/step - accuracy: 0.3795 - loss: 2.9864 - val_accuracy: 0.5331 - val_loss: 2.1379 - learning_rate: 2.5974e-04
Epoch 42/300
785/785 - 91s - 116ms/step - accuracy: 0.3754 - loss: 2.9705 - val_accuracy: 0.5387 - val_loss: 2.1456 - learning_rate: 2.5974e-04
Epoch 43/300
785/785 - 89s - 113ms/step - accuracy: 0.3730 - loss: 2.9790 - val_accuracy: 0.5424 - val_loss: 2.1569 - learning_rate: 2.5974e-04
Epoch 44/300
785/785 - 84s - 107ms/step - accuracy: 0.3781 - loss: 2.9719 - val_accuracy: 0.5350 - val_loss: 2.1047 - learning_rate: 2.5974e-04
Epoch 45/300
785/785 - 86s - 110ms/step - accuracy: 0.3735 - loss: 2.9603 - val_accuracy: 0.5306 - val_loss: 2.1790 - learning_rate: 2.5974e-04
Epoch 46/300
785/785 - 86s - 109ms/step - accuracy: 0.3779 - loss: 2.9764 - val_accuracy: 0.5196 - val_loss: 2.1979 - learning_rate: 2.5974e-04
Epoch 47/300
785/785 - 86s - 109ms/step - accuracy: 0.3853 - loss: 2.9541 - val_accuracy: 0.5256 - val_loss: 2.1529 - learning_rate: 2.5974e-04
Epoch 48/300
785/785 - 86s - 110ms/step - accuracy: 0.3945 - loss: 2.9273 - val_accuracy: 0.5400 - val_loss: 2.1172 - learning_rate: 2.5974e-04
Epoch 49/300
785/785 - 84s - 108ms/step - accuracy: 0.3779 - loss: 2.9739 - val_accuracy: 0.5197 - val_loss: 2.1574 - learning_rate: 2.5974e-04
Epoch 50/300
785/785 - 86s - 110ms/step - accuracy: 0.3843 - loss: 2.9378 - val_accuracy: 0.5274 - val_loss: 2.0974 - learning_rate: 2.5974e-04
Epoch 51/300
785/785 - 84s - 107ms/step - accuracy: 0.3824 - loss: 2.9289 - val_accuracy: 0.5422 - val_loss: 2.1135 - learning_rate: 2.5974e-04
Epoch 52/300
785/785 - 85s - 109ms/step - accuracy: 0.3878 - loss: 2.9454 - val_accuracy: 0.5414 - val_loss: 2.1321 - learning_rate: 2.5974e-04
Epoch 53/300
785/785 - 86s - 110ms/step - accuracy: 0.3822 - loss: 2.9487 - val_accuracy: 0.5285 - val_loss: 2.1225 - learning_rate: 2.5974e-04
Epoch 54/300
785/785 - 92s - 118ms/step - accuracy: 0.3853 - loss: 2.9238 - val_accuracy: 0.5374 - val_loss: 2.0982 - learning_rate: 2.5974e-04
Epoch 55/300
785/785 - 85s - 108ms/step - accuracy: 0.3935 - loss: 2.8984 - val_accuracy: 0.5342 - val_loss: 2.1676 - learning_rate: 2.5974e-04
Epoch 56/300
785/785 - 89s - 113ms/step - accuracy: 0.3876 - loss: 2.9329 - val_accuracy: 0.5365 - val_loss: 2.0942 - learning_rate: 2.5974e-04
Epoch 57/300
785/785 - 85s - 109ms/step - accuracy: 0.3880 - loss: 2.9203 - val_accuracy: 0.5416 - val_loss: 2.1035 - learning_rate: 2.5974e-04
Epoch 58/300
785/785 - 87s - 111ms/step - accuracy: 0.3876 - loss: 2.9109 - val_accuracy: 0.5452 - val_loss: 2.0992 - learning_rate: 2.5974e-04
Epoch 59/300
785/785 - 86s - 110ms/step - accuracy: 0.3881 - loss: 2.9270 - val_accuracy: 0.5178 - val_loss: 2.1718 - learning_rate: 2.5974e-04
Epoch 60/300
785/785 - 85s - 109ms/step - accuracy: 0.3907 - loss: 2.8958 - val_accuracy: 0.5494 - val_loss: 2.0795 - learning_rate: 2.5974e-04
Epoch 61/300
785/785 - 85s - 108ms/step - accuracy: 0.3894 - loss: 2.8943 - val_accuracy: 0.5454 - val_loss: 2.0742 - learning_rate: 2.5974e-04
Epoch 62/300
785/785 - 93s - 118ms/step - accuracy: 0.3923 - loss: 2.9042 - val_accuracy: 0.5403 - val_loss: 2.0806 - learning_rate: 2.5974e-04
Epoch 63/300
785/785 - 85s - 108ms/step - accuracy: 0.3982 - loss: 2.8676 - val_accuracy: 0.5382 - val_loss: 2.0728 - learning_rate: 2.5974e-04
Epoch 64/300
785/785 - 85s - 108ms/step - accuracy: 0.3878 - loss: 2.8983 - val_accuracy: 0.5475 - val_loss: 2.0543 - learning_rate: 2.5974e-04
Epoch 65/300
785/785 - 86s - 109ms/step - accuracy: 0.3837 - loss: 2.8992 - val_accuracy: 0.5441 - val_loss: 2.0686 - learning_rate: 2.5974e-04
Epoch 66/300
785/785 - 83s - 106ms/step - accuracy: 0.3915 - loss: 2.8846 - val_accuracy: 0.5481 - val_loss: 2.0673 - learning_rate: 2.5974e-04
Epoch 67/300
785/785 - 86s - 110ms/step - accuracy: 0.3946 - loss: 2.8879 - val_accuracy: 0.5513 - val_loss: 2.0380 - learning_rate: 2.5974e-04
Epoch 68/300
785/785 - 84s - 107ms/step - accuracy: 0.3833 - loss: 2.8903 - val_accuracy: 0.5374 - val_loss: 2.1007 - learning_rate: 2.5974e-04
Epoch 69/300
785/785 - 85s - 108ms/step - accuracy: 0.3892 - loss: 2.8905 - val_accuracy: 0.5271 - val_loss: 2.1012 - learning_rate: 2.5974e-04
Epoch 70/300
785/785 - 84s - 107ms/step - accuracy: 0.3942 - loss: 2.8806 - val_accuracy: 0.5475 - val_loss: 2.0312 - learning_rate: 2.5974e-04
Epoch 71/300
785/785 - 85s - 108ms/step - accuracy: 0.3986 - loss: 2.8789 - val_accuracy: 0.5532 - val_loss: 2.0831 - learning_rate: 2.5974e-04
Epoch 72/300
785/785 - 86s - 110ms/step - accuracy: 0.3907 - loss: 2.8955 - val_accuracy: 0.5438 - val_loss: 2.0797 - learning_rate: 2.5974e-04
Epoch 73/300
785/785 - 86s - 110ms/step - accuracy: 0.4018 - loss: 2.8415 - val_accuracy: 0.5369 - val_loss: 2.0577 - learning_rate: 2.5974e-04
Epoch 74/300
785/785 - 84s - 107ms/step - accuracy: 0.3918 - loss: 2.8616 - val_accuracy: 0.5455 - val_loss: 2.0550 - learning_rate: 2.5974e-04
Epoch 75/300
785/785 - 84s - 107ms/step - accuracy: 0.3875 - loss: 2.8559 - val_accuracy: 0.5435 - val_loss: 2.1120 - learning_rate: 2.5974e-04
Epoch 76/300
785/785 - 85s - 108ms/step - accuracy: 0.3837 - loss: 2.8583 - val_accuracy: 0.5452 - val_loss: 2.0709 - learning_rate: 2.5974e-04
Epoch 77/300
785/785 - 84s - 107ms/step - accuracy: 0.3972 - loss: 2.8653 - val_accuracy: 0.5492 - val_loss: 2.0194 - learning_rate: 2.5974e-04
Epoch 78/300
785/785 - 86s - 109ms/step - accuracy: 0.4025 - loss: 2.8536 - val_accuracy: 0.5471 - val_loss: 2.0720 - learning_rate: 2.5974e-04
Epoch 79/300
785/785 - 84s - 107ms/step - accuracy: 0.4044 - loss: 2.8445 - val_accuracy: 0.5592 - val_loss: 2.0172 - learning_rate: 2.5974e-04
Epoch 80/300
785/785 - 84s - 107ms/step - accuracy: 0.4009 - loss: 2.8441 - val_accuracy: 0.5393 - val_loss: 2.0904 - learning_rate: 2.5974e-04
Epoch 81/300
785/785 - 86s - 110ms/step - accuracy: 0.3986 - loss: 2.8638 - val_accuracy: 0.5533 - val_loss: 2.0304 - learning_rate: 2.5974e-04
Epoch 82/300
785/785 - 83s - 106ms/step - accuracy: 0.3975 - loss: 2.8131 - val_accuracy: 0.5543 - val_loss: 2.0599 - learning_rate: 2.5974e-04
Epoch 83/300
785/785 - 82s - 104ms/step - accuracy: 0.3969 - loss: 2.8401 - val_accuracy: 0.5449 - val_loss: 2.0582 - learning_rate: 2.5974e-04
Epoch 84/300
785/785 - 84s - 107ms/step - accuracy: 0.3982 - loss: 2.8492 - val_accuracy: 0.5580 - val_loss: 2.0115 - learning_rate: 2.5974e-04
Epoch 85/300
785/785 - 85s - 108ms/step - accuracy: 0.3954 - loss: 2.8418 - val_accuracy: 0.5578 - val_loss: 2.0882 - learning_rate: 2.5974e-04
Epoch 86/300
785/785 - 83s - 106ms/step - accuracy: 0.4009 - loss: 2.8492 - val_accuracy: 0.5476 - val_loss: 2.0340 - learning_rate: 2.5974e-04
Epoch 87/300
785/785 - 84s - 107ms/step - accuracy: 0.4056 - loss: 2.8149 - val_accuracy: 0.5602 - val_loss: 2.0217 - learning_rate: 2.5974e-04
Epoch 88/300
785/785 - 83s - 106ms/step - accuracy: 0.4072 - loss: 2.8290 - val_accuracy: 0.5565 - val_loss: 2.0119 - learning_rate: 2.5974e-04
Epoch 89/300
785/785 - 85s - 109ms/step - accuracy: 0.4055 - loss: 2.8143 - val_accuracy: 0.5653 - val_loss: 1.9976 - learning_rate: 2.5974e-04
Epoch 90/300
785/785 - 83s - 106ms/step - accuracy: 0.4101 - loss: 2.8134 - val_accuracy: 0.5495 - val_loss: 2.0237 - learning_rate: 2.5974e-04
Epoch 91/300
785/785 - 92s - 117ms/step - accuracy: 0.3991 - loss: 2.8262 - val_accuracy: 0.5613 - val_loss: 1.9942 - learning_rate: 2.5974e-04
Epoch 92/300
785/785 - 85s - 108ms/step - accuracy: 0.4087 - loss: 2.7817 - val_accuracy: 0.5540 - val_loss: 2.0364 - learning_rate: 2.5974e-04
Epoch 93/300
785/785 - 85s - 109ms/step - accuracy: 0.4029 - loss: 2.7971 - val_accuracy: 0.5562 - val_loss: 2.0062 - learning_rate: 2.5974e-04
Epoch 94/300
785/785 - 89s - 113ms/step - accuracy: 0.4028 - loss: 2.8417 - val_accuracy: 0.5637 - val_loss: 2.0334 - learning_rate: 2.5974e-04
Epoch 95/300
785/785 - 89s - 114ms/step - accuracy: 0.4087 - loss: 2.8036 - val_accuracy: 0.5635 - val_loss: 2.0308 - learning_rate: 2.5974e-04
Epoch 96/300
785/785 - 91s - 116ms/step - accuracy: 0.4063 - loss: 2.7750 - val_accuracy: 0.5513 - val_loss: 2.0104 - learning_rate: 2.5974e-04
Epoch 97/300
785/785 - 91s - 115ms/step - accuracy: 0.4048 - loss: 2.8211 - val_accuracy: 0.5519 - val_loss: 2.0189 - learning_rate: 2.5974e-04
Epoch 98/300
785/785 - 91s - 116ms/step - accuracy: 0.4099 - loss: 2.7782 - val_accuracy: 0.5696 - val_loss: 2.0022 - learning_rate: 2.5974e-04
Epoch 99/300

Epoch 99: ReduceLROnPlateau reducing learning rate to 0.0001298690476687625.
785/785 - 92s - 117ms/step - accuracy: 0.3989 - loss: 2.8670 - val_accuracy: 0.5621 - val_loss: 1.9990 - learning_rate: 2.5974e-04
Epoch 100/300
785/785 - 92s - 117ms/step - accuracy: 0.4176 - loss: 2.7587 - val_accuracy: 0.5766 - val_loss: 1.9677 - learning_rate: 1.2987e-04
Epoch 101/300
785/785 - 93s - 118ms/step - accuracy: 0.4131 - loss: 2.7500 - val_accuracy: 0.5678 - val_loss: 1.9800 - learning_rate: 1.2987e-04
Epoch 102/300
785/785 - 91s - 116ms/step - accuracy: 0.4319 - loss: 2.7092 - val_accuracy: 0.5696 - val_loss: 1.9980 - learning_rate: 1.2987e-04
Epoch 103/300
785/785 - 90s - 115ms/step - accuracy: 0.4224 - loss: 2.6970 - val_accuracy: 0.5717 - val_loss: 1.9565 - learning_rate: 1.2987e-04
Epoch 104/300
785/785 - 91s - 116ms/step - accuracy: 0.4217 - loss: 2.7621 - val_accuracy: 0.5685 - val_loss: 1.9688 - learning_rate: 1.2987e-04
Epoch 105/300
785/785 - 91s - 116ms/step - accuracy: 0.4088 - loss: 2.7488 - val_accuracy: 0.5640 - val_loss: 1.9667 - learning_rate: 1.2987e-04
Epoch 106/300
785/785 - 91s - 116ms/step - accuracy: 0.4197 - loss: 2.7113 - val_accuracy: 0.5664 - val_loss: 1.9637 - learning_rate: 1.2987e-04
Epoch 107/300
785/785 - 92s - 117ms/step - accuracy: 0.4232 - loss: 2.6961 - val_accuracy: 0.5653 - val_loss: 1.9795 - learning_rate: 1.2987e-04
Epoch 108/300
785/785 - 89s - 114ms/step - accuracy: 0.4275 - loss: 2.7025 - val_accuracy: 0.5662 - val_loss: 1.9600 - learning_rate: 1.2987e-04
Epoch 109/300
785/785 - 88s - 113ms/step - accuracy: 0.4311 - loss: 2.7149 - val_accuracy: 0.5567 - val_loss: 1.9681 - learning_rate: 1.2987e-04
Epoch 110/300
785/785 - 85s - 108ms/step - accuracy: 0.4219 - loss: 2.7085 - val_accuracy: 0.5484 - val_loss: 2.0072 - learning_rate: 1.2987e-04
Epoch 111/300

Epoch 111: ReduceLROnPlateau reducing learning rate to 6.493452383438125e-05.
785/785 - 84s - 107ms/step - accuracy: 0.4212 - loss: 2.7022 - val_accuracy: 0.5799 - val_loss: 1.9635 - learning_rate: 1.2987e-04
Epoch 112/300
785/785 - 85s - 108ms/step - accuracy: 0.4364 - loss: 2.6579 - val_accuracy: 0.5804 - val_loss: 1.9381 - learning_rate: 6.4935e-05
Epoch 113/300
785/785 - 83s - 106ms/step - accuracy: 0.4249 - loss: 2.7142 - val_accuracy: 0.5760 - val_loss: 1.9282 - learning_rate: 6.4935e-05
Epoch 114/300
785/785 - 87s - 110ms/step - accuracy: 0.4246 - loss: 2.6915 - val_accuracy: 0.5796 - val_loss: 1.9287 - learning_rate: 6.4935e-05
Epoch 115/300
785/785 - 85s - 108ms/step - accuracy: 0.4311 - loss: 2.6785 - val_accuracy: 0.5664 - val_loss: 1.9295 - learning_rate: 6.4935e-05
Epoch 116/300
785/785 - 85s - 108ms/step - accuracy: 0.4364 - loss: 2.6613 - val_accuracy: 0.5795 - val_loss: 1.9219 - learning_rate: 6.4935e-05
Epoch 117/300
785/785 - 86s - 109ms/step - accuracy: 0.4314 - loss: 2.6693 - val_accuracy: 0.5815 - val_loss: 1.9249 - learning_rate: 6.4935e-05
Epoch 118/300
785/785 - 84s - 107ms/step - accuracy: 0.4324 - loss: 2.6567 - val_accuracy: 0.5812 - val_loss: 1.9222 - learning_rate: 6.4935e-05
Epoch 119/300
785/785 - 85s - 109ms/step - accuracy: 0.4364 - loss: 2.6829 - val_accuracy: 0.5761 - val_loss: 1.9189 - learning_rate: 6.4935e-05
Epoch 120/300
785/785 - 85s - 108ms/step - accuracy: 0.4276 - loss: 2.6728 - val_accuracy: 0.5709 - val_loss: 1.9335 - learning_rate: 6.4935e-05
Epoch 121/300
785/785 - 84s - 108ms/step - accuracy: 0.4265 - loss: 2.6698 - val_accuracy: 0.5734 - val_loss: 1.9293 - learning_rate: 6.4935e-05
Epoch 122/300
785/785 - 83s - 106ms/step - accuracy: 0.4370 - loss: 2.6693 - val_accuracy: 0.5847 - val_loss: 1.9146 - learning_rate: 6.4935e-05
Epoch 123/300
785/785 - 84s - 107ms/step - accuracy: 0.4329 - loss: 2.6562 - val_accuracy: 0.5772 - val_loss: 1.9297 - learning_rate: 6.4935e-05
Epoch 124/300
785/785 - 84s - 108ms/step - accuracy: 0.4338 - loss: 2.6770 - val_accuracy: 0.5780 - val_loss: 1.9114 - learning_rate: 6.4935e-05
Epoch 125/300
785/785 - 85s - 109ms/step - accuracy: 0.4396 - loss: 2.6718 - val_accuracy: 0.5748 - val_loss: 1.9219 - learning_rate: 6.4935e-05
Epoch 126/300
785/785 - 85s - 108ms/step - accuracy: 0.4338 - loss: 2.6745 - val_accuracy: 0.5728 - val_loss: 1.9028 - learning_rate: 6.4935e-05
Epoch 127/300
785/785 - 87s - 111ms/step - accuracy: 0.4440 - loss: 2.6226 - val_accuracy: 0.5804 - val_loss: 1.9033 - learning_rate: 6.4935e-05
Epoch 128/300
785/785 - 84s - 107ms/step - accuracy: 0.4408 - loss: 2.6420 - val_accuracy: 0.5825 - val_loss: 1.9032 - learning_rate: 6.4935e-05
Epoch 129/300
785/785 - 86s - 109ms/step - accuracy: 0.4370 - loss: 2.6461 - val_accuracy: 0.5785 - val_loss: 1.9166 - learning_rate: 6.4935e-05
Epoch 130/300
785/785 - 86s - 109ms/step - accuracy: 0.4287 - loss: 2.6884 - val_accuracy: 0.5768 - val_loss: 1.9049 - learning_rate: 6.4935e-05
Epoch 131/300
785/785 - 85s - 109ms/step - accuracy: 0.4346 - loss: 2.6586 - val_accuracy: 0.5771 - val_loss: 1.9136 - learning_rate: 6.4935e-05
Epoch 132/300
785/785 - 85s - 109ms/step - accuracy: 0.4404 - loss: 2.6252 - val_accuracy: 0.5828 - val_loss: 1.9100 - learning_rate: 6.4935e-05
Epoch 133/300
785/785 - 84s - 107ms/step - accuracy: 0.4365 - loss: 2.6535 - val_accuracy: 0.5868 - val_loss: 1.9025 - learning_rate: 6.4935e-05
Epoch 134/300
785/785 - 85s - 109ms/step - accuracy: 0.4351 - loss: 2.6522 - val_accuracy: 0.5844 - val_loss: 1.8918 - learning_rate: 6.4935e-05
Epoch 135/300
785/785 - 84s - 106ms/step - accuracy: 0.4362 - loss: 2.6473 - val_accuracy: 0.5836 - val_loss: 1.8968 - learning_rate: 6.4935e-05
Epoch 136/300
785/785 - 84s - 108ms/step - accuracy: 0.4343 - loss: 2.6555 - val_accuracy: 0.5799 - val_loss: 1.9106 - learning_rate: 6.4935e-05
Epoch 137/300
785/785 - 86s - 109ms/step - accuracy: 0.4442 - loss: 2.6499 - val_accuracy: 0.5871 - val_loss: 1.8933 - learning_rate: 6.4935e-05
Epoch 138/300
785/785 - 86s - 109ms/step - accuracy: 0.4470 - loss: 2.6191 - val_accuracy: 0.5847 - val_loss: 1.9091 - learning_rate: 6.4935e-05
Epoch 139/300
785/785 - 85s - 109ms/step - accuracy: 0.4287 - loss: 2.6826 - val_accuracy: 0.5817 - val_loss: 1.8967 - learning_rate: 6.4935e-05
Epoch 140/300
785/785 - 85s - 108ms/step - accuracy: 0.4340 - loss: 2.6338 - val_accuracy: 0.5793 - val_loss: 1.8949 - learning_rate: 6.4935e-05
Epoch 141/300
785/785 - 85s - 109ms/step - accuracy: 0.4265 - loss: 2.6814 - val_accuracy: 0.5844 - val_loss: 1.9112 - learning_rate: 6.4935e-05
Epoch 142/300

Epoch 142: ReduceLROnPlateau reducing learning rate to 3.2467261917190626e-05.
785/785 - 84s - 108ms/step - accuracy: 0.4402 - loss: 2.6464 - val_accuracy: 0.5779 - val_loss: 1.9042 - learning_rate: 6.4935e-05
Epoch 143/300
785/785 - 90s - 115ms/step - accuracy: 0.4402 - loss: 2.6162 - val_accuracy: 0.5772 - val_loss: 1.8985 - learning_rate: 3.2467e-05
Epoch 144/300
785/785 - 84s - 107ms/step - accuracy: 0.4408 - loss: 2.6376 - val_accuracy: 0.5774 - val_loss: 1.9066 - learning_rate: 3.2467e-05
Epoch 145/300
785/785 - 144s - 183ms/step - accuracy: 0.4356 - loss: 2.6370 - val_accuracy: 0.5807 - val_loss: 1.8998 - learning_rate: 3.2467e-05
Epoch 146/300
785/785 - 84s - 107ms/step - accuracy: 0.4467 - loss: 2.5962 - val_accuracy: 0.5833 - val_loss: 1.8859 - learning_rate: 3.2467e-05
Epoch 147/300
785/785 - 85s - 108ms/step - accuracy: 0.4424 - loss: 2.6193 - val_accuracy: 0.5834 - val_loss: 1.9000 - learning_rate: 3.2467e-05
Epoch 148/300
785/785 - 86s - 110ms/step - accuracy: 0.4466 - loss: 2.6540 - val_accuracy: 0.5885 - val_loss: 1.8963 - learning_rate: 3.2467e-05
Epoch 149/300
785/785 - 84s - 107ms/step - accuracy: 0.4534 - loss: 2.5894 - val_accuracy: 0.5857 - val_loss: 1.8949 - learning_rate: 3.2467e-05
Epoch 150/300
785/785 - 88s - 112ms/step - accuracy: 0.4437 - loss: 2.6174 - val_accuracy: 0.5865 - val_loss: 1.8926 - learning_rate: 3.2467e-05
Epoch 151/300
785/785 - 85s - 108ms/step - accuracy: 0.4455 - loss: 2.6044 - val_accuracy: 0.5830 - val_loss: 1.8869 - learning_rate: 3.2467e-05
Epoch 152/300
785/785 - 87s - 110ms/step - accuracy: 0.4485 - loss: 2.5878 - val_accuracy: 0.5884 - val_loss: 1.8842 - learning_rate: 3.2467e-05
Epoch 153/300
785/785 - 85s - 108ms/step - accuracy: 0.4359 - loss: 2.6325 - val_accuracy: 0.5898 - val_loss: 1.8910 - learning_rate: 3.2467e-05
Epoch 154/300
785/785 - 92s - 117ms/step - accuracy: 0.4376 - loss: 2.6214 - val_accuracy: 0.5874 - val_loss: 1.8882 - learning_rate: 3.2467e-05
Epoch 155/300
785/785 - 92s - 117ms/step - accuracy: 0.4440 - loss: 2.6066 - val_accuracy: 0.5890 - val_loss: 1.8962 - learning_rate: 3.2467e-05
Epoch 156/300
785/785 - 93s - 119ms/step - accuracy: 0.4445 - loss: 2.6194 - val_accuracy: 0.5873 - val_loss: 1.8759 - learning_rate: 3.2467e-05
Epoch 157/300
785/785 - 92s - 117ms/step - accuracy: 0.4410 - loss: 2.6583 - val_accuracy: 0.5857 - val_loss: 1.8877 - learning_rate: 3.2467e-05
Epoch 158/300
785/785 - 92s - 117ms/step - accuracy: 0.4432 - loss: 2.6178 - val_accuracy: 0.5903 - val_loss: 1.8835 - learning_rate: 3.2467e-05
Epoch 159/300
785/785 - 92s - 118ms/step - accuracy: 0.4308 - loss: 2.6492 - val_accuracy: 0.5818 - val_loss: 1.8954 - learning_rate: 3.2467e-05
Epoch 160/300
785/785 - 90s - 115ms/step - accuracy: 0.4421 - loss: 2.6396 - val_accuracy: 0.5858 - val_loss: 1.8907 - learning_rate: 3.2467e-05
Epoch 161/300
785/785 - 92s - 118ms/step - accuracy: 0.4470 - loss: 2.6180 - val_accuracy: 0.5869 - val_loss: 1.8834 - learning_rate: 3.2467e-05
Epoch 162/300
785/785 - 91s - 116ms/step - accuracy: 0.4450 - loss: 2.6372 - val_accuracy: 0.5793 - val_loss: 1.8881 - learning_rate: 3.2467e-05
Epoch 163/300
785/785 - 93s - 118ms/step - accuracy: 0.4447 - loss: 2.6106 - val_accuracy: 0.5812 - val_loss: 1.8850 - learning_rate: 3.2467e-05
Epoch 164/300

Epoch 164: ReduceLROnPlateau reducing learning rate to 1.6233630958595313e-05.
785/785 - 93s - 118ms/step - accuracy: 0.4415 - loss: 2.5978 - val_accuracy: 0.5865 - val_loss: 1.8879 - learning_rate: 3.2467e-05
Epoch 165/300
785/785 - 90s - 115ms/step - accuracy: 0.4335 - loss: 2.6357 - val_accuracy: 0.5860 - val_loss: 1.8808 - learning_rate: 1.6234e-05
Epoch 166/300
785/785 - 88s - 112ms/step - accuracy: 0.4513 - loss: 2.6080 - val_accuracy: 0.5849 - val_loss: 1.8803 - learning_rate: 1.6234e-05
Epoch 167/300
785/785 - 86s - 110ms/step - accuracy: 0.4381 - loss: 2.6349 - val_accuracy: 0.5825 - val_loss: 1.8823 - learning_rate: 1.6234e-05
Epoch 168/300
785/785 - 140s - 179ms/step - accuracy: 0.4474 - loss: 2.6085 - val_accuracy: 0.5879 - val_loss: 1.8818 - learning_rate: 1.6234e-05
Epoch 169/300
785/785 - 87s - 111ms/step - accuracy: 0.4442 - loss: 2.5885 - val_accuracy: 0.5846 - val_loss: 1.8802 - learning_rate: 1.6234e-05
Epoch 170/300
785/785 - 87s - 110ms/step - accuracy: 0.4383 - loss: 2.6150 - val_accuracy: 0.5857 - val_loss: 1.8822 - learning_rate: 1.6234e-05
Epoch 171/300
785/785 - 86s - 109ms/step - accuracy: 0.4450 - loss: 2.5755 - val_accuracy: 0.5866 - val_loss: 1.8772 - learning_rate: 1.6234e-05
Epoch 172/300

Epoch 172: ReduceLROnPlateau reducing learning rate to 8.116815479297657e-06.
785/785 - 85s - 108ms/step - accuracy: 0.4396 - loss: 2.6340 - val_accuracy: 0.5833 - val_loss: 1.8808 - learning_rate: 1.6234e-05
Epoch 172: early stopping
Restoring model weights from the end of the best epoch: 156.
Fold 0_1 Evaluation results: [1.881618857383728, 0.5872611403465271]
              precision    recall  f1-score   support

        1820       0.72      0.77      0.75       311
        1821       0.88      0.79      0.84       278
        1822       0.00      0.00      0.00         4
        1823       0.33      0.17      0.22         6
        1824       0.00      0.00      0.00         5
        1825       0.00      0.00      0.00        12
        1826       0.00      0.00      0.00        10
        1827       0.71      0.78      0.75       130
        1828       0.33      0.25      0.29         4
        1829       0.80      0.42      0.55        19
        1830       0.52      0.69      0.59       283
        1831       0.70      0.94      0.80       664
        1832       0.77      0.71      0.74       310
        1833       0.75      0.87      0.80        90
        1834       0.51      0.59      0.55       143
        1835       0.00      0.00      0.00        10
        1836       0.00      0.00      0.00        17
        1837       0.25      0.45      0.32        29
        1838       0.50      0.06      0.11        17
        1839       0.00      0.00      0.00         5
        1840       0.48      0.62      0.54       229
        1841       0.81      0.47      0.59       560
        1842       0.73      0.38      0.50        29
        1843       0.00      0.00      0.00        33
        1844       0.00      0.00      0.00         2
        1845       0.00      0.00      0.00         9
        1846       1.00      0.14      0.25        21
        1847       0.00      0.00      0.00         8
        1848       0.00      0.00      0.00        32
        1849       0.25      0.08      0.12        24
        1850       0.32      0.65      0.42       231
        1851       0.76      0.65      0.70       379
        1852       0.00      0.00      0.00        34
        1853       0.00      0.00      0.00        31
        1854       0.00      0.00      0.00        11
        1855       0.67      0.03      0.06       123
        1856       0.83      0.45      0.59        64
        1857       0.42      0.66      0.52       150
        1858       0.00      0.00      0.00        10
        1859       0.00      0.00      0.00        10
        1860       0.29      0.35      0.31       311
        1861       0.72      0.82      0.77       423
        1862       0.31      0.14      0.19        93
        1863       0.32      0.51      0.40        90
        1864       0.40      0.35      0.38        94
        1865       0.75      0.16      0.26        38
        1866       0.30      0.10      0.15        30
        1867       0.32      0.22      0.26        51
        1868       0.00      0.00      0.00        33
        1869       0.00      0.00      0.00        27
        1870       0.39      0.54      0.45       162
        1871       0.61      0.77      0.68       249
        1872       0.32      0.35      0.33        40
        1873       0.33      0.04      0.06        57
        1874       0.50      0.04      0.07        25
        1875       0.32      0.24      0.28        78
        1876       0.85      0.87      0.86        52
        1877       0.25      0.06      0.10        32
        1878       0.55      0.45      0.49        51
        1879       0.00      0.00      0.00         7

    accuracy                           0.59      6280
   macro avg       0.36      0.29      0.29      6280
weighted avg       0.58      0.59      0.56      6280

Matthews Correlation Coefficient: 0.567
Macro avg F1: 0.294
Weighted avg F1: 0.561
Micro avg F1: 0.587
Top-3 Accuracy: 0.842
Top-5 Accuracy: 0.900
Micro ROC AUC  = 0.98
Macro ROC AUC (present classes) = 0.97
Classification MAE (in years): 3.30

Fold 0_1 Misclassification Analysis:
Near misses (within 2 years): 593 out of 2592 misclassifications (22.88%)
Big misses (greater than 10 years): 1098
MAE with outliers: 3.30
MAE without outliers: 2.36 (improvement: 0.93)

10 Worst misclassifications:
Image: data/datasets/public/1870/1879_26wikimedia2.jpg, True: 1879, Predicted: 1820, Error: 59
Image: data/datasets/public/1870/1877_035met.jpg, True: 1877, Predicted: 1820, Error: 57
Image: data/datasets/private/1820/1820_034_Zrzut ekranu 2022-07-26 203655.png, True: 1820, Predicted: 1876, Error: 56
Image: data/datasets/private/1870/1871_358etsy.jpg, True: 1871, Predicted: 1821, Error: 50
Image: data/datasets/public/1870/1870_79wikimedia2.jpg, True: 1870, Predicted: 1820, Error: 50
Image: data/datasets/private/1870/1871_384etsy.jpg, True: 1871, Predicted: 1821, Error: 50
Image: data/datasets/private/1870/1871_415etsy.jpg, True: 1871, Predicted: 1821, Error: 50
Image: data/datasets/public/1870/1877_033met.jpg, True: 1877, Predicted: 1832, Error: 45
Image: data/datasets/private/1870/1875_74et.jpg, True: 1875, Predicted: 1830, Error: 45
Image: data/datasets/public/1870/1875_012met.jpg, True: 1875, Predicted: 1830, Error: 45

===== Fine Tuning 9 layers! =====
Epoch 1/300
785/785 - 111s - 141ms/step - accuracy: 0.1161 - loss: 4.5095 - val_accuracy: 0.2368 - val_loss: 4.0887 - learning_rate: 2.5974e-04
Epoch 2/300
785/785 - 86s - 109ms/step - accuracy: 0.1596 - loss: 4.1461 - val_accuracy: 0.2607 - val_loss: 3.7643 - learning_rate: 2.5974e-04
Epoch 3/300
785/785 - 86s - 110ms/step - accuracy: 0.1971 - loss: 3.9396 - val_accuracy: 0.3387 - val_loss: 3.4608 - learning_rate: 2.5974e-04
Epoch 4/300
785/785 - 84s - 107ms/step - accuracy: 0.2197 - loss: 3.8137 - val_accuracy: 0.3214 - val_loss: 3.2053 - learning_rate: 2.5974e-04
Epoch 5/300
785/785 - 87s - 111ms/step - accuracy: 0.2336 - loss: 3.7026 - val_accuracy: 0.3507 - val_loss: 3.1640 - learning_rate: 2.5974e-04
Epoch 6/300
785/785 - 86s - 110ms/step - accuracy: 0.2500 - loss: 3.6363 - val_accuracy: 0.4045 - val_loss: 3.0259 - learning_rate: 2.5974e-04
Epoch 7/300
785/785 - 85s - 108ms/step - accuracy: 0.2656 - loss: 3.5376 - val_accuracy: 0.4031 - val_loss: 2.8936 - learning_rate: 2.5974e-04
Epoch 8/300
785/785 - 87s - 110ms/step - accuracy: 0.2642 - loss: 3.5159 - val_accuracy: 0.4353 - val_loss: 2.9804 - learning_rate: 2.5974e-04
Epoch 9/300
785/785 - 86s - 110ms/step - accuracy: 0.2811 - loss: 3.4921 - val_accuracy: 0.4698 - val_loss: 2.8457 - learning_rate: 2.5974e-04
Epoch 10/300
785/785 - 87s - 111ms/step - accuracy: 0.2889 - loss: 3.4656 - val_accuracy: 0.4698 - val_loss: 2.6988 - learning_rate: 2.5974e-04
Epoch 11/300
785/785 - 83s - 105ms/step - accuracy: 0.2868 - loss: 3.3914 - val_accuracy: 0.4741 - val_loss: 2.6276 - learning_rate: 2.5974e-04
Epoch 12/300
785/785 - 86s - 110ms/step - accuracy: 0.2982 - loss: 3.3663 - val_accuracy: 0.4787 - val_loss: 2.6655 - learning_rate: 2.5974e-04
Epoch 13/300
785/785 - 85s - 109ms/step - accuracy: 0.2998 - loss: 3.3636 - val_accuracy: 0.4972 - val_loss: 2.5885 - learning_rate: 2.5974e-04
Epoch 14/300
785/785 - 84s - 106ms/step - accuracy: 0.3084 - loss: 3.3402 - val_accuracy: 0.4980 - val_loss: 2.5408 - learning_rate: 2.5974e-04
Epoch 15/300
785/785 - 85s - 108ms/step - accuracy: 0.3217 - loss: 3.2696 - val_accuracy: 0.4910 - val_loss: 2.5324 - learning_rate: 2.5974e-04
Epoch 16/300
785/785 - 85s - 108ms/step - accuracy: 0.3139 - loss: 3.2857 - val_accuracy: 0.5066 - val_loss: 2.4987 - learning_rate: 2.5974e-04
Epoch 17/300
785/785 - 85s - 108ms/step - accuracy: 0.3317 - loss: 3.2519 - val_accuracy: 0.4977 - val_loss: 2.4665 - learning_rate: 2.5974e-04
Epoch 18/300
785/785 - 91s - 116ms/step - accuracy: 0.3220 - loss: 3.2357 - val_accuracy: 0.5026 - val_loss: 2.3985 - learning_rate: 2.5974e-04
Epoch 19/300
785/785 - 92s - 117ms/step - accuracy: 0.3201 - loss: 3.2305 - val_accuracy: 0.5009 - val_loss: 2.4571 - learning_rate: 2.5974e-04
Epoch 20/300
785/785 - 136s - 173ms/step - accuracy: 0.3400 - loss: 3.1872 - val_accuracy: 0.5104 - val_loss: 2.4182 - learning_rate: 2.5974e-04
Epoch 21/300
785/785 - 83s - 106ms/step - accuracy: 0.3381 - loss: 3.1868 - val_accuracy: 0.5209 - val_loss: 2.3737 - learning_rate: 2.5974e-04
Epoch 22/300
785/785 - 86s - 109ms/step - accuracy: 0.3436 - loss: 3.1706 - val_accuracy: 0.5267 - val_loss: 2.4304 - learning_rate: 2.5974e-04
Epoch 23/300
785/785 - 85s - 109ms/step - accuracy: 0.3449 - loss: 3.1590 - val_accuracy: 0.5299 - val_loss: 2.3217 - learning_rate: 2.5974e-04
Epoch 24/300
785/785 - 85s - 108ms/step - accuracy: 0.3403 - loss: 3.1234 - val_accuracy: 0.5463 - val_loss: 2.2863 - learning_rate: 2.5974e-04
Epoch 25/300
785/785 - 86s - 109ms/step - accuracy: 0.3484 - loss: 3.1279 - val_accuracy: 0.5321 - val_loss: 2.2835 - learning_rate: 2.5974e-04
Epoch 26/300
785/785 - 85s - 108ms/step - accuracy: 0.3422 - loss: 3.1059 - val_accuracy: 0.5350 - val_loss: 2.2778 - learning_rate: 2.5974e-04
Epoch 27/300
785/785 - 86s - 110ms/step - accuracy: 0.3510 - loss: 3.1090 - val_accuracy: 0.5377 - val_loss: 2.2556 - learning_rate: 2.5974e-04
Epoch 28/300
785/785 - 85s - 108ms/step - accuracy: 0.3508 - loss: 3.1008 - val_accuracy: 0.5426 - val_loss: 2.3108 - learning_rate: 2.5974e-04
Epoch 29/300
785/785 - 83s - 106ms/step - accuracy: 0.3635 - loss: 3.0854 - val_accuracy: 0.5323 - val_loss: 2.2665 - learning_rate: 2.5974e-04
Epoch 30/300
785/785 - 86s - 109ms/step - accuracy: 0.3482 - loss: 3.0943 - val_accuracy: 0.5536 - val_loss: 2.2444 - learning_rate: 2.5974e-04
Epoch 31/300
785/785 - 83s - 106ms/step - accuracy: 0.3559 - loss: 3.0412 - val_accuracy: 0.5187 - val_loss: 2.3234 - learning_rate: 2.5974e-04
Epoch 32/300
785/785 - 85s - 108ms/step - accuracy: 0.3654 - loss: 3.0905 - val_accuracy: 0.5386 - val_loss: 2.2147 - learning_rate: 2.5974e-04
Epoch 33/300
785/785 - 85s - 108ms/step - accuracy: 0.3498 - loss: 3.0736 - val_accuracy: 0.5480 - val_loss: 2.2021 - learning_rate: 2.5974e-04
Epoch 34/300
785/785 - 85s - 108ms/step - accuracy: 0.3573 - loss: 3.0882 - val_accuracy: 0.5592 - val_loss: 2.2070 - learning_rate: 2.5974e-04
Epoch 35/300
785/785 - 86s - 109ms/step - accuracy: 0.3688 - loss: 3.0417 - val_accuracy: 0.5573 - val_loss: 2.2046 - learning_rate: 2.5974e-04
Epoch 36/300
785/785 - 83s - 106ms/step - accuracy: 0.3602 - loss: 3.0479 - val_accuracy: 0.5502 - val_loss: 2.2249 - learning_rate: 2.5974e-04
Epoch 37/300
785/785 - 86s - 110ms/step - accuracy: 0.3779 - loss: 3.0095 - val_accuracy: 0.5471 - val_loss: 2.1780 - learning_rate: 2.5974e-04
Epoch 38/300
785/785 - 84s - 106ms/step - accuracy: 0.3750 - loss: 3.0168 - val_accuracy: 0.5600 - val_loss: 2.1634 - learning_rate: 2.5974e-04
Epoch 39/300
785/785 - 86s - 109ms/step - accuracy: 0.3712 - loss: 3.0334 - val_accuracy: 0.5461 - val_loss: 2.1474 - learning_rate: 2.5974e-04
Epoch 40/300
785/785 - 86s - 109ms/step - accuracy: 0.3669 - loss: 3.0218 - val_accuracy: 0.5530 - val_loss: 2.1764 - learning_rate: 2.5974e-04
Epoch 41/300
785/785 - 85s - 108ms/step - accuracy: 0.3629 - loss: 3.0158 - val_accuracy: 0.5475 - val_loss: 2.1482 - learning_rate: 2.5974e-04
Epoch 42/300
785/785 - 85s - 109ms/step - accuracy: 0.3748 - loss: 2.9843 - val_accuracy: 0.5501 - val_loss: 2.2415 - learning_rate: 2.5974e-04
Epoch 43/300
785/785 - 91s - 116ms/step - accuracy: 0.3866 - loss: 2.9500 - val_accuracy: 0.5662 - val_loss: 2.0798 - learning_rate: 2.5974e-04
Epoch 44/300
785/785 - 84s - 107ms/step - accuracy: 0.3748 - loss: 2.9894 - val_accuracy: 0.5506 - val_loss: 2.1057 - learning_rate: 2.5974e-04
Epoch 45/300
785/785 - 92s - 117ms/step - accuracy: 0.3744 - loss: 2.9672 - val_accuracy: 0.5495 - val_loss: 2.1413 - learning_rate: 2.5974e-04
Epoch 46/300
785/785 - 84s - 107ms/step - accuracy: 0.3785 - loss: 2.9964 - val_accuracy: 0.5627 - val_loss: 2.0885 - learning_rate: 2.5974e-04
Epoch 47/300
785/785 - 85s - 108ms/step - accuracy: 0.3761 - loss: 2.9614 - val_accuracy: 0.5660 - val_loss: 2.0938 - learning_rate: 2.5974e-04
Epoch 48/300
785/785 - 85s - 108ms/step - accuracy: 0.3812 - loss: 2.9219 - val_accuracy: 0.5660 - val_loss: 2.0862 - learning_rate: 2.5974e-04
Epoch 49/300
785/785 - 82s - 105ms/step - accuracy: 0.3831 - loss: 2.9814 - val_accuracy: 0.5555 - val_loss: 2.1076 - learning_rate: 2.5974e-04
Epoch 50/300
785/785 - 84s - 107ms/step - accuracy: 0.3750 - loss: 2.9459 - val_accuracy: 0.5442 - val_loss: 2.1429 - learning_rate: 2.5974e-04
Epoch 51/300
785/785 - 86s - 110ms/step - accuracy: 0.3854 - loss: 2.9500 - val_accuracy: 0.5619 - val_loss: 2.0633 - learning_rate: 2.5974e-04
Epoch 52/300
785/785 - 84s - 108ms/step - accuracy: 0.3847 - loss: 2.9650 - val_accuracy: 0.5643 - val_loss: 2.0802 - learning_rate: 2.5974e-04
Epoch 53/300
785/785 - 86s - 110ms/step - accuracy: 0.3981 - loss: 2.9277 - val_accuracy: 0.5703 - val_loss: 2.0958 - learning_rate: 2.5974e-04
Epoch 54/300
785/785 - 87s - 110ms/step - accuracy: 0.3785 - loss: 2.9687 - val_accuracy: 0.5695 - val_loss: 2.1172 - learning_rate: 2.5974e-04
Epoch 55/300
785/785 - 86s - 110ms/step - accuracy: 0.3836 - loss: 2.9619 - val_accuracy: 0.5647 - val_loss: 2.0568 - learning_rate: 2.5974e-04
Epoch 56/300
785/785 - 86s - 109ms/step - accuracy: 0.3815 - loss: 2.9439 - val_accuracy: 0.5708 - val_loss: 2.0659 - learning_rate: 2.5974e-04
Epoch 57/300
785/785 - 84s - 107ms/step - accuracy: 0.3766 - loss: 2.9241 - val_accuracy: 0.5482 - val_loss: 2.1060 - learning_rate: 2.5974e-04
Epoch 58/300
785/785 - 84s - 107ms/step - accuracy: 0.3887 - loss: 2.9429 - val_accuracy: 0.5756 - val_loss: 2.0738 - learning_rate: 2.5974e-04
Epoch 59/300
785/785 - 91s - 116ms/step - accuracy: 0.3833 - loss: 2.9039 - val_accuracy: 0.5592 - val_loss: 2.1064 - learning_rate: 2.5974e-04
Epoch 60/300
785/785 - 86s - 110ms/step - accuracy: 0.3868 - loss: 2.9417 - val_accuracy: 0.5687 - val_loss: 2.0521 - learning_rate: 2.5974e-04
Epoch 61/300
785/785 - 87s - 110ms/step - accuracy: 0.3890 - loss: 2.9315 - val_accuracy: 0.5760 - val_loss: 2.0242 - learning_rate: 2.5974e-04
Epoch 62/300
785/785 - 85s - 109ms/step - accuracy: 0.3922 - loss: 2.9284 - val_accuracy: 0.5727 - val_loss: 2.0598 - learning_rate: 2.5974e-04
Epoch 63/300
785/785 - 86s - 109ms/step - accuracy: 0.3833 - loss: 2.9214 - val_accuracy: 0.5770 - val_loss: 2.0087 - learning_rate: 2.5974e-04
Epoch 64/300
785/785 - 87s - 110ms/step - accuracy: 0.3871 - loss: 2.9298 - val_accuracy: 0.5743 - val_loss: 2.0302 - learning_rate: 2.5974e-04
Epoch 65/300
785/785 - 83s - 106ms/step - accuracy: 0.3890 - loss: 2.9047 - val_accuracy: 0.5748 - val_loss: 2.0238 - learning_rate: 2.5974e-04
Epoch 66/300
785/785 - 84s - 106ms/step - accuracy: 0.3828 - loss: 2.9170 - val_accuracy: 0.5735 - val_loss: 1.9970 - learning_rate: 2.5974e-04
Epoch 67/300
785/785 - 83s - 106ms/step - accuracy: 0.3949 - loss: 2.8695 - val_accuracy: 0.5762 - val_loss: 2.0176 - learning_rate: 2.5974e-04
Epoch 68/300
785/785 - 87s - 111ms/step - accuracy: 0.4037 - loss: 2.8658 - val_accuracy: 0.5749 - val_loss: 2.0008 - learning_rate: 2.5974e-04
Epoch 69/300
785/785 - 86s - 110ms/step - accuracy: 0.3949 - loss: 2.9095 - val_accuracy: 0.5792 - val_loss: 2.0164 - learning_rate: 2.5974e-04
Epoch 70/300
785/785 - 85s - 109ms/step - accuracy: 0.3877 - loss: 2.9272 - val_accuracy: 0.5737 - val_loss: 2.0162 - learning_rate: 2.5974e-04
Epoch 71/300
785/785 - 86s - 110ms/step - accuracy: 0.4018 - loss: 2.8619 - val_accuracy: 0.5843 - val_loss: 2.0120 - learning_rate: 2.5974e-04
Epoch 72/300
785/785 - 86s - 110ms/step - accuracy: 0.3932 - loss: 2.9043 - val_accuracy: 0.5824 - val_loss: 1.9921 - learning_rate: 2.5974e-04
Epoch 73/300
785/785 - 85s - 108ms/step - accuracy: 0.3876 - loss: 2.9123 - val_accuracy: 0.5819 - val_loss: 1.9941 - learning_rate: 2.5974e-04
Epoch 74/300
785/785 - 85s - 109ms/step - accuracy: 0.3946 - loss: 2.8752 - val_accuracy: 0.5641 - val_loss: 2.1195 - learning_rate: 2.5974e-04
Epoch 75/300
785/785 - 93s - 118ms/step - accuracy: 0.3924 - loss: 2.8648 - val_accuracy: 0.5684 - val_loss: 2.0263 - learning_rate: 2.5974e-04
Epoch 76/300
785/785 - 84s - 107ms/step - accuracy: 0.3924 - loss: 2.8971 - val_accuracy: 0.5730 - val_loss: 2.0401 - learning_rate: 2.5974e-04
Epoch 77/300
785/785 - 85s - 108ms/step - accuracy: 0.4035 - loss: 2.8485 - val_accuracy: 0.5783 - val_loss: 2.0287 - learning_rate: 2.5974e-04
Epoch 78/300
785/785 - 86s - 109ms/step - accuracy: 0.3952 - loss: 2.8896 - val_accuracy: 0.5775 - val_loss: 1.9990 - learning_rate: 2.5974e-04
Epoch 79/300
785/785 - 86s - 109ms/step - accuracy: 0.3936 - loss: 2.8779 - val_accuracy: 0.5776 - val_loss: 2.0492 - learning_rate: 2.5974e-04
Epoch 80/300

Epoch 80: ReduceLROnPlateau reducing learning rate to 0.0001298690476687625.
785/785 - 85s - 109ms/step - accuracy: 0.4032 - loss: 2.8544 - val_accuracy: 0.5719 - val_loss: 2.0212 - learning_rate: 2.5974e-04
Epoch 81/300
785/785 - 86s - 109ms/step - accuracy: 0.4099 - loss: 2.8130 - val_accuracy: 0.5802 - val_loss: 1.9609 - learning_rate: 1.2987e-04
Epoch 82/300
785/785 - 87s - 111ms/step - accuracy: 0.4088 - loss: 2.7730 - val_accuracy: 0.5867 - val_loss: 1.9467 - learning_rate: 1.2987e-04
Epoch 83/300
785/785 - 85s - 109ms/step - accuracy: 0.4158 - loss: 2.7829 - val_accuracy: 0.5969 - val_loss: 1.9597 - learning_rate: 1.2987e-04
Epoch 84/300
785/785 - 83s - 106ms/step - accuracy: 0.4188 - loss: 2.7617 - val_accuracy: 0.5880 - val_loss: 1.9394 - learning_rate: 1.2987e-04
Epoch 85/300
785/785 - 87s - 110ms/step - accuracy: 0.4008 - loss: 2.7792 - val_accuracy: 0.5807 - val_loss: 1.9526 - learning_rate: 1.2987e-04
Epoch 86/300
785/785 - 85s - 109ms/step - accuracy: 0.4121 - loss: 2.7710 - val_accuracy: 0.5897 - val_loss: 1.9199 - learning_rate: 1.2987e-04
Epoch 87/300
785/785 - 87s - 111ms/step - accuracy: 0.4100 - loss: 2.7933 - val_accuracy: 0.5912 - val_loss: 1.9486 - learning_rate: 1.2987e-04
Epoch 88/300
785/785 - 85s - 109ms/step - accuracy: 0.4111 - loss: 2.7896 - val_accuracy: 0.5905 - val_loss: 1.9750 - learning_rate: 1.2987e-04
Epoch 89/300
785/785 - 85s - 109ms/step - accuracy: 0.4121 - loss: 2.7911 - val_accuracy: 0.5877 - val_loss: 1.9634 - learning_rate: 1.2987e-04
Epoch 90/300
785/785 - 87s - 110ms/step - accuracy: 0.4180 - loss: 2.7674 - val_accuracy: 0.5918 - val_loss: 1.9536 - learning_rate: 1.2987e-04
Epoch 91/300
785/785 - 84s - 108ms/step - accuracy: 0.4131 - loss: 2.7790 - val_accuracy: 0.5950 - val_loss: 1.9380 - learning_rate: 1.2987e-04
Epoch 92/300
785/785 - 84s - 107ms/step - accuracy: 0.4096 - loss: 2.7672 - val_accuracy: 0.5934 - val_loss: 1.9355 - learning_rate: 1.2987e-04
Epoch 93/300
785/785 - 86s - 109ms/step - accuracy: 0.4169 - loss: 2.7447 - val_accuracy: 0.5921 - val_loss: 1.9104 - learning_rate: 1.2987e-04
Epoch 94/300
785/785 - 142s - 181ms/step - accuracy: 0.4091 - loss: 2.7717 - val_accuracy: 0.5988 - val_loss: 1.9052 - learning_rate: 1.2987e-04
Epoch 95/300
785/785 - 85s - 109ms/step - accuracy: 0.4175 - loss: 2.7618 - val_accuracy: 0.5932 - val_loss: 1.9372 - learning_rate: 1.2987e-04
Epoch 96/300
785/785 - 85s - 109ms/step - accuracy: 0.4162 - loss: 2.7311 - val_accuracy: 0.5963 - val_loss: 1.9250 - learning_rate: 1.2987e-04
Epoch 97/300
785/785 - 86s - 109ms/step - accuracy: 0.4221 - loss: 2.7649 - val_accuracy: 0.5944 - val_loss: 1.9521 - learning_rate: 1.2987e-04
Epoch 98/300
785/785 - 87s - 111ms/step - accuracy: 0.4158 - loss: 2.7535 - val_accuracy: 0.5948 - val_loss: 1.9056 - learning_rate: 1.2987e-04
Epoch 99/300
785/785 - 83s - 106ms/step - accuracy: 0.4266 - loss: 2.7289 - val_accuracy: 0.5993 - val_loss: 1.9155 - learning_rate: 1.2987e-04
Epoch 100/300
785/785 - 85s - 109ms/step - accuracy: 0.4207 - loss: 2.7325 - val_accuracy: 0.5932 - val_loss: 1.9179 - learning_rate: 1.2987e-04
Epoch 101/300
785/785 - 85s - 109ms/step - accuracy: 0.4201 - loss: 2.7680 - val_accuracy: 0.6011 - val_loss: 1.9097 - learning_rate: 1.2987e-04
Epoch 102/300

Epoch 102: ReduceLROnPlateau reducing learning rate to 6.493452383438125e-05.
785/785 - 86s - 110ms/step - accuracy: 0.4202 - loss: 2.7561 - val_accuracy: 0.6007 - val_loss: 1.9106 - learning_rate: 1.2987e-04
Epoch 103/300
785/785 - 85s - 108ms/step - accuracy: 0.4272 - loss: 2.6946 - val_accuracy: 0.5977 - val_loss: 1.9047 - learning_rate: 6.4935e-05
Epoch 104/300
785/785 - 86s - 109ms/step - accuracy: 0.4328 - loss: 2.7112 - val_accuracy: 0.5979 - val_loss: 1.8898 - learning_rate: 6.4935e-05
Epoch 105/300
785/785 - 86s - 109ms/step - accuracy: 0.4255 - loss: 2.7163 - val_accuracy: 0.6055 - val_loss: 1.9100 - learning_rate: 6.4935e-05
Epoch 106/300
785/785 - 85s - 109ms/step - accuracy: 0.4315 - loss: 2.6801 - val_accuracy: 0.6052 - val_loss: 1.8857 - learning_rate: 6.4935e-05
Epoch 107/300
785/785 - 84s - 107ms/step - accuracy: 0.4226 - loss: 2.7273 - val_accuracy: 0.5998 - val_loss: 1.8987 - learning_rate: 6.4935e-05
Epoch 108/300
785/785 - 86s - 109ms/step - accuracy: 0.4253 - loss: 2.7172 - val_accuracy: 0.6034 - val_loss: 1.8909 - learning_rate: 6.4935e-05
Epoch 109/300
785/785 - 86s - 109ms/step - accuracy: 0.4274 - loss: 2.7018 - val_accuracy: 0.6063 - val_loss: 1.9121 - learning_rate: 6.4935e-05
Epoch 110/300
785/785 - 85s - 109ms/step - accuracy: 0.4360 - loss: 2.6982 - val_accuracy: 0.6057 - val_loss: 1.8828 - learning_rate: 6.4935e-05
Epoch 111/300
785/785 - 86s - 110ms/step - accuracy: 0.4373 - loss: 2.6698 - val_accuracy: 0.6063 - val_loss: 1.8939 - learning_rate: 6.4935e-05
Epoch 112/300
785/785 - 86s - 110ms/step - accuracy: 0.4263 - loss: 2.7036 - val_accuracy: 0.6087 - val_loss: 1.8753 - learning_rate: 6.4935e-05
Epoch 113/300
785/785 - 86s - 109ms/step - accuracy: 0.4411 - loss: 2.6858 - val_accuracy: 0.6092 - val_loss: 1.8716 - learning_rate: 6.4935e-05
Epoch 114/300
785/785 - 85s - 108ms/step - accuracy: 0.4239 - loss: 2.7267 - val_accuracy: 0.6058 - val_loss: 1.8792 - learning_rate: 6.4935e-05
Epoch 115/300
785/785 - 83s - 106ms/step - accuracy: 0.4352 - loss: 2.7030 - val_accuracy: 0.6022 - val_loss: 1.8939 - learning_rate: 6.4935e-05
Epoch 116/300
785/785 - 84s - 107ms/step - accuracy: 0.4299 - loss: 2.6794 - val_accuracy: 0.6085 - val_loss: 1.8796 - learning_rate: 6.4935e-05
Epoch 117/300
785/785 - 85s - 108ms/step - accuracy: 0.4245 - loss: 2.7074 - val_accuracy: 0.6068 - val_loss: 1.8914 - learning_rate: 6.4935e-05
Epoch 118/300
785/785 - 86s - 110ms/step - accuracy: 0.4242 - loss: 2.7091 - val_accuracy: 0.6061 - val_loss: 1.8954 - learning_rate: 6.4935e-05
Epoch 119/300
785/785 - 88s - 112ms/step - accuracy: 0.4303 - loss: 2.7066 - val_accuracy: 0.6054 - val_loss: 1.8714 - learning_rate: 6.4935e-05
Epoch 120/300
785/785 - 87s - 111ms/step - accuracy: 0.4361 - loss: 2.6994 - val_accuracy: 0.6057 - val_loss: 1.8892 - learning_rate: 6.4935e-05
Epoch 121/300
785/785 - 86s - 109ms/step - accuracy: 0.4271 - loss: 2.6888 - val_accuracy: 0.6046 - val_loss: 1.8904 - learning_rate: 6.4935e-05
Epoch 122/300
785/785 - 85s - 108ms/step - accuracy: 0.4387 - loss: 2.6875 - val_accuracy: 0.6069 - val_loss: 1.8770 - learning_rate: 6.4935e-05
Epoch 123/300
785/785 - 85s - 108ms/step - accuracy: 0.4258 - loss: 2.7201 - val_accuracy: 0.6077 - val_loss: 1.8834 - learning_rate: 6.4935e-05
Epoch 124/300
785/785 - 87s - 111ms/step - accuracy: 0.4333 - loss: 2.6816 - val_accuracy: 0.6074 - val_loss: 1.8664 - learning_rate: 6.4935e-05
Epoch 125/300
785/785 - 86s - 109ms/step - accuracy: 0.4349 - loss: 2.6976 - val_accuracy: 0.6020 - val_loss: 1.8966 - learning_rate: 6.4935e-05
Epoch 126/300
785/785 - 85s - 108ms/step - accuracy: 0.4336 - loss: 2.7029 - val_accuracy: 0.6057 - val_loss: 1.8743 - learning_rate: 6.4935e-05
Epoch 127/300
785/785 - 86s - 110ms/step - accuracy: 0.4250 - loss: 2.7030 - val_accuracy: 0.6017 - val_loss: 1.9014 - learning_rate: 6.4935e-05
Epoch 128/300
785/785 - 86s - 109ms/step - accuracy: 0.4283 - loss: 2.7157 - val_accuracy: 0.6089 - val_loss: 1.8798 - learning_rate: 6.4935e-05
Epoch 129/300
785/785 - 86s - 110ms/step - accuracy: 0.4326 - loss: 2.6779 - val_accuracy: 0.6089 - val_loss: 1.8751 - learning_rate: 6.4935e-05
Epoch 130/300
785/785 - 141s - 179ms/step - accuracy: 0.4350 - loss: 2.6990 - val_accuracy: 0.6060 - val_loss: 1.8729 - learning_rate: 6.4935e-05
Epoch 131/300
785/785 - 84s - 108ms/step - accuracy: 0.4381 - loss: 2.6844 - val_accuracy: 0.6090 - val_loss: 1.8569 - learning_rate: 6.4935e-05
Epoch 132/300
785/785 - 85s - 108ms/step - accuracy: 0.4291 - loss: 2.6825 - val_accuracy: 0.6108 - val_loss: 1.8754 - learning_rate: 6.4935e-05
Epoch 133/300
785/785 - 84s - 107ms/step - accuracy: 0.4309 - loss: 2.6690 - val_accuracy: 0.6081 - val_loss: 1.8714 - learning_rate: 6.4935e-05
Epoch 134/300
785/785 - 85s - 108ms/step - accuracy: 0.4253 - loss: 2.7057 - val_accuracy: 0.6084 - val_loss: 1.8816 - learning_rate: 6.4935e-05
Epoch 135/300
785/785 - 92s - 117ms/step - accuracy: 0.4229 - loss: 2.6989 - val_accuracy: 0.6081 - val_loss: 1.8535 - learning_rate: 6.4935e-05
Epoch 136/300
785/785 - 86s - 109ms/step - accuracy: 0.4396 - loss: 2.6844 - val_accuracy: 0.6055 - val_loss: 1.8889 - learning_rate: 6.4935e-05
Epoch 137/300
785/785 - 86s - 110ms/step - accuracy: 0.4282 - loss: 2.6665 - val_accuracy: 0.6125 - val_loss: 1.8468 - learning_rate: 6.4935e-05
Epoch 138/300
785/785 - 84s - 108ms/step - accuracy: 0.4234 - loss: 2.6968 - val_accuracy: 0.6103 - val_loss: 1.8803 - learning_rate: 6.4935e-05
Epoch 139/300
785/785 - 86s - 109ms/step - accuracy: 0.4269 - loss: 2.7016 - val_accuracy: 0.6074 - val_loss: 1.8714 - learning_rate: 6.4935e-05
Epoch 140/300
785/785 - 86s - 110ms/step - accuracy: 0.4322 - loss: 2.6583 - val_accuracy: 0.6049 - val_loss: 1.8579 - learning_rate: 6.4935e-05
Epoch 141/300
785/785 - 85s - 108ms/step - accuracy: 0.4250 - loss: 2.7064 - val_accuracy: 0.6128 - val_loss: 1.8661 - learning_rate: 6.4935e-05
Epoch 142/300
785/785 - 85s - 109ms/step - accuracy: 0.4318 - loss: 2.7009 - val_accuracy: 0.6084 - val_loss: 1.8531 - learning_rate: 6.4935e-05
Epoch 143/300
785/785 - 86s - 109ms/step - accuracy: 0.4390 - loss: 2.6711 - val_accuracy: 0.6085 - val_loss: 1.8565 - learning_rate: 6.4935e-05
Epoch 144/300
785/785 - 85s - 109ms/step - accuracy: 0.4404 - loss: 2.6785 - val_accuracy: 0.6038 - val_loss: 1.8683 - learning_rate: 6.4935e-05
Epoch 145/300

Epoch 145: ReduceLROnPlateau reducing learning rate to 3.2467261917190626e-05.
785/785 - 86s - 110ms/step - accuracy: 0.4236 - loss: 2.7126 - val_accuracy: 0.6057 - val_loss: 1.8722 - learning_rate: 6.4935e-05
Epoch 146/300
785/785 - 82s - 105ms/step - accuracy: 0.4331 - loss: 2.6785 - val_accuracy: 0.6112 - val_loss: 1.8630 - learning_rate: 3.2467e-05
Epoch 147/300
785/785 - 85s - 109ms/step - accuracy: 0.4323 - loss: 2.6595 - val_accuracy: 0.6114 - val_loss: 1.8514 - learning_rate: 3.2467e-05
Epoch 148/300
785/785 - 86s - 109ms/step - accuracy: 0.4487 - loss: 2.6347 - val_accuracy: 0.6143 - val_loss: 1.8386 - learning_rate: 3.2467e-05
Epoch 149/300
785/785 - 93s - 119ms/step - accuracy: 0.4465 - loss: 2.6431 - val_accuracy: 0.6104 - val_loss: 1.8403 - learning_rate: 3.2467e-05
Epoch 150/300
785/785 - 85s - 109ms/step - accuracy: 0.4328 - loss: 2.6630 - val_accuracy: 0.6104 - val_loss: 1.8558 - learning_rate: 3.2467e-05
Epoch 151/300
785/785 - 85s - 109ms/step - accuracy: 0.4432 - loss: 2.6216 - val_accuracy: 0.6146 - val_loss: 1.8426 - learning_rate: 3.2467e-05
Epoch 152/300
785/785 - 86s - 109ms/step - accuracy: 0.4379 - loss: 2.6456 - val_accuracy: 0.6133 - val_loss: 1.8435 - learning_rate: 3.2467e-05
Epoch 153/300
785/785 - 85s - 108ms/step - accuracy: 0.4350 - loss: 2.6612 - val_accuracy: 0.6093 - val_loss: 1.8361 - learning_rate: 3.2467e-05
Epoch 154/300
785/785 - 83s - 105ms/step - accuracy: 0.4306 - loss: 2.6842 - val_accuracy: 0.6163 - val_loss: 1.8431 - learning_rate: 3.2467e-05
Epoch 155/300
785/785 - 86s - 110ms/step - accuracy: 0.4301 - loss: 2.6563 - val_accuracy: 0.6116 - val_loss: 1.8376 - learning_rate: 3.2467e-05
Epoch 156/300
785/785 - 85s - 109ms/step - accuracy: 0.4334 - loss: 2.6258 - val_accuracy: 0.6128 - val_loss: 1.8421 - learning_rate: 3.2467e-05
Epoch 157/300
785/785 - 86s - 110ms/step - accuracy: 0.4395 - loss: 2.6609 - val_accuracy: 0.6114 - val_loss: 1.8406 - learning_rate: 3.2467e-05
Epoch 158/300
785/785 - 87s - 111ms/step - accuracy: 0.4328 - loss: 2.6627 - val_accuracy: 0.6165 - val_loss: 1.8353 - learning_rate: 3.2467e-05
Epoch 159/300
785/785 - 86s - 110ms/step - accuracy: 0.4293 - loss: 2.6771 - val_accuracy: 0.6100 - val_loss: 1.8476 - learning_rate: 3.2467e-05
Epoch 160/300
785/785 - 84s - 107ms/step - accuracy: 0.4446 - loss: 2.6316 - val_accuracy: 0.6147 - val_loss: 1.8409 - learning_rate: 3.2467e-05
Epoch 161/300
785/785 - 91s - 116ms/step - accuracy: 0.4309 - loss: 2.6837 - val_accuracy: 0.6120 - val_loss: 1.8525 - learning_rate: 3.2467e-05
Epoch 162/300
785/785 - 138s - 176ms/step - accuracy: 0.4396 - loss: 2.6338 - val_accuracy: 0.6127 - val_loss: 1.8438 - learning_rate: 3.2467e-05
Epoch 163/300
785/785 - 86s - 110ms/step - accuracy: 0.4341 - loss: 2.6442 - val_accuracy: 0.6125 - val_loss: 1.8356 - learning_rate: 3.2467e-05
Epoch 164/300
785/785 - 86s - 110ms/step - accuracy: 0.4452 - loss: 2.6278 - val_accuracy: 0.6159 - val_loss: 1.8476 - learning_rate: 3.2467e-05
Epoch 165/300
785/785 - 88s - 111ms/step - accuracy: 0.4365 - loss: 2.6283 - val_accuracy: 0.6155 - val_loss: 1.8356 - learning_rate: 3.2467e-05
Epoch 166/300

Epoch 166: ReduceLROnPlateau reducing learning rate to 1.6233630958595313e-05.
785/785 - 93s - 118ms/step - accuracy: 0.4346 - loss: 2.6599 - val_accuracy: 0.6138 - val_loss: 1.8525 - learning_rate: 3.2467e-05
Epoch 167/300
785/785 - 86s - 109ms/step - accuracy: 0.4425 - loss: 2.6323 - val_accuracy: 0.6117 - val_loss: 1.8292 - learning_rate: 1.6234e-05
Epoch 168/300
785/785 - 84s - 107ms/step - accuracy: 0.4427 - loss: 2.6337 - val_accuracy: 0.6128 - val_loss: 1.8355 - learning_rate: 1.6234e-05
Epoch 169/300
785/785 - 86s - 110ms/step - accuracy: 0.4309 - loss: 2.6389 - val_accuracy: 0.6162 - val_loss: 1.8328 - learning_rate: 1.6234e-05
Epoch 170/300
785/785 - 87s - 111ms/step - accuracy: 0.4317 - loss: 2.6706 - val_accuracy: 0.6152 - val_loss: 1.8382 - learning_rate: 1.6234e-05
Epoch 171/300
785/785 - 85s - 108ms/step - accuracy: 0.4301 - loss: 2.6620 - val_accuracy: 0.6155 - val_loss: 1.8426 - learning_rate: 1.6234e-05
Epoch 172/300
785/785 - 86s - 110ms/step - accuracy: 0.4460 - loss: 2.6172 - val_accuracy: 0.6149 - val_loss: 1.8337 - learning_rate: 1.6234e-05
Epoch 173/300
785/785 - 85s - 109ms/step - accuracy: 0.4489 - loss: 2.6278 - val_accuracy: 0.6154 - val_loss: 1.8322 - learning_rate: 1.6234e-05
Epoch 174/300
785/785 - 86s - 110ms/step - accuracy: 0.4325 - loss: 2.6394 - val_accuracy: 0.6141 - val_loss: 1.8317 - learning_rate: 1.6234e-05
Epoch 175/300

Epoch 175: ReduceLROnPlateau reducing learning rate to 8.116815479297657e-06.
785/785 - 86s - 109ms/step - accuracy: 0.4427 - loss: 2.6247 - val_accuracy: 0.6152 - val_loss: 1.8344 - learning_rate: 1.6234e-05
Epoch 176/300
785/785 - 85s - 108ms/step - accuracy: 0.4443 - loss: 2.6262 - val_accuracy: 0.6159 - val_loss: 1.8343 - learning_rate: 8.1168e-06
Epoch 177/300
785/785 - 86s - 109ms/step - accuracy: 0.4392 - loss: 2.6335 - val_accuracy: 0.6168 - val_loss: 1.8340 - learning_rate: 8.1168e-06
Epoch 178/300
785/785 - 86s - 109ms/step - accuracy: 0.4322 - loss: 2.6741 - val_accuracy: 0.6165 - val_loss: 1.8308 - learning_rate: 8.1168e-06
Epoch 179/300
785/785 - 85s - 108ms/step - accuracy: 0.4459 - loss: 2.6461 - val_accuracy: 0.6163 - val_loss: 1.8371 - learning_rate: 8.1168e-06
Epoch 180/300
785/785 - 85s - 108ms/step - accuracy: 0.4436 - loss: 2.6426 - val_accuracy: 0.6168 - val_loss: 1.8363 - learning_rate: 8.1168e-06
Epoch 181/300
785/785 - 86s - 109ms/step - accuracy: 0.4349 - loss: 2.6354 - val_accuracy: 0.6160 - val_loss: 1.8372 - learning_rate: 8.1168e-06
Epoch 182/300
785/785 - 85s - 109ms/step - accuracy: 0.4412 - loss: 2.6097 - val_accuracy: 0.6141 - val_loss: 1.8350 - learning_rate: 8.1168e-06
Epoch 183/300

Epoch 183: ReduceLROnPlateau reducing learning rate to 4.058407739648828e-06.
785/785 - 85s - 109ms/step - accuracy: 0.4381 - loss: 2.6489 - val_accuracy: 0.6168 - val_loss: 1.8340 - learning_rate: 8.1168e-06
Epoch 183: early stopping
Restoring model weights from the end of the best epoch: 167.
Fold 0_2 Evaluation results: [1.8303277492523193, 0.6117216348648071]
              precision    recall  f1-score   support

        1820       0.72      0.81      0.76       306
        1821       0.93      0.86      0.90       296
        1822       0.00      0.00      0.00        10
        1823       0.00      0.00      0.00         7
        1824       0.00      0.00      0.00         5
        1825       0.00      0.00      0.00         9
        1826       0.14      0.08      0.10        13
        1827       0.78      0.75      0.76       120
        1828       1.00      0.08      0.14        13
        1829       0.73      0.32      0.44        25
        1830       0.52      0.70      0.60       277
        1831       0.78      0.91      0.84       680
        1832       0.89      0.71      0.79       369
        1833       0.74      0.92      0.82       100
        1834       0.41      0.71      0.52       149
        1835       0.00      0.00      0.00        11
        1836       0.00      0.00      0.00        18
        1837       0.67      0.11      0.20        35
        1838       0.00      0.00      0.00        21
        1839       0.00      0.00      0.00         3
        1840       0.48      0.58      0.52       198
        1841       0.69      0.60      0.64       515
        1842       0.50      0.42      0.46        26
        1843       0.67      0.08      0.14        25
        1844       0.00      0.00      0.00         1
        1845       0.00      0.00      0.00         2
        1846       0.50      0.06      0.10        36
        1847       0.00      0.00      0.00        12
        1848       0.18      0.22      0.20        23
        1849       0.33      0.03      0.06        29
        1850       0.37      0.57      0.45       246
        1851       0.76      0.70      0.73       391
        1852       0.00      0.00      0.00        40
        1853       0.00      0.00      0.00        32
        1854       0.00      0.00      0.00        13
        1855       0.35      0.10      0.16       109
        1856       0.62      0.54      0.58        56
        1857       0.44      0.53      0.48       157
        1858       0.00      0.00      0.00        13
        1859       0.00      0.00      0.00        15
        1860       0.30      0.46      0.36       335
        1861       0.80      0.79      0.79       427
        1862       0.32      0.07      0.12        96
        1863       0.36      0.55      0.44        94
        1864       0.39      0.39      0.39        76
        1865       0.69      0.32      0.44        28
        1866       0.00      0.00      0.00        27
        1867       0.71      0.09      0.17        53
        1868       0.60      0.07      0.13        40
        1869       0.00      0.00      0.00        26
        1870       0.38      0.61      0.46       145
        1871       0.68      0.79      0.73       242
        1872       0.37      0.35      0.36        31
        1873       0.14      0.02      0.04        49
        1874       0.80      0.15      0.25        27
        1875       0.33      0.30      0.31        61
        1876       0.98      0.85      0.91        48
        1877       0.33      0.32      0.33        22
        1878       0.69      0.46      0.55        39
        1879       0.00      0.00      0.00         7

    accuracy                           0.61      6279
   macro avg       0.38      0.30      0.30      6279
weighted avg       0.61      0.61      0.59      6279

Matthews Correlation Coefficient: 0.592
Macro avg F1: 0.303
Weighted avg F1: 0.590
Micro avg F1: 0.612
Top-3 Accuracy: 0.842
Top-5 Accuracy: 0.898
Micro ROC AUC  = 0.98
Macro ROC AUC (present classes) = 0.97
Classification MAE (in years): 3.09

Fold 0_2 Misclassification Analysis:
Near misses (within 2 years): 549 out of 2438 misclassifications (22.52%)
Big misses (greater than 10 years): 967
MAE with outliers: 3.09
MAE without outliers: 2.22 (improvement: 0.87)

10 Worst misclassifications:
Image: data/datasets/public/1820/1820_12wikimedia2.jpg, True: 1820, Predicted: 1871, Error: 51
Image: data/datasets/public/1820/1820_13wikimedia2.jpg, True: 1820, Predicted: 1871, Error: 51
Image: data/datasets/private/1870/1871_404etsy.jpg, True: 1871, Predicted: 1821, Error: 50
Image: data/datasets/public/1820/1820_037met.jpg, True: 1820, Predicted: 1870, Error: 50
Image: data/datasets/public/1870/1876_70washington.jpg, True: 1876, Predicted: 1826, Error: 50
Image: data/datasets/private/1820/1821_580etsy.jpg, True: 1821, Predicted: 1871, Error: 50
Image: data/datasets/public/1820/1820_021met.jpg, True: 1820, Predicted: 1870, Error: 50
Image: data/datasets/public/1820/1820_10wikimedia2.jpg, True: 1820, Predicted: 1870, Error: 50
Image: data/datasets/private/1820/1821_486etsy.jpg, True: 1821, Predicted: 1871, Error: 50
Image: data/datasets/public/1870/1879_9wikimedia2.jpg, True: 1879, Predicted: 1831, Error: 48
=== Training Alternative Model ===

===== Fine Tuning 9 layers! =====
Epoch 1/300
785/785 - 113s - 143ms/step - accuracy: 0.1185 - loss: 4.4647 - val_accuracy: 0.1844 - val_loss: 4.1415 - learning_rate: 2.5974e-04
Epoch 2/300
785/785 - 87s - 110ms/step - accuracy: 0.1680 - loss: 4.1754 - val_accuracy: 0.2306 - val_loss: 3.9501 - learning_rate: 2.5974e-04
Epoch 3/300
785/785 - 86s - 110ms/step - accuracy: 0.1983 - loss: 3.9700 - val_accuracy: 0.2709 - val_loss: 3.5275 - learning_rate: 2.5974e-04
Epoch 4/300
785/785 - 87s - 111ms/step - accuracy: 0.2112 - loss: 3.8225 - val_accuracy: 0.3287 - val_loss: 3.2957 - learning_rate: 2.5974e-04
Epoch 5/300
785/785 - 88s - 112ms/step - accuracy: 0.2376 - loss: 3.7407 - val_accuracy: 0.3325 - val_loss: 3.2036 - learning_rate: 2.5974e-04
Epoch 6/300
785/785 - 87s - 110ms/step - accuracy: 0.2515 - loss: 3.6397 - val_accuracy: 0.3570 - val_loss: 3.0082 - learning_rate: 2.5974e-04
Epoch 7/300
785/785 - 87s - 111ms/step - accuracy: 0.2658 - loss: 3.5454 - val_accuracy: 0.4006 - val_loss: 2.9475 - learning_rate: 2.5974e-04
Epoch 8/300
785/785 - 87s - 111ms/step - accuracy: 0.2755 - loss: 3.5014 - val_accuracy: 0.4274 - val_loss: 2.8958 - learning_rate: 2.5974e-04
Epoch 9/300
785/785 - 85s - 109ms/step - accuracy: 0.2875 - loss: 3.4421 - val_accuracy: 0.4127 - val_loss: 2.8454 - learning_rate: 2.5974e-04
Epoch 10/300
785/785 - 87s - 111ms/step - accuracy: 0.2881 - loss: 3.4275 - val_accuracy: 0.4315 - val_loss: 2.8028 - learning_rate: 2.5974e-04
Epoch 11/300
785/785 - 88s - 112ms/step - accuracy: 0.3074 - loss: 3.3744 - val_accuracy: 0.4449 - val_loss: 2.7664 - learning_rate: 2.5974e-04
Epoch 12/300
785/785 - 87s - 111ms/step - accuracy: 0.3110 - loss: 3.3575 - val_accuracy: 0.4565 - val_loss: 2.6612 - learning_rate: 2.5974e-04
Epoch 13/300
785/785 - 85s - 109ms/step - accuracy: 0.3122 - loss: 3.2882 - val_accuracy: 0.4535 - val_loss: 2.6432 - learning_rate: 2.5974e-04
Epoch 14/300
785/785 - 88s - 112ms/step - accuracy: 0.3209 - loss: 3.3163 - val_accuracy: 0.4583 - val_loss: 2.5785 - learning_rate: 2.5974e-04
Epoch 15/300
785/785 - 86s - 110ms/step - accuracy: 0.3238 - loss: 3.2544 - val_accuracy: 0.4728 - val_loss: 2.5757 - learning_rate: 2.5974e-04
Epoch 16/300
785/785 - 88s - 112ms/step - accuracy: 0.3279 - loss: 3.2431 - val_accuracy: 0.4632 - val_loss: 2.5671 - learning_rate: 2.5974e-04
Epoch 17/300
785/785 - 87s - 111ms/step - accuracy: 0.3340 - loss: 3.2400 - val_accuracy: 0.4803 - val_loss: 2.5020 - learning_rate: 2.5974e-04
Epoch 18/300
785/785 - 89s - 113ms/step - accuracy: 0.3427 - loss: 3.1945 - val_accuracy: 0.4874 - val_loss: 2.4458 - learning_rate: 2.5974e-04
Epoch 19/300
785/785 - 85s - 108ms/step - accuracy: 0.3418 - loss: 3.1436 - val_accuracy: 0.4903 - val_loss: 2.4180 - learning_rate: 2.5974e-04
Epoch 20/300
785/785 - 88s - 112ms/step - accuracy: 0.3372 - loss: 3.1573 - val_accuracy: 0.4874 - val_loss: 2.4752 - learning_rate: 2.5974e-04
Epoch 21/300
785/785 - 86s - 110ms/step - accuracy: 0.3505 - loss: 3.1421 - val_accuracy: 0.4954 - val_loss: 2.4070 - learning_rate: 2.5974e-04
Epoch 22/300
785/785 - 86s - 110ms/step - accuracy: 0.3464 - loss: 3.1563 - val_accuracy: 0.4990 - val_loss: 2.3991 - learning_rate: 2.5974e-04
Epoch 23/300
785/785 - 88s - 112ms/step - accuracy: 0.3588 - loss: 3.1102 - val_accuracy: 0.5057 - val_loss: 2.3362 - learning_rate: 2.5974e-04
Epoch 24/300
785/785 - 88s - 112ms/step - accuracy: 0.3491 - loss: 3.1623 - val_accuracy: 0.5135 - val_loss: 2.4174 - learning_rate: 2.5974e-04
Epoch 25/300
785/785 - 87s - 110ms/step - accuracy: 0.3526 - loss: 3.0967 - val_accuracy: 0.5164 - val_loss: 2.3409 - learning_rate: 2.5974e-04
Epoch 26/300
785/785 - 87s - 111ms/step - accuracy: 0.3630 - loss: 3.0982 - val_accuracy: 0.5045 - val_loss: 2.3358 - learning_rate: 2.5974e-04
Epoch 27/300
785/785 - 87s - 110ms/step - accuracy: 0.3512 - loss: 3.0920 - val_accuracy: 0.5049 - val_loss: 2.3369 - learning_rate: 2.5974e-04
Epoch 28/300
785/785 - 86s - 109ms/step - accuracy: 0.3558 - loss: 3.0710 - val_accuracy: 0.5068 - val_loss: 2.3241 - learning_rate: 2.5974e-04
Epoch 29/300
785/785 - 87s - 111ms/step - accuracy: 0.3625 - loss: 3.0892 - val_accuracy: 0.5003 - val_loss: 2.3117 - learning_rate: 2.5974e-04
Epoch 30/300
785/785 - 87s - 111ms/step - accuracy: 0.3609 - loss: 3.0902 - val_accuracy: 0.5283 - val_loss: 2.2924 - learning_rate: 2.5974e-04
Epoch 31/300
785/785 - 86s - 109ms/step - accuracy: 0.3746 - loss: 3.0200 - val_accuracy: 0.5269 - val_loss: 2.2611 - learning_rate: 2.5974e-04
Epoch 32/300
785/785 - 86s - 109ms/step - accuracy: 0.3733 - loss: 3.0155 - val_accuracy: 0.5194 - val_loss: 2.2835 - learning_rate: 2.5974e-04
Epoch 33/300
785/785 - 88s - 112ms/step - accuracy: 0.3782 - loss: 3.0422 - val_accuracy: 0.5368 - val_loss: 2.2513 - learning_rate: 2.5974e-04
Epoch 34/300
785/785 - 85s - 109ms/step - accuracy: 0.3719 - loss: 3.0284 - val_accuracy: 0.5191 - val_loss: 2.2373 - learning_rate: 2.5974e-04
Epoch 35/300
785/785 - 87s - 111ms/step - accuracy: 0.3657 - loss: 3.0296 - val_accuracy: 0.5189 - val_loss: 2.2481 - learning_rate: 2.5974e-04
Epoch 36/300
785/785 - 88s - 113ms/step - accuracy: 0.3803 - loss: 3.0179 - val_accuracy: 0.5354 - val_loss: 2.1920 - learning_rate: 2.5974e-04
Epoch 37/300
785/785 - 87s - 110ms/step - accuracy: 0.3677 - loss: 3.0205 - val_accuracy: 0.5223 - val_loss: 2.2137 - learning_rate: 2.5974e-04
Epoch 38/300
785/785 - 91s - 116ms/step - accuracy: 0.3787 - loss: 2.9932 - val_accuracy: 0.4992 - val_loss: 2.2767 - learning_rate: 2.5974e-04
Epoch 39/300
785/785 - 87s - 111ms/step - accuracy: 0.3711 - loss: 3.0168 - val_accuracy: 0.5357 - val_loss: 2.1848 - learning_rate: 2.5974e-04
Epoch 40/300
785/785 - 87s - 111ms/step - accuracy: 0.3782 - loss: 2.9848 - val_accuracy: 0.5338 - val_loss: 2.2505 - learning_rate: 2.5974e-04
Epoch 41/300
785/785 - 89s - 113ms/step - accuracy: 0.3719 - loss: 3.0320 - val_accuracy: 0.5234 - val_loss: 2.1482 - learning_rate: 2.5974e-04
Epoch 42/300
785/785 - 86s - 110ms/step - accuracy: 0.3759 - loss: 2.9892 - val_accuracy: 0.5326 - val_loss: 2.2073 - learning_rate: 2.5974e-04
Epoch 43/300
785/785 - 93s - 119ms/step - accuracy: 0.3800 - loss: 2.9816 - val_accuracy: 0.5365 - val_loss: 2.1285 - learning_rate: 2.5974e-04
Epoch 44/300
785/785 - 86s - 109ms/step - accuracy: 0.3943 - loss: 2.9235 - val_accuracy: 0.5443 - val_loss: 2.1686 - learning_rate: 2.5974e-04
Epoch 45/300
785/785 - 84s - 107ms/step - accuracy: 0.3860 - loss: 2.9244 - val_accuracy: 0.5505 - val_loss: 2.1353 - learning_rate: 2.5974e-04
Epoch 46/300
785/785 - 87s - 111ms/step - accuracy: 0.3927 - loss: 2.9441 - val_accuracy: 0.5341 - val_loss: 2.1534 - learning_rate: 2.5974e-04
Epoch 47/300
785/785 - 87s - 111ms/step - accuracy: 0.3860 - loss: 2.9443 - val_accuracy: 0.5357 - val_loss: 2.1871 - learning_rate: 2.5974e-04
Epoch 48/300
785/785 - 86s - 110ms/step - accuracy: 0.3860 - loss: 2.9370 - val_accuracy: 0.5404 - val_loss: 2.1470 - learning_rate: 2.5974e-04
Epoch 49/300
785/785 - 87s - 111ms/step - accuracy: 0.3926 - loss: 2.9351 - val_accuracy: 0.5373 - val_loss: 2.1423 - learning_rate: 2.5974e-04
Epoch 50/300
785/785 - 86s - 110ms/step - accuracy: 0.3888 - loss: 2.9299 - val_accuracy: 0.5455 - val_loss: 2.1203 - learning_rate: 2.5974e-04
Epoch 51/300
785/785 - 94s - 120ms/step - accuracy: 0.3857 - loss: 2.9428 - val_accuracy: 0.5525 - val_loss: 2.1004 - learning_rate: 2.5974e-04
Epoch 52/300
785/785 - 84s - 108ms/step - accuracy: 0.3860 - loss: 2.9529 - val_accuracy: 0.5411 - val_loss: 2.1189 - learning_rate: 2.5974e-04
Epoch 53/300
785/785 - 84s - 107ms/step - accuracy: 0.3880 - loss: 2.9128 - val_accuracy: 0.5425 - val_loss: 2.1199 - learning_rate: 2.5974e-04
Epoch 54/300
785/785 - 144s - 184ms/step - accuracy: 0.3907 - loss: 2.9128 - val_accuracy: 0.5446 - val_loss: 2.1148 - learning_rate: 2.5974e-04
Epoch 55/300
785/785 - 87s - 110ms/step - accuracy: 0.3819 - loss: 2.9170 - val_accuracy: 0.5592 - val_loss: 2.0823 - learning_rate: 2.5974e-04
Epoch 56/300
785/785 - 86s - 109ms/step - accuracy: 0.3846 - loss: 2.8908 - val_accuracy: 0.5373 - val_loss: 2.1881 - learning_rate: 2.5974e-04
Epoch 57/300
785/785 - 87s - 111ms/step - accuracy: 0.3966 - loss: 2.8954 - val_accuracy: 0.5586 - val_loss: 2.1059 - learning_rate: 2.5974e-04
Epoch 58/300
785/785 - 87s - 111ms/step - accuracy: 0.3888 - loss: 2.9282 - val_accuracy: 0.5422 - val_loss: 2.1000 - learning_rate: 2.5974e-04
Epoch 59/300
785/785 - 84s - 108ms/step - accuracy: 0.4012 - loss: 2.9052 - val_accuracy: 0.5567 - val_loss: 2.0600 - learning_rate: 2.5974e-04
Epoch 60/300
785/785 - 84s - 107ms/step - accuracy: 0.3886 - loss: 2.9230 - val_accuracy: 0.5511 - val_loss: 2.0950 - learning_rate: 2.5974e-04
Epoch 61/300
785/785 - 87s - 110ms/step - accuracy: 0.3816 - loss: 2.9440 - val_accuracy: 0.5522 - val_loss: 2.1183 - learning_rate: 2.5974e-04
Epoch 62/300
785/785 - 86s - 110ms/step - accuracy: 0.3939 - loss: 2.8985 - val_accuracy: 0.5639 - val_loss: 2.0856 - learning_rate: 2.5974e-04
Epoch 63/300
785/785 - 86s - 110ms/step - accuracy: 0.3908 - loss: 2.8959 - val_accuracy: 0.5650 - val_loss: 2.0953 - learning_rate: 2.5974e-04
Epoch 64/300
785/785 - 93s - 118ms/step - accuracy: 0.3985 - loss: 2.8799 - val_accuracy: 0.5514 - val_loss: 2.0739 - learning_rate: 2.5974e-04
Epoch 65/300
785/785 - 85s - 109ms/step - accuracy: 0.3862 - loss: 2.8862 - val_accuracy: 0.5669 - val_loss: 2.0931 - learning_rate: 2.5974e-04
Epoch 66/300
785/785 - 86s - 109ms/step - accuracy: 0.3974 - loss: 2.8757 - val_accuracy: 0.5554 - val_loss: 2.0841 - learning_rate: 2.5974e-04
Epoch 67/300

Epoch 67: ReduceLROnPlateau reducing learning rate to 0.0001298690476687625.
785/785 - 86s - 110ms/step - accuracy: 0.3958 - loss: 2.8938 - val_accuracy: 0.5455 - val_loss: 2.1031 - learning_rate: 2.5974e-04
Epoch 68/300
785/785 - 94s - 119ms/step - accuracy: 0.4176 - loss: 2.7749 - val_accuracy: 0.5672 - val_loss: 2.0466 - learning_rate: 1.2987e-04
Epoch 69/300
785/785 - 88s - 112ms/step - accuracy: 0.4101 - loss: 2.7978 - val_accuracy: 0.5581 - val_loss: 2.0234 - learning_rate: 1.2987e-04
Epoch 70/300
785/785 - 93s - 119ms/step - accuracy: 0.4093 - loss: 2.7741 - val_accuracy: 0.5686 - val_loss: 2.0333 - learning_rate: 1.2987e-04
Epoch 71/300
785/785 - 134s - 170ms/step - accuracy: 0.4093 - loss: 2.8277 - val_accuracy: 0.5592 - val_loss: 2.0229 - learning_rate: 1.2987e-04
Epoch 72/300
785/785 - 87s - 110ms/step - accuracy: 0.4165 - loss: 2.8029 - val_accuracy: 0.5564 - val_loss: 2.0175 - learning_rate: 1.2987e-04
Epoch 73/300
785/785 - 86s - 110ms/step - accuracy: 0.4216 - loss: 2.7924 - val_accuracy: 0.5667 - val_loss: 2.0298 - learning_rate: 1.2987e-04
Epoch 74/300
785/785 - 88s - 112ms/step - accuracy: 0.4109 - loss: 2.8174 - val_accuracy: 0.5591 - val_loss: 2.0214 - learning_rate: 1.2987e-04
Epoch 75/300
785/785 - 86s - 109ms/step - accuracy: 0.4142 - loss: 2.7816 - val_accuracy: 0.5578 - val_loss: 2.0270 - learning_rate: 1.2987e-04
Epoch 76/300
785/785 - 87s - 111ms/step - accuracy: 0.4112 - loss: 2.7698 - val_accuracy: 0.5686 - val_loss: 1.9865 - learning_rate: 1.2987e-04
Epoch 77/300
785/785 - 85s - 109ms/step - accuracy: 0.4181 - loss: 2.7540 - val_accuracy: 0.5656 - val_loss: 2.0114 - learning_rate: 1.2987e-04
Epoch 78/300
785/785 - 87s - 110ms/step - accuracy: 0.4171 - loss: 2.7705 - val_accuracy: 0.5659 - val_loss: 1.9953 - learning_rate: 1.2987e-04
Epoch 79/300
785/785 - 87s - 110ms/step - accuracy: 0.4165 - loss: 2.7659 - val_accuracy: 0.5669 - val_loss: 2.0079 - learning_rate: 1.2987e-04
Epoch 80/300
785/785 - 87s - 111ms/step - accuracy: 0.4212 - loss: 2.7462 - val_accuracy: 0.5589 - val_loss: 2.0136 - learning_rate: 1.2987e-04
Epoch 81/300
785/785 - 87s - 111ms/step - accuracy: 0.4219 - loss: 2.7896 - val_accuracy: 0.5607 - val_loss: 2.0054 - learning_rate: 1.2987e-04
Epoch 82/300
785/785 - 87s - 110ms/step - accuracy: 0.4174 - loss: 2.7762 - val_accuracy: 0.5685 - val_loss: 2.0015 - learning_rate: 1.2987e-04
Epoch 83/300
785/785 - 93s - 119ms/step - accuracy: 0.4225 - loss: 2.7557 - val_accuracy: 0.5521 - val_loss: 2.0014 - learning_rate: 1.2987e-04
Epoch 84/300

Epoch 84: ReduceLROnPlateau reducing learning rate to 6.493452383438125e-05.
785/785 - 86s - 109ms/step - accuracy: 0.4181 - loss: 2.7606 - val_accuracy: 0.5685 - val_loss: 2.0059 - learning_rate: 1.2987e-04
Epoch 85/300
785/785 - 86s - 110ms/step - accuracy: 0.4247 - loss: 2.7048 - val_accuracy: 0.5726 - val_loss: 2.0005 - learning_rate: 6.4935e-05
Epoch 86/300
785/785 - 87s - 110ms/step - accuracy: 0.4243 - loss: 2.6946 - val_accuracy: 0.5710 - val_loss: 1.9610 - learning_rate: 6.4935e-05
Epoch 87/300
785/785 - 85s - 108ms/step - accuracy: 0.4214 - loss: 2.7452 - val_accuracy: 0.5734 - val_loss: 1.9838 - learning_rate: 6.4935e-05
Epoch 88/300
785/785 - 87s - 111ms/step - accuracy: 0.4208 - loss: 2.7296 - val_accuracy: 0.5670 - val_loss: 1.9787 - learning_rate: 6.4935e-05
Epoch 89/300
785/785 - 86s - 110ms/step - accuracy: 0.4306 - loss: 2.7052 - val_accuracy: 0.5785 - val_loss: 1.9564 - learning_rate: 6.4935e-05
Epoch 90/300
785/785 - 86s - 109ms/step - accuracy: 0.4244 - loss: 2.7444 - val_accuracy: 0.5748 - val_loss: 1.9821 - learning_rate: 6.4935e-05
Epoch 91/300
785/785 - 87s - 110ms/step - accuracy: 0.4232 - loss: 2.6917 - val_accuracy: 0.5686 - val_loss: 1.9652 - learning_rate: 6.4935e-05
Epoch 92/300
785/785 - 93s - 119ms/step - accuracy: 0.4174 - loss: 2.7186 - val_accuracy: 0.5739 - val_loss: 1.9680 - learning_rate: 6.4935e-05
Epoch 93/300
785/785 - 88s - 112ms/step - accuracy: 0.4343 - loss: 2.7127 - val_accuracy: 0.5721 - val_loss: 1.9531 - learning_rate: 6.4935e-05
Epoch 94/300
785/785 - 86s - 110ms/step - accuracy: 0.4359 - loss: 2.6904 - val_accuracy: 0.5764 - val_loss: 1.9743 - learning_rate: 6.4935e-05
Epoch 95/300
785/785 - 143s - 183ms/step - accuracy: 0.4271 - loss: 2.6948 - val_accuracy: 0.5729 - val_loss: 1.9571 - learning_rate: 6.4935e-05
Epoch 96/300
785/785 - 86s - 110ms/step - accuracy: 0.4235 - loss: 2.7342 - val_accuracy: 0.5693 - val_loss: 1.9577 - learning_rate: 6.4935e-05
Epoch 97/300
785/785 - 85s - 109ms/step - accuracy: 0.4174 - loss: 2.7160 - val_accuracy: 0.5709 - val_loss: 1.9836 - learning_rate: 6.4935e-05
Epoch 98/300
785/785 - 88s - 112ms/step - accuracy: 0.4240 - loss: 2.7037 - val_accuracy: 0.5768 - val_loss: 1.9412 - learning_rate: 6.4935e-05
Epoch 99/300
785/785 - 87s - 111ms/step - accuracy: 0.4174 - loss: 2.7188 - val_accuracy: 0.5761 - val_loss: 1.9413 - learning_rate: 6.4935e-05
Epoch 100/300
785/785 - 89s - 113ms/step - accuracy: 0.4187 - loss: 2.7289 - val_accuracy: 0.5806 - val_loss: 1.9362 - learning_rate: 6.4935e-05
Epoch 101/300
785/785 - 86s - 109ms/step - accuracy: 0.4236 - loss: 2.7089 - val_accuracy: 0.5748 - val_loss: 1.9516 - learning_rate: 6.4935e-05
Epoch 102/300
785/785 - 87s - 111ms/step - accuracy: 0.4303 - loss: 2.7006 - val_accuracy: 0.5752 - val_loss: 1.9529 - learning_rate: 6.4935e-05
Epoch 103/300
785/785 - 85s - 108ms/step - accuracy: 0.4362 - loss: 2.6964 - val_accuracy: 0.5755 - val_loss: 1.9470 - learning_rate: 6.4935e-05
Epoch 104/300
785/785 - 88s - 112ms/step - accuracy: 0.4287 - loss: 2.6866 - val_accuracy: 0.5763 - val_loss: 1.9452 - learning_rate: 6.4935e-05
Epoch 105/300
785/785 - 88s - 112ms/step - accuracy: 0.4356 - loss: 2.6671 - val_accuracy: 0.5740 - val_loss: 1.9388 - learning_rate: 6.4935e-05
Epoch 106/300
785/785 - 86s - 110ms/step - accuracy: 0.4251 - loss: 2.6959 - val_accuracy: 0.5795 - val_loss: 1.9426 - learning_rate: 6.4935e-05
Epoch 107/300
785/785 - 94s - 119ms/step - accuracy: 0.4404 - loss: 2.6756 - val_accuracy: 0.5748 - val_loss: 1.9464 - learning_rate: 6.4935e-05
Epoch 108/300
785/785 - 86s - 110ms/step - accuracy: 0.4349 - loss: 2.6807 - val_accuracy: 0.5756 - val_loss: 1.9287 - learning_rate: 6.4935e-05
Epoch 109/300
785/785 - 87s - 111ms/step - accuracy: 0.4249 - loss: 2.7235 - val_accuracy: 0.5842 - val_loss: 1.9532 - learning_rate: 6.4935e-05
Epoch 110/300
785/785 - 87s - 111ms/step - accuracy: 0.4314 - loss: 2.6754 - val_accuracy: 0.5814 - val_loss: 1.9336 - learning_rate: 6.4935e-05
Epoch 111/300
785/785 - 88s - 112ms/step - accuracy: 0.4321 - loss: 2.6809 - val_accuracy: 0.5795 - val_loss: 1.9318 - learning_rate: 6.4935e-05
Epoch 112/300
785/785 - 87s - 110ms/step - accuracy: 0.4335 - loss: 2.6948 - val_accuracy: 0.5758 - val_loss: 1.9251 - learning_rate: 6.4935e-05
Epoch 113/300
785/785 - 87s - 110ms/step - accuracy: 0.4314 - loss: 2.6928 - val_accuracy: 0.5830 - val_loss: 1.9405 - learning_rate: 6.4935e-05
Epoch 114/300
785/785 - 86s - 109ms/step - accuracy: 0.4356 - loss: 2.6667 - val_accuracy: 0.5717 - val_loss: 1.9521 - learning_rate: 6.4935e-05
Epoch 115/300
785/785 - 87s - 111ms/step - accuracy: 0.4273 - loss: 2.6962 - val_accuracy: 0.5799 - val_loss: 1.9280 - learning_rate: 6.4935e-05
Epoch 116/300
785/785 - 86s - 109ms/step - accuracy: 0.4244 - loss: 2.7055 - val_accuracy: 0.5863 - val_loss: 1.9403 - learning_rate: 6.4935e-05
Epoch 117/300
785/785 - 87s - 111ms/step - accuracy: 0.4306 - loss: 2.6776 - val_accuracy: 0.5795 - val_loss: 1.9337 - learning_rate: 6.4935e-05
Epoch 118/300
785/785 - 143s - 182ms/step - accuracy: 0.4300 - loss: 2.6874 - val_accuracy: 0.5796 - val_loss: 1.9307 - learning_rate: 6.4935e-05
Epoch 119/300
785/785 - 93s - 118ms/step - accuracy: 0.4326 - loss: 2.6417 - val_accuracy: 0.5745 - val_loss: 1.9416 - learning_rate: 6.4935e-05
Epoch 120/300

Epoch 120: ReduceLROnPlateau reducing learning rate to 3.2467261917190626e-05.
785/785 - 87s - 111ms/step - accuracy: 0.4394 - loss: 2.6683 - val_accuracy: 0.5838 - val_loss: 1.9260 - learning_rate: 6.4935e-05
Epoch 121/300
785/785 - 87s - 110ms/step - accuracy: 0.4362 - loss: 2.6644 - val_accuracy: 0.5828 - val_loss: 1.9160 - learning_rate: 3.2467e-05
Epoch 122/300
785/785 - 88s - 112ms/step - accuracy: 0.4361 - loss: 2.6751 - val_accuracy: 0.5839 - val_loss: 1.9195 - learning_rate: 3.2467e-05
Epoch 123/300
785/785 - 87s - 111ms/step - accuracy: 0.4388 - loss: 2.6787 - val_accuracy: 0.5795 - val_loss: 1.9279 - learning_rate: 3.2467e-05
Epoch 124/300
785/785 - 85s - 109ms/step - accuracy: 0.4405 - loss: 2.6698 - val_accuracy: 0.5799 - val_loss: 1.9134 - learning_rate: 3.2467e-05
Epoch 125/300
785/785 - 88s - 112ms/step - accuracy: 0.4407 - loss: 2.6718 - val_accuracy: 0.5791 - val_loss: 1.9166 - learning_rate: 3.2467e-05
Epoch 126/300
785/785 - 86s - 110ms/step - accuracy: 0.4329 - loss: 2.6775 - val_accuracy: 0.5814 - val_loss: 1.9187 - learning_rate: 3.2467e-05
Epoch 127/300
785/785 - 142s - 181ms/step - accuracy: 0.4400 - loss: 2.6532 - val_accuracy: 0.5857 - val_loss: 1.9158 - learning_rate: 3.2467e-05
Epoch 128/300
785/785 - 87s - 111ms/step - accuracy: 0.4399 - loss: 2.6607 - val_accuracy: 0.5857 - val_loss: 1.9135 - learning_rate: 3.2467e-05
Epoch 129/300
785/785 - 87s - 111ms/step - accuracy: 0.4292 - loss: 2.6891 - val_accuracy: 0.5798 - val_loss: 1.9242 - learning_rate: 3.2467e-05
Epoch 130/300
785/785 - 87s - 111ms/step - accuracy: 0.4332 - loss: 2.6837 - val_accuracy: 0.5790 - val_loss: 1.9157 - learning_rate: 3.2467e-05
Epoch 131/300
785/785 - 87s - 111ms/step - accuracy: 0.4369 - loss: 2.6443 - val_accuracy: 0.5788 - val_loss: 1.9146 - learning_rate: 3.2467e-05
Epoch 132/300

Epoch 132: ReduceLROnPlateau reducing learning rate to 1.6233630958595313e-05.
785/785 - 86s - 110ms/step - accuracy: 0.4431 - loss: 2.6415 - val_accuracy: 0.5889 - val_loss: 1.9184 - learning_rate: 3.2467e-05
Epoch 133/300
785/785 - 85s - 108ms/step - accuracy: 0.4423 - loss: 2.6421 - val_accuracy: 0.5836 - val_loss: 1.9125 - learning_rate: 1.6234e-05
Epoch 134/300
785/785 - 88s - 112ms/step - accuracy: 0.4306 - loss: 2.6787 - val_accuracy: 0.5846 - val_loss: 1.9091 - learning_rate: 1.6234e-05
Epoch 135/300
785/785 - 86s - 109ms/step - accuracy: 0.4367 - loss: 2.6685 - val_accuracy: 0.5820 - val_loss: 1.9067 - learning_rate: 1.6234e-05
Epoch 136/300
785/785 - 94s - 119ms/step - accuracy: 0.4341 - loss: 2.6485 - val_accuracy: 0.5857 - val_loss: 1.9169 - learning_rate: 1.6234e-05
Epoch 137/300
785/785 - 86s - 109ms/step - accuracy: 0.4388 - loss: 2.6706 - val_accuracy: 0.5825 - val_loss: 1.9123 - learning_rate: 1.6234e-05
Epoch 138/300
785/785 - 92s - 118ms/step - accuracy: 0.4432 - loss: 2.6424 - val_accuracy: 0.5861 - val_loss: 1.9181 - learning_rate: 1.6234e-05
Epoch 139/300
785/785 - 91s - 117ms/step - accuracy: 0.4372 - loss: 2.6486 - val_accuracy: 0.5865 - val_loss: 1.9203 - learning_rate: 1.6234e-05
Epoch 140/300
785/785 - 91s - 117ms/step - accuracy: 0.4378 - loss: 2.6506 - val_accuracy: 0.5812 - val_loss: 1.9162 - learning_rate: 1.6234e-05
Epoch 141/300
785/785 - 94s - 120ms/step - accuracy: 0.4380 - loss: 2.6632 - val_accuracy: 0.5850 - val_loss: 1.9132 - learning_rate: 1.6234e-05
Epoch 142/300
785/785 - 92s - 117ms/step - accuracy: 0.4327 - loss: 2.6585 - val_accuracy: 0.5854 - val_loss: 1.9130 - learning_rate: 1.6234e-05
Epoch 143/300

Epoch 143: ReduceLROnPlateau reducing learning rate to 8.116815479297657e-06.
785/785 - 93s - 119ms/step - accuracy: 0.4386 - loss: 2.6657 - val_accuracy: 0.5881 - val_loss: 1.9073 - learning_rate: 1.6234e-05
Epoch 144/300
785/785 - 92s - 118ms/step - accuracy: 0.4381 - loss: 2.6293 - val_accuracy: 0.5841 - val_loss: 1.9080 - learning_rate: 8.1168e-06
Epoch 145/300
785/785 - 92s - 117ms/step - accuracy: 0.4439 - loss: 2.6576 - val_accuracy: 0.5841 - val_loss: 1.9068 - learning_rate: 8.1168e-06
Epoch 146/300
785/785 - 92s - 118ms/step - accuracy: 0.4424 - loss: 2.6675 - val_accuracy: 0.5865 - val_loss: 1.9058 - learning_rate: 8.1168e-06
Epoch 147/300
785/785 - 92s - 117ms/step - accuracy: 0.4450 - loss: 2.6557 - val_accuracy: 0.5830 - val_loss: 1.9017 - learning_rate: 8.1168e-06
Epoch 148/300
785/785 - 93s - 118ms/step - accuracy: 0.4364 - loss: 2.6380 - val_accuracy: 0.5818 - val_loss: 1.9101 - learning_rate: 8.1168e-06
Epoch 149/300
785/785 - 94s - 120ms/step - accuracy: 0.4429 - loss: 2.6501 - val_accuracy: 0.5842 - val_loss: 1.9075 - learning_rate: 8.1168e-06
Epoch 150/300
785/785 - 92s - 117ms/step - accuracy: 0.4485 - loss: 2.6389 - val_accuracy: 0.5842 - val_loss: 1.9075 - learning_rate: 8.1168e-06
Epoch 151/300
785/785 - 93s - 119ms/step - accuracy: 0.4369 - loss: 2.6460 - val_accuracy: 0.5830 - val_loss: 1.9074 - learning_rate: 8.1168e-06
Epoch 152/300
785/785 - 91s - 116ms/step - accuracy: 0.4442 - loss: 2.6400 - val_accuracy: 0.5852 - val_loss: 1.9127 - learning_rate: 8.1168e-06
Epoch 153/300
785/785 - 94s - 119ms/step - accuracy: 0.4455 - loss: 2.6153 - val_accuracy: 0.5834 - val_loss: 1.9125 - learning_rate: 8.1168e-06
Epoch 154/300
785/785 - 93s - 118ms/step - accuracy: 0.4391 - loss: 2.6491 - val_accuracy: 0.5842 - val_loss: 1.9090 - learning_rate: 8.1168e-06
Epoch 155/300

Epoch 155: ReduceLROnPlateau reducing learning rate to 4.058407739648828e-06.
785/785 - 93s - 119ms/step - accuracy: 0.4351 - loss: 2.6461 - val_accuracy: 0.5846 - val_loss: 1.9051 - learning_rate: 8.1168e-06
Epoch 156/300
785/785 - 92s - 118ms/step - accuracy: 0.4455 - loss: 2.6264 - val_accuracy: 0.5855 - val_loss: 1.9044 - learning_rate: 4.0584e-06
Epoch 157/300
785/785 - 92s - 117ms/step - accuracy: 0.4478 - loss: 2.6777 - val_accuracy: 0.5822 - val_loss: 1.9016 - learning_rate: 4.0584e-06
Epoch 158/300
785/785 - 95s - 120ms/step - accuracy: 0.4354 - loss: 2.6802 - val_accuracy: 0.5852 - val_loss: 1.9041 - learning_rate: 4.0584e-06
Epoch 159/300
785/785 - 90s - 115ms/step - accuracy: 0.4341 - loss: 2.6536 - val_accuracy: 0.5861 - val_loss: 1.9018 - learning_rate: 4.0584e-06
Epoch 160/300
785/785 - 93s - 119ms/step - accuracy: 0.4478 - loss: 2.6165 - val_accuracy: 0.5861 - val_loss: 1.9013 - learning_rate: 4.0584e-06
Epoch 161/300
785/785 - 93s - 118ms/step - accuracy: 0.4413 - loss: 2.6517 - val_accuracy: 0.5839 - val_loss: 1.8999 - learning_rate: 4.0584e-06
Epoch 162/300
785/785 - 93s - 119ms/step - accuracy: 0.4456 - loss: 2.6530 - val_accuracy: 0.5858 - val_loss: 1.9011 - learning_rate: 4.0584e-06
Epoch 163/300
785/785 - 92s - 117ms/step - accuracy: 0.4351 - loss: 2.6460 - val_accuracy: 0.5863 - val_loss: 1.9044 - learning_rate: 4.0584e-06
Epoch 164/300
785/785 - 93s - 119ms/step - accuracy: 0.4392 - loss: 2.6552 - val_accuracy: 0.5858 - val_loss: 1.9044 - learning_rate: 4.0584e-06
Epoch 165/300
785/785 - 94s - 120ms/step - accuracy: 0.4397 - loss: 2.6244 - val_accuracy: 0.5858 - val_loss: 1.9035 - learning_rate: 4.0584e-06
Epoch 166/300
785/785 - 91s - 116ms/step - accuracy: 0.4400 - loss: 2.6049 - val_accuracy: 0.5866 - val_loss: 1.9014 - learning_rate: 4.0584e-06
Epoch 167/300
785/785 - 94s - 120ms/step - accuracy: 0.4447 - loss: 2.6197 - val_accuracy: 0.5865 - val_loss: 1.9088 - learning_rate: 4.0584e-06
Epoch 168/300
785/785 - 91s - 116ms/step - accuracy: 0.4424 - loss: 2.6544 - val_accuracy: 0.5841 - val_loss: 1.9086 - learning_rate: 4.0584e-06
Epoch 169/300

Epoch 169: ReduceLROnPlateau reducing learning rate to 2.029203869824414e-06.
785/785 - 94s - 120ms/step - accuracy: 0.4332 - loss: 2.6796 - val_accuracy: 0.5868 - val_loss: 1.9026 - learning_rate: 4.0584e-06
Epoch 170/300
785/785 - 92s - 117ms/step - accuracy: 0.4357 - loss: 2.6280 - val_accuracy: 0.5857 - val_loss: 1.9017 - learning_rate: 2.0292e-06
Epoch 171/300
785/785 - 93s - 118ms/step - accuracy: 0.4346 - loss: 2.6403 - val_accuracy: 0.5857 - val_loss: 1.9043 - learning_rate: 2.0292e-06
Epoch 172/300
785/785 - 92s - 117ms/step - accuracy: 0.4536 - loss: 2.5966 - val_accuracy: 0.5858 - val_loss: 1.9021 - learning_rate: 2.0292e-06
Epoch 173/300
785/785 - 91s - 116ms/step - accuracy: 0.4389 - loss: 2.6477 - val_accuracy: 0.5849 - val_loss: 1.9036 - learning_rate: 2.0292e-06
Epoch 174/300
785/785 - 93s - 119ms/step - accuracy: 0.4496 - loss: 2.6050 - val_accuracy: 0.5861 - val_loss: 1.9057 - learning_rate: 2.0292e-06
Epoch 175/300
785/785 - 93s - 119ms/step - accuracy: 0.4383 - loss: 2.6255 - val_accuracy: 0.5844 - val_loss: 1.9035 - learning_rate: 2.0292e-06
Epoch 176/300
785/785 - 140s - 179ms/step - accuracy: 0.4396 - loss: 2.6284 - val_accuracy: 0.5860 - val_loss: 1.9015 - learning_rate: 2.0292e-06
Epoch 177/300
785/785 - 93s - 119ms/step - accuracy: 0.4442 - loss: 2.6288 - val_accuracy: 0.5866 - val_loss: 1.8987 - learning_rate: 2.0292e-06
Epoch 178/300
785/785 - 93s - 119ms/step - accuracy: 0.4429 - loss: 2.6004 - val_accuracy: 0.5868 - val_loss: 1.9002 - learning_rate: 2.0292e-06
Epoch 179/300
785/785 - 91s - 116ms/step - accuracy: 0.4396 - loss: 2.6323 - val_accuracy: 0.5877 - val_loss: 1.8971 - learning_rate: 2.0292e-06
Epoch 180/300
785/785 - 94s - 119ms/step - accuracy: 0.4329 - loss: 2.6600 - val_accuracy: 0.5869 - val_loss: 1.9006 - learning_rate: 2.0292e-06
Epoch 181/300
785/785 - 93s - 118ms/step - accuracy: 0.4392 - loss: 2.5999 - val_accuracy: 0.5865 - val_loss: 1.9032 - learning_rate: 2.0292e-06
Epoch 182/300
785/785 - 92s - 118ms/step - accuracy: 0.4419 - loss: 2.6651 - val_accuracy: 0.5868 - val_loss: 1.9008 - learning_rate: 2.0292e-06
Epoch 183/300
785/785 - 91s - 116ms/step - accuracy: 0.4434 - loss: 2.6369 - val_accuracy: 0.5857 - val_loss: 1.8978 - learning_rate: 2.0292e-06
Epoch 184/300
785/785 - 97s - 124ms/step - accuracy: 0.4483 - loss: 2.6471 - val_accuracy: 0.5854 - val_loss: 1.8960 - learning_rate: 2.0292e-06
Epoch 185/300
785/785 - 92s - 118ms/step - accuracy: 0.4405 - loss: 2.6180 - val_accuracy: 0.5852 - val_loss: 1.9013 - learning_rate: 2.0292e-06
Epoch 186/300
785/785 - 94s - 119ms/step - accuracy: 0.4407 - loss: 2.5997 - val_accuracy: 0.5860 - val_loss: 1.8946 - learning_rate: 2.0292e-06
Epoch 187/300
785/785 - 94s - 120ms/step - accuracy: 0.4373 - loss: 2.6549 - val_accuracy: 0.5850 - val_loss: 1.8999 - learning_rate: 2.0292e-06
Epoch 188/300
785/785 - 94s - 119ms/step - accuracy: 0.4378 - loss: 2.6529 - val_accuracy: 0.5881 - val_loss: 1.8987 - learning_rate: 2.0292e-06
Epoch 189/300
785/785 - 92s - 117ms/step - accuracy: 0.4408 - loss: 2.6468 - val_accuracy: 0.5874 - val_loss: 1.8965 - learning_rate: 2.0292e-06
Epoch 190/300
785/785 - 93s - 118ms/step - accuracy: 0.4415 - loss: 2.6399 - val_accuracy: 0.5874 - val_loss: 1.9001 - learning_rate: 2.0292e-06
Epoch 191/300
785/785 - 96s - 122ms/step - accuracy: 0.4427 - loss: 2.6579 - val_accuracy: 0.5868 - val_loss: 1.9020 - learning_rate: 2.0292e-06
Epoch 192/300
785/785 - 93s - 119ms/step - accuracy: 0.4437 - loss: 2.6193 - val_accuracy: 0.5861 - val_loss: 1.9056 - learning_rate: 2.0292e-06
Epoch 193/300
785/785 - 97s - 123ms/step - accuracy: 0.4303 - loss: 2.6440 - val_accuracy: 0.5863 - val_loss: 1.8982 - learning_rate: 2.0292e-06
Epoch 194/300

Epoch 194: ReduceLROnPlateau reducing learning rate to 1.014601934912207e-06.
785/785 - 95s - 121ms/step - accuracy: 0.4478 - loss: 2.6217 - val_accuracy: 0.5873 - val_loss: 1.9022 - learning_rate: 2.0292e-06
Epoch 195/300
785/785 - 95s - 121ms/step - accuracy: 0.4517 - loss: 2.6416 - val_accuracy: 0.5869 - val_loss: 1.9008 - learning_rate: 1.0146e-06
Epoch 196/300
785/785 - 96s - 122ms/step - accuracy: 0.4413 - loss: 2.6503 - val_accuracy: 0.5866 - val_loss: 1.8981 - learning_rate: 1.0146e-06
Epoch 197/300
785/785 - 96s - 122ms/step - accuracy: 0.4356 - loss: 2.6530 - val_accuracy: 0.5869 - val_loss: 1.9020 - learning_rate: 1.0146e-06
Epoch 198/300
785/785 - 92s - 117ms/step - accuracy: 0.4461 - loss: 2.6575 - val_accuracy: 0.5871 - val_loss: 1.9018 - learning_rate: 1.0146e-06
Epoch 199/300
785/785 - 96s - 122ms/step - accuracy: 0.4461 - loss: 2.6314 - val_accuracy: 0.5877 - val_loss: 1.9023 - learning_rate: 1.0146e-06
Epoch 200/300
785/785 - 100s - 127ms/step - accuracy: 0.4456 - loss: 2.6457 - val_accuracy: 0.5876 - val_loss: 1.9007 - learning_rate: 1.0146e-06
Epoch 201/300
785/785 - 95s - 121ms/step - accuracy: 0.4351 - loss: 2.6157 - val_accuracy: 0.5890 - val_loss: 1.9016 - learning_rate: 1.0146e-06
Epoch 202/300

Epoch 202: ReduceLROnPlateau reducing learning rate to 1e-06.
785/785 - 89s - 114ms/step - accuracy: 0.4474 - loss: 2.6309 - val_accuracy: 0.5874 - val_loss: 1.9034 - learning_rate: 1.0146e-06
Epoch 202: early stopping
Restoring model weights from the end of the best epoch: 186.
Fold 0_1 Evaluation results: [1.897392988204956, 0.5859872698783875]
              precision    recall  f1-score   support

        1820       0.67      0.75      0.71       311
        1821       0.87      0.80      0.83       278
        1822       0.00      0.00      0.00         4
        1823       0.00      0.00      0.00         6
        1824       0.00      0.00      0.00         5
        1825       0.00      0.00      0.00        12
        1826       0.00      0.00      0.00        10
        1827       0.71      0.75      0.73       130
        1828       0.50      0.75      0.60         4
        1829       1.00      0.11      0.19        19
        1830       0.48      0.64      0.55       283
        1831       0.72      0.93      0.81       664
        1832       0.78      0.71      0.74       310
        1833       0.79      0.89      0.84        90
        1834       0.48      0.64      0.55       143
        1835       0.00      0.00      0.00        10
        1836       0.00      0.00      0.00        17
        1837       0.27      0.41      0.33        29
        1838       0.00      0.00      0.00        17
        1839       0.00      0.00      0.00         5
        1840       0.50      0.58      0.54       229
        1841       0.74      0.51      0.60       560
        1842       0.75      0.31      0.44        29
        1843       0.00      0.00      0.00        33
        1844       0.00      0.00      0.00         2
        1845       0.00      0.00      0.00         9
        1846       0.30      0.14      0.19        21
        1847       0.00      0.00      0.00         8
        1848       0.00      0.00      0.00        32
        1849       0.14      0.04      0.06        24
        1850       0.32      0.61      0.42       231
        1851       0.74      0.74      0.74       379
        1852       0.00      0.00      0.00        34
        1853       0.00      0.00      0.00        31
        1854       0.00      0.00      0.00        11
        1855       0.41      0.14      0.21       123
        1856       0.62      0.41      0.49        64
        1857       0.42      0.69      0.52       150
        1858       0.00      0.00      0.00        10
        1859       0.00      0.00      0.00        10
        1860       0.28      0.38      0.32       311
        1861       0.82      0.80      0.81       423
        1862       0.10      0.02      0.04        93
        1863       0.31      0.51      0.39        90
        1864       0.41      0.41      0.41        94
        1865       0.00      0.00      0.00        38
        1866       0.50      0.20      0.29        30
        1867       0.18      0.06      0.09        51
        1868       0.00      0.00      0.00        33
        1869       0.00      0.00      0.00        27
        1870       0.36      0.57      0.44       162
        1871       0.66      0.78      0.71       249
        1872       0.33      0.12      0.18        40
        1873       1.00      0.04      0.07        57
        1874       0.25      0.04      0.07        25
        1875       0.24      0.15      0.19        78
        1876       0.81      0.88      0.84        52
        1877       1.00      0.06      0.12        32
        1878       0.39      0.25      0.31        51
        1879       0.00      0.00      0.00         7

    accuracy                           0.59      6280
   macro avg       0.33      0.28      0.27      6280
weighted avg       0.57      0.59      0.56      6280

Matthews Correlation Coefficient: 0.565
Macro avg F1: 0.273
Weighted avg F1: 0.558
Micro avg F1: 0.586
Top-3 Accuracy: 0.832
Top-5 Accuracy: 0.894
Micro ROC AUC  = 0.98
Macro ROC AUC (present classes) = 0.97
Classification MAE (in years): 3.39

Fold 0_1 Misclassification Analysis:
Near misses (within 2 years): 569 out of 2600 misclassifications (21.88%)
Big misses (greater than 10 years): 1095
MAE with outliers: 3.39
MAE without outliers: 2.43 (improvement: 0.96)

10 Worst misclassifications:
Image: data/datasets/public/1870/1879_26wikimedia2.jpg, True: 1879, Predicted: 1820, Error: 59
Image: data/datasets/public/1870/1877_035met.jpg, True: 1877, Predicted: 1820, Error: 57
Image: data/datasets/public/1870/1877_033met.jpg, True: 1877, Predicted: 1820, Error: 57
Image: data/datasets/public/1870/1876_53washington.jpg, True: 1876, Predicted: 1820, Error: 56
Image: data/datasets/private/1870/1871_114etsy.jpg, True: 1871, Predicted: 1820, Error: 51
Image: data/datasets/private/1820/1820_034_Zrzut ekranu 2022-07-26 203655.png, True: 1820, Predicted: 1870, Error: 50
Image: data/datasets/private/1870/1871_415etsy.jpg, True: 1871, Predicted: 1821, Error: 50
Image: data/datasets/public/1870/1870_79wikimedia2.jpg, True: 1870, Predicted: 1820, Error: 50
Image: data/datasets/private/1870/1871_358etsy.jpg, True: 1871, Predicted: 1821, Error: 50
Image: data/datasets/public/1870/1870_75wikimedia2.jpg, True: 1870, Predicted: 1820, Error: 50

===== Fine Tuning 9 layers! =====
Epoch 1/300
785/785 - 113s - 144ms/step - accuracy: 0.1143 - loss: 4.4754 - val_accuracy: 0.2021 - val_loss: 4.3312 - learning_rate: 2.5974e-04
Epoch 2/300
785/785 - 90s - 115ms/step - accuracy: 0.1576 - loss: 4.2232 - val_accuracy: 0.2879 - val_loss: 4.0311 - learning_rate: 2.5974e-04
Epoch 3/300
785/785 - 88s - 112ms/step - accuracy: 0.1960 - loss: 3.9932 - val_accuracy: 0.3056 - val_loss: 3.6489 - learning_rate: 2.5974e-04
Epoch 4/300
785/785 - 88s - 112ms/step - accuracy: 0.2170 - loss: 3.8269 - val_accuracy: 0.3421 - val_loss: 3.3950 - learning_rate: 2.5974e-04
Epoch 5/300
785/785 - 89s - 114ms/step - accuracy: 0.2323 - loss: 3.7451 - val_accuracy: 0.3660 - val_loss: 3.0155 - learning_rate: 2.5974e-04
Epoch 6/300
785/785 - 88s - 112ms/step - accuracy: 0.2393 - loss: 3.6340 - val_accuracy: 0.3942 - val_loss: 3.0153 - learning_rate: 2.5974e-04
Epoch 7/300
785/785 - 90s - 114ms/step - accuracy: 0.2680 - loss: 3.5430 - val_accuracy: 0.4185 - val_loss: 2.9464 - learning_rate: 2.5974e-04
Epoch 8/300
785/785 - 90s - 115ms/step - accuracy: 0.2667 - loss: 3.5148 - val_accuracy: 0.4249 - val_loss: 2.8099 - learning_rate: 2.5974e-04
Epoch 9/300
785/785 - 90s - 115ms/step - accuracy: 0.2761 - loss: 3.4896 - val_accuracy: 0.4319 - val_loss: 2.7550 - learning_rate: 2.5974e-04
Epoch 10/300
785/785 - 89s - 114ms/step - accuracy: 0.2841 - loss: 3.4236 - val_accuracy: 0.4386 - val_loss: 2.7526 - learning_rate: 2.5974e-04
Epoch 11/300
785/785 - 88s - 112ms/step - accuracy: 0.2857 - loss: 3.4107 - val_accuracy: 0.4556 - val_loss: 2.7046 - learning_rate: 2.5974e-04
Epoch 12/300
785/785 - 91s - 116ms/step - accuracy: 0.2995 - loss: 3.3466 - val_accuracy: 0.4437 - val_loss: 2.5951 - learning_rate: 2.5974e-04
Epoch 13/300
785/785 - 90s - 115ms/step - accuracy: 0.2975 - loss: 3.3563 - val_accuracy: 0.4706 - val_loss: 2.5916 - learning_rate: 2.5974e-04
Epoch 14/300
785/785 - 91s - 116ms/step - accuracy: 0.3022 - loss: 3.3239 - val_accuracy: 0.4746 - val_loss: 2.5810 - learning_rate: 2.5974e-04
Epoch 15/300
785/785 - 89s - 114ms/step - accuracy: 0.3148 - loss: 3.3011 - val_accuracy: 0.4743 - val_loss: 2.6119 - learning_rate: 2.5974e-04
Epoch 16/300
785/785 - 89s - 114ms/step - accuracy: 0.3212 - loss: 3.2536 - val_accuracy: 0.4929 - val_loss: 2.4514 - learning_rate: 2.5974e-04
Epoch 17/300
785/785 - 87s - 110ms/step - accuracy: 0.3239 - loss: 3.2626 - val_accuracy: 0.5002 - val_loss: 2.4820 - learning_rate: 2.5974e-04
Epoch 18/300
785/785 - 91s - 116ms/step - accuracy: 0.3244 - loss: 3.2325 - val_accuracy: 0.5001 - val_loss: 2.5494 - learning_rate: 2.5974e-04
Epoch 19/300
785/785 - 91s - 116ms/step - accuracy: 0.3215 - loss: 3.1976 - val_accuracy: 0.5222 - val_loss: 2.4324 - learning_rate: 2.5974e-04
Epoch 20/300
785/785 - 90s - 115ms/step - accuracy: 0.3226 - loss: 3.1991 - val_accuracy: 0.4907 - val_loss: 2.4945 - learning_rate: 2.5974e-04
Epoch 21/300
785/785 - 89s - 113ms/step - accuracy: 0.3317 - loss: 3.2005 - val_accuracy: 0.5114 - val_loss: 2.3554 - learning_rate: 2.5974e-04
Epoch 22/300
785/785 - 88s - 112ms/step - accuracy: 0.3454 - loss: 3.1468 - val_accuracy: 0.4864 - val_loss: 2.3874 - learning_rate: 2.5974e-04
Epoch 23/300
785/785 - 92s - 117ms/step - accuracy: 0.3412 - loss: 3.1548 - val_accuracy: 0.5179 - val_loss: 2.3250 - learning_rate: 2.5974e-04
Epoch 24/300
785/785 - 89s - 114ms/step - accuracy: 0.3435 - loss: 3.1567 - val_accuracy: 0.5104 - val_loss: 2.3117 - learning_rate: 2.5974e-04
Epoch 25/300
785/785 - 89s - 113ms/step - accuracy: 0.3454 - loss: 3.1535 - val_accuracy: 0.5186 - val_loss: 2.3131 - learning_rate: 2.5974e-04
Epoch 26/300
785/785 - 89s - 113ms/step - accuracy: 0.3476 - loss: 3.1117 - val_accuracy: 0.5393 - val_loss: 2.3116 - learning_rate: 2.5974e-04
Epoch 27/300
785/785 - 89s - 113ms/step - accuracy: 0.3506 - loss: 3.1334 - val_accuracy: 0.5211 - val_loss: 2.2693 - learning_rate: 2.5974e-04
Epoch 28/300
785/785 - 88s - 112ms/step - accuracy: 0.3487 - loss: 3.0823 - val_accuracy: 0.5415 - val_loss: 2.2347 - learning_rate: 2.5974e-04
Epoch 29/300
785/785 - 92s - 117ms/step - accuracy: 0.3564 - loss: 3.0910 - val_accuracy: 0.5315 - val_loss: 2.2435 - learning_rate: 2.5974e-04
Epoch 30/300
785/785 - 90s - 114ms/step - accuracy: 0.3535 - loss: 3.0803 - val_accuracy: 0.5361 - val_loss: 2.2237 - learning_rate: 2.5974e-04
Epoch 31/300
785/785 - 89s - 113ms/step - accuracy: 0.3605 - loss: 3.0724 - val_accuracy: 0.5286 - val_loss: 2.1888 - learning_rate: 2.5974e-04
Epoch 32/300
785/785 - 88s - 113ms/step - accuracy: 0.3634 - loss: 3.0626 - val_accuracy: 0.5571 - val_loss: 2.2318 - learning_rate: 2.5974e-04
Epoch 33/300
785/785 - 90s - 115ms/step - accuracy: 0.3578 - loss: 3.0563 - val_accuracy: 0.5436 - val_loss: 2.2189 - learning_rate: 2.5974e-04
Epoch 34/300
785/785 - 93s - 119ms/step - accuracy: 0.3634 - loss: 3.0536 - val_accuracy: 0.5353 - val_loss: 2.2596 - learning_rate: 2.5974e-04
Epoch 35/300
785/785 - 90s - 115ms/step - accuracy: 0.3631 - loss: 3.0341 - val_accuracy: 0.5463 - val_loss: 2.1799 - learning_rate: 2.5974e-04
Epoch 36/300
785/785 - 89s - 114ms/step - accuracy: 0.3653 - loss: 3.0382 - val_accuracy: 0.5458 - val_loss: 2.1642 - learning_rate: 2.5974e-04
Epoch 37/300
785/785 - 89s - 113ms/step - accuracy: 0.3772 - loss: 3.0048 - val_accuracy: 0.5472 - val_loss: 2.1687 - learning_rate: 2.5974e-04
Epoch 38/300
785/785 - 89s - 114ms/step - accuracy: 0.3689 - loss: 3.0156 - val_accuracy: 0.5506 - val_loss: 2.1567 - learning_rate: 2.5974e-04
Epoch 39/300
785/785 - 89s - 113ms/step - accuracy: 0.3669 - loss: 3.0063 - val_accuracy: 0.5581 - val_loss: 2.1485 - learning_rate: 2.5974e-04
Epoch 40/300
785/785 - 90s - 114ms/step - accuracy: 0.3755 - loss: 2.9862 - val_accuracy: 0.5453 - val_loss: 2.1122 - learning_rate: 2.5974e-04
Epoch 41/300
785/785 - 86s - 110ms/step - accuracy: 0.3723 - loss: 2.9865 - val_accuracy: 0.5566 - val_loss: 2.1380 - learning_rate: 2.5974e-04
Epoch 42/300
785/785 - 90s - 114ms/step - accuracy: 0.3753 - loss: 2.9606 - val_accuracy: 0.5455 - val_loss: 2.1442 - learning_rate: 2.5974e-04
Epoch 43/300
785/785 - 89s - 114ms/step - accuracy: 0.3833 - loss: 2.9735 - val_accuracy: 0.5644 - val_loss: 2.1139 - learning_rate: 2.5974e-04
Epoch 44/300
785/785 - 90s - 115ms/step - accuracy: 0.3732 - loss: 2.9567 - val_accuracy: 0.5676 - val_loss: 2.1252 - learning_rate: 2.5974e-04
Epoch 45/300
785/785 - 94s - 120ms/step - accuracy: 0.3771 - loss: 2.9888 - val_accuracy: 0.5533 - val_loss: 2.1501 - learning_rate: 2.5974e-04
Epoch 46/300
785/785 - 89s - 113ms/step - accuracy: 0.3747 - loss: 2.9682 - val_accuracy: 0.5432 - val_loss: 2.1315 - learning_rate: 2.5974e-04
Epoch 47/300
785/785 - 89s - 114ms/step - accuracy: 0.3758 - loss: 2.9752 - val_accuracy: 0.5440 - val_loss: 2.1154 - learning_rate: 2.5974e-04
Epoch 48/300
785/785 - 93s - 118ms/step - accuracy: 0.3798 - loss: 2.9576 - val_accuracy: 0.5708 - val_loss: 2.0909 - learning_rate: 2.5974e-04
Epoch 49/300
785/785 - 88s - 112ms/step - accuracy: 0.3691 - loss: 2.9771 - val_accuracy: 0.5560 - val_loss: 2.1054 - learning_rate: 2.5974e-04
Epoch 50/300
785/785 - 92s - 117ms/step - accuracy: 0.3849 - loss: 2.9268 - val_accuracy: 0.5552 - val_loss: 2.1297 - learning_rate: 2.5974e-04
Epoch 51/300
785/785 - 88s - 112ms/step - accuracy: 0.3788 - loss: 2.9129 - val_accuracy: 0.5678 - val_loss: 2.0858 - learning_rate: 2.5974e-04
Epoch 52/300
785/785 - 89s - 113ms/step - accuracy: 0.3699 - loss: 2.9801 - val_accuracy: 0.5369 - val_loss: 2.1651 - learning_rate: 2.5974e-04
Epoch 53/300
785/785 - 88s - 112ms/step - accuracy: 0.3893 - loss: 2.9196 - val_accuracy: 0.5631 - val_loss: 2.0907 - learning_rate: 2.5974e-04
Epoch 54/300
785/785 - 90s - 115ms/step - accuracy: 0.3906 - loss: 2.8900 - val_accuracy: 0.5659 - val_loss: 2.0451 - learning_rate: 2.5974e-04
Epoch 55/300
785/785 - 87s - 111ms/step - accuracy: 0.3750 - loss: 2.9671 - val_accuracy: 0.5641 - val_loss: 2.1373 - learning_rate: 2.5974e-04
Epoch 56/300
785/785 - 89s - 113ms/step - accuracy: 0.3818 - loss: 2.9379 - val_accuracy: 0.5708 - val_loss: 2.0516 - learning_rate: 2.5974e-04
Epoch 57/300
785/785 - 143s - 182ms/step - accuracy: 0.3785 - loss: 2.9190 - val_accuracy: 0.5673 - val_loss: 2.0248 - learning_rate: 2.5974e-04
Epoch 58/300
785/785 - 88s - 113ms/step - accuracy: 0.3917 - loss: 2.8920 - val_accuracy: 0.5716 - val_loss: 2.0546 - learning_rate: 2.5974e-04
Epoch 59/300
785/785 - 90s - 114ms/step - accuracy: 0.3877 - loss: 2.9279 - val_accuracy: 0.5687 - val_loss: 2.0749 - learning_rate: 2.5974e-04
Epoch 60/300
785/785 - 94s - 119ms/step - accuracy: 0.3884 - loss: 2.8866 - val_accuracy: 0.5663 - val_loss: 2.0083 - learning_rate: 2.5974e-04
Epoch 61/300
785/785 - 86s - 109ms/step - accuracy: 0.3830 - loss: 2.9464 - val_accuracy: 0.5714 - val_loss: 2.0294 - learning_rate: 2.5974e-04
Epoch 62/300
785/785 - 93s - 119ms/step - accuracy: 0.3882 - loss: 2.9012 - val_accuracy: 0.5770 - val_loss: 2.0061 - learning_rate: 2.5974e-04
Epoch 63/300
785/785 - 97s - 124ms/step - accuracy: 0.3874 - loss: 2.8871 - val_accuracy: 0.5719 - val_loss: 2.0597 - learning_rate: 2.5974e-04
Epoch 64/300
785/785 - 96s - 122ms/step - accuracy: 0.3943 - loss: 2.8336 - val_accuracy: 0.5627 - val_loss: 2.0764 - learning_rate: 2.5974e-04
Epoch 65/300
785/785 - 97s - 123ms/step - accuracy: 0.3963 - loss: 2.8763 - val_accuracy: 0.5730 - val_loss: 2.0954 - learning_rate: 2.5974e-04
Epoch 66/300
785/785 - 96s - 122ms/step - accuracy: 0.3952 - loss: 2.8944 - val_accuracy: 0.5827 - val_loss: 1.9791 - learning_rate: 2.5974e-04
Epoch 67/300
785/785 - 96s - 122ms/step - accuracy: 0.3863 - loss: 2.9071 - val_accuracy: 0.5784 - val_loss: 2.0739 - learning_rate: 2.5974e-04
Epoch 68/300
785/785 - 97s - 124ms/step - accuracy: 0.3903 - loss: 2.9073 - val_accuracy: 0.5749 - val_loss: 2.0448 - learning_rate: 2.5974e-04
Epoch 69/300
785/785 - 97s - 123ms/step - accuracy: 0.3874 - loss: 2.8947 - val_accuracy: 0.5807 - val_loss: 1.9802 - learning_rate: 2.5974e-04
Epoch 70/300
785/785 - 96s - 122ms/step - accuracy: 0.3946 - loss: 2.8577 - val_accuracy: 0.5576 - val_loss: 2.0628 - learning_rate: 2.5974e-04
Epoch 71/300
785/785 - 95s - 121ms/step - accuracy: 0.3951 - loss: 2.9075 - val_accuracy: 0.5768 - val_loss: 1.9995 - learning_rate: 2.5974e-04
Epoch 72/300
785/785 - 96s - 122ms/step - accuracy: 0.3928 - loss: 2.8780 - val_accuracy: 0.5878 - val_loss: 2.0035 - learning_rate: 2.5974e-04
Epoch 73/300
785/785 - 98s - 125ms/step - accuracy: 0.3981 - loss: 2.8578 - val_accuracy: 0.5641 - val_loss: 2.0334 - learning_rate: 2.5974e-04
Epoch 74/300
785/785 - 94s - 120ms/step - accuracy: 0.3951 - loss: 2.8679 - val_accuracy: 0.5837 - val_loss: 1.9515 - learning_rate: 2.5974e-04
Epoch 75/300
785/785 - 97s - 124ms/step - accuracy: 0.3927 - loss: 2.8816 - val_accuracy: 0.5923 - val_loss: 2.0033 - learning_rate: 2.5974e-04
Epoch 76/300
785/785 - 97s - 123ms/step - accuracy: 0.3992 - loss: 2.8400 - val_accuracy: 0.5754 - val_loss: 1.9869 - learning_rate: 2.5974e-04
Epoch 77/300
785/785 - 96s - 123ms/step - accuracy: 0.3976 - loss: 2.8532 - val_accuracy: 0.5773 - val_loss: 2.0465 - learning_rate: 2.5974e-04
Epoch 78/300
785/785 - 95s - 122ms/step - accuracy: 0.3998 - loss: 2.8247 - val_accuracy: 0.5843 - val_loss: 1.9726 - learning_rate: 2.5974e-04
Epoch 79/300
785/785 - 96s - 122ms/step - accuracy: 0.3860 - loss: 2.8665 - val_accuracy: 0.5832 - val_loss: 2.0102 - learning_rate: 2.5974e-04
Epoch 80/300
785/785 - 94s - 120ms/step - accuracy: 0.3994 - loss: 2.8193 - val_accuracy: 0.5870 - val_loss: 1.9814 - learning_rate: 2.5974e-04
Epoch 81/300
785/785 - 96s - 122ms/step - accuracy: 0.4045 - loss: 2.8102 - val_accuracy: 0.5783 - val_loss: 1.9972 - learning_rate: 2.5974e-04
Epoch 82/300

Epoch 82: ReduceLROnPlateau reducing learning rate to 0.0001298690476687625.
785/785 - 97s - 123ms/step - accuracy: 0.3986 - loss: 2.8313 - val_accuracy: 0.5803 - val_loss: 1.9848 - learning_rate: 2.5974e-04
Epoch 83/300
785/785 - 98s - 124ms/step - accuracy: 0.4027 - loss: 2.7925 - val_accuracy: 0.5889 - val_loss: 1.9407 - learning_rate: 1.2987e-04
Epoch 84/300
785/785 - 98s - 124ms/step - accuracy: 0.4107 - loss: 2.7655 - val_accuracy: 0.5915 - val_loss: 1.9502 - learning_rate: 1.2987e-04
Epoch 85/300
785/785 - 96s - 122ms/step - accuracy: 0.4188 - loss: 2.7296 - val_accuracy: 0.5961 - val_loss: 1.9262 - learning_rate: 1.2987e-04
Epoch 86/300
785/785 - 96s - 122ms/step - accuracy: 0.4121 - loss: 2.7812 - val_accuracy: 0.5883 - val_loss: 1.9648 - learning_rate: 1.2987e-04
Epoch 87/300
785/785 - 95s - 120ms/step - accuracy: 0.4164 - loss: 2.7432 - val_accuracy: 0.5928 - val_loss: 1.9214 - learning_rate: 1.2987e-04
Epoch 88/300
785/785 - 98s - 125ms/step - accuracy: 0.4189 - loss: 2.7624 - val_accuracy: 0.5928 - val_loss: 1.9537 - learning_rate: 1.2987e-04
Epoch 89/300
785/785 - 100s - 127ms/step - accuracy: 0.4166 - loss: 2.7418 - val_accuracy: 0.5964 - val_loss: 1.9132 - learning_rate: 1.2987e-04
Epoch 90/300
785/785 - 98s - 124ms/step - accuracy: 0.4115 - loss: 2.7480 - val_accuracy: 0.5897 - val_loss: 1.9368 - learning_rate: 1.2987e-04
Epoch 91/300
785/785 - 96s - 123ms/step - accuracy: 0.4124 - loss: 2.7639 - val_accuracy: 0.5918 - val_loss: 1.9230 - learning_rate: 1.2987e-04
Epoch 92/300
785/785 - 96s - 122ms/step - accuracy: 0.4134 - loss: 2.7780 - val_accuracy: 0.5934 - val_loss: 1.9263 - learning_rate: 1.2987e-04
Epoch 93/300
785/785 - 96s - 122ms/step - accuracy: 0.4134 - loss: 2.7658 - val_accuracy: 0.5917 - val_loss: 1.9211 - learning_rate: 1.2987e-04
Epoch 94/300
785/785 - 99s - 126ms/step - accuracy: 0.4134 - loss: 2.7359 - val_accuracy: 0.5945 - val_loss: 1.9432 - learning_rate: 1.2987e-04
Epoch 95/300
785/785 - 97s - 124ms/step - accuracy: 0.4159 - loss: 2.7479 - val_accuracy: 0.5886 - val_loss: 1.9399 - learning_rate: 1.2987e-04
Epoch 96/300
785/785 - 95s - 121ms/step - accuracy: 0.4111 - loss: 2.7491 - val_accuracy: 0.5882 - val_loss: 1.8965 - learning_rate: 1.2987e-04
Epoch 97/300
785/785 - 97s - 124ms/step - accuracy: 0.4137 - loss: 2.7594 - val_accuracy: 0.5952 - val_loss: 1.9433 - learning_rate: 1.2987e-04
Epoch 98/300
785/785 - 95s - 121ms/step - accuracy: 0.4191 - loss: 2.7180 - val_accuracy: 0.5896 - val_loss: 1.8982 - learning_rate: 1.2987e-04
Epoch 99/300
785/785 - 96s - 122ms/step - accuracy: 0.4244 - loss: 2.7178 - val_accuracy: 0.6001 - val_loss: 1.9287 - learning_rate: 1.2987e-04
Epoch 100/300
785/785 - 96s - 122ms/step - accuracy: 0.4180 - loss: 2.7504 - val_accuracy: 0.5966 - val_loss: 1.9275 - learning_rate: 1.2987e-04
Epoch 101/300
785/785 - 97s - 124ms/step - accuracy: 0.4140 - loss: 2.7390 - val_accuracy: 0.5885 - val_loss: 1.9180 - learning_rate: 1.2987e-04
Epoch 102/300
785/785 - 98s - 124ms/step - accuracy: 0.4139 - loss: 2.7094 - val_accuracy: 0.5958 - val_loss: 1.9008 - learning_rate: 1.2987e-04
Epoch 103/300
785/785 - 96s - 122ms/step - accuracy: 0.4272 - loss: 2.7244 - val_accuracy: 0.5966 - val_loss: 1.9133 - learning_rate: 1.2987e-04
Epoch 104/300

Epoch 104: ReduceLROnPlateau reducing learning rate to 6.493452383438125e-05.
785/785 - 97s - 123ms/step - accuracy: 0.4220 - loss: 2.7217 - val_accuracy: 0.5956 - val_loss: 1.9123 - learning_rate: 1.2987e-04
Epoch 105/300
785/785 - 96s - 122ms/step - accuracy: 0.4225 - loss: 2.6967 - val_accuracy: 0.6006 - val_loss: 1.8641 - learning_rate: 6.4935e-05
Epoch 106/300
785/785 - 98s - 125ms/step - accuracy: 0.4323 - loss: 2.6654 - val_accuracy: 0.6079 - val_loss: 1.8825 - learning_rate: 6.4935e-05
Epoch 107/300
785/785 - 97s - 123ms/step - accuracy: 0.4322 - loss: 2.6576 - val_accuracy: 0.6092 - val_loss: 1.8757 - learning_rate: 6.4935e-05
Epoch 108/300
785/785 - 97s - 123ms/step - accuracy: 0.4322 - loss: 2.6678 - val_accuracy: 0.6066 - val_loss: 1.8705 - learning_rate: 6.4935e-05
Epoch 109/300
785/785 - 96s - 123ms/step - accuracy: 0.4287 - loss: 2.6838 - val_accuracy: 0.6047 - val_loss: 1.8632 - learning_rate: 6.4935e-05
Epoch 110/300
785/785 - 97s - 123ms/step - accuracy: 0.4263 - loss: 2.6982 - val_accuracy: 0.6071 - val_loss: 1.8796 - learning_rate: 6.4935e-05
Epoch 111/300
785/785 - 95s - 121ms/step - accuracy: 0.4299 - loss: 2.6757 - val_accuracy: 0.6047 - val_loss: 1.8656 - learning_rate: 6.4935e-05
Epoch 112/300
785/785 - 97s - 123ms/step - accuracy: 0.4275 - loss: 2.6471 - val_accuracy: 0.6022 - val_loss: 1.8623 - learning_rate: 6.4935e-05
Epoch 113/300
785/785 - 96s - 122ms/step - accuracy: 0.4318 - loss: 2.6994 - val_accuracy: 0.5982 - val_loss: 1.8729 - learning_rate: 6.4935e-05
Epoch 114/300
785/785 - 95s - 121ms/step - accuracy: 0.4298 - loss: 2.6745 - val_accuracy: 0.6007 - val_loss: 1.8552 - learning_rate: 6.4935e-05
Epoch 115/300
785/785 - 96s - 123ms/step - accuracy: 0.4209 - loss: 2.7072 - val_accuracy: 0.5987 - val_loss: 1.8619 - learning_rate: 6.4935e-05
Epoch 116/300
785/785 - 96s - 122ms/step - accuracy: 0.4306 - loss: 2.6740 - val_accuracy: 0.5985 - val_loss: 1.8628 - learning_rate: 6.4935e-05
Epoch 117/300
785/785 - 97s - 124ms/step - accuracy: 0.4271 - loss: 2.6980 - val_accuracy: 0.6014 - val_loss: 1.8675 - learning_rate: 6.4935e-05
Epoch 118/300
785/785 - 95s - 121ms/step - accuracy: 0.4247 - loss: 2.6713 - val_accuracy: 0.5985 - val_loss: 1.8738 - learning_rate: 6.4935e-05
Epoch 119/300
785/785 - 97s - 124ms/step - accuracy: 0.4288 - loss: 2.6755 - val_accuracy: 0.6050 - val_loss: 1.8459 - learning_rate: 6.4935e-05
Epoch 120/300
785/785 - 96s - 122ms/step - accuracy: 0.4269 - loss: 2.6777 - val_accuracy: 0.6030 - val_loss: 1.8570 - learning_rate: 6.4935e-05
Epoch 121/300
785/785 - 96s - 123ms/step - accuracy: 0.4336 - loss: 2.6485 - val_accuracy: 0.6017 - val_loss: 1.8539 - learning_rate: 6.4935e-05
Epoch 122/300
785/785 - 96s - 122ms/step - accuracy: 0.4237 - loss: 2.6727 - val_accuracy: 0.6066 - val_loss: 1.8562 - learning_rate: 6.4935e-05
Epoch 123/300
785/785 - 95s - 121ms/step - accuracy: 0.4328 - loss: 2.6366 - val_accuracy: 0.6054 - val_loss: 1.8480 - learning_rate: 6.4935e-05
Epoch 124/300
785/785 - 97s - 123ms/step - accuracy: 0.4288 - loss: 2.6764 - val_accuracy: 0.5956 - val_loss: 1.8564 - learning_rate: 6.4935e-05
Epoch 125/300
785/785 - 96s - 122ms/step - accuracy: 0.4398 - loss: 2.6781 - val_accuracy: 0.6068 - val_loss: 1.8640 - learning_rate: 6.4935e-05
Epoch 126/300
785/785 - 97s - 124ms/step - accuracy: 0.4290 - loss: 2.6899 - val_accuracy: 0.6106 - val_loss: 1.8593 - learning_rate: 6.4935e-05
Epoch 127/300

Epoch 127: ReduceLROnPlateau reducing learning rate to 3.2467261917190626e-05.
785/785 - 97s - 123ms/step - accuracy: 0.4299 - loss: 2.6887 - val_accuracy: 0.6023 - val_loss: 1.8554 - learning_rate: 6.4935e-05
Epoch 128/300
785/785 - 100s - 127ms/step - accuracy: 0.4328 - loss: 2.6866 - val_accuracy: 0.6081 - val_loss: 1.8487 - learning_rate: 3.2467e-05
Epoch 129/300
785/785 - 96s - 122ms/step - accuracy: 0.4385 - loss: 2.6471 - val_accuracy: 0.6071 - val_loss: 1.8417 - learning_rate: 3.2467e-05
Epoch 130/300
785/785 - 97s - 124ms/step - accuracy: 0.4392 - loss: 2.6390 - val_accuracy: 0.6087 - val_loss: 1.8360 - learning_rate: 3.2467e-05
Epoch 131/300
785/785 - 96s - 123ms/step - accuracy: 0.4379 - loss: 2.6353 - val_accuracy: 0.6093 - val_loss: 1.8405 - learning_rate: 3.2467e-05
Epoch 132/300
785/785 - 96s - 123ms/step - accuracy: 0.4342 - loss: 2.6697 - val_accuracy: 0.6101 - val_loss: 1.8461 - learning_rate: 3.2467e-05
Epoch 133/300
785/785 - 97s - 123ms/step - accuracy: 0.4379 - loss: 2.6657 - val_accuracy: 0.6071 - val_loss: 1.8499 - learning_rate: 3.2467e-05
Epoch 134/300
785/785 - 95s - 121ms/step - accuracy: 0.4373 - loss: 2.6285 - val_accuracy: 0.6122 - val_loss: 1.8368 - learning_rate: 3.2467e-05
Epoch 135/300
785/785 - 96s - 122ms/step - accuracy: 0.4323 - loss: 2.6611 - val_accuracy: 0.6069 - val_loss: 1.8321 - learning_rate: 3.2467e-05
Epoch 136/300
785/785 - 97s - 124ms/step - accuracy: 0.4350 - loss: 2.6786 - val_accuracy: 0.6057 - val_loss: 1.8586 - learning_rate: 3.2467e-05
Epoch 137/300
785/785 - 97s - 124ms/step - accuracy: 0.4288 - loss: 2.6752 - val_accuracy: 0.6060 - val_loss: 1.8415 - learning_rate: 3.2467e-05
Epoch 138/300
785/785 - 96s - 123ms/step - accuracy: 0.4260 - loss: 2.6443 - val_accuracy: 0.6071 - val_loss: 1.8334 - learning_rate: 3.2467e-05
Epoch 139/300
785/785 - 97s - 124ms/step - accuracy: 0.4349 - loss: 2.6421 - val_accuracy: 0.6093 - val_loss: 1.8364 - learning_rate: 3.2467e-05
Epoch 140/300
785/785 - 95s - 121ms/step - accuracy: 0.4408 - loss: 2.6184 - val_accuracy: 0.6089 - val_loss: 1.8412 - learning_rate: 3.2467e-05
Epoch 141/300
785/785 - 96s - 123ms/step - accuracy: 0.4347 - loss: 2.6511 - val_accuracy: 0.6074 - val_loss: 1.8460 - learning_rate: 3.2467e-05
Epoch 142/300
785/785 - 98s - 124ms/step - accuracy: 0.4374 - loss: 2.6608 - val_accuracy: 0.6074 - val_loss: 1.8532 - learning_rate: 3.2467e-05
Epoch 143/300

Epoch 143: ReduceLROnPlateau reducing learning rate to 1.6233630958595313e-05.
785/785 - 96s - 122ms/step - accuracy: 0.4336 - loss: 2.6242 - val_accuracy: 0.6057 - val_loss: 1.8380 - learning_rate: 3.2467e-05
Epoch 144/300
785/785 - 98s - 124ms/step - accuracy: 0.4395 - loss: 2.6317 - val_accuracy: 0.6108 - val_loss: 1.8316 - learning_rate: 1.6234e-05
Epoch 145/300
785/785 - 96s - 123ms/step - accuracy: 0.4377 - loss: 2.6309 - val_accuracy: 0.6065 - val_loss: 1.8330 - learning_rate: 1.6234e-05
Epoch 146/300
785/785 - 96s - 123ms/step - accuracy: 0.4387 - loss: 2.5970 - val_accuracy: 0.6106 - val_loss: 1.8293 - learning_rate: 1.6234e-05
Epoch 147/300
785/785 - 96s - 122ms/step - accuracy: 0.4436 - loss: 2.6135 - val_accuracy: 0.6087 - val_loss: 1.8274 - learning_rate: 1.6234e-05
Epoch 148/300
785/785 - 96s - 122ms/step - accuracy: 0.4379 - loss: 2.6094 - val_accuracy: 0.6092 - val_loss: 1.8289 - learning_rate: 1.6234e-05
Epoch 149/300
785/785 - 97s - 124ms/step - accuracy: 0.4396 - loss: 2.6150 - val_accuracy: 0.6100 - val_loss: 1.8337 - learning_rate: 1.6234e-05
Epoch 150/300
785/785 - 95s - 120ms/step - accuracy: 0.4396 - loss: 2.6625 - val_accuracy: 0.6103 - val_loss: 1.8365 - learning_rate: 1.6234e-05
Epoch 151/300
785/785 - 98s - 125ms/step - accuracy: 0.4341 - loss: 2.6620 - val_accuracy: 0.6089 - val_loss: 1.8226 - learning_rate: 1.6234e-05
Epoch 152/300
785/785 - 97s - 123ms/step - accuracy: 0.4377 - loss: 2.6345 - val_accuracy: 0.6074 - val_loss: 1.8325 - learning_rate: 1.6234e-05
Epoch 153/300
785/785 - 96s - 122ms/step - accuracy: 0.4341 - loss: 2.6183 - val_accuracy: 0.6101 - val_loss: 1.8289 - learning_rate: 1.6234e-05
Epoch 154/300
785/785 - 98s - 124ms/step - accuracy: 0.4403 - loss: 2.6051 - val_accuracy: 0.6097 - val_loss: 1.8383 - learning_rate: 1.6234e-05
Epoch 155/300
785/785 - 96s - 122ms/step - accuracy: 0.4503 - loss: 2.5825 - val_accuracy: 0.6081 - val_loss: 1.8422 - learning_rate: 1.6234e-05
Epoch 156/300
785/785 - 97s - 123ms/step - accuracy: 0.4463 - loss: 2.6175 - val_accuracy: 0.6104 - val_loss: 1.8287 - learning_rate: 1.6234e-05
Epoch 157/300
785/785 - 97s - 123ms/step - accuracy: 0.4342 - loss: 2.6124 - val_accuracy: 0.6132 - val_loss: 1.8320 - learning_rate: 1.6234e-05
Epoch 158/300
785/785 - 96s - 122ms/step - accuracy: 0.4339 - loss: 2.6277 - val_accuracy: 0.6109 - val_loss: 1.8322 - learning_rate: 1.6234e-05
Epoch 159/300

Epoch 159: ReduceLROnPlateau reducing learning rate to 8.116815479297657e-06.
785/785 - 96s - 123ms/step - accuracy: 0.4369 - loss: 2.6513 - val_accuracy: 0.6114 - val_loss: 1.8348 - learning_rate: 1.6234e-05
Epoch 160/300
785/785 - 96s - 123ms/step - accuracy: 0.4385 - loss: 2.6415 - val_accuracy: 0.6112 - val_loss: 1.8265 - learning_rate: 8.1168e-06
Epoch 161/300
785/785 - 97s - 123ms/step - accuracy: 0.4449 - loss: 2.6588 - val_accuracy: 0.6112 - val_loss: 1.8288 - learning_rate: 8.1168e-06
Epoch 162/300
785/785 - 96s - 122ms/step - accuracy: 0.4460 - loss: 2.5887 - val_accuracy: 0.6097 - val_loss: 1.8273 - learning_rate: 8.1168e-06
Epoch 163/300
785/785 - 96s - 123ms/step - accuracy: 0.4435 - loss: 2.6257 - val_accuracy: 0.6095 - val_loss: 1.8228 - learning_rate: 8.1168e-06
Epoch 164/300
785/785 - 97s - 124ms/step - accuracy: 0.4361 - loss: 2.6447 - val_accuracy: 0.6106 - val_loss: 1.8306 - learning_rate: 8.1168e-06
Epoch 165/300
785/785 - 97s - 124ms/step - accuracy: 0.4514 - loss: 2.6114 - val_accuracy: 0.6101 - val_loss: 1.8307 - learning_rate: 8.1168e-06
Epoch 166/300
785/785 - 96s - 122ms/step - accuracy: 0.4371 - loss: 2.6570 - val_accuracy: 0.6104 - val_loss: 1.8240 - learning_rate: 8.1168e-06
Epoch 167/300

Epoch 167: ReduceLROnPlateau reducing learning rate to 4.058407739648828e-06.
785/785 - 97s - 124ms/step - accuracy: 0.4349 - loss: 2.6438 - val_accuracy: 0.6120 - val_loss: 1.8251 - learning_rate: 8.1168e-06
Epoch 167: early stopping
Restoring model weights from the end of the best epoch: 151.
Fold 0_2 Evaluation results: [1.8252249956130981, 0.6088548898696899]
              precision    recall  f1-score   support

        1820       0.71      0.81      0.75       306
        1821       0.90      0.87      0.88       296
        1822       0.00      0.00      0.00        10
        1823       0.00      0.00      0.00         7
        1824       0.00      0.00      0.00         5
        1825       0.25      0.22      0.24         9
        1826       0.12      0.08      0.10        13
        1827       0.78      0.75      0.77       120
        1828       0.00      0.00      0.00        13
        1829       0.75      0.24      0.36        25
        1830       0.45      0.71      0.55       277
        1831       0.78      0.90      0.84       680
        1832       0.87      0.71      0.79       369
        1833       0.74      0.92      0.82       100
        1834       0.43      0.60      0.50       149
        1835       0.00      0.00      0.00        11
        1836       0.29      0.11      0.16        18
        1837       0.36      0.23      0.28        35
        1838       0.00      0.00      0.00        21
        1839       0.00      0.00      0.00         3
        1840       0.46      0.53      0.49       198
        1841       0.70      0.58      0.64       515
        1842       0.77      0.38      0.51        26
        1843       0.00      0.00      0.00        25
        1844       0.00      0.00      0.00         1
        1845       0.00      0.00      0.00         2
        1846       0.00      0.00      0.00        36
        1847       0.00      0.00      0.00        12
        1848       0.13      0.22      0.16        23
        1849       0.50      0.14      0.22        29
        1850       0.37      0.64      0.47       246
        1851       0.74      0.74      0.74       391
        1852       0.50      0.07      0.13        40
        1853       0.00      0.00      0.00        32
        1854       0.00      0.00      0.00        13
        1855       0.41      0.08      0.14       109
        1856       0.60      0.66      0.63        56
        1857       0.41      0.53      0.46       157
        1858       0.00      0.00      0.00        13
        1859       0.00      0.00      0.00        15
        1860       0.34      0.42      0.37       335
        1861       0.82      0.77      0.79       427
        1862       0.32      0.06      0.10        96
        1863       0.39      0.49      0.43        94
        1864       0.38      0.38      0.38        76
        1865       0.57      0.29      0.38        28
        1866       0.29      0.07      0.12        27
        1867       0.46      0.30      0.36        53
        1868       0.00      0.00      0.00        40
        1869       0.00      0.00      0.00        26
        1870       0.35      0.66      0.46       145
        1871       0.73      0.76      0.74       242
        1872       0.50      0.10      0.16        31
        1873       0.17      0.02      0.04        49
        1874       1.00      0.04      0.07        27
        1875       0.34      0.48      0.39        61
        1876       0.84      0.90      0.87        48
        1877       0.24      0.27      0.26        22
        1878       0.69      0.46      0.55        39
        1879       0.00      0.00      0.00         7

    accuracy                           0.61      6279
   macro avg       0.36      0.30      0.30      6279
weighted avg       0.60      0.61      0.59      6279

Matthews Correlation Coefficient: 0.589
Macro avg F1: 0.302
Weighted avg F1: 0.587
Micro avg F1: 0.609
Top-3 Accuracy: 0.841
Top-5 Accuracy: 0.898
Micro ROC AUC  = 0.98
Macro ROC AUC (present classes) = 0.97
Classification MAE (in years): 3.16

Fold 0_2 Misclassification Analysis:
Near misses (within 2 years): 561 out of 2456 misclassifications (22.84%)
Big misses (greater than 10 years): 1018
MAE with outliers: 3.16
MAE without outliers: 2.22 (improvement: 0.93)

10 Worst misclassifications:
Image: data/datasets/private/1820/1824_032_Zrzut ekranu 2022-07-26 203037.png, True: 1824, Predicted: 1876, Error: 52
Image: data/datasets/private/1820/1820_037_Zrzut ekranu 2022-07-26 210308.png, True: 1820, Predicted: 1871, Error: 51
Image: data/datasets/private/1820/1820_031_Zrzut ekranu 2022-07-26 195637.png, True: 1820, Predicted: 1871, Error: 51
Image: data/datasets/public/1820/1820_12wikimedia2.jpg, True: 1820, Predicted: 1871, Error: 51
Image: data/datasets/public/1870/1876_70washington.jpg, True: 1876, Predicted: 1826, Error: 50
Image: data/datasets/private/1820/1821_580etsy.jpg, True: 1821, Predicted: 1871, Error: 50
Image: data/datasets/private/1820/1821_486etsy.jpg, True: 1821, Predicted: 1871, Error: 50
Image: data/datasets/private/1870/1871_404etsy.jpg, True: 1871, Predicted: 1821, Error: 50
Image: data/datasets/public/1820/1820_021met.jpg, True: 1820, Predicted: 1870, Error: 50
Image: data/datasets/public/1870/1879_9wikimedia2.jpg, True: 1879, Predicted: 1830, Error: 49

===== Iteration 2/5 =====
=== Training Base Model ===

===== Fine Tuning 9 layers! =====
Epoch 1/300
785/785 - 124s - 158ms/step - accuracy: 0.1057 - loss: 4.4046 - val_accuracy: 0.1877 - val_loss: 4.1811 - learning_rate: 2.5974e-04
Epoch 2/300
785/785 - 96s - 122ms/step - accuracy: 0.1685 - loss: 4.1202 - val_accuracy: 0.2476 - val_loss: 3.7511 - learning_rate: 2.5974e-04
Epoch 3/300
785/785 - 97s - 123ms/step - accuracy: 0.1941 - loss: 3.9781 - val_accuracy: 0.2912 - val_loss: 3.6480 - learning_rate: 2.5974e-04
Epoch 4/300
785/785 - 97s - 124ms/step - accuracy: 0.2064 - loss: 3.8410 - val_accuracy: 0.3696 - val_loss: 3.3428 - learning_rate: 2.5974e-04
Epoch 5/300
785/785 - 97s - 123ms/step - accuracy: 0.2335 - loss: 3.7474 - val_accuracy: 0.3653 - val_loss: 3.3456 - learning_rate: 2.5974e-04
Epoch 6/300
785/785 - 96s - 122ms/step - accuracy: 0.2477 - loss: 3.6774 - val_accuracy: 0.4021 - val_loss: 2.9815 - learning_rate: 2.5974e-04
Epoch 7/300
785/785 - 97s - 123ms/step - accuracy: 0.2570 - loss: 3.5795 - val_accuracy: 0.4072 - val_loss: 2.9611 - learning_rate: 2.5974e-04
Epoch 8/300
785/785 - 98s - 125ms/step - accuracy: 0.2755 - loss: 3.5036 - val_accuracy: 0.4347 - val_loss: 2.8364 - learning_rate: 2.5974e-04
Epoch 9/300
785/785 - 96s - 123ms/step - accuracy: 0.2830 - loss: 3.4698 - val_accuracy: 0.4250 - val_loss: 2.7492 - learning_rate: 2.5974e-04
Epoch 10/300
785/785 - 98s - 124ms/step - accuracy: 0.2930 - loss: 3.4185 - val_accuracy: 0.4487 - val_loss: 2.8007 - learning_rate: 2.5974e-04
Epoch 11/300
785/785 - 98s - 124ms/step - accuracy: 0.2997 - loss: 3.3868 - val_accuracy: 0.4675 - val_loss: 2.7024 - learning_rate: 2.5974e-04
Epoch 12/300
785/785 - 93s - 118ms/step - accuracy: 0.2973 - loss: 3.3546 - val_accuracy: 0.4581 - val_loss: 2.5991 - learning_rate: 2.5974e-04
Epoch 13/300
785/785 - 97s - 124ms/step - accuracy: 0.3047 - loss: 3.3259 - val_accuracy: 0.4715 - val_loss: 2.5203 - learning_rate: 2.5974e-04
Epoch 14/300
785/785 - 97s - 124ms/step - accuracy: 0.3101 - loss: 3.2953 - val_accuracy: 0.4839 - val_loss: 2.5463 - learning_rate: 2.5974e-04
Epoch 15/300
785/785 - 98s - 125ms/step - accuracy: 0.3184 - loss: 3.2545 - val_accuracy: 0.4920 - val_loss: 2.5094 - learning_rate: 2.5974e-04
Epoch 16/300
785/785 - 96s - 123ms/step - accuracy: 0.3262 - loss: 3.2432 - val_accuracy: 0.5043 - val_loss: 2.4411 - learning_rate: 2.5974e-04
Epoch 17/300
785/785 - 98s - 125ms/step - accuracy: 0.3346 - loss: 3.2431 - val_accuracy: 0.5041 - val_loss: 2.4520 - learning_rate: 2.5974e-04
Epoch 18/300
785/785 - 95s - 121ms/step - accuracy: 0.3297 - loss: 3.2256 - val_accuracy: 0.5027 - val_loss: 2.3721 - learning_rate: 2.5974e-04
Epoch 19/300
785/785 - 97s - 124ms/step - accuracy: 0.3391 - loss: 3.1932 - val_accuracy: 0.5164 - val_loss: 2.3835 - learning_rate: 2.5974e-04
Epoch 20/300
785/785 - 97s - 124ms/step - accuracy: 0.3408 - loss: 3.1687 - val_accuracy: 0.5062 - val_loss: 2.4086 - learning_rate: 2.5974e-04
Epoch 21/300
785/785 - 95s - 121ms/step - accuracy: 0.3397 - loss: 3.1526 - val_accuracy: 0.5212 - val_loss: 2.4248 - learning_rate: 2.5974e-04
Epoch 22/300
785/785 - 97s - 124ms/step - accuracy: 0.3504 - loss: 3.1155 - val_accuracy: 0.5153 - val_loss: 2.3157 - learning_rate: 2.5974e-04
Epoch 23/300
785/785 - 97s - 124ms/step - accuracy: 0.3529 - loss: 3.1363 - val_accuracy: 0.5188 - val_loss: 2.3163 - learning_rate: 2.5974e-04
Epoch 24/300
785/785 - 97s - 123ms/step - accuracy: 0.3464 - loss: 3.1360 - val_accuracy: 0.5228 - val_loss: 2.3337 - learning_rate: 2.5974e-04
Epoch 25/300
785/785 - 94s - 119ms/step - accuracy: 0.3561 - loss: 3.1017 - val_accuracy: 0.5162 - val_loss: 2.3591 - learning_rate: 2.5974e-04
Epoch 26/300
785/785 - 96s - 122ms/step - accuracy: 0.3650 - loss: 3.0860 - val_accuracy: 0.5291 - val_loss: 2.2742 - learning_rate: 2.5974e-04
Epoch 27/300
785/785 - 97s - 123ms/step - accuracy: 0.3625 - loss: 3.1031 - val_accuracy: 0.5183 - val_loss: 2.2659 - learning_rate: 2.5974e-04
Epoch 28/300
785/785 - 99s - 126ms/step - accuracy: 0.3574 - loss: 3.1049 - val_accuracy: 0.5202 - val_loss: 2.2274 - learning_rate: 2.5974e-04
Epoch 29/300
785/785 - 97s - 124ms/step - accuracy: 0.3561 - loss: 3.0682 - val_accuracy: 0.5264 - val_loss: 2.2522 - learning_rate: 2.5974e-04
Epoch 30/300
785/785 - 97s - 124ms/step - accuracy: 0.3676 - loss: 3.0408 - val_accuracy: 0.5382 - val_loss: 2.2539 - learning_rate: 2.5974e-04
Epoch 31/300
785/785 - 97s - 123ms/step - accuracy: 0.3741 - loss: 2.9934 - val_accuracy: 0.5202 - val_loss: 2.1854 - learning_rate: 2.5974e-04
Epoch 32/300
785/785 - 95s - 121ms/step - accuracy: 0.3760 - loss: 3.0241 - val_accuracy: 0.5369 - val_loss: 2.2236 - learning_rate: 2.5974e-04
Epoch 33/300
785/785 - 97s - 123ms/step - accuracy: 0.3617 - loss: 3.0077 - val_accuracy: 0.5503 - val_loss: 2.1876 - learning_rate: 2.5974e-04
Epoch 34/300
785/785 - 100s - 128ms/step - accuracy: 0.3755 - loss: 2.9824 - val_accuracy: 0.5427 - val_loss: 2.1552 - learning_rate: 2.5974e-04
Epoch 35/300
785/785 - 98s - 124ms/step - accuracy: 0.3774 - loss: 2.9860 - val_accuracy: 0.4920 - val_loss: 2.3123 - learning_rate: 2.5974e-04
Epoch 36/300
785/785 - 98s - 125ms/step - accuracy: 0.3771 - loss: 3.0039 - val_accuracy: 0.5334 - val_loss: 2.1770 - learning_rate: 2.5974e-04
Epoch 37/300
785/785 - 97s - 124ms/step - accuracy: 0.3768 - loss: 2.9740 - val_accuracy: 0.5387 - val_loss: 2.1870 - learning_rate: 2.5974e-04
Epoch 38/300
785/785 - 97s - 123ms/step - accuracy: 0.3838 - loss: 2.9892 - val_accuracy: 0.5435 - val_loss: 2.1543 - learning_rate: 2.5974e-04
Epoch 39/300
785/785 - 97s - 124ms/step - accuracy: 0.3773 - loss: 2.9782 - val_accuracy: 0.5467 - val_loss: 2.2164 - learning_rate: 2.5974e-04
Epoch 40/300
785/785 - 97s - 124ms/step - accuracy: 0.3881 - loss: 2.9406 - val_accuracy: 0.5361 - val_loss: 2.1326 - learning_rate: 2.5974e-04
Epoch 41/300
785/785 - 95s - 121ms/step - accuracy: 0.3808 - loss: 2.9662 - val_accuracy: 0.5296 - val_loss: 2.2038 - learning_rate: 2.5974e-04
Epoch 42/300
785/785 - 98s - 125ms/step - accuracy: 0.3814 - loss: 2.9630 - val_accuracy: 0.5350 - val_loss: 2.1264 - learning_rate: 2.5974e-04
Epoch 43/300
785/785 - 97s - 123ms/step - accuracy: 0.3712 - loss: 2.9561 - val_accuracy: 0.5553 - val_loss: 2.1120 - learning_rate: 2.5974e-04
Epoch 44/300
785/785 - 96s - 122ms/step - accuracy: 0.3868 - loss: 2.9583 - val_accuracy: 0.5506 - val_loss: 2.1521 - learning_rate: 2.5974e-04
Epoch 45/300
785/785 - 98s - 125ms/step - accuracy: 0.3784 - loss: 2.9671 - val_accuracy: 0.5604 - val_loss: 2.1307 - learning_rate: 2.5974e-04
Epoch 46/300
785/785 - 96s - 123ms/step - accuracy: 0.3872 - loss: 2.9529 - val_accuracy: 0.5312 - val_loss: 2.1506 - learning_rate: 2.5974e-04
Epoch 47/300
785/785 - 95s - 122ms/step - accuracy: 0.3857 - loss: 2.9751 - val_accuracy: 0.5554 - val_loss: 2.1190 - learning_rate: 2.5974e-04
Epoch 48/300
785/785 - 96s - 123ms/step - accuracy: 0.3899 - loss: 2.9199 - val_accuracy: 0.5447 - val_loss: 2.1170 - learning_rate: 2.5974e-04
Epoch 49/300
785/785 - 96s - 122ms/step - accuracy: 0.3865 - loss: 2.9565 - val_accuracy: 0.5470 - val_loss: 2.1412 - learning_rate: 2.5974e-04
Epoch 50/300
785/785 - 96s - 122ms/step - accuracy: 0.3873 - loss: 2.9281 - val_accuracy: 0.5462 - val_loss: 2.1716 - learning_rate: 2.5974e-04
Epoch 51/300
785/785 - 96s - 123ms/step - accuracy: 0.3870 - loss: 2.8878 - val_accuracy: 0.5554 - val_loss: 2.0831 - learning_rate: 2.5974e-04
Epoch 52/300
785/785 - 96s - 122ms/step - accuracy: 0.3897 - loss: 2.8884 - val_accuracy: 0.5470 - val_loss: 2.0900 - learning_rate: 2.5974e-04
Epoch 53/300
785/785 - 97s - 124ms/step - accuracy: 0.3708 - loss: 2.9601 - val_accuracy: 0.5478 - val_loss: 2.1233 - learning_rate: 2.5974e-04
Epoch 54/300
785/785 - 95s - 121ms/step - accuracy: 0.3910 - loss: 2.9218 - val_accuracy: 0.5420 - val_loss: 2.1293 - learning_rate: 2.5974e-04
Epoch 55/300
785/785 - 97s - 123ms/step - accuracy: 0.3939 - loss: 2.8927 - val_accuracy: 0.5508 - val_loss: 2.1207 - learning_rate: 2.5974e-04
Epoch 56/300
785/785 - 95s - 121ms/step - accuracy: 0.4002 - loss: 2.8738 - val_accuracy: 0.5498 - val_loss: 2.0784 - learning_rate: 2.5974e-04
Epoch 57/300
785/785 - 93s - 118ms/step - accuracy: 0.3903 - loss: 2.8700 - val_accuracy: 0.5599 - val_loss: 2.0490 - learning_rate: 2.5974e-04
Epoch 58/300
785/785 - 87s - 111ms/step - accuracy: 0.3923 - loss: 2.9095 - val_accuracy: 0.5533 - val_loss: 2.0214 - learning_rate: 2.5974e-04
Epoch 59/300
785/785 - 86s - 110ms/step - accuracy: 0.3888 - loss: 2.8576 - val_accuracy: 0.5355 - val_loss: 2.0737 - learning_rate: 2.5974e-04
Epoch 60/300
785/785 - 89s - 113ms/step - accuracy: 0.3977 - loss: 2.8616 - val_accuracy: 0.5533 - val_loss: 2.0331 - learning_rate: 2.5974e-04
Epoch 61/300
785/785 - 88s - 112ms/step - accuracy: 0.4001 - loss: 2.8520 - val_accuracy: 0.5618 - val_loss: 2.0581 - learning_rate: 2.5974e-04
Epoch 62/300
785/785 - 88s - 112ms/step - accuracy: 0.3974 - loss: 2.8800 - val_accuracy: 0.5540 - val_loss: 2.0416 - learning_rate: 2.5974e-04
Epoch 63/300
785/785 - 87s - 110ms/step - accuracy: 0.3905 - loss: 2.8568 - val_accuracy: 0.5592 - val_loss: 2.0532 - learning_rate: 2.5974e-04
Epoch 64/300
785/785 - 87s - 111ms/step - accuracy: 0.3946 - loss: 2.8608 - val_accuracy: 0.5632 - val_loss: 2.0489 - learning_rate: 2.5974e-04
Epoch 65/300
785/785 - 88s - 113ms/step - accuracy: 0.4029 - loss: 2.8715 - val_accuracy: 0.5615 - val_loss: 2.0556 - learning_rate: 2.5974e-04
Epoch 66/300

Epoch 66: ReduceLROnPlateau reducing learning rate to 0.0001298690476687625.
785/785 - 87s - 111ms/step - accuracy: 0.4004 - loss: 2.8699 - val_accuracy: 0.5486 - val_loss: 2.0754 - learning_rate: 2.5974e-04
Epoch 67/300
785/785 - 87s - 111ms/step - accuracy: 0.4112 - loss: 2.7899 - val_accuracy: 0.5656 - val_loss: 2.0169 - learning_rate: 1.2987e-04
Epoch 68/300
785/785 - 87s - 111ms/step - accuracy: 0.4099 - loss: 2.7937 - val_accuracy: 0.5535 - val_loss: 2.0132 - learning_rate: 1.2987e-04
Epoch 69/300
785/785 - 85s - 109ms/step - accuracy: 0.4080 - loss: 2.7990 - val_accuracy: 0.5689 - val_loss: 2.0005 - learning_rate: 1.2987e-04
Epoch 70/300
785/785 - 87s - 111ms/step - accuracy: 0.4071 - loss: 2.7770 - val_accuracy: 0.5642 - val_loss: 1.9964 - learning_rate: 1.2987e-04
Epoch 71/300
785/785 - 86s - 109ms/step - accuracy: 0.4166 - loss: 2.7564 - val_accuracy: 0.5742 - val_loss: 1.9842 - learning_rate: 1.2987e-04
Epoch 72/300
785/785 - 87s - 111ms/step - accuracy: 0.4155 - loss: 2.7741 - val_accuracy: 0.5685 - val_loss: 1.9812 - learning_rate: 1.2987e-04
Epoch 73/300
785/785 - 86s - 110ms/step - accuracy: 0.4222 - loss: 2.7611 - val_accuracy: 0.5709 - val_loss: 2.0168 - learning_rate: 1.2987e-04
Epoch 74/300
785/785 - 87s - 111ms/step - accuracy: 0.4181 - loss: 2.7238 - val_accuracy: 0.5728 - val_loss: 1.9895 - learning_rate: 1.2987e-04
Epoch 75/300
785/785 - 89s - 113ms/step - accuracy: 0.4198 - loss: 2.7645 - val_accuracy: 0.5696 - val_loss: 1.9673 - learning_rate: 1.2987e-04
Epoch 76/300
785/785 - 85s - 109ms/step - accuracy: 0.4197 - loss: 2.7650 - val_accuracy: 0.5710 - val_loss: 1.9840 - learning_rate: 1.2987e-04
Epoch 77/300
785/785 - 88s - 112ms/step - accuracy: 0.4165 - loss: 2.7558 - val_accuracy: 0.5672 - val_loss: 1.9943 - learning_rate: 1.2987e-04
Epoch 78/300
785/785 - 87s - 111ms/step - accuracy: 0.4130 - loss: 2.8067 - val_accuracy: 0.5729 - val_loss: 1.9816 - learning_rate: 1.2987e-04
Epoch 79/300
785/785 - 91s - 117ms/step - accuracy: 0.4212 - loss: 2.7397 - val_accuracy: 0.5653 - val_loss: 1.9665 - learning_rate: 1.2987e-04
Epoch 80/300
785/785 - 87s - 111ms/step - accuracy: 0.4217 - loss: 2.7387 - val_accuracy: 0.5734 - val_loss: 1.9473 - learning_rate: 1.2987e-04
Epoch 81/300
785/785 - 88s - 112ms/step - accuracy: 0.4176 - loss: 2.7383 - val_accuracy: 0.5726 - val_loss: 1.9495 - learning_rate: 1.2987e-04
Epoch 82/300
785/785 - 86s - 110ms/step - accuracy: 0.4276 - loss: 2.7654 - val_accuracy: 0.5696 - val_loss: 1.9698 - learning_rate: 1.2987e-04
Epoch 83/300
785/785 - 89s - 113ms/step - accuracy: 0.4192 - loss: 2.7527 - val_accuracy: 0.5718 - val_loss: 1.9523 - learning_rate: 1.2987e-04
Epoch 84/300
785/785 - 88s - 112ms/step - accuracy: 0.4101 - loss: 2.7726 - val_accuracy: 0.5686 - val_loss: 1.9808 - learning_rate: 1.2987e-04
Epoch 85/300
785/785 - 88s - 112ms/step - accuracy: 0.4182 - loss: 2.7444 - val_accuracy: 0.5775 - val_loss: 1.9494 - learning_rate: 1.2987e-04
Epoch 86/300
785/785 - 87s - 110ms/step - accuracy: 0.4136 - loss: 2.7803 - val_accuracy: 0.5732 - val_loss: 1.9803 - learning_rate: 1.2987e-04
Epoch 87/300
785/785 - 87s - 111ms/step - accuracy: 0.4257 - loss: 2.6998 - val_accuracy: 0.5723 - val_loss: 1.9502 - learning_rate: 1.2987e-04
Epoch 88/300

Epoch 88: ReduceLROnPlateau reducing learning rate to 6.493452383438125e-05.
785/785 - 86s - 110ms/step - accuracy: 0.4216 - loss: 2.7336 - val_accuracy: 0.5796 - val_loss: 1.9546 - learning_rate: 1.2987e-04
Epoch 89/300
785/785 - 86s - 109ms/step - accuracy: 0.4136 - loss: 2.7132 - val_accuracy: 0.5814 - val_loss: 1.9248 - learning_rate: 6.4935e-05
Epoch 90/300
785/785 - 87s - 110ms/step - accuracy: 0.4235 - loss: 2.6722 - val_accuracy: 0.5729 - val_loss: 1.9421 - learning_rate: 6.4935e-05
Epoch 91/300
785/785 - 86s - 110ms/step - accuracy: 0.4383 - loss: 2.6650 - val_accuracy: 0.5795 - val_loss: 1.9368 - learning_rate: 6.4935e-05
Epoch 92/300
785/785 - 87s - 111ms/step - accuracy: 0.4243 - loss: 2.7116 - val_accuracy: 0.5791 - val_loss: 1.9212 - learning_rate: 6.4935e-05
Epoch 93/300
785/785 - 90s - 114ms/step - accuracy: 0.4297 - loss: 2.6947 - val_accuracy: 0.5793 - val_loss: 1.9349 - learning_rate: 6.4935e-05
Epoch 94/300
785/785 - 87s - 110ms/step - accuracy: 0.4246 - loss: 2.7101 - val_accuracy: 0.5849 - val_loss: 1.9142 - learning_rate: 6.4935e-05
Epoch 95/300
785/785 - 87s - 111ms/step - accuracy: 0.4236 - loss: 2.7405 - val_accuracy: 0.5820 - val_loss: 1.9340 - learning_rate: 6.4935e-05
Epoch 96/300
785/785 - 86s - 110ms/step - accuracy: 0.4318 - loss: 2.6776 - val_accuracy: 0.5846 - val_loss: 1.9407 - learning_rate: 6.4935e-05
Epoch 97/300
785/785 - 87s - 111ms/step - accuracy: 0.4267 - loss: 2.7070 - val_accuracy: 0.5817 - val_loss: 1.9185 - learning_rate: 6.4935e-05
Epoch 98/300
785/785 - 88s - 112ms/step - accuracy: 0.4367 - loss: 2.6904 - val_accuracy: 0.5871 - val_loss: 1.9152 - learning_rate: 6.4935e-05
Epoch 99/300
785/785 - 86s - 110ms/step - accuracy: 0.4292 - loss: 2.6845 - val_accuracy: 0.5764 - val_loss: 1.9565 - learning_rate: 6.4935e-05
Epoch 100/300
785/785 - 94s - 119ms/step - accuracy: 0.4357 - loss: 2.7232 - val_accuracy: 0.5846 - val_loss: 1.9233 - learning_rate: 6.4935e-05
Epoch 101/300
785/785 - 85s - 109ms/step - accuracy: 0.4319 - loss: 2.6816 - val_accuracy: 0.5833 - val_loss: 1.9122 - learning_rate: 6.4935e-05
Epoch 102/300
785/785 - 88s - 113ms/step - accuracy: 0.4333 - loss: 2.6772 - val_accuracy: 0.5787 - val_loss: 1.9299 - learning_rate: 6.4935e-05
Epoch 103/300
785/785 - 87s - 111ms/step - accuracy: 0.4316 - loss: 2.6894 - val_accuracy: 0.5809 - val_loss: 1.9209 - learning_rate: 6.4935e-05
Epoch 104/300
785/785 - 88s - 112ms/step - accuracy: 0.4348 - loss: 2.6444 - val_accuracy: 0.5841 - val_loss: 1.9188 - learning_rate: 6.4935e-05
Epoch 105/300
785/785 - 87s - 111ms/step - accuracy: 0.4394 - loss: 2.6760 - val_accuracy: 0.5855 - val_loss: 1.9094 - learning_rate: 6.4935e-05
Epoch 106/300
785/785 - 88s - 112ms/step - accuracy: 0.4332 - loss: 2.6645 - val_accuracy: 0.5869 - val_loss: 1.9194 - learning_rate: 6.4935e-05
Epoch 107/300
785/785 - 87s - 111ms/step - accuracy: 0.4324 - loss: 2.6843 - val_accuracy: 0.5860 - val_loss: 1.9191 - learning_rate: 6.4935e-05
Epoch 108/300
785/785 - 87s - 111ms/step - accuracy: 0.4284 - loss: 2.7141 - val_accuracy: 0.5877 - val_loss: 1.9236 - learning_rate: 6.4935e-05
Epoch 109/300
785/785 - 87s - 111ms/step - accuracy: 0.4367 - loss: 2.6594 - val_accuracy: 0.5882 - val_loss: 1.9015 - learning_rate: 6.4935e-05
Epoch 110/300
785/785 - 91s - 115ms/step - accuracy: 0.4322 - loss: 2.6714 - val_accuracy: 0.5863 - val_loss: 1.9044 - learning_rate: 6.4935e-05
Epoch 111/300
785/785 - 89s - 113ms/step - accuracy: 0.4399 - loss: 2.6413 - val_accuracy: 0.5852 - val_loss: 1.8888 - learning_rate: 6.4935e-05
Epoch 112/300
785/785 - 88s - 112ms/step - accuracy: 0.4300 - loss: 2.6780 - val_accuracy: 0.5879 - val_loss: 1.9053 - learning_rate: 6.4935e-05
Epoch 113/300
785/785 - 88s - 112ms/step - accuracy: 0.4408 - loss: 2.6519 - val_accuracy: 0.5887 - val_loss: 1.9054 - learning_rate: 6.4935e-05
Epoch 114/300
785/785 - 86s - 110ms/step - accuracy: 0.4389 - loss: 2.6425 - val_accuracy: 0.5795 - val_loss: 1.9075 - learning_rate: 6.4935e-05
Epoch 115/300
785/785 - 87s - 110ms/step - accuracy: 0.4271 - loss: 2.6808 - val_accuracy: 0.5849 - val_loss: 1.9083 - learning_rate: 6.4935e-05
Epoch 116/300
785/785 - 88s - 113ms/step - accuracy: 0.4373 - loss: 2.6565 - val_accuracy: 0.5836 - val_loss: 1.9259 - learning_rate: 6.4935e-05
Epoch 117/300
785/785 - 88s - 112ms/step - accuracy: 0.4338 - loss: 2.6991 - val_accuracy: 0.5830 - val_loss: 1.9045 - learning_rate: 6.4935e-05
Epoch 118/300
785/785 - 88s - 112ms/step - accuracy: 0.4372 - loss: 2.6619 - val_accuracy: 0.5844 - val_loss: 1.9097 - learning_rate: 6.4935e-05
Epoch 119/300

Epoch 119: ReduceLROnPlateau reducing learning rate to 3.2467261917190626e-05.
785/785 - 87s - 110ms/step - accuracy: 0.4345 - loss: 2.6696 - val_accuracy: 0.5828 - val_loss: 1.9199 - learning_rate: 6.4935e-05
Epoch 120/300
785/785 - 86s - 110ms/step - accuracy: 0.4343 - loss: 2.6303 - val_accuracy: 0.5906 - val_loss: 1.8776 - learning_rate: 3.2467e-05
Epoch 121/300
785/785 - 87s - 111ms/step - accuracy: 0.4469 - loss: 2.6278 - val_accuracy: 0.5860 - val_loss: 1.8895 - learning_rate: 3.2467e-05
Epoch 122/300
785/785 - 87s - 111ms/step - accuracy: 0.4402 - loss: 2.6398 - val_accuracy: 0.5865 - val_loss: 1.8861 - learning_rate: 3.2467e-05
Epoch 123/300
785/785 - 94s - 119ms/step - accuracy: 0.4453 - loss: 2.6084 - val_accuracy: 0.5852 - val_loss: 1.8846 - learning_rate: 3.2467e-05
Epoch 124/300
785/785 - 88s - 112ms/step - accuracy: 0.4501 - loss: 2.6268 - val_accuracy: 0.5889 - val_loss: 1.8828 - learning_rate: 3.2467e-05
Epoch 125/300
785/785 - 87s - 111ms/step - accuracy: 0.4483 - loss: 2.6441 - val_accuracy: 0.5919 - val_loss: 1.8926 - learning_rate: 3.2467e-05
Epoch 126/300
785/785 - 88s - 113ms/step - accuracy: 0.4311 - loss: 2.6674 - val_accuracy: 0.5904 - val_loss: 1.8936 - learning_rate: 3.2467e-05
Epoch 127/300
785/785 - 86s - 110ms/step - accuracy: 0.4372 - loss: 2.6467 - val_accuracy: 0.5930 - val_loss: 1.8779 - learning_rate: 3.2467e-05
Epoch 128/300
785/785 - 89s - 113ms/step - accuracy: 0.4362 - loss: 2.6574 - val_accuracy: 0.5919 - val_loss: 1.8764 - learning_rate: 3.2467e-05
Epoch 129/300
785/785 - 87s - 111ms/step - accuracy: 0.4381 - loss: 2.6616 - val_accuracy: 0.5847 - val_loss: 1.8837 - learning_rate: 3.2467e-05
Epoch 130/300
785/785 - 92s - 117ms/step - accuracy: 0.4407 - loss: 2.6141 - val_accuracy: 0.5924 - val_loss: 1.8803 - learning_rate: 3.2467e-05
Epoch 131/300
785/785 - 88s - 112ms/step - accuracy: 0.4470 - loss: 2.6070 - val_accuracy: 0.5903 - val_loss: 1.8843 - learning_rate: 3.2467e-05
Epoch 132/300
785/785 - 140s - 179ms/step - accuracy: 0.4318 - loss: 2.6408 - val_accuracy: 0.5933 - val_loss: 1.8776 - learning_rate: 3.2467e-05
Epoch 133/300
785/785 - 87s - 111ms/step - accuracy: 0.4437 - loss: 2.6351 - val_accuracy: 0.5900 - val_loss: 1.8799 - learning_rate: 3.2467e-05
Epoch 134/300
785/785 - 89s - 114ms/step - accuracy: 0.4412 - loss: 2.6334 - val_accuracy: 0.5895 - val_loss: 1.8764 - learning_rate: 3.2467e-05
Epoch 135/300
785/785 - 85s - 109ms/step - accuracy: 0.4399 - loss: 2.6417 - val_accuracy: 0.5896 - val_loss: 1.8795 - learning_rate: 3.2467e-05
Epoch 136/300

Epoch 136: ReduceLROnPlateau reducing learning rate to 1.6233630958595313e-05.
785/785 - 86s - 110ms/step - accuracy: 0.4392 - loss: 2.6163 - val_accuracy: 0.5924 - val_loss: 1.8808 - learning_rate: 3.2467e-05
Epoch 137/300
785/785 - 87s - 111ms/step - accuracy: 0.4416 - loss: 2.6333 - val_accuracy: 0.5903 - val_loss: 1.8718 - learning_rate: 1.6234e-05
Epoch 138/300
785/785 - 87s - 111ms/step - accuracy: 0.4461 - loss: 2.6052 - val_accuracy: 0.5884 - val_loss: 1.8721 - learning_rate: 1.6234e-05
Epoch 139/300
785/785 - 85s - 108ms/step - accuracy: 0.4389 - loss: 2.6554 - val_accuracy: 0.5919 - val_loss: 1.8752 - learning_rate: 1.6234e-05
Epoch 140/300
785/785 - 87s - 111ms/step - accuracy: 0.4437 - loss: 2.6011 - val_accuracy: 0.5917 - val_loss: 1.8795 - learning_rate: 1.6234e-05
Epoch 141/300
785/785 - 88s - 112ms/step - accuracy: 0.4541 - loss: 2.5899 - val_accuracy: 0.5893 - val_loss: 1.8789 - learning_rate: 1.6234e-05
Epoch 142/300
785/785 - 87s - 111ms/step - accuracy: 0.4426 - loss: 2.6122 - val_accuracy: 0.5892 - val_loss: 1.8741 - learning_rate: 1.6234e-05
Epoch 143/300
785/785 - 89s - 113ms/step - accuracy: 0.4362 - loss: 2.6434 - val_accuracy: 0.5906 - val_loss: 1.8797 - learning_rate: 1.6234e-05
Epoch 144/300
785/785 - 90s - 114ms/step - accuracy: 0.4494 - loss: 2.6091 - val_accuracy: 0.5890 - val_loss: 1.8725 - learning_rate: 1.6234e-05
Epoch 145/300

Epoch 145: ReduceLROnPlateau reducing learning rate to 8.116815479297657e-06.
785/785 - 86s - 109ms/step - accuracy: 0.4400 - loss: 2.6172 - val_accuracy: 0.5904 - val_loss: 1.8750 - learning_rate: 1.6234e-05
Epoch 146/300
785/785 - 87s - 111ms/step - accuracy: 0.4341 - loss: 2.6241 - val_accuracy: 0.5927 - val_loss: 1.8678 - learning_rate: 8.1168e-06
Epoch 147/300
785/785 - 86s - 110ms/step - accuracy: 0.4386 - loss: 2.6153 - val_accuracy: 0.5898 - val_loss: 1.8731 - learning_rate: 8.1168e-06
Epoch 148/300
785/785 - 144s - 183ms/step - accuracy: 0.4443 - loss: 2.6056 - val_accuracy: 0.5903 - val_loss: 1.8764 - learning_rate: 8.1168e-06
Epoch 149/300
785/785 - 88s - 113ms/step - accuracy: 0.4424 - loss: 2.6179 - val_accuracy: 0.5912 - val_loss: 1.8692 - learning_rate: 8.1168e-06
Epoch 150/300
785/785 - 87s - 111ms/step - accuracy: 0.4513 - loss: 2.6072 - val_accuracy: 0.5906 - val_loss: 1.8720 - learning_rate: 8.1168e-06
Epoch 151/300
785/785 - 86s - 109ms/step - accuracy: 0.4391 - loss: 2.6357 - val_accuracy: 0.5909 - val_loss: 1.8712 - learning_rate: 8.1168e-06
Epoch 152/300
785/785 - 88s - 112ms/step - accuracy: 0.4491 - loss: 2.6086 - val_accuracy: 0.5898 - val_loss: 1.8755 - learning_rate: 8.1168e-06
Epoch 153/300
785/785 - 86s - 109ms/step - accuracy: 0.4480 - loss: 2.6125 - val_accuracy: 0.5903 - val_loss: 1.8770 - learning_rate: 8.1168e-06
Epoch 154/300

Epoch 154: ReduceLROnPlateau reducing learning rate to 4.058407739648828e-06.
785/785 - 88s - 112ms/step - accuracy: 0.4439 - loss: 2.6007 - val_accuracy: 0.5890 - val_loss: 1.8735 - learning_rate: 8.1168e-06
Epoch 155/300
785/785 - 88s - 112ms/step - accuracy: 0.4399 - loss: 2.6395 - val_accuracy: 0.5911 - val_loss: 1.8721 - learning_rate: 4.0584e-06
Epoch 156/300
785/785 - 87s - 111ms/step - accuracy: 0.4461 - loss: 2.6475 - val_accuracy: 0.5919 - val_loss: 1.8689 - learning_rate: 4.0584e-06
Epoch 157/300
785/785 - 86s - 110ms/step - accuracy: 0.4482 - loss: 2.6327 - val_accuracy: 0.5901 - val_loss: 1.8734 - learning_rate: 4.0584e-06
Epoch 158/300
785/785 - 87s - 111ms/step - accuracy: 0.4528 - loss: 2.5858 - val_accuracy: 0.5909 - val_loss: 1.8764 - learning_rate: 4.0584e-06
Epoch 159/300
785/785 - 88s - 112ms/step - accuracy: 0.4561 - loss: 2.5892 - val_accuracy: 0.5916 - val_loss: 1.8698 - learning_rate: 4.0584e-06
Epoch 160/300
785/785 - 87s - 111ms/step - accuracy: 0.4423 - loss: 2.5971 - val_accuracy: 0.5924 - val_loss: 1.8697 - learning_rate: 4.0584e-06
Epoch 161/300
785/785 - 87s - 111ms/step - accuracy: 0.4316 - loss: 2.6333 - val_accuracy: 0.5917 - val_loss: 1.8630 - learning_rate: 4.0584e-06
Epoch 162/300
785/785 - 86s - 109ms/step - accuracy: 0.4445 - loss: 2.6054 - val_accuracy: 0.5930 - val_loss: 1.8726 - learning_rate: 4.0584e-06
Epoch 163/300
785/785 - 87s - 111ms/step - accuracy: 0.4402 - loss: 2.6498 - val_accuracy: 0.5939 - val_loss: 1.8722 - learning_rate: 4.0584e-06
Epoch 164/300
785/785 - 86s - 109ms/step - accuracy: 0.4472 - loss: 2.6111 - val_accuracy: 0.5917 - val_loss: 1.8746 - learning_rate: 4.0584e-06
Epoch 165/300
785/785 - 87s - 110ms/step - accuracy: 0.4427 - loss: 2.6281 - val_accuracy: 0.5917 - val_loss: 1.8731 - learning_rate: 4.0584e-06
Epoch 166/300
785/785 - 93s - 119ms/step - accuracy: 0.4396 - loss: 2.6261 - val_accuracy: 0.5938 - val_loss: 1.8694 - learning_rate: 4.0584e-06
Epoch 167/300
785/785 - 88s - 112ms/step - accuracy: 0.4413 - loss: 2.5964 - val_accuracy: 0.5917 - val_loss: 1.8750 - learning_rate: 4.0584e-06
Epoch 168/300
785/785 - 88s - 112ms/step - accuracy: 0.4480 - loss: 2.6332 - val_accuracy: 0.5912 - val_loss: 1.8698 - learning_rate: 4.0584e-06
Epoch 169/300

Epoch 169: ReduceLROnPlateau reducing learning rate to 2.029203869824414e-06.
785/785 - 89s - 113ms/step - accuracy: 0.4439 - loss: 2.6457 - val_accuracy: 0.5933 - val_loss: 1.8682 - learning_rate: 4.0584e-06
Epoch 170/300
785/785 - 85s - 109ms/step - accuracy: 0.4429 - loss: 2.6158 - val_accuracy: 0.5925 - val_loss: 1.8708 - learning_rate: 2.0292e-06
Epoch 171/300
785/785 - 87s - 110ms/step - accuracy: 0.4431 - loss: 2.6236 - val_accuracy: 0.5928 - val_loss: 1.8691 - learning_rate: 2.0292e-06
Epoch 172/300
785/785 - 87s - 111ms/step - accuracy: 0.4439 - loss: 2.6040 - val_accuracy: 0.5933 - val_loss: 1.8688 - learning_rate: 2.0292e-06
Epoch 173/300
785/785 - 91s - 116ms/step - accuracy: 0.4415 - loss: 2.6229 - val_accuracy: 0.5935 - val_loss: 1.8736 - learning_rate: 2.0292e-06
Epoch 174/300
785/785 - 87s - 111ms/step - accuracy: 0.4485 - loss: 2.5910 - val_accuracy: 0.5935 - val_loss: 1.8679 - learning_rate: 2.0292e-06
Epoch 175/300
785/785 - 87s - 111ms/step - accuracy: 0.4419 - loss: 2.6437 - val_accuracy: 0.5930 - val_loss: 1.8687 - learning_rate: 2.0292e-06
Epoch 176/300
785/785 - 87s - 111ms/step - accuracy: 0.4521 - loss: 2.5757 - val_accuracy: 0.5911 - val_loss: 1.8686 - learning_rate: 2.0292e-06
Epoch 177/300

Epoch 177: ReduceLROnPlateau reducing learning rate to 1.014601934912207e-06.
785/785 - 86s - 109ms/step - accuracy: 0.4499 - loss: 2.5891 - val_accuracy: 0.5916 - val_loss: 1.8687 - learning_rate: 2.0292e-06
Epoch 177: early stopping
Restoring model weights from the end of the best epoch: 161.
Fold 1_1 Evaluation results: [1.8653091192245483, 0.5917197465896606]
              precision    recall  f1-score   support

        1820       0.67      0.81      0.74       296
        1821       0.90      0.81      0.85       289
        1822       0.00      0.00      0.00         6
        1823       0.00      0.00      0.00         9
        1824       0.00      0.00      0.00         6
        1825       0.00      0.00      0.00        11
        1826       0.33      0.25      0.29         8
        1827       0.81      0.66      0.73       118
        1828       0.00      0.00      0.00         6
        1829       0.77      0.48      0.59        21
        1830       0.52      0.60      0.56       282
        1831       0.73      0.92      0.81       673
        1832       0.71      0.71      0.71       338
        1833       0.78      0.91      0.84        88
        1834       0.42      0.69      0.52       143
        1835       0.00      0.00      0.00         8
        1836       0.00      0.00      0.00        18
        1837       0.37      0.29      0.32        38
        1838       0.00      0.00      0.00        23
        1839       0.00      0.00      0.00         3
        1840       0.57      0.56      0.56       220
        1841       0.74      0.52      0.61       552
        1842       0.40      0.67      0.50        21
        1843       0.00      0.00      0.00        37
        1844       0.00      0.00      0.00         1
        1845       0.00      0.00      0.00         4
        1846       0.33      0.07      0.12        27
        1847       0.00      0.00      0.00        11
        1848       0.27      0.13      0.18        23
        1849       0.50      0.15      0.24        26
        1850       0.35      0.63      0.45       227
        1851       0.75      0.73      0.74       380
        1852       0.00      0.00      0.00        40
        1853       0.00      0.00      0.00        25
        1854       0.00      0.00      0.00        14
        1855       0.36      0.10      0.16       119
        1856       0.59      0.58      0.58        59
        1857       0.40      0.71      0.51       149
        1858       0.00      0.00      0.00        13
        1859       0.00      0.00      0.00        16
        1860       0.29      0.41      0.34       328
        1861       0.79      0.82      0.80       436
        1862       0.24      0.05      0.08        98
        1863       0.36      0.46      0.40        90
        1864       0.31      0.35      0.33        86
        1865       0.42      0.16      0.23        31
        1866       0.43      0.09      0.15        33
        1867       0.50      0.07      0.12        56
        1868       0.00      0.00      0.00        37
        1869       0.00      0.00      0.00        27
        1870       0.41      0.51      0.46       162
        1871       0.65      0.74      0.69       239
        1872       0.33      0.08      0.13        36
        1873       0.30      0.12      0.17        51
        1874       0.00      0.00      0.00        22
        1875       0.29      0.21      0.24        77
        1876       0.84      0.73      0.78        49
        1877       0.33      0.07      0.12        27
        1878       0.40      0.60      0.48        40
        1879       0.00      0.00      0.00         7

    accuracy                           0.59      6280
   macro avg       0.32      0.29      0.29      6280
weighted avg       0.57      0.59      0.57      6280

Matthews Correlation Coefficient: 0.571
Macro avg F1: 0.286
Weighted avg F1: 0.566
Micro avg F1: 0.592
Top-3 Accuracy: 0.832
Top-5 Accuracy: 0.891
Micro ROC AUC  = 0.98
Macro ROC AUC (present classes) = 0.97
Classification MAE (in years): 3.31

Fold 1_1 Misclassification Analysis:
Near misses (within 2 years): 592 out of 2564 misclassifications (23.09%)
Big misses (greater than 10 years): 1068
MAE with outliers: 3.31
MAE without outliers: 2.37 (improvement: 0.94)

10 Worst misclassifications:
Image: data/datasets/public/1870/1879_9wikimedia2.jpg, True: 1879, Predicted: 1820, Error: 59
Image: data/datasets/public/1870/1879_26wikimedia2.jpg, True: 1879, Predicted: 1820, Error: 59
Image: data/datasets/public/1870/1877_033met.jpg, True: 1877, Predicted: 1820, Error: 57
Image: data/datasets/public/1820/1820_10wikimedia2.jpg, True: 1820, Predicted: 1876, Error: 56
Image: data/datasets/public/1820/1820_12wikimedia2.jpg, True: 1820, Predicted: 1871, Error: 51
Image: data/datasets/private/1870/1871_114etsy.jpg, True: 1871, Predicted: 1820, Error: 51
Image: data/datasets/private/1820/1821_462etsy.jpg, True: 1821, Predicted: 1871, Error: 50
Image: data/datasets/public/1820/1820_27wikimedia2.jpg, True: 1820, Predicted: 1870, Error: 50
Image: data/datasets/private/1820/1820_034_Zrzut ekranu 2022-07-26 203655.png, True: 1820, Predicted: 1870, Error: 50
Image: data/datasets/private/1870/1871_358etsy.jpg, True: 1871, Predicted: 1821, Error: 50

===== Fine Tuning 9 layers! =====
Epoch 1/300
785/785 - 149s - 190ms/step - accuracy: 0.1172 - loss: 4.5374 - val_accuracy: 0.1551 - val_loss: 3.8997 - learning_rate: 2.5974e-04
Epoch 2/300
785/785 - 86s - 110ms/step - accuracy: 0.1683 - loss: 4.2359 - val_accuracy: 0.2422 - val_loss: 3.8485 - learning_rate: 2.5974e-04
Epoch 3/300
785/785 - 86s - 110ms/step - accuracy: 0.2025 - loss: 4.0138 - val_accuracy: 0.3172 - val_loss: 3.5801 - learning_rate: 2.5974e-04
Epoch 4/300
785/785 - 89s - 113ms/step - accuracy: 0.2264 - loss: 3.8670 - val_accuracy: 0.3429 - val_loss: 3.2999 - learning_rate: 2.5974e-04
Epoch 5/300
785/785 - 87s - 111ms/step - accuracy: 0.2341 - loss: 3.7320 - val_accuracy: 0.3821 - val_loss: 3.1932 - learning_rate: 2.5974e-04
Epoch 6/300
785/785 - 87s - 111ms/step - accuracy: 0.2588 - loss: 3.6504 - val_accuracy: 0.3631 - val_loss: 3.0298 - learning_rate: 2.5974e-04
Epoch 7/300
785/785 - 88s - 112ms/step - accuracy: 0.2627 - loss: 3.5770 - val_accuracy: 0.4142 - val_loss: 2.9640 - learning_rate: 2.5974e-04
Epoch 8/300
785/785 - 88s - 112ms/step - accuracy: 0.2752 - loss: 3.5194 - val_accuracy: 0.4263 - val_loss: 2.8994 - learning_rate: 2.5974e-04
Epoch 9/300
785/785 - 86s - 109ms/step - accuracy: 0.2804 - loss: 3.4687 - val_accuracy: 0.4123 - val_loss: 2.7668 - learning_rate: 2.5974e-04
Epoch 10/300
785/785 - 87s - 111ms/step - accuracy: 0.3045 - loss: 3.4161 - val_accuracy: 0.4633 - val_loss: 2.7423 - learning_rate: 2.5974e-04
Epoch 11/300
785/785 - 87s - 111ms/step - accuracy: 0.2925 - loss: 3.3879 - val_accuracy: 0.4603 - val_loss: 2.6263 - learning_rate: 2.5974e-04
Epoch 12/300
785/785 - 89s - 114ms/step - accuracy: 0.3037 - loss: 3.3568 - val_accuracy: 0.4660 - val_loss: 2.6207 - learning_rate: 2.5974e-04
Epoch 13/300
785/785 - 89s - 113ms/step - accuracy: 0.3201 - loss: 3.3232 - val_accuracy: 0.4601 - val_loss: 2.5588 - learning_rate: 2.5974e-04
Epoch 14/300
785/785 - 88s - 112ms/step - accuracy: 0.3150 - loss: 3.3346 - val_accuracy: 0.4821 - val_loss: 2.6172 - learning_rate: 2.5974e-04
Epoch 15/300
785/785 - 85s - 109ms/step - accuracy: 0.3189 - loss: 3.2790 - val_accuracy: 0.4791 - val_loss: 2.5864 - learning_rate: 2.5974e-04
Epoch 16/300
785/785 - 86s - 110ms/step - accuracy: 0.3253 - loss: 3.2464 - val_accuracy: 0.4861 - val_loss: 2.5784 - learning_rate: 2.5974e-04
Epoch 17/300
785/785 - 88s - 112ms/step - accuracy: 0.3199 - loss: 3.2537 - val_accuracy: 0.4951 - val_loss: 2.4858 - learning_rate: 2.5974e-04
Epoch 18/300
785/785 - 87s - 111ms/step - accuracy: 0.3258 - loss: 3.2165 - val_accuracy: 0.4958 - val_loss: 2.4394 - learning_rate: 2.5974e-04
Epoch 19/300
785/785 - 88s - 112ms/step - accuracy: 0.3425 - loss: 3.1772 - val_accuracy: 0.5026 - val_loss: 2.4129 - learning_rate: 2.5974e-04
Epoch 20/300
785/785 - 88s - 112ms/step - accuracy: 0.3338 - loss: 3.2025 - val_accuracy: 0.5173 - val_loss: 2.3544 - learning_rate: 2.5974e-04
Epoch 21/300
785/785 - 88s - 112ms/step - accuracy: 0.3422 - loss: 3.2025 - val_accuracy: 0.4956 - val_loss: 2.4195 - learning_rate: 2.5974e-04
Epoch 22/300
785/785 - 88s - 112ms/step - accuracy: 0.3432 - loss: 3.1730 - val_accuracy: 0.4676 - val_loss: 2.4195 - learning_rate: 2.5974e-04
Epoch 23/300
785/785 - 88s - 112ms/step - accuracy: 0.3389 - loss: 3.1681 - val_accuracy: 0.5227 - val_loss: 2.3069 - learning_rate: 2.5974e-04
Epoch 24/300
                                                                                                                                                785/785 - 89s - 114ms/step - accuracy: 0.3471 - loss: 3.1267 - val_accuracy: 0.5049 - val_loss: 2.3588 - learning_rate: 2.5974e-04
Epoch 26/300
785/785 - 86s - 110ms/step - accuracy: 0.3510 - loss: 3.0982 - val_accuracy: 0.5052 - val_loss: 2.3763 - learning_rate: 2.5974e-04
Epoch 27/300
785/785 - 89s - 113ms/step - accuracy: 0.3511 - loss: 3.1023 - val_accuracy: 0.5179 - val_loss: 2.3023 - learning_rate: 2.5974e-04
Epoch 28/300
785/785 - 85s - 108ms/step - accuracy: 0.3530 - loss: 3.1025 - val_accuracy: 0.5158 - val_loss: 2.2835 - learning_rate: 2.5974e-04
Epoch 29/300
785/785 - 85s - 109ms/step - accuracy: 0.3538 - loss: 3.0690 - val_accuracy: 0.5345 - val_loss: 2.2437 - learning_rate: 2.5974e-04
Epoch 30/300
785/785 - 89s - 114ms/step - accuracy: 0.3629 - loss: 3.0705 - val_accuracy: 0.5216 - val_loss: 2.3010 - learning_rate: 2.5974e-04
Epoch 31/300
785/785 - 86s - 110ms/step - accuracy: 0.3650 - loss: 3.0736 - val_accuracy: 0.5227 - val_loss: 2.2800 - learning_rate: 2.5974e-04
Epoch 32/300
785/785 - 89s - 113ms/step - accuracy: 0.3613 - loss: 3.0615 - val_accuracy: 0.5251 - val_loss: 2.2138 - learning_rate: 2.5974e-04
Epoch 33/300
785/785 - 87s - 110ms/step - accuracy: 0.3618 - loss: 3.0578 - val_accuracy: 0.5127 - val_loss: 2.2525 - learning_rate: 2.5974e-04
Epoch 34/300
785/785 - 85s - 108ms/step - accuracy: 0.3689 - loss: 3.0329 - val_accuracy: 0.5225 - val_loss: 2.2355 - learning_rate: 2.5974e-04
Epoch 35/300
785/785 - 88s - 112ms/step - accuracy: 0.3556 - loss: 3.0746 - val_accuracy: 0.5343 - val_loss: 2.1688 - learning_rate: 2.5974e-04
Epoch 36/300
785/785 - 87s - 111ms/step - accuracy: 0.3621 - loss: 3.0332 - val_accuracy: 0.5214 - val_loss: 2.1985 - learning_rate: 2.5974e-04
Epoch 37/300
785/785 - 88s - 112ms/step - accuracy: 0.3739 - loss: 3.0272 - val_accuracy: 0.5265 - val_loss: 2.1959 - learning_rate: 2.5974e-04
Epoch 38/300
785/785 - 85s - 108ms/step - accuracy: 0.3734 - loss: 3.0013 - val_accuracy: 0.5463 - val_loss: 2.2150 - learning_rate: 2.5974e-04
Epoch 39/300
785/785 - 86s - 110ms/step - accuracy: 0.3747 - loss: 3.0158 - val_accuracy: 0.5318 - val_loss: 2.2068 - learning_rate: 2.5974e-04
Epoch 40/300
785/785 - 87s - 111ms/step - accuracy: 0.3689 - loss: 3.0024 - val_accuracy: 0.5538 - val_loss: 2.1248 - learning_rate: 2.5974e-04
Epoch 41/300
785/785 - 87s - 110ms/step - accuracy: 0.3666 - loss: 3.0165 - val_accuracy: 0.5404 - val_loss: 2.2079 - learning_rate: 2.5974e-04
Epoch 42/300
785/785 - 88s - 112ms/step - accuracy: 0.3675 - loss: 3.0017 - val_accuracy: 0.5257 - val_loss: 2.1413 - learning_rate: 2.5974e-04
Epoch 43/300
785/785 - 89s - 113ms/step - accuracy: 0.3739 - loss: 2.9871 - val_accuracy: 0.5493 - val_loss: 2.1480 - learning_rate: 2.5974e-04
Epoch 44/300
785/785 - 89s - 113ms/step - accuracy: 0.3707 - loss: 2.9950 - val_accuracy: 0.5455 - val_loss: 2.2592 - learning_rate: 2.5974e-04
Epoch 45/300
785/785 - 89s - 113ms/step - accuracy: 0.3799 - loss: 2.9783 - val_accuracy: 0.5412 - val_loss: 2.1679 - learning_rate: 2.5974e-04
Epoch 46/300
785/785 - 88s - 112ms/step - accuracy: 0.3818 - loss: 2.9435 - val_accuracy: 0.5416 - val_loss: 2.1096 - learning_rate: 2.5974e-04
Epoch 47/300
785/785 - 86s - 109ms/step - accuracy: 0.3903 - loss: 2.9599 - val_accuracy: 0.5520 - val_loss: 2.1788 - learning_rate: 2.5974e-04
Epoch 48/300
785/785 - 89s - 113ms/step - accuracy: 0.3814 - loss: 2.9775 - val_accuracy: 0.5485 - val_loss: 2.0643 - learning_rate: 2.5974e-04
Epoch 49/300
785/785 - 86s - 109ms/step - accuracy: 0.3761 - loss: 2.9441 - val_accuracy: 0.5459 - val_loss: 2.1286 - learning_rate: 2.5974e-04
Epoch 50/300
785/785 - 88s - 112ms/step - accuracy: 0.3788 - loss: 2.9635 - val_accuracy: 0.5456 - val_loss: 2.1106 - learning_rate: 2.5974e-04
Epoch 51/300
785/785 - 87s - 111ms/step - accuracy: 0.3834 - loss: 2.9471 - val_accuracy: 0.5549 - val_loss: 2.1019 - learning_rate: 2.5974e-04
Epoch 52/300
785/785 - 87s - 111ms/step - accuracy: 0.3830 - loss: 2.9748 - val_accuracy: 0.5630 - val_loss: 2.1213 - learning_rate: 2.5974e-04
Epoch 53/300
785/785 - 87s - 111ms/step - accuracy: 0.3892 - loss: 2.9209 - val_accuracy: 0.5482 - val_loss: 2.1021 - learning_rate: 2.5974e-04
Epoch 54/300
785/785 - 87s - 111ms/step - accuracy: 0.3852 - loss: 2.9295 - val_accuracy: 0.5636 - val_loss: 2.1083 - learning_rate: 2.5974e-04
Epoch 55/300
785/785 - 88s - 112ms/step - accuracy: 0.3939 - loss: 2.8980 - val_accuracy: 0.5638 - val_loss: 2.0731 - learning_rate: 2.5974e-04
Epoch 56/300

Epoch 56: ReduceLROnPlateau reducing learning rate to 0.0001298690476687625.
785/785 - 87s - 111ms/step - accuracy: 0.3817 - loss: 2.9432 - val_accuracy: 0.5498 - val_loss: 2.1065 - learning_rate: 2.5974e-04
Epoch 57/300
785/785 - 87s - 111ms/step - accuracy: 0.3960 - loss: 2.8794 - val_accuracy: 0.5678 - val_loss: 2.0678 - learning_rate: 1.2987e-04
Epoch 58/300
785/785 - 87s - 110ms/step - accuracy: 0.4010 - loss: 2.8615 - val_accuracy: 0.5703 - val_loss: 2.0245 - learning_rate: 1.2987e-04
Epoch 59/300
785/785 - 87s - 111ms/step - accuracy: 0.3912 - loss: 2.8713 - val_accuracy: 0.5652 - val_loss: 2.0353 - learning_rate: 1.2987e-04
Epoch 60/300
785/785 - 85s - 108ms/step - accuracy: 0.4075 - loss: 2.8395 - val_accuracy: 0.5703 - val_loss: 2.0490 - learning_rate: 1.2987e-04
Epoch 61/300
785/785 - 88s - 112ms/step - accuracy: 0.3873 - loss: 2.9002 - val_accuracy: 0.5689 - val_loss: 2.0454 - learning_rate: 1.2987e-04
Epoch 62/300
785/785 - 88s - 112ms/step - accuracy: 0.4029 - loss: 2.8755 - val_accuracy: 0.5689 - val_loss: 2.0338 - learning_rate: 1.2987e-04
Epoch 63/300
785/785 - 87s - 111ms/step - accuracy: 0.4030 - loss: 2.8452 - val_accuracy: 0.5775 - val_loss: 2.0192 - learning_rate: 1.2987e-04
Epoch 64/300
785/785 - 88s - 112ms/step - accuracy: 0.4040 - loss: 2.8347 - val_accuracy: 0.5655 - val_loss: 2.0357 - learning_rate: 1.2987e-04
Epoch 65/300
785/785 - 88s - 112ms/step - accuracy: 0.4025 - loss: 2.8456 - val_accuracy: 0.5624 - val_loss: 2.0526 - learning_rate: 1.2987e-04
Epoch 66/300
785/785 - 85s - 108ms/step - accuracy: 0.3986 - loss: 2.8598 - val_accuracy: 0.5700 - val_loss: 2.0171 - learning_rate: 1.2987e-04
Epoch 67/300
785/785 - 87s - 111ms/step - accuracy: 0.3939 - loss: 2.8449 - val_accuracy: 0.5775 - val_loss: 2.0019 - learning_rate: 1.2987e-04
Epoch 68/300
785/785 - 88s - 113ms/step - accuracy: 0.3952 - loss: 2.8077 - val_accuracy: 0.5660 - val_loss: 2.0138 - learning_rate: 1.2987e-04
Epoch 69/300
785/785 - 86s - 110ms/step - accuracy: 0.4014 - loss: 2.8261 - val_accuracy: 0.5697 - val_loss: 2.0179 - learning_rate: 1.2987e-04
Epoch 70/300
785/785 - 87s - 111ms/step - accuracy: 0.4065 - loss: 2.8191 - val_accuracy: 0.5770 - val_loss: 1.9897 - learning_rate: 1.2987e-04
Epoch 71/300
785/785 - 88s - 112ms/step - accuracy: 0.3995 - loss: 2.8380 - val_accuracy: 0.5725 - val_loss: 1.9920 - learning_rate: 1.2987e-04
Epoch 72/300
785/785 - 87s - 111ms/step - accuracy: 0.3973 - loss: 2.8011 - val_accuracy: 0.5786 - val_loss: 1.9876 - learning_rate: 1.2987e-04
Epoch 73/300
785/785 - 89s - 113ms/step - accuracy: 0.4100 - loss: 2.7615 - val_accuracy: 0.5759 - val_loss: 1.9807 - learning_rate: 1.2987e-04
Epoch 74/300
785/785 - 88s - 112ms/step - accuracy: 0.4049 - loss: 2.8115 - val_accuracy: 0.5703 - val_loss: 2.0045 - learning_rate: 1.2987e-04
Epoch 75/300
785/785 - 86s - 109ms/step - accuracy: 0.4124 - loss: 2.8025 - val_accuracy: 0.5713 - val_loss: 1.9736 - learning_rate: 1.2987e-04
Epoch 76/300
785/785 - 89s - 113ms/step - accuracy: 0.4040 - loss: 2.8078 - val_accuracy: 0.5791 - val_loss: 1.9643 - learning_rate: 1.2987e-04
Epoch 77/300
785/785 - 87s - 111ms/step - accuracy: 0.4084 - loss: 2.7857 - val_accuracy: 0.5826 - val_loss: 1.9687 - learning_rate: 1.2987e-04
Epoch 78/300
785/785 - 86s - 110ms/step - accuracy: 0.4029 - loss: 2.8282 - val_accuracy: 0.5826 - val_loss: 1.9670 - learning_rate: 1.2987e-04
Epoch 79/300
785/785 - 87s - 111ms/step - accuracy: 0.4008 - loss: 2.8322 - val_accuracy: 0.5773 - val_loss: 1.9978 - learning_rate: 1.2987e-04
Epoch 80/300
785/785 - 86s - 110ms/step - accuracy: 0.4089 - loss: 2.7911 - val_accuracy: 0.5780 - val_loss: 1.9860 - learning_rate: 1.2987e-04
Epoch 81/300
785/785 - 93s - 119ms/step - accuracy: 0.4068 - loss: 2.8052 - val_accuracy: 0.5710 - val_loss: 2.0045 - learning_rate: 1.2987e-04
Epoch 82/300
785/785 - 86s - 109ms/step - accuracy: 0.4111 - loss: 2.8266 - val_accuracy: 0.5832 - val_loss: 2.0179 - learning_rate: 1.2987e-04
Epoch 83/300
785/785 - 88s - 112ms/step - accuracy: 0.4078 - loss: 2.7969 - val_accuracy: 0.5789 - val_loss: 1.9657 - learning_rate: 1.2987e-04
Epoch 84/300

Epoch 84: ReduceLROnPlateau reducing learning rate to 6.493452383438125e-05.
785/785 - 87s - 111ms/step - accuracy: 0.4111 - loss: 2.7820 - val_accuracy: 0.5724 - val_loss: 2.0007 - learning_rate: 1.2987e-04
Epoch 85/300
785/785 - 85s - 108ms/step - accuracy: 0.4100 - loss: 2.7737 - val_accuracy: 0.5791 - val_loss: 1.9620 - learning_rate: 6.4935e-05
Epoch 86/300
785/785 - 88s - 112ms/step - accuracy: 0.4123 - loss: 2.7661 - val_accuracy: 0.5735 - val_loss: 1.9842 - learning_rate: 6.4935e-05
Epoch 87/300
785/785 - 86s - 109ms/step - accuracy: 0.4143 - loss: 2.7519 - val_accuracy: 0.5862 - val_loss: 1.9551 - learning_rate: 6.4935e-05
Epoch 88/300
785/785 - 88s - 112ms/step - accuracy: 0.4148 - loss: 2.7651 - val_accuracy: 0.5831 - val_loss: 1.9571 - learning_rate: 6.4935e-05
Epoch 89/300
785/785 - 87s - 111ms/step - accuracy: 0.4158 - loss: 2.7378 - val_accuracy: 0.5867 - val_loss: 1.9484 - learning_rate: 6.4935e-05
Epoch 90/300
785/785 - 87s - 111ms/step - accuracy: 0.4143 - loss: 2.7559 - val_accuracy: 0.5872 - val_loss: 1.9504 - learning_rate: 6.4935e-05
Epoch 91/300
785/785 - 87s - 111ms/step - accuracy: 0.4135 - loss: 2.7396 - val_accuracy: 0.5815 - val_loss: 1.9561 - learning_rate: 6.4935e-05
Epoch 92/300
785/785 - 88s - 112ms/step - accuracy: 0.4146 - loss: 2.7333 - val_accuracy: 0.5896 - val_loss: 1.9375 - learning_rate: 6.4935e-05
Epoch 93/300
785/785 - 87s - 110ms/step - accuracy: 0.4139 - loss: 2.7416 - val_accuracy: 0.5864 - val_loss: 1.9528 - learning_rate: 6.4935e-05
Epoch 94/300
785/785 - 88s - 112ms/step - accuracy: 0.4245 - loss: 2.6987 - val_accuracy: 0.5869 - val_loss: 1.9413 - learning_rate: 6.4935e-05
Epoch 95/300
785/785 - 87s - 110ms/step - accuracy: 0.4167 - loss: 2.7498 - val_accuracy: 0.5832 - val_loss: 1.9444 - learning_rate: 6.4935e-05
Epoch 96/300
785/785 - 87s - 111ms/step - accuracy: 0.4159 - loss: 2.7297 - val_accuracy: 0.5869 - val_loss: 1.9497 - learning_rate: 6.4935e-05
Epoch 97/300
785/785 - 89s - 113ms/step - accuracy: 0.4199 - loss: 2.7354 - val_accuracy: 0.5883 - val_loss: 1.9541 - learning_rate: 6.4935e-05
Epoch 98/300
785/785 - 84s - 107ms/step - accuracy: 0.4240 - loss: 2.7465 - val_accuracy: 0.5889 - val_loss: 1.9398 - learning_rate: 6.4935e-05
Epoch 99/300
785/785 - 89s - 113ms/step - accuracy: 0.4183 - loss: 2.7518 - val_accuracy: 0.5872 - val_loss: 1.9519 - learning_rate: 6.4935e-05
Epoch 100/300
785/785 - 87s - 110ms/step - accuracy: 0.4142 - loss: 2.7551 - val_accuracy: 0.5872 - val_loss: 1.9348 - learning_rate: 6.4935e-05
Epoch 101/300
785/785 - 87s - 111ms/step - accuracy: 0.4104 - loss: 2.7750 - val_accuracy: 0.5875 - val_loss: 1.9467 - learning_rate: 6.4935e-05
Epoch 102/300
785/785 - 94s - 120ms/step - accuracy: 0.4271 - loss: 2.7175 - val_accuracy: 0.5888 - val_loss: 1.9414 - learning_rate: 6.4935e-05
Epoch 103/300
785/785 - 87s - 111ms/step - accuracy: 0.4154 - loss: 2.7430 - val_accuracy: 0.5905 - val_loss: 1.9333 - learning_rate: 6.4935e-05
Epoch 104/300
785/785 - 87s - 111ms/step - accuracy: 0.4248 - loss: 2.7313 - val_accuracy: 0.5850 - val_loss: 1.9288 - learning_rate: 6.4935e-05
Epoch 105/300
785/785 - 86s - 110ms/step - accuracy: 0.4188 - loss: 2.7346 - val_accuracy: 0.5859 - val_loss: 1.9302 - learning_rate: 6.4935e-05
Epoch 106/300
785/785 - 87s - 111ms/step - accuracy: 0.4205 - loss: 2.7111 - val_accuracy: 0.5893 - val_loss: 1.9265 - learning_rate: 6.4935e-05
Epoch 107/300
785/785 - 86s - 110ms/step - accuracy: 0.4151 - loss: 2.7591 - val_accuracy: 0.5837 - val_loss: 1.9357 - learning_rate: 6.4935e-05
Epoch 108/300
785/785 - 86s - 110ms/step - accuracy: 0.4212 - loss: 2.7666 - val_accuracy: 0.5819 - val_loss: 1.9491 - learning_rate: 6.4935e-05
Epoch 109/300
785/785 - 86s - 109ms/step - accuracy: 0.4264 - loss: 2.7485 - val_accuracy: 0.5918 - val_loss: 1.9105 - learning_rate: 6.4935e-05
Epoch 110/300
785/785 - 88s - 112ms/step - accuracy: 0.4204 - loss: 2.7247 - val_accuracy: 0.5883 - val_loss: 1.9247 - learning_rate: 6.4935e-05
Epoch 111/300
785/785 - 85s - 108ms/step - accuracy: 0.4142 - loss: 2.7317 - val_accuracy: 0.5880 - val_loss: 1.9364 - learning_rate: 6.4935e-05
Epoch 112/300
785/785 - 88s - 113ms/step - accuracy: 0.4220 - loss: 2.7120 - val_accuracy: 0.5969 - val_loss: 1.9266 - learning_rate: 6.4935e-05
Epoch 113/300
785/785 - 87s - 110ms/step - accuracy: 0.4207 - loss: 2.7102 - val_accuracy: 0.5882 - val_loss: 1.9162 - learning_rate: 6.4935e-05
Epoch 114/300
785/785 - 87s - 110ms/step - accuracy: 0.4185 - loss: 2.7469 - val_accuracy: 0.5888 - val_loss: 1.9374 - learning_rate: 6.4935e-05
Epoch 115/300
785/785 - 88s - 112ms/step - accuracy: 0.4199 - loss: 2.7207 - val_accuracy: 0.5902 - val_loss: 1.9272 - learning_rate: 6.4935e-05
Epoch 116/300
785/785 - 86s - 109ms/step - accuracy: 0.4186 - loss: 2.7720 - val_accuracy: 0.5792 - val_loss: 1.9609 - learning_rate: 6.4935e-05
Epoch 117/300

Epoch 117: ReduceLROnPlateau reducing learning rate to 3.2467261917190626e-05.
785/785 - 86s - 110ms/step - accuracy: 0.4226 - loss: 2.7143 - val_accuracy: 0.5913 - val_loss: 1.9258 - learning_rate: 6.4935e-05
Epoch 118/300
785/785 - 87s - 111ms/step - accuracy: 0.4269 - loss: 2.6911 - val_accuracy: 0.5940 - val_loss: 1.9076 - learning_rate: 3.2467e-05
Epoch 119/300
785/785 - 86s - 110ms/step - accuracy: 0.4239 - loss: 2.6907 - val_accuracy: 0.5939 - val_loss: 1.9126 - learning_rate: 3.2467e-05
Epoch 120/300
785/785 - 89s - 113ms/step - accuracy: 0.4260 - loss: 2.6912 - val_accuracy: 0.5945 - val_loss: 1.9271 - learning_rate: 3.2467e-05
Epoch 121/300
785/785 - 87s - 111ms/step - accuracy: 0.4320 - loss: 2.6820 - val_accuracy: 0.5944 - val_loss: 1.9086 - learning_rate: 3.2467e-05
Epoch 122/300
785/785 - 87s - 110ms/step - accuracy: 0.4202 - loss: 2.7265 - val_accuracy: 0.5921 - val_loss: 1.9089 - learning_rate: 3.2467e-05
Epoch 123/300
785/785 - 88s - 112ms/step - accuracy: 0.4250 - loss: 2.7008 - val_accuracy: 0.5921 - val_loss: 1.9085 - learning_rate: 3.2467e-05
Epoch 124/300
785/785 - 87s - 111ms/step - accuracy: 0.4355 - loss: 2.6648 - val_accuracy: 0.5925 - val_loss: 1.9062 - learning_rate: 3.2467e-05
Epoch 125/300
785/785 - 89s - 113ms/step - accuracy: 0.4221 - loss: 2.7063 - val_accuracy: 0.5917 - val_loss: 1.9118 - learning_rate: 3.2467e-05
Epoch 126/300
785/785 - 88s - 111ms/step - accuracy: 0.4285 - loss: 2.6945 - val_accuracy: 0.5891 - val_loss: 1.9096 - learning_rate: 3.2467e-05
Epoch 127/300
785/785 - 86s - 110ms/step - accuracy: 0.4342 - loss: 2.7010 - val_accuracy: 0.5961 - val_loss: 1.9011 - learning_rate: 3.2467e-05
Epoch 128/300
785/785 - 87s - 110ms/step - accuracy: 0.4236 - loss: 2.7157 - val_accuracy: 0.5929 - val_loss: 1.9096 - learning_rate: 3.2467e-05
Epoch 129/300
785/785 - 140s - 179ms/step - accuracy: 0.4339 - loss: 2.6582 - val_accuracy: 0.5939 - val_loss: 1.8889 - learning_rate: 3.2467e-05
Epoch 130/300
785/785 - 89s - 113ms/step - accuracy: 0.4400 - loss: 2.6544 - val_accuracy: 0.5862 - val_loss: 1.9083 - learning_rate: 3.2467e-05
Epoch 131/300
785/785 - 87s - 111ms/step - accuracy: 0.4314 - loss: 2.6705 - val_accuracy: 0.5952 - val_loss: 1.8841 - learning_rate: 3.2467e-05
Epoch 132/300
785/785 - 87s - 111ms/step - accuracy: 0.4269 - loss: 2.7112 - val_accuracy: 0.5956 - val_loss: 1.8991 - learning_rate: 3.2467e-05
Epoch 133/300
785/785 - 86s - 110ms/step - accuracy: 0.4320 - loss: 2.6745 - val_accuracy: 0.5936 - val_loss: 1.9175 - learning_rate: 3.2467e-05
Epoch 134/300
785/785 - 87s - 110ms/step - accuracy: 0.4322 - loss: 2.6954 - val_accuracy: 0.5934 - val_loss: 1.9027 - learning_rate: 3.2467e-05
Epoch 135/300
785/785 - 87s - 111ms/step - accuracy: 0.4285 - loss: 2.6936 - val_accuracy: 0.5974 - val_loss: 1.8885 - learning_rate: 3.2467e-05
Epoch 136/300
785/785 - 86s - 109ms/step - accuracy: 0.4269 - loss: 2.6944 - val_accuracy: 0.5944 - val_loss: 1.8954 - learning_rate: 3.2467e-05
Epoch 137/300
785/785 - 86s - 109ms/step - accuracy: 0.4237 - loss: 2.6974 - val_accuracy: 0.5964 - val_loss: 1.9011 - learning_rate: 3.2467e-05
Epoch 138/300
785/785 - 89s - 113ms/step - accuracy: 0.4314 - loss: 2.6973 - val_accuracy: 0.5936 - val_loss: 1.8874 - learning_rate: 3.2467e-05
Epoch 139/300

Epoch 139: ReduceLROnPlateau reducing learning rate to 1.6233630958595313e-05.
785/785 - 87s - 111ms/step - accuracy: 0.4384 - loss: 2.6694 - val_accuracy: 0.5985 - val_loss: 1.8890 - learning_rate: 3.2467e-05
Epoch 140/300
785/785 - 88s - 112ms/step - accuracy: 0.4306 - loss: 2.6647 - val_accuracy: 0.5955 - val_loss: 1.8888 - learning_rate: 1.6234e-05
Epoch 141/300
785/785 - 87s - 111ms/step - accuracy: 0.4323 - loss: 2.6798 - val_accuracy: 0.5950 - val_loss: 1.8962 - learning_rate: 1.6234e-05
Epoch 142/300
785/785 - 86s - 109ms/step - accuracy: 0.4376 - loss: 2.6690 - val_accuracy: 0.5947 - val_loss: 1.8884 - learning_rate: 1.6234e-05
Epoch 143/300
785/785 - 89s - 114ms/step - accuracy: 0.4385 - loss: 2.6744 - val_accuracy: 0.5966 - val_loss: 1.8771 - learning_rate: 1.6234e-05
Epoch 144/300
785/785 - 87s - 111ms/step - accuracy: 0.4285 - loss: 2.6625 - val_accuracy: 0.5968 - val_loss: 1.8919 - learning_rate: 1.6234e-05
Epoch 145/300
785/785 - 89s - 114ms/step - accuracy: 0.4247 - loss: 2.6823 - val_accuracy: 0.5955 - val_loss: 1.8894 - learning_rate: 1.6234e-05
Epoch 146/300
785/785 - 86s - 110ms/step - accuracy: 0.4322 - loss: 2.6906 - val_accuracy: 0.5960 - val_loss: 1.9037 - learning_rate: 1.6234e-05
Epoch 147/300
785/785 - 87s - 111ms/step - accuracy: 0.4268 - loss: 2.6710 - val_accuracy: 0.5958 - val_loss: 1.8905 - learning_rate: 1.6234e-05
Epoch 148/300
785/785 - 86s - 110ms/step - accuracy: 0.4240 - loss: 2.6808 - val_accuracy: 0.5953 - val_loss: 1.8910 - learning_rate: 1.6234e-05
Epoch 149/300
785/785 - 86s - 110ms/step - accuracy: 0.4311 - loss: 2.7297 - val_accuracy: 0.5956 - val_loss: 1.8797 - learning_rate: 1.6234e-05
Epoch 150/300
785/785 - 87s - 111ms/step - accuracy: 0.4317 - loss: 2.6601 - val_accuracy: 0.5950 - val_loss: 1.8916 - learning_rate: 1.6234e-05
Epoch 151/300

Epoch 151: ReduceLROnPlateau reducing learning rate to 8.116815479297657e-06.
785/785 - 92s - 118ms/step - accuracy: 0.4279 - loss: 2.6975 - val_accuracy: 0.5942 - val_loss: 1.8884 - learning_rate: 1.6234e-05
Epoch 152/300
785/785 - 94s - 119ms/step - accuracy: 0.4248 - loss: 2.6859 - val_accuracy: 0.5974 - val_loss: 1.8886 - learning_rate: 8.1168e-06
Epoch 153/300
785/785 - 85s - 108ms/step - accuracy: 0.4463 - loss: 2.6586 - val_accuracy: 0.5966 - val_loss: 1.8830 - learning_rate: 8.1168e-06
Epoch 154/300
785/785 - 87s - 111ms/step - accuracy: 0.4428 - loss: 2.6391 - val_accuracy: 0.5977 - val_loss: 1.8844 - learning_rate: 8.1168e-06
Epoch 155/300
785/785 - 86s - 109ms/step - accuracy: 0.4256 - loss: 2.6740 - val_accuracy: 0.5975 - val_loss: 1.8876 - learning_rate: 8.1168e-06
Epoch 156/300
785/785 - 87s - 111ms/step - accuracy: 0.4299 - loss: 2.6797 - val_accuracy: 0.5964 - val_loss: 1.8855 - learning_rate: 8.1168e-06
Epoch 157/300
785/785 - 89s - 114ms/step - accuracy: 0.4322 - loss: 2.6717 - val_accuracy: 0.5963 - val_loss: 1.8828 - learning_rate: 8.1168e-06
Epoch 158/300
785/785 - 87s - 110ms/step - accuracy: 0.4354 - loss: 2.6714 - val_accuracy: 0.5963 - val_loss: 1.8931 - learning_rate: 8.1168e-06
Epoch 159/300

Epoch 159: ReduceLROnPlateau reducing learning rate to 4.058407739648828e-06.
785/785 - 88s - 112ms/step - accuracy: 0.4385 - loss: 2.6584 - val_accuracy: 0.5960 - val_loss: 1.8833 - learning_rate: 8.1168e-06
Epoch 159: early stopping
Restoring model weights from the end of the best epoch: 143.
Fold 1_2 Evaluation results: [1.880307674407959, 0.5965918302536011]
              precision    recall  f1-score   support

        1820       0.70      0.79      0.74       321
        1821       0.90      0.86      0.88       285
        1822       0.00      0.00      0.00         8
        1823       0.00      0.00      0.00         4
        1824       0.00      0.00      0.00         4
        1825       0.33      0.10      0.15        10
        1826       1.00      0.07      0.12        15
        1827       0.73      0.78      0.75       132
        1828       0.00      0.00      0.00        11
        1829       1.00      0.17      0.30        23
        1830       0.54      0.62      0.57       278
        1831       0.79      0.91      0.84       671
        1832       0.76      0.76      0.76       341
        1833       0.71      0.90      0.80       102
        1834       0.43      0.60      0.50       149
        1835       0.00      0.00      0.00        13
        1836       0.00      0.00      0.00        17
        1837       0.36      0.46      0.41        26
        1838       0.00      0.00      0.00        15
        1839       0.00      0.00      0.00         5
        1840       0.38      0.62      0.47       207
        1841       0.71      0.58      0.64       523
        1842       0.80      0.12      0.21        34
        1843       0.33      0.10      0.15        21
        1844       0.00      0.00      0.00         2
        1845       0.00      0.00      0.00         7
        1846       1.00      0.03      0.06        30
        1847       0.00      0.00      0.00         9
        1848       0.00      0.00      0.00        32
        1849       0.00      0.00      0.00        27
        1850       0.35      0.58      0.44       250
        1851       0.71      0.68      0.69       390
        1852       0.11      0.03      0.05        34
        1853       0.00      0.00      0.00        38
        1854       0.00      0.00      0.00        10
        1855       0.29      0.02      0.03       113
        1856       0.69      0.54      0.61        61
        1857       0.38      0.65      0.48       158
        1858       0.00      0.00      0.00        10
        1859       0.00      0.00      0.00         9
        1860       0.30      0.39      0.34       318
        1861       0.78      0.79      0.78       414
        1862       0.27      0.04      0.08        91
        1863       0.35      0.44      0.39        94
        1864       0.29      0.12      0.17        84
        1865       1.00      0.11      0.21        35
        1866       0.67      0.08      0.15        24
        1867       0.17      0.04      0.07        48
        1868       0.00      0.00      0.00        36
        1869       0.00      0.00      0.00        26
        1870       0.33      0.66      0.44       145
        1871       0.76      0.79      0.77       252
        1872       0.43      0.09      0.14        35
        1873       0.67      0.04      0.07        55
        1874       0.00      0.00      0.00        30
        1875       0.31      0.66      0.42        62
        1876       0.88      0.88      0.88        51
        1877       0.20      0.15      0.17        27
        1878       1.00      0.30      0.46        50
        1879       0.00      0.00      0.00         7

    accuracy                           0.60      6279
   macro avg       0.37      0.28      0.27      6279
weighted avg       0.59      0.60      0.57      6279

Matthews Correlation Coefficient: 0.576
Macro avg F1: 0.270
Weighted avg F1: 0.568
Micro avg F1: 0.597
Top-3 Accuracy: 0.830
Top-5 Accuracy: 0.890
Micro ROC AUC  = 0.98
Macro ROC AUC (present classes) = 0.96
Classification MAE (in years): 3.30

Fold 1_2 Misclassification Analysis:
Near misses (within 2 years): 519 out of 2533 misclassifications (20.49%)
Big misses (greater than 10 years): 1044
MAE with outliers: 3.30
MAE without outliers: 2.36 (improvement: 0.94)

10 Worst misclassifications:
Image: data/datasets/public/1870/1877_035met.jpg, True: 1877, Predicted: 1820, Error: 57
Image: data/datasets/public/1870/1876_70washington.jpg, True: 1876, Predicted: 1820, Error: 56
Image: data/datasets/private/1870/1871_404etsy.jpg, True: 1871, Predicted: 1821, Error: 50
Image: data/datasets/private/1820/1821_580etsy.jpg, True: 1821, Predicted: 1871, Error: 50
Image: data/datasets/private/1820/1826_036_Zrzut ekranu 2022-07-26 210151.png, True: 1826, Predicted: 1876, Error: 50
Image: data/datasets/public/1870/1870_75wikimedia2.jpg, True: 1870, Predicted: 1820, Error: 50
Image: data/datasets/private/1870/1871_384etsy.jpg, True: 1871, Predicted: 1821, Error: 50
Image: data/datasets/public/1860/1868_007met.jpg, True: 1868, Predicted: 1820, Error: 48
Image: data/datasets/public/1870/1879_39wikimedia2.jpg, True: 1879, Predicted: 1831, Error: 48
Image: data/datasets/public/1870/1878_1258vna.jpg, True: 1878, Predicted: 1832, Error: 46
=== Training Alternative Model ===

===== Fine Tuning 9 layers! =====
Epoch 1/300
785/785 - 113s - 144ms/step - accuracy: 0.1174 - loss: 4.5023 - val_accuracy: 0.1873 - val_loss: 3.8912 - learning_rate: 2.5974e-04
Epoch 2/300
785/785 - 87s - 110ms/step - accuracy: 0.1640 - loss: 4.2280 - val_accuracy: 0.2541 - val_loss: 3.9740 - learning_rate: 2.5974e-04
Epoch 3/300
785/785 - 87s - 111ms/step - accuracy: 0.1986 - loss: 4.0234 - val_accuracy: 0.2838 - val_loss: 3.5360 - learning_rate: 2.5974e-04
Epoch 4/300
785/785 - 87s - 111ms/step - accuracy: 0.2166 - loss: 3.8420 - val_accuracy: 0.3447 - val_loss: 3.3012 - learning_rate: 2.5974e-04
Epoch 5/300
785/785 - 85s - 108ms/step - accuracy: 0.2440 - loss: 3.7108 - val_accuracy: 0.4118 - val_loss: 3.1909 - learning_rate: 2.5974e-04
Epoch 6/300
785/785 - 87s - 111ms/step - accuracy: 0.2639 - loss: 3.6355 - val_accuracy: 0.4054 - val_loss: 3.0605 - learning_rate: 2.5974e-04
Epoch 7/300
785/785 - 97s - 123ms/step - accuracy: 0.2744 - loss: 3.5386 - val_accuracy: 0.4240 - val_loss: 2.8967 - learning_rate: 2.5974e-04
Epoch 8/300
785/785 - 97s - 123ms/step - accuracy: 0.2838 - loss: 3.4695 - val_accuracy: 0.4395 - val_loss: 2.8103 - learning_rate: 2.5974e-04
Epoch 9/300
785/785 - 97s - 123ms/step - accuracy: 0.2856 - loss: 3.4544 - val_accuracy: 0.4202 - val_loss: 2.7573 - learning_rate: 2.5974e-04
Epoch 10/300
785/785 - 96s - 122ms/step - accuracy: 0.3005 - loss: 3.4087 - val_accuracy: 0.4406 - val_loss: 2.6478 - learning_rate: 2.5974e-04
Epoch 11/300
785/785 - 95s - 121ms/step - accuracy: 0.2993 - loss: 3.3357 - val_accuracy: 0.4110 - val_loss: 2.7360 - learning_rate: 2.5974e-04
Epoch 12/300
785/785 - 96s - 123ms/step - accuracy: 0.3142 - loss: 3.2940 - val_accuracy: 0.4908 - val_loss: 2.5824 - learning_rate: 2.5974e-04
Epoch 13/300
785/785 - 97s - 123ms/step - accuracy: 0.3165 - loss: 3.3156 - val_accuracy: 0.4748 - val_loss: 2.5821 - learning_rate: 2.5974e-04
Epoch 14/300
785/785 - 96s - 122ms/step - accuracy: 0.3177 - loss: 3.2896 - val_accuracy: 0.4849 - val_loss: 2.5812 - learning_rate: 2.5974e-04
Epoch 15/300
785/785 - 96s - 122ms/step - accuracy: 0.3219 - loss: 3.2394 - val_accuracy: 0.5005 - val_loss: 2.4749 - learning_rate: 2.5974e-04
Epoch 16/300
785/785 - 97s - 123ms/step - accuracy: 0.3313 - loss: 3.2443 - val_accuracy: 0.4946 - val_loss: 2.5106 - learning_rate: 2.5974e-04
Epoch 17/300
785/785 - 95s - 121ms/step - accuracy: 0.3305 - loss: 3.2073 - val_accuracy: 0.5043 - val_loss: 2.4364 - learning_rate: 2.5974e-04
Epoch 18/300
785/785 - 144s - 183ms/step - accuracy: 0.3354 - loss: 3.2085 - val_accuracy: 0.4967 - val_loss: 2.4497 - learning_rate: 2.5974e-04
Epoch 19/300
785/785 - 97s - 123ms/step - accuracy: 0.3360 - loss: 3.1743 - val_accuracy: 0.5182 - val_loss: 2.4064 - learning_rate: 2.5974e-04
Epoch 20/300
785/785 - 95s - 121ms/step - accuracy: 0.3440 - loss: 3.1636 - val_accuracy: 0.4971 - val_loss: 2.3776 - learning_rate: 2.5974e-04
Epoch 21/300
785/785 - 96s - 123ms/step - accuracy: 0.3467 - loss: 3.1719 - val_accuracy: 0.5127 - val_loss: 2.4074 - learning_rate: 2.5974e-04
Epoch 22/300
785/785 - 94s - 120ms/step - accuracy: 0.3467 - loss: 3.1342 - val_accuracy: 0.5041 - val_loss: 2.3789 - learning_rate: 2.5974e-04
Epoch 23/300
785/785 - 95s - 121ms/step - accuracy: 0.3505 - loss: 3.1319 - val_accuracy: 0.5215 - val_loss: 2.3089 - learning_rate: 2.5974e-04
Epoch 24/300
785/785 - 96s - 122ms/step - accuracy: 0.3469 - loss: 3.1161 - val_accuracy: 0.5073 - val_loss: 2.3745 - learning_rate: 2.5974e-04
Epoch 25/300
785/785 - 96s - 122ms/step - accuracy: 0.3673 - loss: 3.1046 - val_accuracy: 0.5150 - val_loss: 2.3725 - learning_rate: 2.5974e-04
Epoch 26/300
785/785 - 96s - 122ms/step - accuracy: 0.3587 - loss: 3.0727 - val_accuracy: 0.5315 - val_loss: 2.2438 - learning_rate: 2.5974e-04
Epoch 27/300
785/785 - 96s - 122ms/step - accuracy: 0.3575 - loss: 3.0686 - val_accuracy: 0.5043 - val_loss: 2.3438 - learning_rate: 2.5974e-04
Epoch 28/300
785/785 - 96s - 123ms/step - accuracy: 0.3617 - loss: 3.0804 - val_accuracy: 0.5189 - val_loss: 2.2882 - learning_rate: 2.5974e-04
Epoch 29/300
785/785 - 95s - 121ms/step - accuracy: 0.3571 - loss: 3.0503 - val_accuracy: 0.5228 - val_loss: 2.2932 - learning_rate: 2.5974e-04
Epoch 30/300
785/785 - 96s - 122ms/step - accuracy: 0.3552 - loss: 3.0449 - val_accuracy: 0.5102 - val_loss: 2.2335 - learning_rate: 2.5974e-04
Epoch 31/300
785/785 - 96s - 122ms/step - accuracy: 0.3706 - loss: 3.0380 - val_accuracy: 0.5051 - val_loss: 2.3347 - learning_rate: 2.5974e-04
Epoch 32/300
785/785 - 96s - 123ms/step - accuracy: 0.3701 - loss: 3.0302 - val_accuracy: 0.5416 - val_loss: 2.2271 - learning_rate: 2.5974e-04
Epoch 33/300
785/785 - 95s - 121ms/step - accuracy: 0.3645 - loss: 3.0182 - val_accuracy: 0.5465 - val_loss: 2.2562 - learning_rate: 2.5974e-04
Epoch 34/300
785/785 - 97s - 124ms/step - accuracy: 0.3731 - loss: 3.0076 - val_accuracy: 0.5293 - val_loss: 2.2021 - learning_rate: 2.5974e-04
Epoch 35/300
785/785 - 94s - 120ms/step - accuracy: 0.3669 - loss: 3.0083 - val_accuracy: 0.5323 - val_loss: 2.1956 - learning_rate: 2.5974e-04
Epoch 36/300
785/785 - 96s - 123ms/step - accuracy: 0.3824 - loss: 2.9845 - val_accuracy: 0.5301 - val_loss: 2.1962 - learning_rate: 2.5974e-04
Epoch 37/300
785/785 - 96s - 123ms/step - accuracy: 0.3711 - loss: 2.9945 - val_accuracy: 0.5438 - val_loss: 2.1837 - learning_rate: 2.5974e-04
Epoch 38/300
785/785 - 96s - 123ms/step - accuracy: 0.3760 - loss: 3.0032 - val_accuracy: 0.5427 - val_loss: 2.1831 - learning_rate: 2.5974e-04
Epoch 39/300
785/785 - 96s - 123ms/step - accuracy: 0.3821 - loss: 2.9696 - val_accuracy: 0.5452 - val_loss: 2.2147 - learning_rate: 2.5974e-04
Epoch 40/300
785/785 - 95s - 121ms/step - accuracy: 0.3759 - loss: 2.9810 - val_accuracy: 0.5377 - val_loss: 2.1645 - learning_rate: 2.5974e-04
Epoch 41/300
785/785 - 95s - 121ms/step - accuracy: 0.3883 - loss: 2.9693 - val_accuracy: 0.5490 - val_loss: 2.1800 - learning_rate: 2.5974e-04
Epoch 42/300
785/785 - 97s - 123ms/step - accuracy: 0.3813 - loss: 2.9573 - val_accuracy: 0.5387 - val_loss: 2.1227 - learning_rate: 2.5974e-04
Epoch 43/300
785/785 - 95s - 121ms/step - accuracy: 0.3757 - loss: 2.9884 - val_accuracy: 0.5382 - val_loss: 2.1742 - learning_rate: 2.5974e-04
Epoch 44/300
785/785 - 96s - 123ms/step - accuracy: 0.3666 - loss: 2.9947 - val_accuracy: 0.5459 - val_loss: 2.1552 - learning_rate: 2.5974e-04
Epoch 45/300
785/785 - 96s - 122ms/step - accuracy: 0.3797 - loss: 2.9646 - val_accuracy: 0.5315 - val_loss: 2.1433 - learning_rate: 2.5974e-04
Epoch 46/300
785/785 - 97s - 123ms/step - accuracy: 0.3853 - loss: 2.9196 - val_accuracy: 0.5457 - val_loss: 2.1463 - learning_rate: 2.5974e-04
Epoch 47/300
785/785 - 95s - 121ms/step - accuracy: 0.3853 - loss: 2.9284 - val_accuracy: 0.5435 - val_loss: 2.1589 - learning_rate: 2.5974e-04
Epoch 48/300
785/785 - 96s - 122ms/step - accuracy: 0.3883 - loss: 2.9056 - val_accuracy: 0.5494 - val_loss: 2.0977 - learning_rate: 2.5974e-04
Epoch 49/300
785/785 - 96s - 122ms/step - accuracy: 0.3814 - loss: 2.8972 - val_accuracy: 0.5605 - val_loss: 2.0808 - learning_rate: 2.5974e-04
Epoch 50/300
785/785 - 96s - 122ms/step - accuracy: 0.3797 - loss: 2.9587 - val_accuracy: 0.5484 - val_loss: 2.1407 - learning_rate: 2.5974e-04
Epoch 51/300
785/785 - 96s - 122ms/step - accuracy: 0.3832 - loss: 2.9514 - val_accuracy: 0.5460 - val_loss: 2.0993 - learning_rate: 2.5974e-04
Epoch 52/300
785/785 - 96s - 122ms/step - accuracy: 0.3892 - loss: 2.9197 - val_accuracy: 0.5420 - val_loss: 2.1462 - learning_rate: 2.5974e-04
Epoch 53/300
785/785 - 100s - 127ms/step - accuracy: 0.3824 - loss: 2.9477 - val_accuracy: 0.5385 - val_loss: 2.1103 - learning_rate: 2.5974e-04
Epoch 54/300
785/785 - 95s - 122ms/step - accuracy: 0.3857 - loss: 2.9187 - val_accuracy: 0.5462 - val_loss: 2.0808 - learning_rate: 2.5974e-04
Epoch 55/300
785/785 - 96s - 123ms/step - accuracy: 0.3924 - loss: 2.8963 - val_accuracy: 0.5511 - val_loss: 2.0995 - learning_rate: 2.5974e-04
Epoch 56/300
785/785 - 97s - 123ms/step - accuracy: 0.3841 - loss: 2.9264 - val_accuracy: 0.5463 - val_loss: 2.1090 - learning_rate: 2.5974e-04
Epoch 57/300

Epoch 57: ReduceLROnPlateau reducing learning rate to 0.0001298690476687625.
785/785 - 96s - 123ms/step - accuracy: 0.3872 - loss: 2.8981 - val_accuracy: 0.5457 - val_loss: 2.1506 - learning_rate: 2.5974e-04
Epoch 58/300
785/785 - 96s - 122ms/step - accuracy: 0.4044 - loss: 2.8279 - val_accuracy: 0.5540 - val_loss: 2.0543 - learning_rate: 1.2987e-04
Epoch 59/300
785/785 - 94s - 119ms/step - accuracy: 0.4075 - loss: 2.8188 - val_accuracy: 0.5427 - val_loss: 2.0698 - learning_rate: 1.2987e-04
Epoch 60/300
785/785 - 97s - 124ms/step - accuracy: 0.4040 - loss: 2.8244 - val_accuracy: 0.5627 - val_loss: 2.0327 - learning_rate: 1.2987e-04
Epoch 61/300
785/785 - 96s - 123ms/step - accuracy: 0.4020 - loss: 2.7975 - val_accuracy: 0.5533 - val_loss: 2.0331 - learning_rate: 1.2987e-04
Epoch 62/300
785/785 - 95s - 121ms/step - accuracy: 0.4026 - loss: 2.8073 - val_accuracy: 0.5600 - val_loss: 2.0425 - learning_rate: 1.2987e-04
Epoch 63/300
785/785 - 96s - 122ms/step - accuracy: 0.4138 - loss: 2.8274 - val_accuracy: 0.5616 - val_loss: 2.0434 - learning_rate: 1.2987e-04
Epoch 64/300
785/785 - 96s - 122ms/step - accuracy: 0.4069 - loss: 2.8044 - val_accuracy: 0.5545 - val_loss: 2.0420 - learning_rate: 1.2987e-04
Epoch 65/300
785/785 - 96s - 122ms/step - accuracy: 0.4029 - loss: 2.8036 - val_accuracy: 0.5457 - val_loss: 2.0528 - learning_rate: 1.2987e-04
Epoch 66/300
785/785 - 95s - 121ms/step - accuracy: 0.4154 - loss: 2.7818 - val_accuracy: 0.5643 - val_loss: 2.0115 - learning_rate: 1.2987e-04
Epoch 67/300
785/785 - 100s - 127ms/step - accuracy: 0.4128 - loss: 2.8015 - val_accuracy: 0.5744 - val_loss: 2.0119 - learning_rate: 1.2987e-04
Epoch 68/300
785/785 - 96s - 123ms/step - accuracy: 0.4109 - loss: 2.7899 - val_accuracy: 0.5600 - val_loss: 1.9855 - learning_rate: 1.2987e-04
Epoch 69/300
785/785 - 96s - 122ms/step - accuracy: 0.4141 - loss: 2.8005 - val_accuracy: 0.5662 - val_loss: 2.0009 - learning_rate: 1.2987e-04
Epoch 70/300
785/785 - 96s - 123ms/step - accuracy: 0.4056 - loss: 2.7903 - val_accuracy: 0.5659 - val_loss: 2.0035 - learning_rate: 1.2987e-04
Epoch 71/300
785/785 - 96s - 122ms/step - accuracy: 0.4144 - loss: 2.7738 - val_accuracy: 0.5551 - val_loss: 2.0136 - learning_rate: 1.2987e-04
Epoch 72/300
785/785 - 93s - 119ms/step - accuracy: 0.4147 - loss: 2.7731 - val_accuracy: 0.5562 - val_loss: 2.0329 - learning_rate: 1.2987e-04
Epoch 73/300
785/785 - 96s - 122ms/step - accuracy: 0.4203 - loss: 2.7797 - val_accuracy: 0.5693 - val_loss: 2.0254 - learning_rate: 1.2987e-04
Epoch 74/300
785/785 - 97s - 123ms/step - accuracy: 0.4098 - loss: 2.7874 - val_accuracy: 0.5629 - val_loss: 2.0259 - learning_rate: 1.2987e-04
Epoch 75/300
785/785 - 97s - 123ms/step - accuracy: 0.4136 - loss: 2.7760 - val_accuracy: 0.5662 - val_loss: 1.9817 - learning_rate: 1.2987e-04
Epoch 76/300
785/785 - 96s - 122ms/step - accuracy: 0.4160 - loss: 2.7520 - val_accuracy: 0.5750 - val_loss: 1.9932 - learning_rate: 1.2987e-04
Epoch 77/300
785/785 - 96s - 122ms/step - accuracy: 0.4134 - loss: 2.7397 - val_accuracy: 0.5780 - val_loss: 2.0194 - learning_rate: 1.2987e-04
Epoch 78/300
785/785 - 94s - 119ms/step - accuracy: 0.4118 - loss: 2.7710 - val_accuracy: 0.5720 - val_loss: 1.9957 - learning_rate: 1.2987e-04
Epoch 79/300
785/785 - 95s - 122ms/step - accuracy: 0.4212 - loss: 2.7397 - val_accuracy: 0.5662 - val_loss: 1.9723 - learning_rate: 1.2987e-04
Epoch 80/300
785/785 - 96s - 122ms/step - accuracy: 0.4107 - loss: 2.7857 - val_accuracy: 0.5678 - val_loss: 1.9992 - learning_rate: 1.2987e-04
Epoch 81/300
785/785 - 96s - 122ms/step - accuracy: 0.4182 - loss: 2.7523 - val_accuracy: 0.5760 - val_loss: 2.0198 - learning_rate: 1.2987e-04
Epoch 82/300
785/785 - 97s - 124ms/step - accuracy: 0.4185 - loss: 2.7642 - val_accuracy: 0.5775 - val_loss: 1.9669 - learning_rate: 1.2987e-04
Epoch 83/300
785/785 - 100s - 127ms/step - accuracy: 0.4243 - loss: 2.7422 - val_accuracy: 0.5745 - val_loss: 1.9731 - learning_rate: 1.2987e-04
Epoch 84/300
785/785 - 95s - 122ms/step - accuracy: 0.4123 - loss: 2.7639 - val_accuracy: 0.5584 - val_loss: 1.9995 - learning_rate: 1.2987e-04
Epoch 85/300
785/785 - 96s - 122ms/step - accuracy: 0.4163 - loss: 2.7638 - val_accuracy: 0.5736 - val_loss: 1.9880 - learning_rate: 1.2987e-04
Epoch 86/300
785/785 - 96s - 122ms/step - accuracy: 0.4161 - loss: 2.7481 - val_accuracy: 0.5704 - val_loss: 1.9762 - learning_rate: 1.2987e-04
Epoch 87/300
785/785 - 96s - 122ms/step - accuracy: 0.4176 - loss: 2.7346 - val_accuracy: 0.5643 - val_loss: 1.9708 - learning_rate: 1.2987e-04
Epoch 88/300
785/785 - 96s - 122ms/step - accuracy: 0.4099 - loss: 2.7587 - val_accuracy: 0.5538 - val_loss: 1.9912 - learning_rate: 1.2987e-04
Epoch 89/300
785/785 - 97s - 123ms/step - accuracy: 0.4080 - loss: 2.7811 - val_accuracy: 0.5790 - val_loss: 1.9697 - learning_rate: 1.2987e-04
Epoch 90/300

Epoch 90: ReduceLROnPlateau reducing learning rate to 6.493452383438125e-05.
785/785 - 95s - 120ms/step - accuracy: 0.4126 - loss: 2.7455 - val_accuracy: 0.5790 - val_loss: 1.9733 - learning_rate: 1.2987e-04
Epoch 91/300
785/785 - 96s - 123ms/step - accuracy: 0.4209 - loss: 2.7318 - val_accuracy: 0.5756 - val_loss: 1.9610 - learning_rate: 6.4935e-05
Epoch 92/300
785/785 - 97s - 123ms/step - accuracy: 0.4147 - loss: 2.7318 - val_accuracy: 0.5766 - val_loss: 1.9600 - learning_rate: 6.4935e-05
Epoch 93/300
785/785 - 95s - 121ms/step - accuracy: 0.4252 - loss: 2.7270 - val_accuracy: 0.5763 - val_loss: 1.9499 - learning_rate: 6.4935e-05
Epoch 94/300
785/785 - 96s - 123ms/step - accuracy: 0.4290 - loss: 2.6971 - val_accuracy: 0.5763 - val_loss: 1.9497 - learning_rate: 6.4935e-05
Epoch 95/300
785/785 - 95s - 121ms/step - accuracy: 0.4308 - loss: 2.7054 - val_accuracy: 0.5756 - val_loss: 1.9552 - learning_rate: 6.4935e-05
Epoch 96/300
785/785 - 95s - 121ms/step - accuracy: 0.4260 - loss: 2.7174 - val_accuracy: 0.5844 - val_loss: 1.9422 - learning_rate: 6.4935e-05
Epoch 97/300
785/785 - 96s - 122ms/step - accuracy: 0.4268 - loss: 2.6944 - val_accuracy: 0.5764 - val_loss: 1.9371 - learning_rate: 6.4935e-05
Epoch 98/300
785/785 - 97s - 123ms/step - accuracy: 0.4278 - loss: 2.6928 - val_accuracy: 0.5761 - val_loss: 1.9245 - learning_rate: 6.4935e-05
Epoch 99/300
785/785 - 96s - 122ms/step - accuracy: 0.4318 - loss: 2.6939 - val_accuracy: 0.5756 - val_loss: 1.9260 - learning_rate: 6.4935e-05
Epoch 100/300
785/785 - 95s - 121ms/step - accuracy: 0.4308 - loss: 2.6925 - val_accuracy: 0.5680 - val_loss: 1.9375 - learning_rate: 6.4935e-05
Epoch 101/300
785/785 - 97s - 123ms/step - accuracy: 0.4257 - loss: 2.7301 - val_accuracy: 0.5785 - val_loss: 1.9525 - learning_rate: 6.4935e-05
Epoch 102/300
785/785 - 94s - 119ms/step - accuracy: 0.4230 - loss: 2.7166 - val_accuracy: 0.5753 - val_loss: 1.9291 - learning_rate: 6.4935e-05
Epoch 103/300
785/785 - 96s - 123ms/step - accuracy: 0.4364 - loss: 2.6818 - val_accuracy: 0.5742 - val_loss: 1.9429 - learning_rate: 6.4935e-05
Epoch 104/300
785/785 - 96s - 122ms/step - accuracy: 0.4310 - loss: 2.6930 - val_accuracy: 0.5790 - val_loss: 1.9386 - learning_rate: 6.4935e-05
Epoch 105/300
785/785 - 95s - 122ms/step - accuracy: 0.4284 - loss: 2.6923 - val_accuracy: 0.5758 - val_loss: 1.9320 - learning_rate: 6.4935e-05
Epoch 106/300

Epoch 106: ReduceLROnPlateau reducing learning rate to 3.2467261917190626e-05.
785/785 - 97s - 123ms/step - accuracy: 0.4276 - loss: 2.6999 - val_accuracy: 0.5799 - val_loss: 1.9468 - learning_rate: 6.4935e-05
Epoch 107/300
785/785 - 95s - 121ms/step - accuracy: 0.4319 - loss: 2.6776 - val_accuracy: 0.5861 - val_loss: 1.9178 - learning_rate: 3.2467e-05
Epoch 108/300
785/785 - 96s - 122ms/step - accuracy: 0.4267 - loss: 2.6458 - val_accuracy: 0.5849 - val_loss: 1.9216 - learning_rate: 3.2467e-05
Epoch 109/300
785/785 - 93s - 119ms/step - accuracy: 0.4310 - loss: 2.6918 - val_accuracy: 0.5721 - val_loss: 1.9336 - learning_rate: 3.2467e-05
Epoch 110/300
785/785 - 96s - 122ms/step - accuracy: 0.4413 - loss: 2.6448 - val_accuracy: 0.5799 - val_loss: 1.9260 - learning_rate: 3.2467e-05
Epoch 111/300
785/785 - 97s - 123ms/step - accuracy: 0.4365 - loss: 2.6813 - val_accuracy: 0.5833 - val_loss: 1.9214 - learning_rate: 3.2467e-05
Epoch 112/300
785/785 - 96s - 122ms/step - accuracy: 0.4300 - loss: 2.6764 - val_accuracy: 0.5788 - val_loss: 1.9377 - learning_rate: 3.2467e-05
Epoch 113/300
785/785 - 96s - 123ms/step - accuracy: 0.4310 - loss: 2.6627 - val_accuracy: 0.5799 - val_loss: 1.9187 - learning_rate: 3.2467e-05
Epoch 114/300
785/785 - 95s - 121ms/step - accuracy: 0.4273 - loss: 2.6742 - val_accuracy: 0.5830 - val_loss: 1.9111 - learning_rate: 3.2467e-05
Epoch 115/300
785/785 - 94s - 120ms/step - accuracy: 0.4329 - loss: 2.6383 - val_accuracy: 0.5780 - val_loss: 1.9162 - learning_rate: 3.2467e-05
Epoch 116/300
785/785 - 96s - 122ms/step - accuracy: 0.4311 - loss: 2.6686 - val_accuracy: 0.5768 - val_loss: 1.9157 - learning_rate: 3.2467e-05
Epoch 117/300
785/785 - 96s - 122ms/step - accuracy: 0.4249 - loss: 2.7087 - val_accuracy: 0.5865 - val_loss: 1.9158 - learning_rate: 3.2467e-05
Epoch 118/300
785/785 - 95s - 121ms/step - accuracy: 0.4451 - loss: 2.6277 - val_accuracy: 0.5822 - val_loss: 1.9173 - learning_rate: 3.2467e-05
Epoch 119/300
785/785 - 96s - 122ms/step - accuracy: 0.4340 - loss: 2.6468 - val_accuracy: 0.5771 - val_loss: 1.9154 - learning_rate: 3.2467e-05
Epoch 120/300
785/785 - 96s - 123ms/step - accuracy: 0.4265 - loss: 2.6889 - val_accuracy: 0.5782 - val_loss: 1.9296 - learning_rate: 3.2467e-05
Epoch 121/300
785/785 - 94s - 119ms/step - accuracy: 0.4240 - loss: 2.6910 - val_accuracy: 0.5838 - val_loss: 1.9161 - learning_rate: 3.2467e-05
Epoch 122/300

Epoch 122: ReduceLROnPlateau reducing learning rate to 1.6233630958595313e-05.
785/785 - 96s - 122ms/step - accuracy: 0.4255 - loss: 2.6680 - val_accuracy: 0.5833 - val_loss: 1.9190 - learning_rate: 3.2467e-05
Epoch 123/300
785/785 - 96s - 122ms/step - accuracy: 0.4351 - loss: 2.6660 - val_accuracy: 0.5811 - val_loss: 1.9134 - learning_rate: 1.6234e-05
Epoch 124/300
785/785 - 100s - 128ms/step - accuracy: 0.4340 - loss: 2.6398 - val_accuracy: 0.5876 - val_loss: 1.9171 - learning_rate: 1.6234e-05
Epoch 125/300
785/785 - 96s - 122ms/step - accuracy: 0.4340 - loss: 2.6355 - val_accuracy: 0.5823 - val_loss: 1.9122 - learning_rate: 1.6234e-05
Epoch 126/300
785/785 - 96s - 123ms/step - accuracy: 0.4332 - loss: 2.6922 - val_accuracy: 0.5809 - val_loss: 1.9155 - learning_rate: 1.6234e-05
Epoch 127/300
785/785 - 94s - 120ms/step - accuracy: 0.4324 - loss: 2.6664 - val_accuracy: 0.5850 - val_loss: 1.9073 - learning_rate: 1.6234e-05
Epoch 128/300
785/785 - 96s - 122ms/step - accuracy: 0.4327 - loss: 2.6386 - val_accuracy: 0.5866 - val_loss: 1.9025 - learning_rate: 1.6234e-05
Epoch 129/300
785/785 - 96s - 122ms/step - accuracy: 0.4427 - loss: 2.6303 - val_accuracy: 0.5826 - val_loss: 1.9093 - learning_rate: 1.6234e-05
Epoch 130/300
785/785 - 97s - 123ms/step - accuracy: 0.4359 - loss: 2.6531 - val_accuracy: 0.5818 - val_loss: 1.9036 - learning_rate: 1.6234e-05
Epoch 131/300
785/785 - 97s - 123ms/step - accuracy: 0.4376 - loss: 2.6352 - val_accuracy: 0.5846 - val_loss: 1.9024 - learning_rate: 1.6234e-05
Epoch 132/300
785/785 - 96s - 122ms/step - accuracy: 0.4376 - loss: 2.6610 - val_accuracy: 0.5849 - val_loss: 1.9087 - learning_rate: 1.6234e-05
Epoch 133/300
785/785 - 95s - 121ms/step - accuracy: 0.4313 - loss: 2.6640 - val_accuracy: 0.5834 - val_loss: 1.9060 - learning_rate: 1.6234e-05
Epoch 134/300
785/785 - 96s - 122ms/step - accuracy: 0.4407 - loss: 2.6497 - val_accuracy: 0.5860 - val_loss: 1.9038 - learning_rate: 1.6234e-05
Epoch 135/300
785/785 - 96s - 122ms/step - accuracy: 0.4493 - loss: 2.6145 - val_accuracy: 0.5838 - val_loss: 1.8976 - learning_rate: 1.6234e-05
Epoch 136/300
785/785 - 96s - 122ms/step - accuracy: 0.4369 - loss: 2.6693 - val_accuracy: 0.5863 - val_loss: 1.8987 - learning_rate: 1.6234e-05
Epoch 137/300
785/785 - 95s - 121ms/step - accuracy: 0.4439 - loss: 2.6192 - val_accuracy: 0.5841 - val_loss: 1.9010 - learning_rate: 1.6234e-05
Epoch 138/300
785/785 - 97s - 123ms/step - accuracy: 0.4432 - loss: 2.6201 - val_accuracy: 0.5849 - val_loss: 1.9010 - learning_rate: 1.6234e-05
Epoch 139/300
785/785 - 94s - 120ms/step - accuracy: 0.4247 - loss: 2.6571 - val_accuracy: 0.5846 - val_loss: 1.9061 - learning_rate: 1.6234e-05
Epoch 140/300
785/785 - 96s - 123ms/step - accuracy: 0.4388 - loss: 2.6816 - val_accuracy: 0.5849 - val_loss: 1.9000 - learning_rate: 1.6234e-05
Epoch 141/300
785/785 - 97s - 123ms/step - accuracy: 0.4353 - loss: 2.6594 - val_accuracy: 0.5854 - val_loss: 1.9042 - learning_rate: 1.6234e-05
Epoch 142/300
785/785 - 95s - 121ms/step - accuracy: 0.4330 - loss: 2.6858 - val_accuracy: 0.5874 - val_loss: 1.9078 - learning_rate: 1.6234e-05
Epoch 143/300

Epoch 143: ReduceLROnPlateau reducing learning rate to 8.116815479297657e-06.
785/785 - 96s - 122ms/step - accuracy: 0.4275 - loss: 2.6668 - val_accuracy: 0.5836 - val_loss: 1.9026 - learning_rate: 1.6234e-05
Epoch 144/300
785/785 - 95s - 121ms/step - accuracy: 0.4412 - loss: 2.6285 - val_accuracy: 0.5834 - val_loss: 1.9020 - learning_rate: 8.1168e-06
Epoch 145/300
785/785 - 96s - 122ms/step - accuracy: 0.4346 - loss: 2.6544 - val_accuracy: 0.5844 - val_loss: 1.9002 - learning_rate: 8.1168e-06
Epoch 146/300
785/785 - 96s - 122ms/step - accuracy: 0.4456 - loss: 2.6144 - val_accuracy: 0.5855 - val_loss: 1.9008 - learning_rate: 8.1168e-06
Epoch 147/300
785/785 - 96s - 123ms/step - accuracy: 0.4373 - loss: 2.6370 - val_accuracy: 0.5812 - val_loss: 1.8988 - learning_rate: 8.1168e-06
Epoch 148/300
785/785 - 96s - 122ms/step - accuracy: 0.4504 - loss: 2.6093 - val_accuracy: 0.5836 - val_loss: 1.9010 - learning_rate: 8.1168e-06
Epoch 149/300
785/785 - 96s - 123ms/step - accuracy: 0.4415 - loss: 2.6381 - val_accuracy: 0.5817 - val_loss: 1.9027 - learning_rate: 8.1168e-06
Epoch 150/300
785/785 - 96s - 122ms/step - accuracy: 0.4464 - loss: 2.6070 - val_accuracy: 0.5838 - val_loss: 1.8951 - learning_rate: 8.1168e-06
Epoch 151/300
785/785 - 95s - 121ms/step - accuracy: 0.4464 - loss: 2.6109 - val_accuracy: 0.5833 - val_loss: 1.8989 - learning_rate: 8.1168e-06
Epoch 152/300
785/785 - 96s - 122ms/step - accuracy: 0.4399 - loss: 2.6273 - val_accuracy: 0.5815 - val_loss: 1.8971 - learning_rate: 8.1168e-06
Epoch 153/300
785/785 - 96s - 122ms/step - accuracy: 0.4343 - loss: 2.6718 - val_accuracy: 0.5846 - val_loss: 1.8968 - learning_rate: 8.1168e-06
Epoch 154/300
785/785 - 100s - 127ms/step - accuracy: 0.4281 - loss: 2.6544 - val_accuracy: 0.5849 - val_loss: 1.9010 - learning_rate: 8.1168e-06
Epoch 155/300
785/785 - 97s - 123ms/step - accuracy: 0.4314 - loss: 2.6156 - val_accuracy: 0.5842 - val_loss: 1.9006 - learning_rate: 8.1168e-06
Epoch 156/300
785/785 - 95s - 121ms/step - accuracy: 0.4364 - loss: 2.6391 - val_accuracy: 0.5838 - val_loss: 1.8998 - learning_rate: 8.1168e-06
Epoch 157/300
785/785 - 96s - 122ms/step - accuracy: 0.4349 - loss: 2.6528 - val_accuracy: 0.5844 - val_loss: 1.9001 - learning_rate: 8.1168e-06
Epoch 158/300

Epoch 158: ReduceLROnPlateau reducing learning rate to 4.058407739648828e-06.
785/785 - 94s - 120ms/step - accuracy: 0.4437 - loss: 2.6401 - val_accuracy: 0.5842 - val_loss: 1.8991 - learning_rate: 8.1168e-06
Epoch 159/300
785/785 - 96s - 122ms/step - accuracy: 0.4373 - loss: 2.6525 - val_accuracy: 0.5828 - val_loss: 1.8938 - learning_rate: 4.0584e-06
Epoch 160/300
785/785 - 96s - 122ms/step - accuracy: 0.4381 - loss: 2.6444 - val_accuracy: 0.5841 - val_loss: 1.8970 - learning_rate: 4.0584e-06
Epoch 161/300
785/785 - 95s - 122ms/step - accuracy: 0.4410 - loss: 2.6446 - val_accuracy: 0.5852 - val_loss: 1.8965 - learning_rate: 4.0584e-06
Epoch 162/300
785/785 - 97s - 123ms/step - accuracy: 0.4453 - loss: 2.6085 - val_accuracy: 0.5855 - val_loss: 1.8947 - learning_rate: 4.0584e-06
Epoch 163/300
785/785 - 96s - 123ms/step - accuracy: 0.4268 - loss: 2.6768 - val_accuracy: 0.5830 - val_loss: 1.8975 - learning_rate: 4.0584e-06
Epoch 164/300
785/785 - 142s - 181ms/step - accuracy: 0.4520 - loss: 2.6039 - val_accuracy: 0.5836 - val_loss: 1.8967 - learning_rate: 4.0584e-06
Epoch 165/300
785/785 - 97s - 123ms/step - accuracy: 0.4404 - loss: 2.6194 - val_accuracy: 0.5836 - val_loss: 1.8935 - learning_rate: 4.0584e-06
Epoch 166/300
785/785 - 96s - 122ms/step - accuracy: 0.4361 - loss: 2.6378 - val_accuracy: 0.5833 - val_loss: 1.8910 - learning_rate: 4.0584e-06
Epoch 167/300
785/785 - 94s - 120ms/step - accuracy: 0.4380 - loss: 2.6328 - val_accuracy: 0.5833 - val_loss: 1.8942 - learning_rate: 4.0584e-06
Epoch 168/300
785/785 - 96s - 122ms/step - accuracy: 0.4474 - loss: 2.6170 - val_accuracy: 0.5838 - val_loss: 1.8908 - learning_rate: 4.0584e-06
Epoch 169/300
785/785 - 99s - 126ms/step - accuracy: 0.4384 - loss: 2.6459 - val_accuracy: 0.5820 - val_loss: 1.8959 - learning_rate: 4.0584e-06
Epoch 170/300
785/785 - 93s - 119ms/step - accuracy: 0.4472 - loss: 2.6206 - val_accuracy: 0.5812 - val_loss: 1.8960 - learning_rate: 4.0584e-06
Epoch 171/300
785/785 - 95s - 121ms/step - accuracy: 0.4370 - loss: 2.6404 - val_accuracy: 0.5815 - val_loss: 1.8953 - learning_rate: 4.0584e-06
Epoch 172/300
785/785 - 99s - 126ms/step - accuracy: 0.4364 - loss: 2.6438 - val_accuracy: 0.5811 - val_loss: 1.8922 - learning_rate: 4.0584e-06
Epoch 173/300
785/785 - 96s - 123ms/step - accuracy: 0.4400 - loss: 2.6238 - val_accuracy: 0.5823 - val_loss: 1.8932 - learning_rate: 4.0584e-06
Epoch 174/300
785/785 - 98s - 124ms/step - accuracy: 0.4354 - loss: 2.6714 - val_accuracy: 0.5869 - val_loss: 1.8940 - learning_rate: 4.0584e-06
Epoch 175/300
785/785 - 98s - 125ms/step - accuracy: 0.4369 - loss: 2.6216 - val_accuracy: 0.5857 - val_loss: 1.8912 - learning_rate: 4.0584e-06
Epoch 176/300

Epoch 176: ReduceLROnPlateau reducing learning rate to 2.029203869824414e-06.
785/785 - 96s - 122ms/step - accuracy: 0.4424 - loss: 2.6353 - val_accuracy: 0.5849 - val_loss: 1.8944 - learning_rate: 4.0584e-06
Epoch 177/300
785/785 - 98s - 124ms/step - accuracy: 0.4443 - loss: 2.6453 - val_accuracy: 0.5846 - val_loss: 1.8920 - learning_rate: 2.0292e-06
Epoch 178/300
785/785 - 97s - 123ms/step - accuracy: 0.4359 - loss: 2.6057 - val_accuracy: 0.5841 - val_loss: 1.8944 - learning_rate: 2.0292e-06
Epoch 179/300
785/785 - 98s - 125ms/step - accuracy: 0.4447 - loss: 2.6154 - val_accuracy: 0.5839 - val_loss: 1.8941 - learning_rate: 2.0292e-06
Epoch 180/300
785/785 - 97s - 124ms/step - accuracy: 0.4396 - loss: 2.6125 - val_accuracy: 0.5844 - val_loss: 1.9008 - learning_rate: 2.0292e-06
Epoch 181/300
785/785 - 97s - 123ms/step - accuracy: 0.4462 - loss: 2.6323 - val_accuracy: 0.5831 - val_loss: 1.8979 - learning_rate: 2.0292e-06
Epoch 182/300
785/785 - 95s - 121ms/step - accuracy: 0.4408 - loss: 2.5952 - val_accuracy: 0.5834 - val_loss: 1.8959 - learning_rate: 2.0292e-06
Epoch 183/300
785/785 - 92s - 118ms/step - accuracy: 0.4381 - loss: 2.6349 - val_accuracy: 0.5834 - val_loss: 1.8959 - learning_rate: 2.0292e-06
Epoch 184/300
785/785 - 90s - 115ms/step - accuracy: 0.4343 - loss: 2.6365 - val_accuracy: 0.5849 - val_loss: 1.8902 - learning_rate: 2.0292e-06
Epoch 185/300
785/785 - 92s - 117ms/step - accuracy: 0.4528 - loss: 2.6258 - val_accuracy: 0.5852 - val_loss: 1.8949 - learning_rate: 2.0292e-06
Epoch 186/300
785/785 - 92s - 117ms/step - accuracy: 0.4424 - loss: 2.6294 - val_accuracy: 0.5828 - val_loss: 1.8951 - learning_rate: 2.0292e-06
Epoch 187/300
785/785 - 89s - 113ms/step - accuracy: 0.4388 - loss: 2.6229 - val_accuracy: 0.5838 - val_loss: 1.8948 - learning_rate: 2.0292e-06
Epoch 188/300
785/785 - 91s - 116ms/step - accuracy: 0.4292 - loss: 2.6507 - val_accuracy: 0.5855 - val_loss: 1.8930 - learning_rate: 2.0292e-06
Epoch 189/300
785/785 - 89s - 113ms/step - accuracy: 0.4327 - loss: 2.6483 - val_accuracy: 0.5850 - val_loss: 1.8955 - learning_rate: 2.0292e-06
Epoch 190/300
785/785 - 89s - 113ms/step - accuracy: 0.4391 - loss: 2.6291 - val_accuracy: 0.5847 - val_loss: 1.8978 - learning_rate: 2.0292e-06
Epoch 191/300
785/785 - 89s - 114ms/step - accuracy: 0.4402 - loss: 2.6293 - val_accuracy: 0.5860 - val_loss: 1.8940 - learning_rate: 2.0292e-06
Epoch 192/300

Epoch 192: ReduceLROnPlateau reducing learning rate to 1.014601934912207e-06.
785/785 - 88s - 112ms/step - accuracy: 0.4490 - loss: 2.6093 - val_accuracy: 0.5849 - val_loss: 1.8947 - learning_rate: 2.0292e-06
Epoch 193/300
785/785 - 92s - 117ms/step - accuracy: 0.4426 - loss: 2.6482 - val_accuracy: 0.5857 - val_loss: 1.8946 - learning_rate: 1.0146e-06
Epoch 194/300
785/785 - 90s - 114ms/step - accuracy: 0.4431 - loss: 2.6570 - val_accuracy: 0.5847 - val_loss: 1.8975 - learning_rate: 1.0146e-06
Epoch 195/300
785/785 - 87s - 111ms/step - accuracy: 0.4474 - loss: 2.6137 - val_accuracy: 0.5846 - val_loss: 1.8961 - learning_rate: 1.0146e-06
Epoch 196/300
785/785 - 91s - 116ms/step - accuracy: 0.4381 - loss: 2.6308 - val_accuracy: 0.5839 - val_loss: 1.8941 - learning_rate: 1.0146e-06
Epoch 197/300
785/785 - 88s - 112ms/step - accuracy: 0.4383 - loss: 2.6184 - val_accuracy: 0.5839 - val_loss: 1.8908 - learning_rate: 1.0146e-06
Epoch 198/300
785/785 - 92s - 117ms/step - accuracy: 0.4370 - loss: 2.6440 - val_accuracy: 0.5849 - val_loss: 1.8935 - learning_rate: 1.0146e-06
Epoch 199/300
785/785 - 89s - 114ms/step - accuracy: 0.4431 - loss: 2.6336 - val_accuracy: 0.5852 - val_loss: 1.8964 - learning_rate: 1.0146e-06
Epoch 200/300

Epoch 200: ReduceLROnPlateau reducing learning rate to 1e-06.
785/785 - 86s - 110ms/step - accuracy: 0.4402 - loss: 2.6433 - val_accuracy: 0.5846 - val_loss: 1.8946 - learning_rate: 1.0146e-06
Epoch 200: early stopping
Restoring model weights from the end of the best epoch: 184.
Fold 1_1 Evaluation results: [1.8933641910552979, 0.5848726034164429]
              precision    recall  f1-score   support

        1820       0.65      0.78      0.71       296
        1821       0.86      0.82      0.84       289
        1822       0.00      0.00      0.00         6
        1823       0.00      0.00      0.00         9
        1824       0.00      0.00      0.00         6
        1825       0.00      0.00      0.00        11
        1826       0.00      0.00      0.00         8
        1827       0.81      0.66      0.73       118
        1828       0.00      0.00      0.00         6
        1829       0.43      0.14      0.21        21
        1830       0.48      0.63      0.55       282
        1831       0.73      0.92      0.81       673
        1832       0.78      0.73      0.75       338
        1833       0.83      0.89      0.86        88
        1834       0.42      0.64      0.51       143
        1835       0.00      0.00      0.00         8
        1836       0.00      0.00      0.00        18
        1837       0.37      0.26      0.31        38
        1838       0.00      0.00      0.00        23
        1839       0.00      0.00      0.00         3
        1840       0.55      0.51      0.53       220
        1841       0.73      0.50      0.59       552
        1842       0.60      0.57      0.59        21
        1843       0.00      0.00      0.00        37
        1844       0.00      0.00      0.00         1
        1845       0.00      0.00      0.00         4
        1846       0.36      0.15      0.21        27
        1847       0.00      0.00      0.00        11
        1848       0.12      0.09      0.10        23
        1849       0.43      0.23      0.30        26
        1850       0.33      0.60      0.43       227
        1851       0.76      0.71      0.73       380
        1852       0.00      0.00      0.00        40
        1853       0.00      0.00      0.00        25
        1854       0.00      0.00      0.00        14
        1855       0.22      0.05      0.08       119
        1856       0.53      0.59      0.56        59
        1857       0.41      0.64      0.50       149
        1858       0.00      0.00      0.00        13
        1859       0.00      0.00      0.00        16
        1860       0.29      0.41      0.34       328
        1861       0.77      0.84      0.80       436
        1862       0.26      0.06      0.10        98
        1863       0.32      0.52      0.39        90
        1864       0.31      0.38      0.34        86
        1865       0.67      0.13      0.22        31
        1866       1.00      0.03      0.06        33
        1867       0.31      0.07      0.12        56
        1868       0.00      0.00      0.00        37
        1869       0.00      0.00      0.00        27
        1870       0.40      0.60      0.48       162
        1871       0.71      0.71      0.71       239
        1872       0.29      0.06      0.09        36
        1873       0.30      0.14      0.19        51
        1874       0.00      0.00      0.00        22
        1875       0.24      0.22      0.23        77
        1876       0.92      0.73      0.82        49
        1877       1.00      0.04      0.07        27
        1878       0.43      0.57      0.49        40
        1879       0.00      0.00      0.00         7

    accuracy                           0.58      6280
   macro avg       0.33      0.28      0.27      6280
weighted avg       0.57      0.58      0.56      6280

Matthews Correlation Coefficient: 0.564
Macro avg F1: 0.272
Weighted avg F1: 0.559
Micro avg F1: 0.585
Top-3 Accuracy: 0.831
Top-5 Accuracy: 0.890
Micro ROC AUC  = 0.98
Macro ROC AUC (present classes) = 0.97
Classification MAE (in years): 3.35

Fold 1_1 Misclassification Analysis:
Near misses (within 2 years): 590 out of 2607 misclassifications (22.63%)
Big misses (greater than 10 years): 1089
MAE with outliers: 3.35
MAE without outliers: 2.44 (improvement: 0.91)

10 Worst misclassifications:
Image: data/datasets/public/1870/1879_26wikimedia2.jpg, True: 1879, Predicted: 1820, Error: 59
Image: data/datasets/public/1870/1876_71washington.jpg, True: 1876, Predicted: 1820, Error: 56
Image: data/datasets/public/1870/1876_72washington.jpg, True: 1876, Predicted: 1820, Error: 56
Image: data/datasets/public/1820/1820_6wikimedia2.jpg, True: 1820, Predicted: 1876, Error: 56
Image: data/datasets/public/1820/1820_12wikimedia2.jpg, True: 1820, Predicted: 1871, Error: 51
Image: data/datasets/private/1870/1871_114etsy.jpg, True: 1871, Predicted: 1820, Error: 51
Image: data/datasets/private/1820/1820_034_Zrzut ekranu 2022-07-26 203655.png, True: 1820, Predicted: 1870, Error: 50
Image: data/datasets/private/1820/1821_462etsy.jpg, True: 1821, Predicted: 1871, Error: 50
Image: data/datasets/private/1870/1871_358etsy.jpg, True: 1871, Predicted: 1821, Error: 50
Image: data/datasets/public/1820/1820_27wikimedia2.jpg, True: 1820, Predicted: 1870, Error: 50

===== Fine Tuning 9 layers! =====
Epoch 1/300
785/785 - 116s - 148ms/step - accuracy: 0.1096 - loss: 4.4461 - val_accuracy: 0.1397 - val_loss: 3.9362 - learning_rate: 2.5974e-04
Epoch 2/300
785/785 - 88s - 113ms/step - accuracy: 0.1642 - loss: 4.1755 - val_accuracy: 0.2548 - val_loss: 3.8795 - learning_rate: 2.5974e-04
Epoch 3/300
785/785 - 93s - 118ms/step - accuracy: 0.1987 - loss: 3.9726 - val_accuracy: 0.2793 - val_loss: 3.5431 - learning_rate: 2.5974e-04
Epoch 4/300
785/785 - 88s - 112ms/step - accuracy: 0.2080 - loss: 3.8412 - val_accuracy: 0.3150 - val_loss: 3.3850 - learning_rate: 2.5974e-04
Epoch 5/300
785/785 - 90s - 114ms/step - accuracy: 0.2349 - loss: 3.7115 - val_accuracy: 0.3419 - val_loss: 3.1098 - learning_rate: 2.5974e-04
Epoch 6/300
785/785 - 91s - 116ms/step - accuracy: 0.2482 - loss: 3.6217 - val_accuracy: 0.3825 - val_loss: 3.0289 - learning_rate: 2.5974e-04
Epoch 7/300
785/785 - 89s - 113ms/step - accuracy: 0.2600 - loss: 3.5826 - val_accuracy: 0.3663 - val_loss: 2.9272 - learning_rate: 2.5974e-04
Epoch 8/300
785/785 - 91s - 116ms/step - accuracy: 0.2619 - loss: 3.5368 - val_accuracy: 0.4066 - val_loss: 2.9316 - learning_rate: 2.5974e-04
Epoch 9/300
785/785 - 87s - 111ms/step - accuracy: 0.2804 - loss: 3.5097 - val_accuracy: 0.4204 - val_loss: 2.8701 - learning_rate: 2.5974e-04
Epoch 10/300
785/785 - 90s - 114ms/step - accuracy: 0.2798 - loss: 3.4424 - val_accuracy: 0.4306 - val_loss: 2.7577 - learning_rate: 2.5974e-04
Epoch 11/300
785/785 - 93s - 119ms/step - accuracy: 0.2911 - loss: 3.4235 - val_accuracy: 0.4510 - val_loss: 2.6455 - learning_rate: 2.5974e-04
Epoch 12/300
785/785 - 89s - 114ms/step - accuracy: 0.2970 - loss: 3.4136 - val_accuracy: 0.4464 - val_loss: 2.7338 - learning_rate: 2.5974e-04
Epoch 13/300
785/785 - 91s - 116ms/step - accuracy: 0.3110 - loss: 3.3510 - val_accuracy: 0.4692 - val_loss: 2.5494 - learning_rate: 2.5974e-04
Epoch 14/300
785/785 - 90s - 114ms/step - accuracy: 0.3053 - loss: 3.3110 - val_accuracy: 0.4779 - val_loss: 2.6192 - learning_rate: 2.5974e-04
Epoch 15/300
785/785 - 89s - 114ms/step - accuracy: 0.3089 - loss: 3.3228 - val_accuracy: 0.4638 - val_loss: 2.5822 - learning_rate: 2.5974e-04
Epoch 16/300
785/785 - 91s - 116ms/step - accuracy: 0.3084 - loss: 3.3146 - val_accuracy: 0.4513 - val_loss: 2.5426 - learning_rate: 2.5974e-04
Epoch 17/300
785/785 - 89s - 114ms/step - accuracy: 0.3277 - loss: 3.2589 - val_accuracy: 0.5018 - val_loss: 2.4615 - learning_rate: 2.5974e-04
Epoch 18/300
785/785 - 91s - 116ms/step - accuracy: 0.3250 - loss: 3.2422 - val_accuracy: 0.4943 - val_loss: 2.4926 - learning_rate: 2.5974e-04
Epoch 19/300
785/785 - 91s - 116ms/step - accuracy: 0.3269 - loss: 3.2216 - val_accuracy: 0.5072 - val_loss: 2.4475 - learning_rate: 2.5974e-04
Epoch 20/300
785/785 - 91s - 115ms/step - accuracy: 0.3404 - loss: 3.2007 - val_accuracy: 0.4999 - val_loss: 2.3939 - learning_rate: 2.5974e-04
Epoch 21/300
785/785 - 88s - 112ms/step - accuracy: 0.3330 - loss: 3.1985 - val_accuracy: 0.5079 - val_loss: 2.3717 - learning_rate: 2.5974e-04
Epoch 22/300
785/785 - 90s - 115ms/step - accuracy: 0.3396 - loss: 3.1974 - val_accuracy: 0.5146 - val_loss: 2.3772 - learning_rate: 2.5974e-04
Epoch 23/300
785/785 - 91s - 115ms/step - accuracy: 0.3460 - loss: 3.1191 - val_accuracy: 0.5230 - val_loss: 2.3339 - learning_rate: 2.5974e-04
Epoch 24/300
785/785 - 91s - 116ms/step - accuracy: 0.3457 - loss: 3.1379 - val_accuracy: 0.5127 - val_loss: 2.3787 - learning_rate: 2.5974e-04
Epoch 25/300
785/785 - 91s - 116ms/step - accuracy: 0.3572 - loss: 3.1218 - val_accuracy: 0.5300 - val_loss: 2.3835 - learning_rate: 2.5974e-04
Epoch 26/300
785/785 - 88s - 113ms/step - accuracy: 0.3478 - loss: 3.1267 - val_accuracy: 0.5244 - val_loss: 2.3163 - learning_rate: 2.5974e-04
Epoch 27/300
785/785 - 91s - 115ms/step - accuracy: 0.3511 - loss: 3.1364 - val_accuracy: 0.5168 - val_loss: 2.3435 - learning_rate: 2.5974e-04
Epoch 28/300
785/785 - 92s - 117ms/step - accuracy: 0.3508 - loss: 3.1138 - val_accuracy: 0.5071 - val_loss: 2.3036 - learning_rate: 2.5974e-04
Epoch 29/300
785/785 - 89s - 113ms/step - accuracy: 0.3489 - loss: 3.0975 - val_accuracy: 0.5237 - val_loss: 2.2646 - learning_rate: 2.5974e-04
Epoch 30/300
785/785 - 91s - 116ms/step - accuracy: 0.3591 - loss: 3.0746 - val_accuracy: 0.5209 - val_loss: 2.2903 - learning_rate: 2.5974e-04
Epoch 31/300
785/785 - 89s - 113ms/step - accuracy: 0.3632 - loss: 3.0795 - val_accuracy: 0.5340 - val_loss: 2.2539 - learning_rate: 2.5974e-04
Epoch 32/300
785/785 - 89s - 114ms/step - accuracy: 0.3510 - loss: 3.1052 - val_accuracy: 0.5327 - val_loss: 2.2216 - learning_rate: 2.5974e-04
Epoch 33/300
785/785 - 93s - 118ms/step - accuracy: 0.3605 - loss: 3.0350 - val_accuracy: 0.5305 - val_loss: 2.2961 - learning_rate: 2.5974e-04
Epoch 34/300
785/785 - 90s - 115ms/step - accuracy: 0.3639 - loss: 3.0511 - val_accuracy: 0.5369 - val_loss: 2.2419 - learning_rate: 2.5974e-04
Epoch 35/300
785/785 - 140s - 178ms/step - accuracy: 0.3575 - loss: 3.0720 - val_accuracy: 0.5176 - val_loss: 2.2668 - learning_rate: 2.5974e-04
Epoch 36/300
785/785 - 92s - 117ms/step - accuracy: 0.3545 - loss: 3.0632 - val_accuracy: 0.5428 - val_loss: 2.2350 - learning_rate: 2.5974e-04
Epoch 37/300
785/785 - 89s - 114ms/step - accuracy: 0.3766 - loss: 2.9902 - val_accuracy: 0.5420 - val_loss: 2.1344 - learning_rate: 2.5974e-04
Epoch 38/300
785/785 - 91s - 116ms/step - accuracy: 0.3705 - loss: 3.0131 - val_accuracy: 0.5311 - val_loss: 2.2481 - learning_rate: 2.5974e-04
Epoch 39/300
785/785 - 89s - 113ms/step - accuracy: 0.3605 - loss: 3.0373 - val_accuracy: 0.5471 - val_loss: 2.1555 - learning_rate: 2.5974e-04
Epoch 40/300
785/785 - 87s - 111ms/step - accuracy: 0.3779 - loss: 2.9728 - val_accuracy: 0.5385 - val_loss: 2.1473 - learning_rate: 2.5974e-04
Epoch 41/300
785/785 - 92s - 118ms/step - accuracy: 0.3645 - loss: 3.0190 - val_accuracy: 0.5463 - val_loss: 2.1645 - learning_rate: 2.5974e-04
Epoch 42/300
785/785 - 88s - 112ms/step - accuracy: 0.3785 - loss: 3.0018 - val_accuracy: 0.5388 - val_loss: 2.1872 - learning_rate: 2.5974e-04
Epoch 43/300
785/785 - 92s - 117ms/step - accuracy: 0.3664 - loss: 3.0076 - val_accuracy: 0.5558 - val_loss: 2.1212 - learning_rate: 2.5974e-04
Epoch 44/300
785/785 - 90s - 114ms/step - accuracy: 0.3704 - loss: 2.9650 - val_accuracy: 0.5544 - val_loss: 2.1055 - learning_rate: 2.5974e-04
Epoch 45/300
785/785 - 89s - 113ms/step - accuracy: 0.3713 - loss: 3.0025 - val_accuracy: 0.5483 - val_loss: 2.1249 - learning_rate: 2.5974e-04
Epoch 46/300
785/785 - 93s - 119ms/step - accuracy: 0.3696 - loss: 2.9662 - val_accuracy: 0.5464 - val_loss: 2.1645 - learning_rate: 2.5974e-04
Epoch 47/300
785/785 - 89s - 114ms/step - accuracy: 0.3705 - loss: 2.9568 - val_accuracy: 0.5581 - val_loss: 2.1415 - learning_rate: 2.5974e-04
Epoch 48/300
785/785 - 90s - 114ms/step - accuracy: 0.3683 - loss: 2.9746 - val_accuracy: 0.5389 - val_loss: 2.1708 - learning_rate: 2.5974e-04
Epoch 49/300
785/785 - 89s - 114ms/step - accuracy: 0.3653 - loss: 2.9849 - val_accuracy: 0.5475 - val_loss: 2.0962 - learning_rate: 2.5974e-04
Epoch 50/300
785/785 - 89s - 113ms/step - accuracy: 0.3795 - loss: 2.9831 - val_accuracy: 0.5483 - val_loss: 2.1639 - learning_rate: 2.5974e-04
Epoch 51/300
785/785 - 91s - 116ms/step - accuracy: 0.3830 - loss: 2.9555 - val_accuracy: 0.5568 - val_loss: 2.1309 - learning_rate: 2.5974e-04
Epoch 52/300
785/785 - 88s - 112ms/step - accuracy: 0.3838 - loss: 2.9394 - val_accuracy: 0.5592 - val_loss: 2.1236 - learning_rate: 2.5974e-04
Epoch 53/300
785/785 - 89s - 114ms/step - accuracy: 0.3790 - loss: 2.9237 - val_accuracy: 0.5541 - val_loss: 2.1581 - learning_rate: 2.5974e-04
Epoch 54/300
785/785 - 92s - 117ms/step - accuracy: 0.3818 - loss: 2.9511 - val_accuracy: 0.5598 - val_loss: 2.0623 - learning_rate: 2.5974e-04
Epoch 55/300
785/785 - 90s - 114ms/step - accuracy: 0.3731 - loss: 2.9510 - val_accuracy: 0.5439 - val_loss: 2.1128 - learning_rate: 2.5974e-04
Epoch 56/300
785/785 - 91s - 115ms/step - accuracy: 0.3868 - loss: 2.9691 - val_accuracy: 0.5638 - val_loss: 2.1047 - learning_rate: 2.5974e-04
Epoch 57/300
785/785 - 89s - 113ms/step - accuracy: 0.3791 - loss: 2.9535 - val_accuracy: 0.5541 - val_loss: 2.0863 - learning_rate: 2.5974e-04
Epoch 58/300
785/785 - 96s - 122ms/step - accuracy: 0.3874 - loss: 2.9484 - val_accuracy: 0.5431 - val_loss: 2.0954 - learning_rate: 2.5974e-04
Epoch 59/300
785/785 - 91s - 116ms/step - accuracy: 0.3865 - loss: 2.9131 - val_accuracy: 0.5577 - val_loss: 2.0630 - learning_rate: 2.5974e-04
Epoch 60/300
785/785 - 90s - 114ms/step - accuracy: 0.3826 - loss: 2.9400 - val_accuracy: 0.5525 - val_loss: 2.0776 - learning_rate: 2.5974e-04
Epoch 61/300
785/785 - 91s - 116ms/step - accuracy: 0.3846 - loss: 2.9209 - val_accuracy: 0.5525 - val_loss: 2.1812 - learning_rate: 2.5974e-04
Epoch 62/300

Epoch 62: ReduceLROnPlateau reducing learning rate to 0.0001298690476687625.
785/785 - 89s - 114ms/step - accuracy: 0.3852 - loss: 2.8989 - val_accuracy: 0.5700 - val_loss: 2.1063 - learning_rate: 2.5974e-04
Epoch 63/300
785/785 - 90s - 114ms/step - accuracy: 0.3893 - loss: 2.8963 - val_accuracy: 0.5743 - val_loss: 2.0092 - learning_rate: 1.2987e-04
Epoch 64/300
785/785 - 90s - 115ms/step - accuracy: 0.3922 - loss: 2.8857 - val_accuracy: 0.5724 - val_loss: 2.0389 - learning_rate: 1.2987e-04
Epoch 65/300
785/785 - 90s - 115ms/step - accuracy: 0.3936 - loss: 2.8485 - val_accuracy: 0.5706 - val_loss: 2.0169 - learning_rate: 1.2987e-04
Epoch 66/300
785/785 - 91s - 116ms/step - accuracy: 0.4024 - loss: 2.8091 - val_accuracy: 0.5756 - val_loss: 1.9955 - learning_rate: 1.2987e-04
Epoch 67/300
785/785 - 89s - 113ms/step - accuracy: 0.4065 - loss: 2.8343 - val_accuracy: 0.5735 - val_loss: 2.0026 - learning_rate: 1.2987e-04
Epoch 68/300
785/785 - 89s - 113ms/step - accuracy: 0.4049 - loss: 2.8538 - val_accuracy: 0.5791 - val_loss: 2.0170 - learning_rate: 1.2987e-04
Epoch 69/300
785/785 - 89s - 114ms/step - accuracy: 0.4067 - loss: 2.8024 - val_accuracy: 0.5743 - val_loss: 2.0143 - learning_rate: 1.2987e-04
Epoch 70/300
785/785 - 90s - 115ms/step - accuracy: 0.4056 - loss: 2.8224 - val_accuracy: 0.5694 - val_loss: 2.0300 - learning_rate: 1.2987e-04
Epoch 71/300
785/785 - 96s - 122ms/step - accuracy: 0.4049 - loss: 2.8189 - val_accuracy: 0.5800 - val_loss: 1.9885 - learning_rate: 1.2987e-04
Epoch 72/300
785/785 - 90s - 114ms/step - accuracy: 0.4025 - loss: 2.8324 - val_accuracy: 0.5754 - val_loss: 1.9804 - learning_rate: 1.2987e-04
Epoch 73/300
785/785 - 91s - 116ms/step - accuracy: 0.3992 - loss: 2.8296 - val_accuracy: 0.5807 - val_loss: 2.0252 - learning_rate: 1.2987e-04
Epoch 74/300
785/785 - 90s - 114ms/step - accuracy: 0.4145 - loss: 2.8239 - val_accuracy: 0.5778 - val_loss: 1.9918 - learning_rate: 1.2987e-04
Epoch 75/300
785/785 - 90s - 114ms/step - accuracy: 0.4100 - loss: 2.7960 - val_accuracy: 0.5824 - val_loss: 2.0436 - learning_rate: 1.2987e-04
Epoch 76/300
785/785 - 91s - 115ms/step - accuracy: 0.4065 - loss: 2.7760 - val_accuracy: 0.5851 - val_loss: 1.9711 - learning_rate: 1.2987e-04
Epoch 77/300
785/785 - 90s - 115ms/step - accuracy: 0.4169 - loss: 2.7937 - val_accuracy: 0.5819 - val_loss: 1.9859 - learning_rate: 1.2987e-04
Epoch 78/300
785/785 - 90s - 115ms/step - accuracy: 0.4099 - loss: 2.7847 - val_accuracy: 0.5753 - val_loss: 2.0267 - learning_rate: 1.2987e-04
Epoch 79/300
785/785 - 90s - 115ms/step - accuracy: 0.4083 - loss: 2.7607 - val_accuracy: 0.5827 - val_loss: 1.9774 - learning_rate: 1.2987e-04
Epoch 80/300
785/785 - 88s - 112ms/step - accuracy: 0.4123 - loss: 2.7642 - val_accuracy: 0.5808 - val_loss: 1.9607 - learning_rate: 1.2987e-04
Epoch 81/300
785/785 - 91s - 116ms/step - accuracy: 0.4018 - loss: 2.8042 - val_accuracy: 0.5827 - val_loss: 1.9656 - learning_rate: 1.2987e-04
Epoch 82/300
785/785 - 91s - 115ms/step - accuracy: 0.4140 - loss: 2.7798 - val_accuracy: 0.5819 - val_loss: 1.9678 - learning_rate: 1.2987e-04
Epoch 83/300
785/785 - 89s - 114ms/step - accuracy: 0.4153 - loss: 2.7726 - val_accuracy: 0.5846 - val_loss: 1.9810 - learning_rate: 1.2987e-04
Epoch 84/300
785/785 - 142s - 181ms/step - accuracy: 0.3997 - loss: 2.8188 - val_accuracy: 0.5770 - val_loss: 1.9591 - learning_rate: 1.2987e-04
Epoch 85/300
785/785 - 91s - 116ms/step - accuracy: 0.4041 - loss: 2.7951 - val_accuracy: 0.5797 - val_loss: 1.9475 - learning_rate: 1.2987e-04
Epoch 86/300
785/785 - 88s - 112ms/step - accuracy: 0.4104 - loss: 2.7812 - val_accuracy: 0.5694 - val_loss: 1.9771 - learning_rate: 1.2987e-04
Epoch 87/300
785/785 - 92s - 117ms/step - accuracy: 0.4153 - loss: 2.7590 - val_accuracy: 0.5846 - val_loss: 1.9508 - learning_rate: 1.2987e-04
Epoch 88/300
785/785 - 89s - 114ms/step - accuracy: 0.4064 - loss: 2.8284 - val_accuracy: 0.5854 - val_loss: 1.9683 - learning_rate: 1.2987e-04
Epoch 89/300
785/785 - 88s - 113ms/step - accuracy: 0.4086 - loss: 2.7799 - val_accuracy: 0.5796 - val_loss: 1.9465 - learning_rate: 1.2987e-04
Epoch 90/300
785/785 - 92s - 117ms/step - accuracy: 0.4092 - loss: 2.7748 - val_accuracy: 0.5864 - val_loss: 1.9719 - learning_rate: 1.2987e-04
Epoch 91/300
785/785 - 89s - 113ms/step - accuracy: 0.4207 - loss: 2.7590 - val_accuracy: 0.5796 - val_loss: 1.9818 - learning_rate: 1.2987e-04
Epoch 92/300
785/785 - 91s - 116ms/step - accuracy: 0.4096 - loss: 2.8103 - val_accuracy: 0.5805 - val_loss: 1.9671 - learning_rate: 1.2987e-04
Epoch 93/300
785/785 - 91s - 116ms/step - accuracy: 0.4146 - loss: 2.7709 - val_accuracy: 0.5837 - val_loss: 1.9567 - learning_rate: 1.2987e-04
Epoch 94/300
785/785 - 87s - 111ms/step - accuracy: 0.4146 - loss: 2.7937 - val_accuracy: 0.5909 - val_loss: 1.9797 - learning_rate: 1.2987e-04
Epoch 95/300
785/785 - 93s - 119ms/step - accuracy: 0.4185 - loss: 2.7770 - val_accuracy: 0.5818 - val_loss: 1.9485 - learning_rate: 1.2987e-04
Epoch 96/300
785/785 - 89s - 114ms/step - accuracy: 0.4107 - loss: 2.7758 - val_accuracy: 0.5878 - val_loss: 1.9625 - learning_rate: 1.2987e-04
Epoch 97/300
785/785 - 91s - 116ms/step - accuracy: 0.4156 - loss: 2.7640 - val_accuracy: 0.5843 - val_loss: 1.9261 - learning_rate: 1.2987e-04
Epoch 98/300
785/785 - 91s - 116ms/step - accuracy: 0.4091 - loss: 2.7549 - val_accuracy: 0.5878 - val_loss: 1.9316 - learning_rate: 1.2987e-04
Epoch 99/300
785/785 - 92s - 117ms/step - accuracy: 0.4151 - loss: 2.7504 - val_accuracy: 0.5851 - val_loss: 1.9994 - learning_rate: 1.2987e-04
Epoch 100/300
785/785 - 93s - 118ms/step - accuracy: 0.4153 - loss: 2.7597 - val_accuracy: 0.5904 - val_loss: 1.9572 - learning_rate: 1.2987e-04
Epoch 101/300
785/785 - 90s - 114ms/step - accuracy: 0.4135 - loss: 2.7861 - val_accuracy: 0.5861 - val_loss: 1.9671 - learning_rate: 1.2987e-04
Epoch 102/300
785/785 - 93s - 118ms/step - accuracy: 0.4169 - loss: 2.7584 - val_accuracy: 0.5800 - val_loss: 1.9655 - learning_rate: 1.2987e-04
Epoch 103/300
785/785 - 90s - 114ms/step - accuracy: 0.4156 - loss: 2.7712 - val_accuracy: 0.5827 - val_loss: 1.9563 - learning_rate: 1.2987e-04
Epoch 104/300
785/785 - 89s - 114ms/step - accuracy: 0.4178 - loss: 2.7569 - val_accuracy: 0.5953 - val_loss: 1.9206 - learning_rate: 1.2987e-04
Epoch 105/300
785/785 - 92s - 118ms/step - accuracy: 0.4135 - loss: 2.7787 - val_accuracy: 0.5956 - val_loss: 1.9498 - learning_rate: 1.2987e-04
Epoch 106/300
785/785 - 87s - 111ms/step - accuracy: 0.4169 - loss: 2.7508 - val_accuracy: 0.5869 - val_loss: 1.9347 - learning_rate: 1.2987e-04
Epoch 107/300
785/785 - 90s - 115ms/step - accuracy: 0.4089 - loss: 2.7574 - val_accuracy: 0.5913 - val_loss: 1.9275 - learning_rate: 1.2987e-04
Epoch 108/300
785/785 - 92s - 117ms/step - accuracy: 0.4212 - loss: 2.7442 - val_accuracy: 0.5953 - val_loss: 1.9263 - learning_rate: 1.2987e-04
Epoch 109/300
785/785 - 89s - 113ms/step - accuracy: 0.4146 - loss: 2.7698 - val_accuracy: 0.5882 - val_loss: 1.9450 - learning_rate: 1.2987e-04
Epoch 110/300
785/785 - 92s - 118ms/step - accuracy: 0.4166 - loss: 2.7580 - val_accuracy: 0.5904 - val_loss: 1.9185 - learning_rate: 1.2987e-04
Epoch 111/300
785/785 - 89s - 113ms/step - accuracy: 0.4105 - loss: 2.7673 - val_accuracy: 0.5893 - val_loss: 1.9184 - learning_rate: 1.2987e-04
Epoch 112/300
785/785 - 90s - 114ms/step - accuracy: 0.4228 - loss: 2.7530 - val_accuracy: 0.5923 - val_loss: 1.9043 - learning_rate: 1.2987e-04
Epoch 113/300
785/785 - 91s - 116ms/step - accuracy: 0.4170 - loss: 2.7522 - val_accuracy: 0.5945 - val_loss: 1.9569 - learning_rate: 1.2987e-04
Epoch 114/300
785/785 - 89s - 113ms/step - accuracy: 0.4209 - loss: 2.7301 - val_accuracy: 0.5866 - val_loss: 1.9424 - learning_rate: 1.2987e-04
Epoch 115/300
785/785 - 90s - 115ms/step - accuracy: 0.4178 - loss: 2.7337 - val_accuracy: 0.5982 - val_loss: 1.9575 - learning_rate: 1.2987e-04
Epoch 116/300
785/785 - 90s - 114ms/step - accuracy: 0.4336 - loss: 2.7191 - val_accuracy: 0.5918 - val_loss: 1.9153 - learning_rate: 1.2987e-04
Epoch 117/300
785/785 - 89s - 113ms/step - accuracy: 0.4189 - loss: 2.7195 - val_accuracy: 0.5953 - val_loss: 1.9172 - learning_rate: 1.2987e-04
Epoch 118/300
785/785 - 89s - 114ms/step - accuracy: 0.4194 - loss: 2.7336 - val_accuracy: 0.5932 - val_loss: 1.8980 - learning_rate: 1.2987e-04
Epoch 119/300
785/785 - 90s - 114ms/step - accuracy: 0.4158 - loss: 2.7462 - val_accuracy: 0.5905 - val_loss: 1.9128 - learning_rate: 1.2987e-04
Epoch 120/300
785/785 - 91s - 116ms/step - accuracy: 0.4217 - loss: 2.7524 - val_accuracy: 0.5975 - val_loss: 1.9018 - learning_rate: 1.2987e-04
Epoch 121/300
785/785 - 89s - 114ms/step - accuracy: 0.4137 - loss: 2.7559 - val_accuracy: 0.5937 - val_loss: 1.9185 - learning_rate: 1.2987e-04
Epoch 122/300
785/785 - 88s - 112ms/step - accuracy: 0.4107 - loss: 2.7365 - val_accuracy: 0.5917 - val_loss: 1.9841 - learning_rate: 1.2987e-04
Epoch 123/300
785/785 - 88s - 112ms/step - accuracy: 0.4209 - loss: 2.7521 - val_accuracy: 0.5975 - val_loss: 1.9263 - learning_rate: 1.2987e-04
Epoch 124/300
785/785 - 91s - 116ms/step - accuracy: 0.4210 - loss: 2.7314 - val_accuracy: 0.5928 - val_loss: 1.9345 - learning_rate: 1.2987e-04
Epoch 125/300
785/785 - 90s - 114ms/step - accuracy: 0.4164 - loss: 2.7475 - val_accuracy: 0.5947 - val_loss: 1.9566 - learning_rate: 1.2987e-04
Epoch 126/300

Epoch 126: ReduceLROnPlateau reducing learning rate to 6.493452383438125e-05.
785/785 - 88s - 112ms/step - accuracy: 0.4255 - loss: 2.7517 - val_accuracy: 0.5893 - val_loss: 1.9304 - learning_rate: 1.2987e-04
Epoch 127/300
785/785 - 92s - 117ms/step - accuracy: 0.4239 - loss: 2.6736 - val_accuracy: 0.5999 - val_loss: 1.9144 - learning_rate: 6.4935e-05
Epoch 128/300
785/785 - 88s - 112ms/step - accuracy: 0.4303 - loss: 2.7183 - val_accuracy: 0.5928 - val_loss: 1.9209 - learning_rate: 6.4935e-05
Epoch 129/300
785/785 - 90s - 115ms/step - accuracy: 0.4213 - loss: 2.7122 - val_accuracy: 0.5999 - val_loss: 1.8806 - learning_rate: 6.4935e-05
Epoch 130/300
785/785 - 90s - 115ms/step - accuracy: 0.4250 - loss: 2.6913 - val_accuracy: 0.5960 - val_loss: 1.9025 - learning_rate: 6.4935e-05
Epoch 131/300
785/785 - 89s - 113ms/step - accuracy: 0.4256 - loss: 2.6869 - val_accuracy: 0.6028 - val_loss: 1.8894 - learning_rate: 6.4935e-05
Epoch 132/300
785/785 - 92s - 117ms/step - accuracy: 0.4299 - loss: 2.6948 - val_accuracy: 0.5979 - val_loss: 1.8872 - learning_rate: 6.4935e-05
Epoch 133/300
785/785 - 90s - 115ms/step - accuracy: 0.4242 - loss: 2.7042 - val_accuracy: 0.5974 - val_loss: 1.8973 - learning_rate: 6.4935e-05
Epoch 134/300
785/785 - 90s - 114ms/step - accuracy: 0.4221 - loss: 2.6826 - val_accuracy: 0.6018 - val_loss: 1.8860 - learning_rate: 6.4935e-05
Epoch 135/300
785/785 - 91s - 116ms/step - accuracy: 0.4193 - loss: 2.7306 - val_accuracy: 0.5979 - val_loss: 1.9113 - learning_rate: 6.4935e-05
Epoch 136/300
785/785 - 90s - 114ms/step - accuracy: 0.4272 - loss: 2.7235 - val_accuracy: 0.6025 - val_loss: 1.8893 - learning_rate: 6.4935e-05
Epoch 137/300

Epoch 137: ReduceLROnPlateau reducing learning rate to 3.2467261917190626e-05.
785/785 - 93s - 118ms/step - accuracy: 0.4239 - loss: 2.7119 - val_accuracy: 0.6085 - val_loss: 1.8818 - learning_rate: 6.4935e-05
Epoch 138/300
785/785 - 91s - 116ms/step - accuracy: 0.4293 - loss: 2.6793 - val_accuracy: 0.6017 - val_loss: 1.8767 - learning_rate: 3.2467e-05
Epoch 139/300
785/785 - 90s - 114ms/step - accuracy: 0.4266 - loss: 2.7044 - val_accuracy: 0.6039 - val_loss: 1.8740 - learning_rate: 3.2467e-05
Epoch 140/300
785/785 - 89s - 113ms/step - accuracy: 0.4338 - loss: 2.6551 - val_accuracy: 0.6012 - val_loss: 1.8815 - learning_rate: 3.2467e-05
Epoch 141/300
785/785 - 88s - 112ms/step - accuracy: 0.4263 - loss: 2.6772 - val_accuracy: 0.6009 - val_loss: 1.8876 - learning_rate: 3.2467e-05
Epoch 142/300
785/785 - 92s - 118ms/step - accuracy: 0.4303 - loss: 2.6734 - val_accuracy: 0.6015 - val_loss: 1.8984 - learning_rate: 3.2467e-05
Epoch 143/300
785/785 - 95s - 121ms/step - accuracy: 0.4283 - loss: 2.6847 - val_accuracy: 0.6052 - val_loss: 1.8788 - learning_rate: 3.2467e-05
Epoch 144/300
785/785 - 90s - 114ms/step - accuracy: 0.4366 - loss: 2.6459 - val_accuracy: 0.6047 - val_loss: 1.8771 - learning_rate: 3.2467e-05
Epoch 145/300
785/785 - 91s - 115ms/step - accuracy: 0.4280 - loss: 2.7119 - val_accuracy: 0.6042 - val_loss: 1.8849 - learning_rate: 3.2467e-05
Epoch 146/300
785/785 - 89s - 114ms/step - accuracy: 0.4330 - loss: 2.6609 - val_accuracy: 0.6033 - val_loss: 1.8737 - learning_rate: 3.2467e-05
Epoch 147/300
785/785 - 92s - 118ms/step - accuracy: 0.4344 - loss: 2.6828 - val_accuracy: 0.6004 - val_loss: 1.8718 - learning_rate: 3.2467e-05
Epoch 148/300
785/785 - 89s - 113ms/step - accuracy: 0.4295 - loss: 2.6667 - val_accuracy: 0.6014 - val_loss: 1.8758 - learning_rate: 3.2467e-05
Epoch 149/300
785/785 - 90s - 115ms/step - accuracy: 0.4320 - loss: 2.6878 - val_accuracy: 0.6071 - val_loss: 1.8904 - learning_rate: 3.2467e-05
Epoch 150/300
785/785 - 92s - 117ms/step - accuracy: 0.4428 - loss: 2.6541 - val_accuracy: 0.6038 - val_loss: 1.8691 - learning_rate: 3.2467e-05
Epoch 151/300
785/785 - 89s - 113ms/step - accuracy: 0.4328 - loss: 2.6662 - val_accuracy: 0.6065 - val_loss: 1.8811 - learning_rate: 3.2467e-05
Epoch 152/300
785/785 - 88s - 112ms/step - accuracy: 0.4350 - loss: 2.6736 - val_accuracy: 0.6039 - val_loss: 1.8947 - learning_rate: 3.2467e-05
Epoch 153/300
785/785 - 91s - 115ms/step - accuracy: 0.4381 - loss: 2.6179 - val_accuracy: 0.6017 - val_loss: 1.8807 - learning_rate: 3.2467e-05
Epoch 154/300
785/785 - 89s - 113ms/step - accuracy: 0.4393 - loss: 2.6376 - val_accuracy: 0.6065 - val_loss: 1.8681 - learning_rate: 3.2467e-05
Epoch 155/300
785/785 - 93s - 119ms/step - accuracy: 0.4449 - loss: 2.6236 - val_accuracy: 0.6058 - val_loss: 1.8702 - learning_rate: 3.2467e-05
Epoch 156/300
785/785 - 90s - 114ms/step - accuracy: 0.4328 - loss: 2.6675 - val_accuracy: 0.6020 - val_loss: 1.8899 - learning_rate: 3.2467e-05
Epoch 157/300
785/785 - 91s - 116ms/step - accuracy: 0.4275 - loss: 2.6694 - val_accuracy: 0.6058 - val_loss: 1.8674 - learning_rate: 3.2467e-05
Epoch 158/300
785/785 - 92s - 117ms/step - accuracy: 0.4334 - loss: 2.6562 - val_accuracy: 0.6068 - val_loss: 1.8706 - learning_rate: 3.2467e-05
Epoch 159/300
785/785 - 90s - 115ms/step - accuracy: 0.4271 - loss: 2.6737 - val_accuracy: 0.6079 - val_loss: 1.8712 - learning_rate: 3.2467e-05
Epoch 160/300
785/785 - 92s - 118ms/step - accuracy: 0.4280 - loss: 2.6620 - val_accuracy: 0.6077 - val_loss: 1.8587 - learning_rate: 3.2467e-05
Epoch 161/300
785/785 - 90s - 114ms/step - accuracy: 0.4361 - loss: 2.6505 - val_accuracy: 0.6039 - val_loss: 1.8684 - learning_rate: 3.2467e-05
Epoch 162/300
785/785 - 93s - 118ms/step - accuracy: 0.4237 - loss: 2.6707 - val_accuracy: 0.6047 - val_loss: 1.8678 - learning_rate: 3.2467e-05
Epoch 163/300
785/785 - 96s - 123ms/step - accuracy: 0.4245 - loss: 2.6692 - val_accuracy: 0.6054 - val_loss: 1.8745 - learning_rate: 3.2467e-05
Epoch 164/300
785/785 - 90s - 114ms/step - accuracy: 0.4373 - loss: 2.6664 - val_accuracy: 0.6025 - val_loss: 1.8643 - learning_rate: 3.2467e-05
Epoch 165/300
785/785 - 93s - 118ms/step - accuracy: 0.4280 - loss: 2.6659 - val_accuracy: 0.6050 - val_loss: 1.8572 - learning_rate: 3.2467e-05
Epoch 166/300
785/785 - 89s - 113ms/step - accuracy: 0.4323 - loss: 2.6370 - val_accuracy: 0.6038 - val_loss: 1.8771 - learning_rate: 3.2467e-05
Epoch 167/300
785/785 - 92s - 118ms/step - accuracy: 0.4357 - loss: 2.6558 - val_accuracy: 0.6085 - val_loss: 1.8770 - learning_rate: 3.2467e-05
Epoch 168/300
785/785 - 90s - 115ms/step - accuracy: 0.4312 - loss: 2.6560 - val_accuracy: 0.6054 - val_loss: 1.8739 - learning_rate: 3.2467e-05
Epoch 169/300
785/785 - 89s - 114ms/step - accuracy: 0.4263 - loss: 2.6664 - val_accuracy: 0.6026 - val_loss: 1.8764 - learning_rate: 3.2467e-05
Epoch 170/300
785/785 - 92s - 117ms/step - accuracy: 0.4293 - loss: 2.6737 - val_accuracy: 0.6036 - val_loss: 1.8639 - learning_rate: 3.2467e-05
Epoch 171/300
785/785 - 91s - 116ms/step - accuracy: 0.4290 - loss: 2.6601 - val_accuracy: 0.6041 - val_loss: 1.8859 - learning_rate: 3.2467e-05
Epoch 172/300
785/785 - 93s - 118ms/step - accuracy: 0.4408 - loss: 2.6466 - val_accuracy: 0.6069 - val_loss: 1.8629 - learning_rate: 3.2467e-05
Epoch 173/300

Epoch 173: ReduceLROnPlateau reducing learning rate to 1.6233630958595313e-05.
785/785 - 139s - 176ms/step - accuracy: 0.4231 - loss: 2.6592 - val_accuracy: 0.6052 - val_loss: 1.8680 - learning_rate: 3.2467e-05
Epoch 174/300
785/785 - 89s - 114ms/step - accuracy: 0.4349 - loss: 2.6539 - val_accuracy: 0.6084 - val_loss: 1.8552 - learning_rate: 1.6234e-05
Epoch 175/300
785/785 - 90s - 115ms/step - accuracy: 0.4389 - loss: 2.6278 - val_accuracy: 0.6042 - val_loss: 1.8654 - learning_rate: 1.6234e-05
Epoch 176/300
785/785 - 91s - 115ms/step - accuracy: 0.4360 - loss: 2.6311 - val_accuracy: 0.6055 - val_loss: 1.8589 - learning_rate: 1.6234e-05
Epoch 177/300
785/785 - 89s - 113ms/step - accuracy: 0.4479 - loss: 2.6495 - val_accuracy: 0.6073 - val_loss: 1.8657 - learning_rate: 1.6234e-05
Epoch 178/300
785/785 - 87s - 111ms/step - accuracy: 0.4419 - loss: 2.6435 - val_accuracy: 0.6069 - val_loss: 1.8658 - learning_rate: 1.6234e-05
Epoch 179/300
785/785 - 90s - 115ms/step - accuracy: 0.4344 - loss: 2.6354 - val_accuracy: 0.6095 - val_loss: 1.8500 - learning_rate: 1.6234e-05
Epoch 180/300
785/785 - 90s - 115ms/step - accuracy: 0.4368 - loss: 2.6448 - val_accuracy: 0.6084 - val_loss: 1.8563 - learning_rate: 1.6234e-05
Epoch 181/300
785/785 - 91s - 116ms/step - accuracy: 0.4306 - loss: 2.6486 - val_accuracy: 0.6071 - val_loss: 1.8576 - learning_rate: 1.6234e-05
Epoch 182/300
785/785 - 88s - 112ms/step - accuracy: 0.4361 - loss: 2.6429 - val_accuracy: 0.6092 - val_loss: 1.8541 - learning_rate: 1.6234e-05
Epoch 183/300
785/785 - 90s - 115ms/step - accuracy: 0.4444 - loss: 2.6562 - val_accuracy: 0.6065 - val_loss: 1.8689 - learning_rate: 1.6234e-05
Epoch 184/300
785/785 - 90s - 115ms/step - accuracy: 0.4396 - loss: 2.6500 - val_accuracy: 0.6066 - val_loss: 1.8594 - learning_rate: 1.6234e-05
Epoch 185/300
785/785 - 91s - 116ms/step - accuracy: 0.4412 - loss: 2.6524 - val_accuracy: 0.6095 - val_loss: 1.8594 - learning_rate: 1.6234e-05
Epoch 186/300
785/785 - 94s - 120ms/step - accuracy: 0.4398 - loss: 2.6632 - val_accuracy: 0.6085 - val_loss: 1.8617 - learning_rate: 1.6234e-05
Epoch 187/300

Epoch 187: ReduceLROnPlateau reducing learning rate to 8.116815479297657e-06.
785/785 - 89s - 114ms/step - accuracy: 0.4379 - loss: 2.6205 - val_accuracy: 0.6079 - val_loss: 1.8508 - learning_rate: 1.6234e-05
Epoch 188/300
785/785 - 94s - 120ms/step - accuracy: 0.4416 - loss: 2.6376 - val_accuracy: 0.6087 - val_loss: 1.8507 - learning_rate: 8.1168e-06
Epoch 189/300
785/785 - 93s - 118ms/step - accuracy: 0.4554 - loss: 2.6095 - val_accuracy: 0.6087 - val_loss: 1.8530 - learning_rate: 8.1168e-06
Epoch 190/300
785/785 - 92s - 117ms/step - accuracy: 0.4404 - loss: 2.6170 - val_accuracy: 0.6077 - val_loss: 1.8552 - learning_rate: 8.1168e-06
Epoch 191/300
785/785 - 95s - 120ms/step - accuracy: 0.4342 - loss: 2.6132 - val_accuracy: 0.6098 - val_loss: 1.8529 - learning_rate: 8.1168e-06
Epoch 192/300
785/785 - 90s - 115ms/step - accuracy: 0.4406 - loss: 2.6223 - val_accuracy: 0.6095 - val_loss: 1.8479 - learning_rate: 8.1168e-06
Epoch 193/300
785/785 - 93s - 118ms/step - accuracy: 0.4444 - loss: 2.6017 - val_accuracy: 0.6084 - val_loss: 1.8504 - learning_rate: 8.1168e-06
Epoch 194/300
785/785 - 99s - 127ms/step - accuracy: 0.4422 - loss: 2.6287 - val_accuracy: 0.6103 - val_loss: 1.8493 - learning_rate: 8.1168e-06
Epoch 195/300
785/785 - 98s - 125ms/step - accuracy: 0.4342 - loss: 2.6433 - val_accuracy: 0.6109 - val_loss: 1.8522 - learning_rate: 8.1168e-06
Epoch 196/300
785/785 - 98s - 125ms/step - accuracy: 0.4432 - loss: 2.6244 - val_accuracy: 0.6109 - val_loss: 1.8462 - learning_rate: 8.1168e-06
Epoch 197/300
785/785 - 91s - 116ms/step - accuracy: 0.4436 - loss: 2.6336 - val_accuracy: 0.6106 - val_loss: 1.8550 - learning_rate: 8.1168e-06
Epoch 198/300
785/785 - 92s - 117ms/step - accuracy: 0.4374 - loss: 2.6473 - val_accuracy: 0.6093 - val_loss: 1.8542 - learning_rate: 8.1168e-06
Epoch 199/300
785/785 - 92s - 117ms/step - accuracy: 0.4355 - loss: 2.6009 - val_accuracy: 0.6074 - val_loss: 1.8511 - learning_rate: 8.1168e-06
Epoch 200/300
785/785 - 92s - 117ms/step - accuracy: 0.4315 - loss: 2.6232 - val_accuracy: 0.6087 - val_loss: 1.8563 - learning_rate: 8.1168e-06
Epoch 201/300
785/785 - 93s - 119ms/step - accuracy: 0.4396 - loss: 2.6195 - val_accuracy: 0.6106 - val_loss: 1.8532 - learning_rate: 8.1168e-06
Epoch 202/300
785/785 - 91s - 116ms/step - accuracy: 0.4467 - loss: 2.5901 - val_accuracy: 0.6098 - val_loss: 1.8513 - learning_rate: 8.1168e-06
Epoch 203/300
785/785 - 94s - 120ms/step - accuracy: 0.4417 - loss: 2.6398 - val_accuracy: 0.6097 - val_loss: 1.8517 - learning_rate: 8.1168e-06
Epoch 204/300

Epoch 204: ReduceLROnPlateau reducing learning rate to 4.058407739648828e-06.
785/785 - 90s - 115ms/step - accuracy: 0.4347 - loss: 2.6549 - val_accuracy: 0.6081 - val_loss: 1.8489 - learning_rate: 8.1168e-06
Epoch 205/300
785/785 - 90s - 115ms/step - accuracy: 0.4490 - loss: 2.6192 - val_accuracy: 0.6106 - val_loss: 1.8481 - learning_rate: 4.0584e-06
Epoch 206/300
785/785 - 92s - 118ms/step - accuracy: 0.4470 - loss: 2.6230 - val_accuracy: 0.6098 - val_loss: 1.8509 - learning_rate: 4.0584e-06
Epoch 207/300
785/785 - 91s - 116ms/step - accuracy: 0.4306 - loss: 2.6456 - val_accuracy: 0.6087 - val_loss: 1.8498 - learning_rate: 4.0584e-06
Epoch 208/300
785/785 - 94s - 119ms/step - accuracy: 0.4400 - loss: 2.6542 - val_accuracy: 0.6085 - val_loss: 1.8522 - learning_rate: 4.0584e-06
Epoch 209/300
785/785 - 90s - 115ms/step - accuracy: 0.4419 - loss: 2.6196 - val_accuracy: 0.6090 - val_loss: 1.8545 - learning_rate: 4.0584e-06
Epoch 210/300
785/785 - 92s - 118ms/step - accuracy: 0.4355 - loss: 2.6160 - val_accuracy: 0.6112 - val_loss: 1.8495 - learning_rate: 4.0584e-06
Epoch 211/300
785/785 - 92s - 117ms/step - accuracy: 0.4452 - loss: 2.6119 - val_accuracy: 0.6106 - val_loss: 1.8492 - learning_rate: 4.0584e-06
Epoch 212/300

Epoch 212: ReduceLROnPlateau reducing learning rate to 2.029203869824414e-06.
785/785 - 90s - 114ms/step - accuracy: 0.4333 - loss: 2.6438 - val_accuracy: 0.6097 - val_loss: 1.8574 - learning_rate: 4.0584e-06
Epoch 212: early stopping
Restoring model weights from the end of the best epoch: 196.
Fold 1_2 Evaluation results: [1.8501546382904053, 0.6109253168106079]
              precision    recall  f1-score   support

        1820       0.70      0.80      0.75       321
        1821       0.88      0.88      0.88       285
        1822       0.00      0.00      0.00         8
        1823       0.00      0.00      0.00         4
        1824       0.00      0.00      0.00         4
        1825       0.00      0.00      0.00        10
        1826       0.00      0.00      0.00        15
        1827       0.73      0.74      0.74       132
        1828       0.00      0.00      0.00        11
        1829       0.89      0.35      0.50        23
        1830       0.55      0.65      0.60       278
        1831       0.80      0.89      0.84       671
        1832       0.81      0.84      0.82       341
        1833       0.94      0.90      0.92       102
        1834       0.49      0.56      0.53       149
        1835       0.00      0.00      0.00        13
        1836       0.00      0.00      0.00        17
        1837       0.29      0.46      0.36        26
        1838       0.00      0.00      0.00        15
        1839       0.00      0.00      0.00         5
        1840       0.38      0.67      0.49       207
        1841       0.71      0.62      0.66       523
        1842       0.56      0.26      0.36        34
        1843       0.14      0.05      0.07        21
        1844       0.00      0.00      0.00         2
        1845       0.00      0.00      0.00         7
        1846       1.00      0.03      0.06        30
        1847       0.00      0.00      0.00         9
        1848       0.00      0.00      0.00        32
        1849       0.00      0.00      0.00        27
        1850       0.34      0.58      0.43       250
        1851       0.74      0.67      0.70       390
        1852       0.00      0.00      0.00        34
        1853       0.00      0.00      0.00        38
        1854       0.00      0.00      0.00        10
        1855       0.48      0.10      0.16       113
        1856       0.63      0.70      0.67        61
        1857       0.41      0.63      0.50       158
        1858       0.00      0.00      0.00        10
        1859       0.00      0.00      0.00         9
        1860       0.35      0.38      0.36       318
        1861       0.77      0.80      0.78       414
        1862       0.32      0.07      0.11        91
        1863       0.37      0.47      0.41        94
        1864       0.26      0.10      0.14        84
        1865       0.57      0.11      0.19        35
        1866       0.33      0.17      0.22        24
        1867       0.14      0.06      0.09        48
        1868       0.00      0.00      0.00        36
        1869       0.00      0.00      0.00        26
        1870       0.36      0.63      0.46       145
        1871       0.71      0.79      0.75       252
        1872       0.38      0.14      0.21        35
        1873       1.00      0.02      0.04        55
        1874       0.00      0.00      0.00        30
        1875       0.35      0.74      0.48        62
        1876       0.93      0.82      0.88        51
        1877       0.29      0.44      0.35        27
        1878       0.84      0.32      0.46        50
        1879       0.00      0.00      0.00         7

    accuracy                           0.61      6279
   macro avg       0.34      0.29      0.28      6279
weighted avg       0.60      0.61      0.58      6279

Matthews Correlation Coefficient: 0.591
Macro avg F1: 0.283
Weighted avg F1: 0.583
Micro avg F1: 0.611
Top-3 Accuracy: 0.838
Top-5 Accuracy: 0.894
Micro ROC AUC  = 0.98
Macro ROC AUC (present classes) = 0.96
Classification MAE (in years): 3.18

Fold 1_2 Misclassification Analysis:
Near misses (within 2 years): 519 out of 2443 misclassifications (21.24%)
Big misses (greater than 10 years): 1006
MAE with outliers: 3.18
MAE without outliers: 2.21 (improvement: 0.96)

10 Worst misclassifications:
Image: data/datasets/public/1870/1877_035met.jpg, True: 1877, Predicted: 1820, Error: 57
Image: data/datasets/public/1870/1876_53washington.jpg, True: 1876, Predicted: 1820, Error: 56
Image: data/datasets/public/1870/1876_70washington.jpg, True: 1876, Predicted: 1820, Error: 56
Image: data/datasets/private/1820/1824_032_Zrzut ekranu 2022-07-26 203037.png, True: 1824, Predicted: 1876, Error: 52
Image: data/datasets/public/1870/1870_75wikimedia2.jpg, True: 1870, Predicted: 1820, Error: 50
Image: data/datasets/public/1870/1870_28wikimedia2.jpg, True: 1870, Predicted: 1820, Error: 50
Image: data/datasets/private/1820/1821_486etsy.jpg, True: 1821, Predicted: 1871, Error: 50
Image: data/datasets/private/1870/1871_384etsy.jpg, True: 1871, Predicted: 1821, Error: 50
Image: data/datasets/private/1820/1821_580etsy.jpg, True: 1821, Predicted: 1871, Error: 50
Image: data/datasets/private/1870/1871_404etsy.jpg, True: 1871, Predicted: 1821, Error: 50

===== Iteration 3/5 =====
=== Training Base Model ===

===== Fine Tuning 9 layers! =====
Epoch 1/300
785/785 - 120s - 152ms/step - accuracy: 0.1166 - loss: 4.4654 - val_accuracy: 0.1941 - val_loss: 3.8506 - learning_rate: 2.5974e-04
Epoch 2/300
785/785 - 92s - 117ms/step - accuracy: 0.1728 - loss: 4.1863 - val_accuracy: 0.2621 - val_loss: 4.0156 - learning_rate: 2.5974e-04
Epoch 3/300
785/785 - 91s - 116ms/step - accuracy: 0.1976 - loss: 4.0212 - val_accuracy: 0.3159 - val_loss: 3.4859 - learning_rate: 2.5974e-04
Epoch 4/300
785/785 - 89s - 114ms/step - accuracy: 0.2282 - loss: 3.8359 - val_accuracy: 0.3268 - val_loss: 3.2580 - learning_rate: 2.5974e-04
Epoch 5/300
785/785 - 91s - 116ms/step - accuracy: 0.2324 - loss: 3.7985 - val_accuracy: 0.3333 - val_loss: 3.1293 - learning_rate: 2.5974e-04
Epoch 6/300
785/785 - 93s - 119ms/step - accuracy: 0.2598 - loss: 3.6822 - val_accuracy: 0.3807 - val_loss: 3.0690 - learning_rate: 2.5974e-04
Epoch 7/300
785/785 - 92s - 118ms/step - accuracy: 0.2637 - loss: 3.6129 - val_accuracy: 0.3818 - val_loss: 2.9881 - learning_rate: 2.5974e-04
Epoch 8/300
785/785 - 93s - 118ms/step - accuracy: 0.2749 - loss: 3.5366 - val_accuracy: 0.4051 - val_loss: 2.8639 - learning_rate: 2.5974e-04
Epoch 9/300
785/785 - 91s - 116ms/step - accuracy: 0.2856 - loss: 3.5007 - val_accuracy: 0.3982 - val_loss: 2.7796 - learning_rate: 2.5974e-04
Epoch 10/300
785/785 - 92s - 117ms/step - accuracy: 0.2849 - loss: 3.4489 - val_accuracy: 0.4207 - val_loss: 2.7419 - learning_rate: 2.5974e-04
Epoch 11/300
785/785 - 92s - 117ms/step - accuracy: 0.2970 - loss: 3.3922 - val_accuracy: 0.4411 - val_loss: 2.8110 - learning_rate: 2.5974e-04
Epoch 12/300
785/785 - 92s - 118ms/step - accuracy: 0.3042 - loss: 3.3480 - val_accuracy: 0.4328 - val_loss: 2.6743 - learning_rate: 2.5974e-04
Epoch 13/300
785/785 - 92s - 118ms/step - accuracy: 0.3053 - loss: 3.3532 - val_accuracy: 0.4435 - val_loss: 2.6225 - learning_rate: 2.5974e-04
Epoch 14/300
785/785 - 92s - 117ms/step - accuracy: 0.3110 - loss: 3.3556 - val_accuracy: 0.4580 - val_loss: 2.5925 - learning_rate: 2.5974e-04
Epoch 15/300
785/785 - 92s - 117ms/step - accuracy: 0.3122 - loss: 3.3113 - val_accuracy: 0.4666 - val_loss: 2.5571 - learning_rate: 2.5974e-04
Epoch 16/300
785/785 - 90s - 115ms/step - accuracy: 0.3215 - loss: 3.2692 - val_accuracy: 0.4616 - val_loss: 2.5317 - learning_rate: 2.5974e-04
Epoch 17/300
785/785 - 93s - 118ms/step - accuracy: 0.3247 - loss: 3.2397 - val_accuracy: 0.4857 - val_loss: 2.5750 - learning_rate: 2.5974e-04
Epoch 18/300
785/785 - 93s - 118ms/step - accuracy: 0.3247 - loss: 3.2483 - val_accuracy: 0.4809 - val_loss: 2.5038 - learning_rate: 2.5974e-04
Epoch 19/300
785/785 - 93s - 118ms/step - accuracy: 0.3284 - loss: 3.2234 - val_accuracy: 0.5014 - val_loss: 2.4210 - learning_rate: 2.5974e-04
Epoch 20/300
785/785 - 91s - 117ms/step - accuracy: 0.3413 - loss: 3.2233 - val_accuracy: 0.4758 - val_loss: 2.4968 - learning_rate: 2.5974e-04
Epoch 21/300
785/785 - 92s - 117ms/step - accuracy: 0.3343 - loss: 3.2052 - val_accuracy: 0.4675 - val_loss: 2.5112 - learning_rate: 2.5974e-04
Epoch 22/300
785/785 - 91s - 116ms/step - accuracy: 0.3402 - loss: 3.1832 - val_accuracy: 0.5089 - val_loss: 2.4236 - learning_rate: 2.5974e-04
Epoch 23/300
785/785 - 93s - 118ms/step - accuracy: 0.3512 - loss: 3.1710 - val_accuracy: 0.5025 - val_loss: 2.4779 - learning_rate: 2.5974e-04
Epoch 24/300
785/785 - 91s - 116ms/step - accuracy: 0.3493 - loss: 3.1562 - val_accuracy: 0.4970 - val_loss: 2.3968 - learning_rate: 2.5974e-04
Epoch 25/300
785/785 - 92s - 118ms/step - accuracy: 0.3574 - loss: 3.0994 - val_accuracy: 0.5068 - val_loss: 2.4219 - learning_rate: 2.5974e-04
Epoch 26/300
785/785 - 92s - 117ms/step - accuracy: 0.3512 - loss: 3.1183 - val_accuracy: 0.5083 - val_loss: 2.3367 - learning_rate: 2.5974e-04
Epoch 27/300
785/785 - 91s - 115ms/step - accuracy: 0.3528 - loss: 3.1262 - val_accuracy: 0.5126 - val_loss: 2.3634 - learning_rate: 2.5974e-04
Epoch 28/300
785/785 - 90s - 115ms/step - accuracy: 0.3580 - loss: 3.1052 - val_accuracy: 0.5108 - val_loss: 2.2814 - learning_rate: 2.5974e-04
Epoch 29/300
785/785 - 92s - 117ms/step - accuracy: 0.3509 - loss: 3.1069 - val_accuracy: 0.5197 - val_loss: 2.3163 - learning_rate: 2.5974e-04
Epoch 30/300
785/785 - 93s - 119ms/step - accuracy: 0.3711 - loss: 3.0712 - val_accuracy: 0.5175 - val_loss: 2.3089 - learning_rate: 2.5974e-04
Epoch 31/300
785/785 - 92s - 117ms/step - accuracy: 0.3701 - loss: 3.0565 - val_accuracy: 0.5100 - val_loss: 2.3046 - learning_rate: 2.5974e-04
Epoch 32/300
785/785 - 91s - 116ms/step - accuracy: 0.3653 - loss: 3.0658 - val_accuracy: 0.5298 - val_loss: 2.2892 - learning_rate: 2.5974e-04
Epoch 33/300
785/785 - 93s - 118ms/step - accuracy: 0.3663 - loss: 3.0634 - val_accuracy: 0.5330 - val_loss: 2.2602 - learning_rate: 2.5974e-04
Epoch 34/300
785/785 - 91s - 116ms/step - accuracy: 0.3650 - loss: 3.0534 - val_accuracy: 0.5059 - val_loss: 2.3373 - learning_rate: 2.5974e-04
Epoch 35/300
785/785 - 92s - 118ms/step - accuracy: 0.3599 - loss: 3.0587 - val_accuracy: 0.5290 - val_loss: 2.3348 - learning_rate: 2.5974e-04
Epoch 36/300
785/785 - 91s - 116ms/step - accuracy: 0.3696 - loss: 3.0534 - val_accuracy: 0.5311 - val_loss: 2.2360 - learning_rate: 2.5974e-04
Epoch 37/300
785/785 - 92s - 117ms/step - accuracy: 0.3735 - loss: 3.0224 - val_accuracy: 0.5306 - val_loss: 2.2238 - learning_rate: 2.5974e-04
Epoch 38/300
785/785 - 93s - 119ms/step - accuracy: 0.3731 - loss: 3.0481 - val_accuracy: 0.5347 - val_loss: 2.2433 - learning_rate: 2.5974e-04
Epoch 39/300
785/785 - 91s - 115ms/step - accuracy: 0.3674 - loss: 3.0522 - val_accuracy: 0.5250 - val_loss: 2.2474 - learning_rate: 2.5974e-04
Epoch 40/300
785/785 - 89s - 114ms/step - accuracy: 0.3757 - loss: 3.0043 - val_accuracy: 0.5330 - val_loss: 2.1980 - learning_rate: 2.5974e-04
Epoch 41/300
785/785 - 92s - 117ms/step - accuracy: 0.3719 - loss: 3.0172 - val_accuracy: 0.5381 - val_loss: 2.2163 - learning_rate: 2.5974e-04
Epoch 42/300
785/785 - 92s - 118ms/step - accuracy: 0.3731 - loss: 3.0205 - val_accuracy: 0.5384 - val_loss: 2.2425 - learning_rate: 2.5974e-04
Epoch 43/300
785/785 - 93s - 119ms/step - accuracy: 0.3682 - loss: 3.0494 - val_accuracy: 0.5373 - val_loss: 2.2302 - learning_rate: 2.5974e-04
Epoch 44/300
785/785 - 92s - 117ms/step - accuracy: 0.3757 - loss: 3.0076 - val_accuracy: 0.5424 - val_loss: 2.2143 - learning_rate: 2.5974e-04
Epoch 45/300
785/785 - 93s - 119ms/step - accuracy: 0.3728 - loss: 3.0190 - val_accuracy: 0.5373 - val_loss: 2.1828 - learning_rate: 2.5974e-04
Epoch 46/300
785/785 - 92s - 117ms/step - accuracy: 0.3733 - loss: 3.0140 - val_accuracy: 0.5277 - val_loss: 2.1804 - learning_rate: 2.5974e-04
Epoch 47/300
785/785 - 90s - 115ms/step - accuracy: 0.3806 - loss: 2.9954 - val_accuracy: 0.5312 - val_loss: 2.1560 - learning_rate: 2.5974e-04
Epoch 48/300
785/785 - 94s - 120ms/step - accuracy: 0.3835 - loss: 2.9913 - val_accuracy: 0.5476 - val_loss: 2.1802 - learning_rate: 2.5974e-04
Epoch 49/300
785/785 - 90s - 114ms/step - accuracy: 0.3880 - loss: 2.9836 - val_accuracy: 0.5291 - val_loss: 2.1783 - learning_rate: 2.5974e-04
Epoch 50/300
785/785 - 94s - 120ms/step - accuracy: 0.3841 - loss: 2.9683 - val_accuracy: 0.5366 - val_loss: 2.1886 - learning_rate: 2.5974e-04
Epoch 51/300
785/785 - 91s - 116ms/step - accuracy: 0.3757 - loss: 2.9262 - val_accuracy: 0.5478 - val_loss: 2.1699 - learning_rate: 2.5974e-04
Epoch 52/300
785/785 - 90s - 115ms/step - accuracy: 0.3774 - loss: 2.9542 - val_accuracy: 0.5414 - val_loss: 2.1992 - learning_rate: 2.5974e-04
Epoch 53/300
785/785 - 93s - 119ms/step - accuracy: 0.3843 - loss: 2.9122 - val_accuracy: 0.5435 - val_loss: 2.1978 - learning_rate: 2.5974e-04
Epoch 54/300
785/785 - 92s - 117ms/step - accuracy: 0.3803 - loss: 2.9564 - val_accuracy: 0.5479 - val_loss: 2.1485 - learning_rate: 2.5974e-04
Epoch 55/300
785/785 - 94s - 119ms/step - accuracy: 0.3867 - loss: 2.9388 - val_accuracy: 0.5588 - val_loss: 2.1494 - learning_rate: 2.5974e-04
Epoch 56/300
785/785 - 90s - 115ms/step - accuracy: 0.3931 - loss: 2.9047 - val_accuracy: 0.5416 - val_loss: 2.1588 - learning_rate: 2.5974e-04
Epoch 57/300
785/785 - 93s - 119ms/step - accuracy: 0.3841 - loss: 2.9335 - val_accuracy: 0.5543 - val_loss: 2.1277 - learning_rate: 2.5974e-04
Epoch 58/300
785/785 - 93s - 119ms/step - accuracy: 0.3867 - loss: 2.9393 - val_accuracy: 0.5553 - val_loss: 2.1700 - learning_rate: 2.5974e-04
Epoch 59/300
785/785 - 89s - 113ms/step - accuracy: 0.3763 - loss: 2.9417 - val_accuracy: 0.5650 - val_loss: 2.1528 - learning_rate: 2.5974e-04
Epoch 60/300
785/785 - 94s - 120ms/step - accuracy: 0.3795 - loss: 2.9344 - val_accuracy: 0.5381 - val_loss: 2.2044 - learning_rate: 2.5974e-04
Epoch 61/300
785/785 - 90s - 115ms/step - accuracy: 0.3811 - loss: 2.9425 - val_accuracy: 0.5530 - val_loss: 2.1462 - learning_rate: 2.5974e-04
Epoch 62/300
785/785 - 94s - 120ms/step - accuracy: 0.3798 - loss: 2.9260 - val_accuracy: 0.5280 - val_loss: 2.1479 - learning_rate: 2.5974e-04
Epoch 63/300
785/785 - 91s - 117ms/step - accuracy: 0.3810 - loss: 2.9486 - val_accuracy: 0.5486 - val_loss: 2.1420 - learning_rate: 2.5974e-04
Epoch 64/300
785/785 - 93s - 118ms/step - accuracy: 0.3824 - loss: 2.9411 - val_accuracy: 0.5588 - val_loss: 2.0915 - learning_rate: 2.5974e-04
Epoch 65/300
785/785 - 94s - 119ms/step - accuracy: 0.3747 - loss: 2.9182 - val_accuracy: 0.5352 - val_loss: 2.1722 - learning_rate: 2.5974e-04
Epoch 66/300
785/785 - 90s - 115ms/step - accuracy: 0.3915 - loss: 2.9060 - val_accuracy: 0.5615 - val_loss: 2.1909 - learning_rate: 2.5974e-04
Epoch 67/300
785/785 - 93s - 118ms/step - accuracy: 0.3908 - loss: 2.9310 - val_accuracy: 0.5554 - val_loss: 2.1493 - learning_rate: 2.5974e-04
Epoch 68/300
785/785 - 92s - 117ms/step - accuracy: 0.3878 - loss: 2.8850 - val_accuracy: 0.5473 - val_loss: 2.0978 - learning_rate: 2.5974e-04
Epoch 69/300
785/785 - 92s - 117ms/step - accuracy: 0.3894 - loss: 2.9145 - val_accuracy: 0.5567 - val_loss: 2.1141 - learning_rate: 2.5974e-04
Epoch 70/300
785/785 - 94s - 120ms/step - accuracy: 0.3964 - loss: 2.9253 - val_accuracy: 0.5513 - val_loss: 2.0701 - learning_rate: 2.5974e-04
Epoch 71/300
785/785 - 91s - 116ms/step - accuracy: 0.3902 - loss: 2.9271 - val_accuracy: 0.5505 - val_loss: 2.0933 - learning_rate: 2.5974e-04
Epoch 72/300
785/785 - 93s - 119ms/step - accuracy: 0.3878 - loss: 2.9247 - val_accuracy: 0.5519 - val_loss: 2.1135 - learning_rate: 2.5974e-04
Epoch 73/300
785/785 - 90s - 115ms/step - accuracy: 0.3921 - loss: 2.8840 - val_accuracy: 0.5347 - val_loss: 2.1134 - learning_rate: 2.5974e-04
Epoch 74/300
785/785 - 93s - 118ms/step - accuracy: 0.3996 - loss: 2.8819 - val_accuracy: 0.5521 - val_loss: 2.0720 - learning_rate: 2.5974e-04
Epoch 75/300
785/785 - 93s - 118ms/step - accuracy: 0.3923 - loss: 2.8866 - val_accuracy: 0.5565 - val_loss: 2.1002 - learning_rate: 2.5974e-04
Epoch 76/300
785/785 - 92s - 117ms/step - accuracy: 0.3888 - loss: 2.8879 - val_accuracy: 0.5408 - val_loss: 2.1474 - learning_rate: 2.5974e-04
Epoch 77/300
785/785 - 94s - 120ms/step - accuracy: 0.3996 - loss: 2.8782 - val_accuracy: 0.5556 - val_loss: 2.0935 - learning_rate: 2.5974e-04
Epoch 78/300

Epoch 78: ReduceLROnPlateau reducing learning rate to 0.0001298690476687625.
785/785 - 94s - 120ms/step - accuracy: 0.3972 - loss: 2.8717 - val_accuracy: 0.5484 - val_loss: 2.1081 - learning_rate: 2.5974e-04
Epoch 79/300
785/785 - 93s - 118ms/step - accuracy: 0.3959 - loss: 2.8595 - val_accuracy: 0.5616 - val_loss: 2.0502 - learning_rate: 1.2987e-04
Epoch 80/300
785/785 - 92s - 117ms/step - accuracy: 0.4152 - loss: 2.7881 - val_accuracy: 0.5694 - val_loss: 2.0342 - learning_rate: 1.2987e-04
Epoch 81/300
785/785 - 91s - 116ms/step - accuracy: 0.4020 - loss: 2.8212 - val_accuracy: 0.5744 - val_loss: 2.0420 - learning_rate: 1.2987e-04
Epoch 82/300
785/785 - 94s - 119ms/step - accuracy: 0.4106 - loss: 2.8152 - val_accuracy: 0.5670 - val_loss: 2.0275 - learning_rate: 1.2987e-04
Epoch 83/300
785/785 - 91s - 116ms/step - accuracy: 0.4077 - loss: 2.8235 - val_accuracy: 0.5734 - val_loss: 2.0349 - learning_rate: 1.2987e-04
Epoch 84/300
785/785 - 95s - 121ms/step - accuracy: 0.4203 - loss: 2.7905 - val_accuracy: 0.5828 - val_loss: 2.0514 - learning_rate: 1.2987e-04
Epoch 85/300
785/785 - 138s - 176ms/step - accuracy: 0.4155 - loss: 2.7964 - val_accuracy: 0.5581 - val_loss: 2.0484 - learning_rate: 1.2987e-04
Epoch 86/300
785/785 - 92s - 117ms/step - accuracy: 0.4048 - loss: 2.7860 - val_accuracy: 0.5639 - val_loss: 2.0534 - learning_rate: 1.2987e-04
Epoch 87/300
785/785 - 90s - 115ms/step - accuracy: 0.4075 - loss: 2.8070 - val_accuracy: 0.5683 - val_loss: 2.0064 - learning_rate: 1.2987e-04
Epoch 88/300
785/785 - 91s - 116ms/step - accuracy: 0.4093 - loss: 2.8081 - val_accuracy: 0.5688 - val_loss: 2.0278 - learning_rate: 1.2987e-04
Epoch 89/300
785/785 - 93s - 118ms/step - accuracy: 0.4101 - loss: 2.7951 - val_accuracy: 0.5725 - val_loss: 1.9993 - learning_rate: 1.2987e-04
Epoch 90/300
785/785 - 92s - 118ms/step - accuracy: 0.4111 - loss: 2.7956 - val_accuracy: 0.5635 - val_loss: 2.0194 - learning_rate: 1.2987e-04
Epoch 91/300
785/785 - 91s - 116ms/step - accuracy: 0.4155 - loss: 2.7820 - val_accuracy: 0.5755 - val_loss: 1.9995 - learning_rate: 1.2987e-04
Epoch 92/300
785/785 - 94s - 119ms/step - accuracy: 0.4181 - loss: 2.7710 - val_accuracy: 0.5721 - val_loss: 2.0127 - learning_rate: 1.2987e-04
Epoch 93/300
785/785 - 91s - 115ms/step - accuracy: 0.4111 - loss: 2.7564 - val_accuracy: 0.5626 - val_loss: 2.0096 - learning_rate: 1.2987e-04
Epoch 94/300
785/785 - 89s - 114ms/step - accuracy: 0.4190 - loss: 2.7462 - val_accuracy: 0.5707 - val_loss: 2.0051 - learning_rate: 1.2987e-04
Epoch 95/300
785/785 - 93s - 118ms/step - accuracy: 0.4095 - loss: 2.7903 - val_accuracy: 0.5680 - val_loss: 1.9857 - learning_rate: 1.2987e-04
Epoch 96/300
785/785 - 91s - 116ms/step - accuracy: 0.4141 - loss: 2.7657 - val_accuracy: 0.5739 - val_loss: 1.9920 - learning_rate: 1.2987e-04
Epoch 97/300
785/785 - 94s - 119ms/step - accuracy: 0.4146 - loss: 2.7529 - val_accuracy: 0.5826 - val_loss: 1.9853 - learning_rate: 1.2987e-04
Epoch 98/300
785/785 - 91s - 116ms/step - accuracy: 0.4179 - loss: 2.7858 - val_accuracy: 0.5809 - val_loss: 2.0033 - learning_rate: 1.2987e-04
Epoch 99/300
785/785 - 88s - 112ms/step - accuracy: 0.4142 - loss: 2.7954 - val_accuracy: 0.5830 - val_loss: 2.0099 - learning_rate: 1.2987e-04
Epoch 100/300
785/785 - 94s - 119ms/step - accuracy: 0.4138 - loss: 2.7756 - val_accuracy: 0.5761 - val_loss: 2.0332 - learning_rate: 1.2987e-04
Epoch 101/300
785/785 - 93s - 118ms/step - accuracy: 0.4211 - loss: 2.7695 - val_accuracy: 0.5825 - val_loss: 1.9987 - learning_rate: 1.2987e-04
Epoch 102/300
785/785 - 92s - 117ms/step - accuracy: 0.4220 - loss: 2.7384 - val_accuracy: 0.5825 - val_loss: 2.0123 - learning_rate: 1.2987e-04
Epoch 103/300
785/785 - 92s - 117ms/step - accuracy: 0.4313 - loss: 2.7470 - val_accuracy: 0.5834 - val_loss: 1.9712 - learning_rate: 1.2987e-04
Epoch 104/300
785/785 - 94s - 120ms/step - accuracy: 0.4152 - loss: 2.7500 - val_accuracy: 0.5868 - val_loss: 1.9686 - learning_rate: 1.2987e-04
Epoch 105/300
785/785 - 91s - 116ms/step - accuracy: 0.4169 - loss: 2.7466 - val_accuracy: 0.5731 - val_loss: 1.9946 - learning_rate: 1.2987e-04
Epoch 106/300
785/785 - 94s - 120ms/step - accuracy: 0.4010 - loss: 2.7642 - val_accuracy: 0.5763 - val_loss: 1.9790 - learning_rate: 1.2987e-04
Epoch 107/300
785/785 - 90s - 115ms/step - accuracy: 0.4146 - loss: 2.7525 - val_accuracy: 0.5877 - val_loss: 1.9815 - learning_rate: 1.2987e-04
Epoch 108/300
785/785 - 142s - 182ms/step - accuracy: 0.4208 - loss: 2.7679 - val_accuracy: 0.5737 - val_loss: 2.0062 - learning_rate: 1.2987e-04
Epoch 109/300
785/785 - 91s - 115ms/step - accuracy: 0.4182 - loss: 2.7542 - val_accuracy: 0.5889 - val_loss: 1.9767 - learning_rate: 1.2987e-04
Epoch 110/300
785/785 - 92s - 118ms/step - accuracy: 0.4190 - loss: 2.7340 - val_accuracy: 0.5774 - val_loss: 1.9771 - learning_rate: 1.2987e-04
Epoch 111/300
785/785 - 91s - 116ms/step - accuracy: 0.4244 - loss: 2.7080 - val_accuracy: 0.5868 - val_loss: 1.9773 - learning_rate: 1.2987e-04
Epoch 112/300

Epoch 112: ReduceLROnPlateau reducing learning rate to 6.493452383438125e-05.
785/785 - 94s - 120ms/step - accuracy: 0.4265 - loss: 2.7531 - val_accuracy: 0.5753 - val_loss: 1.9819 - learning_rate: 1.2987e-04
Epoch 113/300
785/785 - 90s - 115ms/step - accuracy: 0.4217 - loss: 2.7501 - val_accuracy: 0.5834 - val_loss: 1.9471 - learning_rate: 6.4935e-05
Epoch 114/300
785/785 - 95s - 121ms/step - accuracy: 0.4236 - loss: 2.7611 - val_accuracy: 0.5839 - val_loss: 1.9569 - learning_rate: 6.4935e-05
Epoch 115/300
785/785 - 91s - 116ms/step - accuracy: 0.4251 - loss: 2.7237 - val_accuracy: 0.5876 - val_loss: 1.9553 - learning_rate: 6.4935e-05
Epoch 116/300
785/785 - 90s - 114ms/step - accuracy: 0.4198 - loss: 2.7426 - val_accuracy: 0.5830 - val_loss: 1.9496 - learning_rate: 6.4935e-05
Epoch 117/300
785/785 - 93s - 119ms/step - accuracy: 0.4337 - loss: 2.7085 - val_accuracy: 0.5764 - val_loss: 1.9507 - learning_rate: 6.4935e-05
Epoch 118/300
785/785 - 91s - 116ms/step - accuracy: 0.4228 - loss: 2.7127 - val_accuracy: 0.5844 - val_loss: 1.9623 - learning_rate: 6.4935e-05
Epoch 119/300
785/785 - 93s - 118ms/step - accuracy: 0.4232 - loss: 2.7142 - val_accuracy: 0.5896 - val_loss: 1.9564 - learning_rate: 6.4935e-05
Epoch 120/300
785/785 - 90s - 115ms/step - accuracy: 0.4247 - loss: 2.7356 - val_accuracy: 0.5833 - val_loss: 1.9653 - learning_rate: 6.4935e-05
Epoch 121/300

Epoch 121: ReduceLROnPlateau reducing learning rate to 3.2467261917190626e-05.
785/785 - 92s - 117ms/step - accuracy: 0.4238 - loss: 2.7322 - val_accuracy: 0.5842 - val_loss: 1.9597 - learning_rate: 6.4935e-05
Epoch 122/300
785/785 - 91s - 116ms/step - accuracy: 0.4327 - loss: 2.6950 - val_accuracy: 0.5879 - val_loss: 1.9405 - learning_rate: 3.2467e-05
Epoch 123/300
785/785 - 87s - 111ms/step - accuracy: 0.4345 - loss: 2.6976 - val_accuracy: 0.5884 - val_loss: 1.9440 - learning_rate: 3.2467e-05
Epoch 124/300
785/785 - 144s - 184ms/step - accuracy: 0.4270 - loss: 2.7111 - val_accuracy: 0.5924 - val_loss: 1.9538 - learning_rate: 3.2467e-05
Epoch 125/300
785/785 - 90s - 114ms/step - accuracy: 0.4306 - loss: 2.6702 - val_accuracy: 0.5885 - val_loss: 1.9513 - learning_rate: 3.2467e-05
Epoch 126/300
785/785 - 90s - 114ms/step - accuracy: 0.4176 - loss: 2.7310 - val_accuracy: 0.5951 - val_loss: 1.9548 - learning_rate: 3.2467e-05
Epoch 127/300
785/785 - 88s - 112ms/step - accuracy: 0.4228 - loss: 2.6938 - val_accuracy: 0.5903 - val_loss: 1.9480 - learning_rate: 3.2467e-05
Epoch 128/300
785/785 - 91s - 116ms/step - accuracy: 0.4330 - loss: 2.6934 - val_accuracy: 0.5818 - val_loss: 1.9440 - learning_rate: 3.2467e-05
Epoch 129/300
785/785 - 88s - 112ms/step - accuracy: 0.4362 - loss: 2.6746 - val_accuracy: 0.5898 - val_loss: 1.9448 - learning_rate: 3.2467e-05
Epoch 130/300
785/785 - 92s - 117ms/step - accuracy: 0.4240 - loss: 2.6869 - val_accuracy: 0.5908 - val_loss: 1.9397 - learning_rate: 3.2467e-05
Epoch 131/300
785/785 - 89s - 114ms/step - accuracy: 0.4340 - loss: 2.7049 - val_accuracy: 0.5854 - val_loss: 1.9409 - learning_rate: 3.2467e-05
Epoch 132/300
785/785 - 90s - 114ms/step - accuracy: 0.4244 - loss: 2.6720 - val_accuracy: 0.5887 - val_loss: 1.9434 - learning_rate: 3.2467e-05
Epoch 133/300
785/785 - 90s - 114ms/step - accuracy: 0.4313 - loss: 2.7075 - val_accuracy: 0.5906 - val_loss: 1.9332 - learning_rate: 3.2467e-05
Epoch 134/300
785/785 - 89s - 114ms/step - accuracy: 0.4313 - loss: 2.6676 - val_accuracy: 0.5900 - val_loss: 1.9443 - learning_rate: 3.2467e-05
Epoch 135/300
785/785 - 90s - 115ms/step - accuracy: 0.4308 - loss: 2.6825 - val_accuracy: 0.5925 - val_loss: 1.9372 - learning_rate: 3.2467e-05
Epoch 136/300
785/785 - 89s - 113ms/step - accuracy: 0.4281 - loss: 2.6963 - val_accuracy: 0.5916 - val_loss: 1.9462 - learning_rate: 3.2467e-05
Epoch 137/300
785/785 - 90s - 114ms/step - accuracy: 0.4375 - loss: 2.6811 - val_accuracy: 0.5901 - val_loss: 1.9275 - learning_rate: 3.2467e-05
Epoch 138/300
785/785 - 87s - 111ms/step - accuracy: 0.4262 - loss: 2.7293 - val_accuracy: 0.5941 - val_loss: 1.9331 - learning_rate: 3.2467e-05
Epoch 139/300
785/785 - 89s - 113ms/step - accuracy: 0.4343 - loss: 2.6893 - val_accuracy: 0.5924 - val_loss: 1.9425 - learning_rate: 3.2467e-05
Epoch 140/300
785/785 - 90s - 115ms/step - accuracy: 0.4257 - loss: 2.7033 - val_accuracy: 0.5916 - val_loss: 1.9315 - learning_rate: 3.2467e-05
Epoch 141/300
785/785 - 90s - 114ms/step - accuracy: 0.4230 - loss: 2.7024 - val_accuracy: 0.5909 - val_loss: 1.9330 - learning_rate: 3.2467e-05
Epoch 142/300
785/785 - 89s - 114ms/step - accuracy: 0.4311 - loss: 2.6968 - val_accuracy: 0.5925 - val_loss: 1.9345 - learning_rate: 3.2467e-05
Epoch 143/300
785/785 - 92s - 117ms/step - accuracy: 0.4286 - loss: 2.6978 - val_accuracy: 0.5849 - val_loss: 1.9219 - learning_rate: 3.2467e-05
Epoch 144/300
785/785 - 96s - 122ms/step - accuracy: 0.4322 - loss: 2.6764 - val_accuracy: 0.5920 - val_loss: 1.9397 - learning_rate: 3.2467e-05
Epoch 145/300
785/785 - 95s - 122ms/step - accuracy: 0.4292 - loss: 2.6730 - val_accuracy: 0.5939 - val_loss: 1.9392 - learning_rate: 3.2467e-05
Epoch 146/300
785/785 - 99s - 127ms/step - accuracy: 0.4349 - loss: 2.6554 - val_accuracy: 0.5928 - val_loss: 1.9365 - learning_rate: 3.2467e-05
Epoch 147/300
785/785 - 95s - 121ms/step - accuracy: 0.4308 - loss: 2.7132 - val_accuracy: 0.5908 - val_loss: 1.9379 - learning_rate: 3.2467e-05
Epoch 148/300
785/785 - 96s - 122ms/step - accuracy: 0.4262 - loss: 2.6950 - val_accuracy: 0.5906 - val_loss: 1.9350 - learning_rate: 3.2467e-05
Epoch 149/300
785/785 - 99s - 126ms/step - accuracy: 0.4329 - loss: 2.6791 - val_accuracy: 0.5916 - val_loss: 1.9317 - learning_rate: 3.2467e-05
Epoch 150/300
785/785 - 96s - 122ms/step - accuracy: 0.4306 - loss: 2.6856 - val_accuracy: 0.5943 - val_loss: 1.9395 - learning_rate: 3.2467e-05
Epoch 151/300

Epoch 151: ReduceLROnPlateau reducing learning rate to 1.6233630958595313e-05.
785/785 - 97s - 124ms/step - accuracy: 0.4367 - loss: 2.6725 - val_accuracy: 0.5965 - val_loss: 1.9294 - learning_rate: 3.2467e-05
Epoch 152/300
785/785 - 96s - 123ms/step - accuracy: 0.4386 - loss: 2.6516 - val_accuracy: 0.5924 - val_loss: 1.9280 - learning_rate: 1.6234e-05
Epoch 153/300
785/785 - 96s - 122ms/step - accuracy: 0.4330 - loss: 2.6402 - val_accuracy: 0.5906 - val_loss: 1.9210 - learning_rate: 1.6234e-05
Epoch 154/300
785/785 - 98s - 124ms/step - accuracy: 0.4348 - loss: 2.6550 - val_accuracy: 0.5925 - val_loss: 1.9200 - learning_rate: 1.6234e-05
Epoch 155/300
785/785 - 93s - 118ms/step - accuracy: 0.4271 - loss: 2.6659 - val_accuracy: 0.5935 - val_loss: 1.9200 - learning_rate: 1.6234e-05
Epoch 156/300
785/785 - 93s - 119ms/step - accuracy: 0.4353 - loss: 2.6410 - val_accuracy: 0.5928 - val_loss: 1.9184 - learning_rate: 1.6234e-05
Epoch 157/300
785/785 - 88s - 112ms/step - accuracy: 0.4373 - loss: 2.6775 - val_accuracy: 0.5911 - val_loss: 1.9235 - learning_rate: 1.6234e-05
Epoch 158/300
785/785 - 93s - 119ms/step - accuracy: 0.4305 - loss: 2.6694 - val_accuracy: 0.5920 - val_loss: 1.9280 - learning_rate: 1.6234e-05
Epoch 159/300
785/785 - 89s - 113ms/step - accuracy: 0.4348 - loss: 2.6801 - val_accuracy: 0.5927 - val_loss: 1.9211 - learning_rate: 1.6234e-05
Epoch 160/300
785/785 - 91s - 116ms/step - accuracy: 0.4273 - loss: 2.6628 - val_accuracy: 0.5928 - val_loss: 1.9209 - learning_rate: 1.6234e-05
Epoch 161/300
785/785 - 92s - 118ms/step - accuracy: 0.4359 - loss: 2.6780 - val_accuracy: 0.5941 - val_loss: 1.9160 - learning_rate: 1.6234e-05
Epoch 162/300
785/785 - 91s - 115ms/step - accuracy: 0.4321 - loss: 2.6873 - val_accuracy: 0.5914 - val_loss: 1.9164 - learning_rate: 1.6234e-05
Epoch 163/300
785/785 - 93s - 118ms/step - accuracy: 0.4373 - loss: 2.6806 - val_accuracy: 0.5922 - val_loss: 1.9203 - learning_rate: 1.6234e-05
Epoch 164/300
785/785 - 89s - 114ms/step - accuracy: 0.4335 - loss: 2.6684 - val_accuracy: 0.5939 - val_loss: 1.9225 - learning_rate: 1.6234e-05
Epoch 165/300
785/785 - 92s - 117ms/step - accuracy: 0.4405 - loss: 2.6599 - val_accuracy: 0.5904 - val_loss: 1.9271 - learning_rate: 1.6234e-05
Epoch 166/300
785/785 - 90s - 114ms/step - accuracy: 0.4362 - loss: 2.6526 - val_accuracy: 0.5928 - val_loss: 1.9228 - learning_rate: 1.6234e-05
Epoch 167/300
785/785 - 89s - 113ms/step - accuracy: 0.4367 - loss: 2.6652 - val_accuracy: 0.5935 - val_loss: 1.9223 - learning_rate: 1.6234e-05
Epoch 168/300
785/785 - 92s - 117ms/step - accuracy: 0.4263 - loss: 2.6567 - val_accuracy: 0.5920 - val_loss: 1.9230 - learning_rate: 1.6234e-05
Epoch 169/300
785/785 - 90s - 115ms/step - accuracy: 0.4429 - loss: 2.6262 - val_accuracy: 0.5927 - val_loss: 1.9097 - learning_rate: 1.6234e-05
Epoch 170/300
785/785 - 92s - 118ms/step - accuracy: 0.4297 - loss: 2.6797 - val_accuracy: 0.5935 - val_loss: 1.9160 - learning_rate: 1.6234e-05
Epoch 171/300
785/785 - 90s - 115ms/step - accuracy: 0.4405 - loss: 2.6243 - val_accuracy: 0.5949 - val_loss: 1.9170 - learning_rate: 1.6234e-05
Epoch 172/300
785/785 - 92s - 117ms/step - accuracy: 0.4303 - loss: 2.6659 - val_accuracy: 0.5900 - val_loss: 1.9134 - learning_rate: 1.6234e-05
Epoch 173/300
785/785 - 90s - 114ms/step - accuracy: 0.4303 - loss: 2.6529 - val_accuracy: 0.5949 - val_loss: 1.9148 - learning_rate: 1.6234e-05
Epoch 174/300
785/785 - 90s - 115ms/step - accuracy: 0.4316 - loss: 2.6722 - val_accuracy: 0.5939 - val_loss: 1.9096 - learning_rate: 1.6234e-05
Epoch 175/300
785/785 - 148s - 189ms/step - accuracy: 0.4419 - loss: 2.6578 - val_accuracy: 0.5927 - val_loss: 1.9126 - learning_rate: 1.6234e-05
Epoch 176/300
785/785 - 95s - 121ms/step - accuracy: 0.4335 - loss: 2.6687 - val_accuracy: 0.5971 - val_loss: 1.9208 - learning_rate: 1.6234e-05
Epoch 177/300

Epoch 177: ReduceLROnPlateau reducing learning rate to 8.116815479297657e-06.
785/785 - 96s - 122ms/step - accuracy: 0.4322 - loss: 2.6525 - val_accuracy: 0.5922 - val_loss: 1.9125 - learning_rate: 1.6234e-05
Epoch 178/300
785/785 - 97s - 124ms/step - accuracy: 0.4380 - loss: 2.6530 - val_accuracy: 0.5965 - val_loss: 1.9095 - learning_rate: 8.1168e-06
Epoch 179/300
785/785 - 96s - 123ms/step - accuracy: 0.4332 - loss: 2.6366 - val_accuracy: 0.5943 - val_loss: 1.9183 - learning_rate: 8.1168e-06
Epoch 180/300
785/785 - 96s - 122ms/step - accuracy: 0.4381 - loss: 2.6661 - val_accuracy: 0.5951 - val_loss: 1.9136 - learning_rate: 8.1168e-06
Epoch 181/300
785/785 - 96s - 123ms/step - accuracy: 0.4341 - loss: 2.6767 - val_accuracy: 0.5932 - val_loss: 1.9105 - learning_rate: 8.1168e-06
Epoch 182/300
785/785 - 97s - 123ms/step - accuracy: 0.4361 - loss: 2.6338 - val_accuracy: 0.5960 - val_loss: 1.9137 - learning_rate: 8.1168e-06
Epoch 183/300
785/785 - 96s - 123ms/step - accuracy: 0.4439 - loss: 2.6270 - val_accuracy: 0.5938 - val_loss: 1.9107 - learning_rate: 8.1168e-06
Epoch 184/300
785/785 - 96s - 123ms/step - accuracy: 0.4362 - loss: 2.6659 - val_accuracy: 0.5935 - val_loss: 1.9102 - learning_rate: 8.1168e-06
Epoch 185/300
785/785 - 97s - 123ms/step - accuracy: 0.4412 - loss: 2.6600 - val_accuracy: 0.5932 - val_loss: 1.9077 - learning_rate: 8.1168e-06
Epoch 186/300
785/785 - 95s - 121ms/step - accuracy: 0.4354 - loss: 2.6424 - val_accuracy: 0.5922 - val_loss: 1.9071 - learning_rate: 8.1168e-06
Epoch 187/300
785/785 - 95s - 122ms/step - accuracy: 0.4353 - loss: 2.6630 - val_accuracy: 0.5949 - val_loss: 1.9139 - learning_rate: 8.1168e-06
Epoch 188/300
785/785 - 97s - 123ms/step - accuracy: 0.4322 - loss: 2.6996 - val_accuracy: 0.5963 - val_loss: 1.9116 - learning_rate: 8.1168e-06
Epoch 189/300
785/785 - 96s - 123ms/step - accuracy: 0.4431 - loss: 2.6366 - val_accuracy: 0.5938 - val_loss: 1.9046 - learning_rate: 8.1168e-06
Epoch 190/300
785/785 - 96s - 123ms/step - accuracy: 0.4400 - loss: 2.6421 - val_accuracy: 0.5938 - val_loss: 1.9097 - learning_rate: 8.1168e-06
Epoch 191/300
785/785 - 96s - 122ms/step - accuracy: 0.4442 - loss: 2.6257 - val_accuracy: 0.5976 - val_loss: 1.9116 - learning_rate: 8.1168e-06
Epoch 192/300
785/785 - 96s - 123ms/step - accuracy: 0.4316 - loss: 2.6708 - val_accuracy: 0.5936 - val_loss: 1.9128 - learning_rate: 8.1168e-06
Epoch 193/300
785/785 - 98s - 124ms/step - accuracy: 0.4365 - loss: 2.6675 - val_accuracy: 0.5960 - val_loss: 1.9089 - learning_rate: 8.1168e-06
Epoch 194/300
785/785 - 97s - 123ms/step - accuracy: 0.4439 - loss: 2.6436 - val_accuracy: 0.5938 - val_loss: 1.9088 - learning_rate: 8.1168e-06
Epoch 195/300
785/785 - 97s - 123ms/step - accuracy: 0.4372 - loss: 2.6662 - val_accuracy: 0.5927 - val_loss: 1.9141 - learning_rate: 8.1168e-06
Epoch 196/300
785/785 - 95s - 121ms/step - accuracy: 0.4287 - loss: 2.6986 - val_accuracy: 0.5908 - val_loss: 1.9077 - learning_rate: 8.1168e-06
Epoch 197/300

Epoch 197: ReduceLROnPlateau reducing learning rate to 4.058407739648828e-06.
785/785 - 93s - 119ms/step - accuracy: 0.4354 - loss: 2.6504 - val_accuracy: 0.5932 - val_loss: 1.9139 - learning_rate: 8.1168e-06
Epoch 198/300
785/785 - 91s - 115ms/step - accuracy: 0.4343 - loss: 2.6623 - val_accuracy: 0.5922 - val_loss: 1.9073 - learning_rate: 4.0584e-06
Epoch 199/300
785/785 - 91s - 116ms/step - accuracy: 0.4308 - loss: 2.6455 - val_accuracy: 0.5938 - val_loss: 1.9109 - learning_rate: 4.0584e-06
Epoch 200/300
785/785 - 92s - 117ms/step - accuracy: 0.4356 - loss: 2.6512 - val_accuracy: 0.5960 - val_loss: 1.9127 - learning_rate: 4.0584e-06
Epoch 201/300
785/785 - 91s - 117ms/step - accuracy: 0.4383 - loss: 2.6573 - val_accuracy: 0.5947 - val_loss: 1.9123 - learning_rate: 4.0584e-06
Epoch 202/300
785/785 - 92s - 117ms/step - accuracy: 0.4297 - loss: 2.6669 - val_accuracy: 0.5952 - val_loss: 1.9079 - learning_rate: 4.0584e-06
Epoch 203/300
785/785 - 89s - 113ms/step - accuracy: 0.4419 - loss: 2.6465 - val_accuracy: 0.5957 - val_loss: 1.9062 - learning_rate: 4.0584e-06
Epoch 204/300
785/785 - 90s - 114ms/step - accuracy: 0.4300 - loss: 2.6703 - val_accuracy: 0.5960 - val_loss: 1.9084 - learning_rate: 4.0584e-06
Epoch 205/300

Epoch 205: ReduceLROnPlateau reducing learning rate to 2.029203869824414e-06.
785/785 - 96s - 123ms/step - accuracy: 0.4491 - loss: 2.6280 - val_accuracy: 0.5970 - val_loss: 1.9088 - learning_rate: 4.0584e-06
Epoch 205: early stopping
Restoring model weights from the end of the best epoch: 189.
Fold 2_1 Evaluation results: [1.9060356616973877, 0.59378981590271]
              precision    recall  f1-score   support

        1820       0.66      0.77      0.71       291
        1821       0.93      0.81      0.87       311
        1822       0.00      0.00      0.00         4
        1823       0.00      0.00      0.00         7
        1824       0.00      0.00      0.00         6
        1825       0.00      0.00      0.00        13
        1826       0.00      0.00      0.00        13
        1827       0.77      0.72      0.75       123
        1828       0.00      0.00      0.00        11
        1829       1.00      0.04      0.07        28
        1830       0.49      0.63      0.55       269
        1831       0.74      0.94      0.83       662
        1832       0.72      0.82      0.77       340
        1833       0.83      0.93      0.87        97
        1834       0.59      0.49      0.54       169
        1835       0.00      0.00      0.00        10
        1836       0.00      0.00      0.00        17
        1837       0.29      0.29      0.29        31
        1838       0.33      0.07      0.11        15
        1839       0.00      0.00      0.00         5
        1840       0.47      0.58      0.52       223
        1841       0.79      0.57      0.66       578
        1842       0.17      0.32      0.22        22
        1843       0.00      0.00      0.00        26
        1844       0.00      0.00      0.00         1
        1845       0.00      0.00      0.00         7
        1846       0.33      0.03      0.05        35
        1847       0.00      0.00      0.00        10
        1848       0.25      0.08      0.12        24
        1849       0.00      0.00      0.00        27
        1850       0.32      0.64      0.43       244
        1851       0.76      0.72      0.74       365
        1852       1.00      0.03      0.05        39
        1853       1.00      0.03      0.06        32
        1854       0.00      0.00      0.00         7
        1855       0.40      0.05      0.09       116
        1856       0.51      0.35      0.41        66
        1857       0.43      0.57      0.49       151
        1858       0.00      0.00      0.00        14
        1859       0.00      0.00      0.00        12
        1860       0.26      0.48      0.33       299
        1861       0.76      0.81      0.78       418
        1862       0.00      0.00      0.00        93
        1863       0.43      0.46      0.45        93
        1864       0.41      0.38      0.39        92
        1865       1.00      0.08      0.15        36
        1866       0.38      0.24      0.29        25
        1867       0.36      0.09      0.15        53
        1868       0.50      0.03      0.05        37
        1869       0.00      0.00      0.00        26
        1870       0.38      0.57      0.46       147
        1871       0.71      0.70      0.70       240
        1872       0.00      0.00      0.00        40
        1873       0.00      0.00      0.00        57
        1874       0.17      0.12      0.14        17
        1875       0.23      0.24      0.24        71
        1876       0.90      0.86      0.88        42
        1877       0.40      0.15      0.22        27
        1878       0.71      0.56      0.63        39
        1879       0.00      0.00      0.00         7

    accuracy                           0.59      6280
   macro avg       0.36      0.27      0.27      6280
weighted avg       0.59      0.59      0.57      6280

Matthews Correlation Coefficient: 0.573
Macro avg F1: 0.268
Weighted avg F1: 0.567
Micro avg F1: 0.594
Top-3 Accuracy: 0.828
Top-5 Accuracy: 0.890
Micro ROC AUC  = 0.98
Macro ROC AUC (present classes) = 0.97
Classification MAE (in years): 3.34

Fold 2_1 Misclassification Analysis:
Near misses (within 2 years): 565 out of 2551 misclassifications (22.15%)
Big misses (greater than 10 years): 1053
MAE with outliers: 3.34
MAE without outliers: 2.34 (improvement: 1.00)

10 Worst misclassifications:
Image: data/datasets/private/1820/1820_034_Zrzut ekranu 2022-07-26 203655.png, True: 1820, Predicted: 1876, Error: 56
Image: data/datasets/private/1820/1824_032_Zrzut ekranu 2022-07-26 203037.png, True: 1824, Predicted: 1876, Error: 52
Image: data/datasets/public/1820/1820_12wikimedia2.jpg, True: 1820, Predicted: 1871, Error: 51
Image: data/datasets/private/1870/1871_114etsy.jpg, True: 1871, Predicted: 1820, Error: 51
Image: data/datasets/private/1870/1871_384etsy.jpg, True: 1871, Predicted: 1821, Error: 50
Image: data/datasets/private/1870/1871_404etsy.jpg, True: 1871, Predicted: 1821, Error: 50
Image: data/datasets/public/1820/1820_033_001met.jpg, True: 1820, Predicted: 1870, Error: 50
Image: data/datasets/public/1870/1870_79wikimedia2.jpg, True: 1870, Predicted: 1820, Error: 50
Image: data/datasets/private/1820/1821_551etsy.jpg, True: 1821, Predicted: 1871, Error: 50
Image: data/datasets/public/1860/1868_042met.jpg, True: 1868, Predicted: 1820, Error: 48

===== Fine Tuning 9 layers! =====
Epoch 1/300
785/785 - 120s - 153ms/step - accuracy: 0.1170 - loss: 4.3768 - val_accuracy: 0.1599 - val_loss: 3.8839 - learning_rate: 2.5974e-04
Epoch 2/300
785/785 - 96s - 122ms/step - accuracy: 0.1567 - loss: 4.1065 - val_accuracy: 0.2594 - val_loss: 3.7101 - learning_rate: 2.5974e-04
Epoch 3/300
785/785 - 97s - 124ms/step - accuracy: 0.1968 - loss: 3.9760 - val_accuracy: 0.3182 - val_loss: 3.5639 - learning_rate: 2.5974e-04
Epoch 4/300
785/785 - 96s - 122ms/step - accuracy: 0.2140 - loss: 3.8226 - val_accuracy: 0.3408 - val_loss: 3.3009 - learning_rate: 2.5974e-04
Epoch 5/300
785/785 - 97s - 124ms/step - accuracy: 0.2256 - loss: 3.7810 - val_accuracy: 0.3403 - val_loss: 3.1874 - learning_rate: 2.5974e-04
Epoch 6/300
785/785 - 97s - 123ms/step - accuracy: 0.2384 - loss: 3.6837 - val_accuracy: 0.3942 - val_loss: 3.1839 - learning_rate: 2.5974e-04
Epoch 7/300
785/785 - 97s - 124ms/step - accuracy: 0.2578 - loss: 3.6034 - val_accuracy: 0.4040 - val_loss: 2.9412 - learning_rate: 2.5974e-04
Epoch 8/300
785/785 - 95s - 121ms/step - accuracy: 0.2694 - loss: 3.5143 - val_accuracy: 0.3951 - val_loss: 2.9104 - learning_rate: 2.5974e-04
Epoch 9/300
785/785 - 95s - 121ms/step - accuracy: 0.2772 - loss: 3.4937 - val_accuracy: 0.4190 - val_loss: 2.7770 - learning_rate: 2.5974e-04
Epoch 10/300
785/785 - 96s - 123ms/step - accuracy: 0.2828 - loss: 3.4611 - val_accuracy: 0.4203 - val_loss: 2.7927 - learning_rate: 2.5974e-04
Epoch 11/300
785/785 - 96s - 123ms/step - accuracy: 0.2865 - loss: 3.4308 - val_accuracy: 0.4491 - val_loss: 2.7410 - learning_rate: 2.5974e-04
Epoch 12/300
785/785 - 96s - 122ms/step - accuracy: 0.2946 - loss: 3.4091 - val_accuracy: 0.4576 - val_loss: 2.6865 - learning_rate: 2.5974e-04
Epoch 13/300
785/785 - 142s - 181ms/step - accuracy: 0.3089 - loss: 3.3580 - val_accuracy: 0.4684 - val_loss: 2.6852 - learning_rate: 2.5974e-04
Epoch 14/300
785/785 - 97s - 124ms/step - accuracy: 0.3178 - loss: 3.3128 - val_accuracy: 0.4588 - val_loss: 2.6164 - learning_rate: 2.5974e-04
Epoch 15/300
785/785 - 96s - 122ms/step - accuracy: 0.3111 - loss: 3.2954 - val_accuracy: 0.4776 - val_loss: 2.5465 - learning_rate: 2.5974e-04
Epoch 16/300
785/785 - 95s - 121ms/step - accuracy: 0.3260 - loss: 3.2486 - val_accuracy: 0.4972 - val_loss: 2.5849 - learning_rate: 2.5974e-04
Epoch 17/300
785/785 - 96s - 122ms/step - accuracy: 0.3205 - loss: 3.2965 - val_accuracy: 0.4803 - val_loss: 2.4998 - learning_rate: 2.5974e-04
Epoch 18/300
785/785 - 94s - 120ms/step - accuracy: 0.3236 - loss: 3.2545 - val_accuracy: 0.4684 - val_loss: 2.5826 - learning_rate: 2.5974e-04
Epoch 19/300
785/785 - 96s - 122ms/step - accuracy: 0.3263 - loss: 3.2296 - val_accuracy: 0.5006 - val_loss: 2.4050 - learning_rate: 2.5974e-04
Epoch 20/300
785/785 - 95s - 122ms/step - accuracy: 0.3323 - loss: 3.2095 - val_accuracy: 0.4937 - val_loss: 2.5682 - learning_rate: 2.5974e-04
Epoch 21/300
785/785 - 96s - 122ms/step - accuracy: 0.3346 - loss: 3.2091 - val_accuracy: 0.5014 - val_loss: 2.3931 - learning_rate: 2.5974e-04
Epoch 22/300
785/785 - 96s - 123ms/step - accuracy: 0.3390 - loss: 3.1820 - val_accuracy: 0.4861 - val_loss: 2.3878 - learning_rate: 2.5974e-04
Epoch 23/300
785/785 - 96s - 122ms/step - accuracy: 0.3432 - loss: 3.1539 - val_accuracy: 0.5101 - val_loss: 2.3440 - learning_rate: 2.5974e-04
Epoch 24/300
785/785 - 96s - 123ms/step - accuracy: 0.3417 - loss: 3.1384 - val_accuracy: 0.5084 - val_loss: 2.3862 - learning_rate: 2.5974e-04
Epoch 25/300
785/785 - 96s - 122ms/step - accuracy: 0.3398 - loss: 3.1541 - val_accuracy: 0.5109 - val_loss: 2.3241 - learning_rate: 2.5974e-04
Epoch 26/300
785/785 - 95s - 121ms/step - accuracy: 0.3363 - loss: 3.1535 - val_accuracy: 0.5014 - val_loss: 2.3219 - learning_rate: 2.5974e-04
Epoch 27/300
785/785 - 97s - 123ms/step - accuracy: 0.3457 - loss: 3.1245 - val_accuracy: 0.5047 - val_loss: 2.3471 - learning_rate: 2.5974e-04
Epoch 28/300
785/785 - 98s - 125ms/step - accuracy: 0.3487 - loss: 3.1319 - val_accuracy: 0.5160 - val_loss: 2.3776 - learning_rate: 2.5974e-04
Epoch 29/300
785/785 - 97s - 123ms/step - accuracy: 0.3462 - loss: 3.1087 - val_accuracy: 0.5287 - val_loss: 2.2752 - learning_rate: 2.5974e-04
Epoch 30/300
785/785 - 96s - 123ms/step - accuracy: 0.3553 - loss: 3.0898 - val_accuracy: 0.5249 - val_loss: 2.2388 - learning_rate: 2.5974e-04
Epoch 31/300
785/785 - 95s - 122ms/step - accuracy: 0.3645 - loss: 3.0634 - val_accuracy: 0.5211 - val_loss: 2.2331 - learning_rate: 2.5974e-04
Epoch 32/300
785/785 - 96s - 122ms/step - accuracy: 0.3600 - loss: 3.0558 - val_accuracy: 0.5194 - val_loss: 2.2400 - learning_rate: 2.5974e-04
Epoch 33/300
785/785 - 92s - 118ms/step - accuracy: 0.3556 - loss: 3.0555 - val_accuracy: 0.5217 - val_loss: 2.2552 - learning_rate: 2.5974e-04
Epoch 34/300
785/785 - 90s - 114ms/step - accuracy: 0.3578 - loss: 3.0609 - val_accuracy: 0.5184 - val_loss: 2.2863 - learning_rate: 2.5974e-04
Epoch 35/300
785/785 - 91s - 116ms/step - accuracy: 0.3562 - loss: 3.0722 - val_accuracy: 0.5356 - val_loss: 2.1865 - learning_rate: 2.5974e-04
Epoch 36/300
785/785 - 92s - 117ms/step - accuracy: 0.3651 - loss: 3.0319 - val_accuracy: 0.5316 - val_loss: 2.2805 - learning_rate: 2.5974e-04
Epoch 37/300
785/785 - 89s - 113ms/step - accuracy: 0.3705 - loss: 3.0210 - val_accuracy: 0.5289 - val_loss: 2.1883 - learning_rate: 2.5974e-04
Epoch 38/300
785/785 - 90s - 114ms/step - accuracy: 0.3723 - loss: 3.0234 - val_accuracy: 0.5229 - val_loss: 2.1974 - learning_rate: 2.5974e-04
Epoch 39/300
785/785 - 88s - 112ms/step - accuracy: 0.3678 - loss: 3.0299 - val_accuracy: 0.5190 - val_loss: 2.2929 - learning_rate: 2.5974e-04
Epoch 40/300
785/785 - 96s - 122ms/step - accuracy: 0.3611 - loss: 3.0300 - val_accuracy: 0.5356 - val_loss: 2.1657 - learning_rate: 2.5974e-04
Epoch 41/300
785/785 - 90s - 115ms/step - accuracy: 0.3728 - loss: 2.9905 - val_accuracy: 0.5356 - val_loss: 2.1526 - learning_rate: 2.5974e-04
Epoch 42/300
785/785 - 89s - 113ms/step - accuracy: 0.3623 - loss: 3.0272 - val_accuracy: 0.5179 - val_loss: 2.2902 - learning_rate: 2.5974e-04
Epoch 43/300
785/785 - 91s - 116ms/step - accuracy: 0.3732 - loss: 2.9757 - val_accuracy: 0.5319 - val_loss: 2.2034 - learning_rate: 2.5974e-04
Epoch 44/300
785/785 - 90s - 114ms/step - accuracy: 0.3739 - loss: 2.9873 - val_accuracy: 0.5332 - val_loss: 2.1499 - learning_rate: 2.5974e-04
Epoch 45/300
785/785 - 90s - 114ms/step - accuracy: 0.3766 - loss: 2.9873 - val_accuracy: 0.5440 - val_loss: 2.1705 - learning_rate: 2.5974e-04
Epoch 46/300
785/785 - 92s - 117ms/step - accuracy: 0.3731 - loss: 2.9708 - val_accuracy: 0.5366 - val_loss: 2.1224 - learning_rate: 2.5974e-04
Epoch 47/300
785/785 - 88s - 112ms/step - accuracy: 0.3807 - loss: 2.9844 - val_accuracy: 0.5459 - val_loss: 2.1509 - learning_rate: 2.5974e-04
Epoch 48/300
785/785 - 88s - 113ms/step - accuracy: 0.3689 - loss: 2.9811 - val_accuracy: 0.5461 - val_loss: 2.1209 - learning_rate: 2.5974e-04
Epoch 49/300
785/785 - 89s - 113ms/step - accuracy: 0.3723 - loss: 2.9686 - val_accuracy: 0.5264 - val_loss: 2.2032 - learning_rate: 2.5974e-04
Epoch 50/300
785/785 - 95s - 122ms/step - accuracy: 0.3879 - loss: 2.9510 - val_accuracy: 0.5362 - val_loss: 2.1563 - learning_rate: 2.5974e-04
Epoch 51/300
785/785 - 90s - 114ms/step - accuracy: 0.3787 - loss: 2.9700 - val_accuracy: 0.5205 - val_loss: 2.1842 - learning_rate: 2.5974e-04
Epoch 52/300
785/785 - 89s - 114ms/step - accuracy: 0.3742 - loss: 2.9552 - val_accuracy: 0.5297 - val_loss: 2.1501 - learning_rate: 2.5974e-04
Epoch 53/300
785/785 - 91s - 116ms/step - accuracy: 0.3860 - loss: 2.9257 - val_accuracy: 0.5444 - val_loss: 2.0783 - learning_rate: 2.5974e-04
Epoch 54/300
785/785 - 90s - 115ms/step - accuracy: 0.3889 - loss: 2.9191 - val_accuracy: 0.5479 - val_loss: 2.1039 - learning_rate: 2.5974e-04
Epoch 55/300
785/785 - 90s - 115ms/step - accuracy: 0.3854 - loss: 2.9179 - val_accuracy: 0.5475 - val_loss: 2.1242 - learning_rate: 2.5974e-04
Epoch 56/300
785/785 - 90s - 114ms/step - accuracy: 0.3796 - loss: 2.9225 - val_accuracy: 0.5522 - val_loss: 2.1157 - learning_rate: 2.5974e-04
Epoch 57/300
785/785 - 88s - 112ms/step - accuracy: 0.3818 - loss: 2.9103 - val_accuracy: 0.5458 - val_loss: 2.0929 - learning_rate: 2.5974e-04
Epoch 58/300
785/785 - 88s - 112ms/step - accuracy: 0.3732 - loss: 2.9431 - val_accuracy: 0.5678 - val_loss: 2.0602 - learning_rate: 2.5974e-04
Epoch 59/300
785/785 - 142s - 181ms/step - accuracy: 0.3817 - loss: 2.9087 - val_accuracy: 0.5522 - val_loss: 2.1464 - learning_rate: 2.5974e-04
Epoch 60/300
785/785 - 91s - 116ms/step - accuracy: 0.3830 - loss: 2.9243 - val_accuracy: 0.5565 - val_loss: 2.0590 - learning_rate: 2.5974e-04
Epoch 61/300
785/785 - 90s - 115ms/step - accuracy: 0.3916 - loss: 2.8883 - val_accuracy: 0.5501 - val_loss: 2.1200 - learning_rate: 2.5974e-04
Epoch 62/300
785/785 - 96s - 122ms/step - accuracy: 0.3916 - loss: 2.9149 - val_accuracy: 0.5622 - val_loss: 2.0288 - learning_rate: 2.5974e-04
Epoch 63/300
785/785 - 92s - 117ms/step - accuracy: 0.3833 - loss: 2.9407 - val_accuracy: 0.5603 - val_loss: 2.0450 - learning_rate: 2.5974e-04
Epoch 64/300
785/785 - 89s - 114ms/step - accuracy: 0.3854 - loss: 2.9260 - val_accuracy: 0.5595 - val_loss: 2.0531 - learning_rate: 2.5974e-04
Epoch 65/300
785/785 - 90s - 114ms/step - accuracy: 0.3844 - loss: 2.9158 - val_accuracy: 0.5469 - val_loss: 2.0914 - learning_rate: 2.5974e-04
Epoch 66/300
785/785 - 90s - 115ms/step - accuracy: 0.3860 - loss: 2.8868 - val_accuracy: 0.5533 - val_loss: 2.0743 - learning_rate: 2.5974e-04
Epoch 67/300
785/785 - 88s - 113ms/step - accuracy: 0.3895 - loss: 2.8845 - val_accuracy: 0.5619 - val_loss: 2.0575 - learning_rate: 2.5974e-04
Epoch 68/300
785/785 - 89s - 113ms/step - accuracy: 0.3818 - loss: 2.9288 - val_accuracy: 0.5528 - val_loss: 2.0589 - learning_rate: 2.5974e-04
Epoch 69/300
785/785 - 90s - 115ms/step - accuracy: 0.3932 - loss: 2.9331 - val_accuracy: 0.5593 - val_loss: 2.0547 - learning_rate: 2.5974e-04
Epoch 70/300
785/785 - 90s - 114ms/step - accuracy: 0.3858 - loss: 2.9142 - val_accuracy: 0.5550 - val_loss: 2.0195 - learning_rate: 2.5974e-04
Epoch 71/300
785/785 - 90s - 115ms/step - accuracy: 0.3914 - loss: 2.8805 - val_accuracy: 0.5552 - val_loss: 2.0451 - learning_rate: 2.5974e-04
Epoch 72/300
785/785 - 91s - 116ms/step - accuracy: 0.3941 - loss: 2.9267 - val_accuracy: 0.5573 - val_loss: 2.0695 - learning_rate: 2.5974e-04
Epoch 73/300
785/785 - 91s - 116ms/step - accuracy: 0.3986 - loss: 2.8973 - val_accuracy: 0.5525 - val_loss: 2.0338 - learning_rate: 2.5974e-04
Epoch 74/300
785/785 - 95s - 120ms/step - accuracy: 0.3954 - loss: 2.8159 - val_accuracy: 0.5604 - val_loss: 2.0509 - learning_rate: 2.5974e-04
Epoch 75/300
785/785 - 88s - 112ms/step - accuracy: 0.3968 - loss: 2.8672 - val_accuracy: 0.5639 - val_loss: 2.0298 - learning_rate: 2.5974e-04
Epoch 76/300
785/785 - 90s - 115ms/step - accuracy: 0.3989 - loss: 2.8861 - val_accuracy: 0.5558 - val_loss: 2.0882 - learning_rate: 2.5974e-04
Epoch 77/300
785/785 - 90s - 114ms/step - accuracy: 0.3877 - loss: 2.8846 - val_accuracy: 0.5644 - val_loss: 2.0154 - learning_rate: 2.5974e-04
Epoch 78/300
785/785 - 88s - 112ms/step - accuracy: 0.3973 - loss: 2.8478 - val_accuracy: 0.5617 - val_loss: 2.0481 - learning_rate: 2.5974e-04
Epoch 79/300
785/785 - 91s - 116ms/step - accuracy: 0.3876 - loss: 2.9048 - val_accuracy: 0.5655 - val_loss: 2.0230 - learning_rate: 2.5974e-04
Epoch 80/300
785/785 - 89s - 114ms/step - accuracy: 0.3881 - loss: 2.8498 - val_accuracy: 0.5601 - val_loss: 2.0369 - learning_rate: 2.5974e-04
Epoch 81/300
785/785 - 91s - 116ms/step - accuracy: 0.3917 - loss: 2.8706 - val_accuracy: 0.5644 - val_loss: 2.0146 - learning_rate: 2.5974e-04
Epoch 82/300
785/785 - 91s - 116ms/step - accuracy: 0.3865 - loss: 2.8948 - val_accuracy: 0.5635 - val_loss: 2.0237 - learning_rate: 2.5974e-04
Epoch 83/300
785/785 - 90s - 115ms/step - accuracy: 0.3877 - loss: 2.8291 - val_accuracy: 0.5622 - val_loss: 2.0380 - learning_rate: 2.5974e-04
Epoch 84/300
785/785 - 92s - 117ms/step - accuracy: 0.3951 - loss: 2.8727 - val_accuracy: 0.5671 - val_loss: 2.0337 - learning_rate: 2.5974e-04
Epoch 85/300
785/785 - 89s - 114ms/step - accuracy: 0.3959 - loss: 2.8757 - val_accuracy: 0.5566 - val_loss: 2.0314 - learning_rate: 2.5974e-04
Epoch 86/300
785/785 - 90s - 115ms/step - accuracy: 0.3941 - loss: 2.8700 - val_accuracy: 0.5652 - val_loss: 2.0416 - learning_rate: 2.5974e-04
Epoch 87/300
785/785 - 90s - 115ms/step - accuracy: 0.3898 - loss: 2.8766 - val_accuracy: 0.5636 - val_loss: 2.0117 - learning_rate: 2.5974e-04
Epoch 88/300
785/785 - 93s - 119ms/step - accuracy: 0.3925 - loss: 2.8698 - val_accuracy: 0.5512 - val_loss: 2.0587 - learning_rate: 2.5974e-04
Epoch 89/300
785/785 - 92s - 117ms/step - accuracy: 0.3982 - loss: 2.8510 - val_accuracy: 0.5426 - val_loss: 2.0533 - learning_rate: 2.5974e-04
Epoch 90/300
785/785 - 94s - 119ms/step - accuracy: 0.3971 - loss: 2.8432 - val_accuracy: 0.5702 - val_loss: 2.0224 - learning_rate: 2.5974e-04
Epoch 91/300
785/785 - 91s - 116ms/step - accuracy: 0.3901 - loss: 2.8710 - val_accuracy: 0.5641 - val_loss: 2.0617 - learning_rate: 2.5974e-04
Epoch 92/300
785/785 - 90s - 114ms/step - accuracy: 0.3932 - loss: 2.8221 - val_accuracy: 0.5585 - val_loss: 2.0493 - learning_rate: 2.5974e-04
Epoch 93/300
785/785 - 91s - 116ms/step - accuracy: 0.3892 - loss: 2.8252 - val_accuracy: 0.5667 - val_loss: 2.0149 - learning_rate: 2.5974e-04
Epoch 94/300
785/785 - 91s - 116ms/step - accuracy: 0.3954 - loss: 2.8209 - val_accuracy: 0.5690 - val_loss: 2.0526 - learning_rate: 2.5974e-04
Epoch 95/300

Epoch 95: ReduceLROnPlateau reducing learning rate to 0.0001298690476687625.
785/785 - 90s - 114ms/step - accuracy: 0.4033 - loss: 2.8318 - val_accuracy: 0.5588 - val_loss: 2.0485 - learning_rate: 2.5974e-04
Epoch 96/300
785/785 - 90s - 115ms/step - accuracy: 0.4097 - loss: 2.8015 - val_accuracy: 0.5697 - val_loss: 1.9723 - learning_rate: 1.2987e-04
Epoch 97/300
785/785 - 90s - 114ms/step - accuracy: 0.4182 - loss: 2.7543 - val_accuracy: 0.5780 - val_loss: 1.9472 - learning_rate: 1.2987e-04
Epoch 98/300
785/785 - 87s - 111ms/step - accuracy: 0.4154 - loss: 2.7747 - val_accuracy: 0.5760 - val_loss: 1.9849 - learning_rate: 1.2987e-04
Epoch 99/300
785/785 - 90s - 115ms/step - accuracy: 0.4174 - loss: 2.7613 - val_accuracy: 0.5767 - val_loss: 1.9699 - learning_rate: 1.2987e-04
Epoch 100/300
785/785 - 89s - 113ms/step - accuracy: 0.4096 - loss: 2.7747 - val_accuracy: 0.5803 - val_loss: 1.9748 - learning_rate: 1.2987e-04
Epoch 101/300
785/785 - 91s - 115ms/step - accuracy: 0.4139 - loss: 2.7251 - val_accuracy: 0.5733 - val_loss: 2.0034 - learning_rate: 1.2987e-04
Epoch 102/300
785/785 - 90s - 115ms/step - accuracy: 0.4161 - loss: 2.7313 - val_accuracy: 0.5803 - val_loss: 1.9589 - learning_rate: 1.2987e-04
Epoch 103/300
785/785 - 90s - 115ms/step - accuracy: 0.4158 - loss: 2.7583 - val_accuracy: 0.5815 - val_loss: 1.9533 - learning_rate: 1.2987e-04
Epoch 104/300
785/785 - 91s - 116ms/step - accuracy: 0.4116 - loss: 2.7455 - val_accuracy: 0.5811 - val_loss: 1.9802 - learning_rate: 1.2987e-04
Epoch 105/300

Epoch 105: ReduceLROnPlateau reducing learning rate to 6.493452383438125e-05.
785/785 - 88s - 112ms/step - accuracy: 0.4100 - loss: 2.7556 - val_accuracy: 0.5682 - val_loss: 1.9809 - learning_rate: 1.2987e-04
Epoch 106/300
785/785 - 90s - 115ms/step - accuracy: 0.4118 - loss: 2.7419 - val_accuracy: 0.5800 - val_loss: 1.9361 - learning_rate: 6.4935e-05
Epoch 107/300
785/785 - 89s - 113ms/step - accuracy: 0.4110 - loss: 2.7346 - val_accuracy: 0.5840 - val_loss: 1.9277 - learning_rate: 6.4935e-05
Epoch 108/300
785/785 - 89s - 113ms/step - accuracy: 0.4218 - loss: 2.7019 - val_accuracy: 0.5853 - val_loss: 1.9304 - learning_rate: 6.4935e-05
Epoch 109/300
785/785 - 86s - 110ms/step - accuracy: 0.4218 - loss: 2.7067 - val_accuracy: 0.5826 - val_loss: 1.9414 - learning_rate: 6.4935e-05
Epoch 110/300
785/785 - 93s - 119ms/step - accuracy: 0.4272 - loss: 2.6960 - val_accuracy: 0.5831 - val_loss: 1.9531 - learning_rate: 6.4935e-05
Epoch 111/300
785/785 - 93s - 118ms/step - accuracy: 0.4285 - loss: 2.6959 - val_accuracy: 0.5840 - val_loss: 1.9292 - learning_rate: 6.4935e-05
Epoch 112/300
785/785 - 94s - 120ms/step - accuracy: 0.4242 - loss: 2.7086 - val_accuracy: 0.5850 - val_loss: 1.9478 - learning_rate: 6.4935e-05
Epoch 113/300
785/785 - 91s - 116ms/step - accuracy: 0.4126 - loss: 2.7077 - val_accuracy: 0.5886 - val_loss: 1.9312 - learning_rate: 6.4935e-05
Epoch 114/300
785/785 - 94s - 119ms/step - accuracy: 0.4290 - loss: 2.7184 - val_accuracy: 0.5840 - val_loss: 1.9178 - learning_rate: 6.4935e-05
Epoch 115/300
785/785 - 97s - 124ms/step - accuracy: 0.4253 - loss: 2.7123 - val_accuracy: 0.5783 - val_loss: 1.9556 - learning_rate: 6.4935e-05
Epoch 116/300
785/785 - 98s - 125ms/step - accuracy: 0.4280 - loss: 2.7070 - val_accuracy: 0.5811 - val_loss: 1.9278 - learning_rate: 6.4935e-05
Epoch 117/300
785/785 - 93s - 119ms/step - accuracy: 0.4295 - loss: 2.6647 - val_accuracy: 0.5862 - val_loss: 1.9208 - learning_rate: 6.4935e-05
Epoch 118/300
785/785 - 90s - 115ms/step - accuracy: 0.4186 - loss: 2.7117 - val_accuracy: 0.5843 - val_loss: 1.9340 - learning_rate: 6.4935e-05
Epoch 119/300
785/785 - 89s - 114ms/step - accuracy: 0.4191 - loss: 2.7263 - val_accuracy: 0.5878 - val_loss: 1.9322 - learning_rate: 6.4935e-05
Epoch 120/300
785/785 - 91s - 117ms/step - accuracy: 0.4215 - loss: 2.7178 - val_accuracy: 0.5810 - val_loss: 1.9346 - learning_rate: 6.4935e-05
Epoch 121/300
785/785 - 93s - 119ms/step - accuracy: 0.4295 - loss: 2.6575 - val_accuracy: 0.5878 - val_loss: 1.9226 - learning_rate: 6.4935e-05
Epoch 122/300

Epoch 122: ReduceLROnPlateau reducing learning rate to 3.2467261917190626e-05.
785/785 - 94s - 119ms/step - accuracy: 0.4253 - loss: 2.6820 - val_accuracy: 0.5880 - val_loss: 1.9282 - learning_rate: 6.4935e-05
Epoch 123/300
785/785 - 91s - 116ms/step - accuracy: 0.4269 - loss: 2.7058 - val_accuracy: 0.5827 - val_loss: 1.9191 - learning_rate: 3.2467e-05
Epoch 124/300
785/785 - 93s - 118ms/step - accuracy: 0.4280 - loss: 2.6922 - val_accuracy: 0.5872 - val_loss: 1.9216 - learning_rate: 3.2467e-05
Epoch 125/300
785/785 - 91s - 116ms/step - accuracy: 0.4247 - loss: 2.7055 - val_accuracy: 0.5886 - val_loss: 1.9120 - learning_rate: 3.2467e-05
Epoch 126/300
785/785 - 93s - 119ms/step - accuracy: 0.4229 - loss: 2.7138 - val_accuracy: 0.5861 - val_loss: 1.8995 - learning_rate: 3.2467e-05
Epoch 127/300
785/785 - 94s - 119ms/step - accuracy: 0.4277 - loss: 2.6899 - val_accuracy: 0.5905 - val_loss: 1.9139 - learning_rate: 3.2467e-05
Epoch 128/300
785/785 - 91s - 116ms/step - accuracy: 0.4304 - loss: 2.6719 - val_accuracy: 0.5920 - val_loss: 1.9108 - learning_rate: 3.2467e-05
Epoch 129/300
785/785 - 92s - 117ms/step - accuracy: 0.4341 - loss: 2.6704 - val_accuracy: 0.5870 - val_loss: 1.9079 - learning_rate: 3.2467e-05
Epoch 130/300
785/785 - 89s - 113ms/step - accuracy: 0.4248 - loss: 2.6971 - val_accuracy: 0.5882 - val_loss: 1.9090 - learning_rate: 3.2467e-05
Epoch 131/300
785/785 - 93s - 118ms/step - accuracy: 0.4333 - loss: 2.6697 - val_accuracy: 0.5856 - val_loss: 1.9138 - learning_rate: 3.2467e-05
Epoch 132/300
785/785 - 98s - 125ms/step - accuracy: 0.4325 - loss: 2.6706 - val_accuracy: 0.5931 - val_loss: 1.9100 - learning_rate: 3.2467e-05
Epoch 133/300
785/785 - 93s - 118ms/step - accuracy: 0.4169 - loss: 2.6942 - val_accuracy: 0.5834 - val_loss: 1.9129 - learning_rate: 3.2467e-05
Epoch 134/300

Epoch 134: ReduceLROnPlateau reducing learning rate to 1.6233630958595313e-05.
785/785 - 94s - 120ms/step - accuracy: 0.4299 - loss: 2.6716 - val_accuracy: 0.5848 - val_loss: 1.9053 - learning_rate: 3.2467e-05
Epoch 135/300
785/785 - 92s - 117ms/step - accuracy: 0.4234 - loss: 2.6730 - val_accuracy: 0.5891 - val_loss: 1.9060 - learning_rate: 1.6234e-05
Epoch 136/300
785/785 - 94s - 120ms/step - accuracy: 0.4218 - loss: 2.6952 - val_accuracy: 0.5870 - val_loss: 1.9053 - learning_rate: 1.6234e-05
Epoch 137/300
785/785 - 94s - 120ms/step - accuracy: 0.4416 - loss: 2.6407 - val_accuracy: 0.5854 - val_loss: 1.9041 - learning_rate: 1.6234e-05
Epoch 138/300
785/785 - 92s - 118ms/step - accuracy: 0.4285 - loss: 2.6790 - val_accuracy: 0.5893 - val_loss: 1.9084 - learning_rate: 1.6234e-05
Epoch 139/300
785/785 - 90s - 115ms/step - accuracy: 0.4357 - loss: 2.6809 - val_accuracy: 0.5877 - val_loss: 1.9072 - learning_rate: 1.6234e-05
Epoch 140/300
785/785 - 92s - 117ms/step - accuracy: 0.4377 - loss: 2.6358 - val_accuracy: 0.5882 - val_loss: 1.8944 - learning_rate: 1.6234e-05
Epoch 141/300
785/785 - 93s - 118ms/step - accuracy: 0.4250 - loss: 2.6507 - val_accuracy: 0.5886 - val_loss: 1.8985 - learning_rate: 1.6234e-05
Epoch 142/300
785/785 - 98s - 124ms/step - accuracy: 0.4201 - loss: 2.6861 - val_accuracy: 0.5901 - val_loss: 1.9006 - learning_rate: 1.6234e-05
Epoch 143/300
785/785 - 92s - 117ms/step - accuracy: 0.4336 - loss: 2.6490 - val_accuracy: 0.5886 - val_loss: 1.9047 - learning_rate: 1.6234e-05
Epoch 144/300
785/785 - 93s - 119ms/step - accuracy: 0.4338 - loss: 2.6758 - val_accuracy: 0.5899 - val_loss: 1.9031 - learning_rate: 1.6234e-05
Epoch 145/300
785/785 - 91s - 116ms/step - accuracy: 0.4334 - loss: 2.6580 - val_accuracy: 0.5907 - val_loss: 1.8974 - learning_rate: 1.6234e-05
Epoch 146/300
785/785 - 98s - 125ms/step - accuracy: 0.4387 - loss: 2.6561 - val_accuracy: 0.5867 - val_loss: 1.9072 - learning_rate: 1.6234e-05
Epoch 147/300
785/785 - 94s - 119ms/step - accuracy: 0.4293 - loss: 2.6697 - val_accuracy: 0.5891 - val_loss: 1.9017 - learning_rate: 1.6234e-05
Epoch 148/300

Epoch 148: ReduceLROnPlateau reducing learning rate to 8.116815479297657e-06.
785/785 - 92s - 117ms/step - accuracy: 0.4322 - loss: 2.6782 - val_accuracy: 0.5867 - val_loss: 1.9042 - learning_rate: 1.6234e-05
Epoch 149/300
785/785 - 89s - 114ms/step - accuracy: 0.4334 - loss: 2.6606 - val_accuracy: 0.5893 - val_loss: 1.8990 - learning_rate: 8.1168e-06
Epoch 150/300
785/785 - 91s - 116ms/step - accuracy: 0.4342 - loss: 2.6630 - val_accuracy: 0.5864 - val_loss: 1.8990 - learning_rate: 8.1168e-06
Epoch 151/300
785/785 - 94s - 119ms/step - accuracy: 0.4237 - loss: 2.6761 - val_accuracy: 0.5885 - val_loss: 1.8996 - learning_rate: 8.1168e-06
Epoch 152/300
785/785 - 93s - 119ms/step - accuracy: 0.4322 - loss: 2.6740 - val_accuracy: 0.5872 - val_loss: 1.9061 - learning_rate: 8.1168e-06
Epoch 153/300
785/785 - 93s - 118ms/step - accuracy: 0.4245 - loss: 2.6844 - val_accuracy: 0.5896 - val_loss: 1.8980 - learning_rate: 8.1168e-06
Epoch 154/300
785/785 - 93s - 118ms/step - accuracy: 0.4256 - loss: 2.6858 - val_accuracy: 0.5920 - val_loss: 1.8988 - learning_rate: 8.1168e-06
Epoch 155/300
785/785 - 91s - 116ms/step - accuracy: 0.4390 - loss: 2.6558 - val_accuracy: 0.5885 - val_loss: 1.9028 - learning_rate: 8.1168e-06
Epoch 156/300

Epoch 156: ReduceLROnPlateau reducing learning rate to 4.058407739648828e-06.
785/785 - 94s - 120ms/step - accuracy: 0.4387 - loss: 2.6490 - val_accuracy: 0.5880 - val_loss: 1.8959 - learning_rate: 8.1168e-06
Epoch 156: early stopping
Restoring model weights from the end of the best epoch: 140.
Fold 2_2 Evaluation results: [1.89609956741333, 0.5881509780883789]
              precision    recall  f1-score   support

        1820       0.74      0.74      0.74       326
        1821       0.89      0.83      0.85       263
        1822       0.00      0.00      0.00        10
        1823       0.00      0.00      0.00         6
        1824       0.00      0.00      0.00         4
        1825       0.08      0.12      0.10         8
        1826       0.00      0.00      0.00        10
        1827       0.67      0.79      0.72       127
        1828       0.40      0.33      0.36         6
        1829       0.56      0.31      0.40        16
        1830       0.56      0.60      0.58       291
        1831       0.74      0.92      0.82       682
        1832       0.82      0.67      0.74       339
        1833       0.88      0.89      0.89        93
        1834       0.32      0.81      0.46       123
        1835       0.00      0.00      0.00        11
        1836       0.00      0.00      0.00        18
        1837       0.33      0.12      0.18        33
        1838       0.00      0.00      0.00        23
        1839       0.00      0.00      0.00         3
        1840       0.45      0.65      0.53       204
        1841       0.68      0.53      0.59       497
        1842       0.80      0.36      0.50        33
        1843       1.00      0.03      0.06        32
        1844       0.00      0.00      0.00         2
        1845       0.00      0.00      0.00         4
        1846       0.11      0.05      0.06        22
        1847       0.00      0.00      0.00        10
        1848       0.31      0.13      0.18        31
        1849       0.60      0.12      0.19        26
        1850       0.36      0.61      0.46       233
        1851       0.79      0.65      0.72       405
        1852       0.00      0.00      0.00        35
        1853       0.00      0.00      0.00        31
        1854       0.00      0.00      0.00        17
        1855       0.75      0.03      0.05       116
        1856       0.56      0.70      0.62        54
        1857       0.33      0.71      0.45       156
        1858       0.00      0.00      0.00         9
        1859       0.00      0.00      0.00        13
        1860       0.34      0.33      0.33       347
        1861       0.75      0.82      0.78       432
        1862       0.38      0.09      0.15        96
        1863       0.27      0.38      0.32        91
        1864       0.24      0.15      0.19        78
        1865       0.40      0.07      0.11        30
        1866       0.00      0.00      0.00        32
        1867       0.30      0.06      0.10        51
        1868       0.00      0.00      0.00        36
        1869       0.00      0.00      0.00        27
        1870       0.37      0.63      0.47       160
        1871       0.75      0.78      0.76       251
        1872       0.19      0.13      0.15        31
        1873       0.50      0.02      0.04        49
        1874       0.00      0.00      0.00        35
        1875       0.31      0.56      0.40        68
        1876       0.84      0.83      0.83        58
        1877       0.31      0.37      0.34        27
        1878       0.50      0.18      0.26        51
        1879       0.00      0.00      0.00         7

    accuracy                           0.59      6279
   macro avg       0.34      0.29      0.28      6279
weighted avg       0.58      0.59      0.56      6279

Matthews Correlation Coefficient: 0.568
Macro avg F1: 0.275
Weighted avg F1: 0.561
Micro avg F1: 0.588
Top-3 Accuracy: 0.837
Top-5 Accuracy: 0.897
Micro ROC AUC  = 0.98
Macro ROC AUC (present classes) = 0.97
Classification MAE (in years): 3.29

Fold 2_2 Misclassification Analysis:
Near misses (within 2 years): 566 out of 2586 misclassifications (21.89%)
Big misses (greater than 10 years): 1048
MAE with outliers: 3.29
MAE without outliers: 2.36 (improvement: 0.93)

10 Worst misclassifications:
Image: data/datasets/public/1870/1877_035met.jpg, True: 1877, Predicted: 1820, Error: 57
Image: data/datasets/public/1870/1876_70washington.jpg, True: 1876, Predicted: 1820, Error: 56
Image: data/datasets/public/1820/1820_044met.jpg, True: 1820, Predicted: 1872, Error: 52
Image: data/datasets/private/1820/1821_580etsy.jpg, True: 1821, Predicted: 1871, Error: 50
Image: data/datasets/public/1870/1870_75wikimedia2.jpg, True: 1870, Predicted: 1820, Error: 50
Image: data/datasets/private/1820/1821_486etsy.jpg, True: 1821, Predicted: 1871, Error: 50
Image: data/datasets/private/1870/1871_358etsy.jpg, True: 1871, Predicted: 1821, Error: 50
Image: data/datasets/public/1860/1869_015met.jpg, True: 1869, Predicted: 1820, Error: 49
Image: data/datasets/public/1870/1879_39wikimedia2.jpg, True: 1879, Predicted: 1831, Error: 48
Image: data/datasets/public/1870/1879_26wikimedia2.jpg, True: 1879, Predicted: 1831, Error: 48
=== Training Alternative Model ===

===== Fine Tuning 9 layers! =====
Epoch 1/300
785/785 - 115s - 146ms/step - accuracy: 0.1118 - loss: 4.5835 - val_accuracy: 0.1629 - val_loss: 4.0350 - learning_rate: 2.5974e-04
Epoch 2/300
785/785 - 94s - 120ms/step - accuracy: 0.1516 - loss: 4.2716 - val_accuracy: 0.2492 - val_loss: 4.2231 - learning_rate: 2.5974e-04
Epoch 3/300
785/785 - 92s - 117ms/step - accuracy: 0.1839 - loss: 4.0563 - val_accuracy: 0.2546 - val_loss: 3.8099 - learning_rate: 2.5974e-04
Epoch 4/300
785/785 - 94s - 119ms/step - accuracy: 0.2206 - loss: 3.8893 - val_accuracy: 0.3024 - val_loss: 3.3662 - learning_rate: 2.5974e-04
Epoch 5/300
785/785 - 93s - 118ms/step - accuracy: 0.2383 - loss: 3.7659 - val_accuracy: 0.3516 - val_loss: 3.1970 - learning_rate: 2.5974e-04
Epoch 6/300
785/785 - 93s - 118ms/step - accuracy: 0.2527 - loss: 3.6592 - val_accuracy: 0.3540 - val_loss: 3.0541 - learning_rate: 2.5974e-04
Epoch 7/300
785/785 - 93s - 119ms/step - accuracy: 0.2578 - loss: 3.5898 - val_accuracy: 0.3769 - val_loss: 3.0263 - learning_rate: 2.5974e-04
Epoch 8/300
785/785 - 93s - 118ms/step - accuracy: 0.2690 - loss: 3.5433 - val_accuracy: 0.3869 - val_loss: 3.0126 - learning_rate: 2.5974e-04
Epoch 9/300
785/785 - 93s - 119ms/step - accuracy: 0.2825 - loss: 3.4902 - val_accuracy: 0.3911 - val_loss: 2.8356 - learning_rate: 2.5974e-04
Epoch 10/300
785/785 - 92s - 118ms/step - accuracy: 0.2878 - loss: 3.4317 - val_accuracy: 0.4301 - val_loss: 2.8137 - learning_rate: 2.5974e-04
Epoch 11/300
785/785 - 90s - 115ms/step - accuracy: 0.3043 - loss: 3.4200 - val_accuracy: 0.4242 - val_loss: 2.6978 - learning_rate: 2.5974e-04
Epoch 12/300
785/785 - 93s - 118ms/step - accuracy: 0.3045 - loss: 3.3595 - val_accuracy: 0.4215 - val_loss: 2.6750 - learning_rate: 2.5974e-04
Epoch 13/300
785/785 - 91s - 116ms/step - accuracy: 0.3071 - loss: 3.3234 - val_accuracy: 0.4505 - val_loss: 2.6115 - learning_rate: 2.5974e-04
Epoch 14/300
785/785 - 94s - 119ms/step - accuracy: 0.3101 - loss: 3.3148 - val_accuracy: 0.4604 - val_loss: 2.5635 - learning_rate: 2.5974e-04
Epoch 15/300
785/785 - 93s - 119ms/step - accuracy: 0.3120 - loss: 3.2995 - val_accuracy: 0.4436 - val_loss: 2.5787 - learning_rate: 2.5974e-04
Epoch 16/300
785/785 - 94s - 119ms/step - accuracy: 0.3238 - loss: 3.2717 - val_accuracy: 0.4416 - val_loss: 2.5015 - learning_rate: 2.5974e-04
Epoch 17/300
785/785 - 93s - 119ms/step - accuracy: 0.3241 - loss: 3.2467 - val_accuracy: 0.4787 - val_loss: 2.5604 - learning_rate: 2.5974e-04
Epoch 18/300
785/785 - 92s - 117ms/step - accuracy: 0.3282 - loss: 3.2297 - val_accuracy: 0.4750 - val_loss: 2.4879 - learning_rate: 2.5974e-04
Epoch 19/300
785/785 - 94s - 120ms/step - accuracy: 0.3295 - loss: 3.2326 - val_accuracy: 0.4809 - val_loss: 2.5033 - learning_rate: 2.5974e-04
Epoch 20/300
785/785 - 94s - 119ms/step - accuracy: 0.3376 - loss: 3.2153 - val_accuracy: 0.4965 - val_loss: 2.5530 - learning_rate: 2.5974e-04
Epoch 21/300
785/785 - 90s - 114ms/step - accuracy: 0.3521 - loss: 3.1349 - val_accuracy: 0.4954 - val_loss: 2.4136 - learning_rate: 2.5974e-04
Epoch 22/300
785/785 - 99s - 126ms/step - accuracy: 0.3470 - loss: 3.1794 - val_accuracy: 0.4879 - val_loss: 2.3907 - learning_rate: 2.5974e-04
Epoch 23/300
785/785 - 92s - 117ms/step - accuracy: 0.3502 - loss: 3.1316 - val_accuracy: 0.4901 - val_loss: 2.4153 - learning_rate: 2.5974e-04
Epoch 24/300
785/785 - 93s - 119ms/step - accuracy: 0.3475 - loss: 3.1341 - val_accuracy: 0.4995 - val_loss: 2.4000 - learning_rate: 2.5974e-04
Epoch 25/300
785/785 - 93s - 119ms/step - accuracy: 0.3526 - loss: 3.1253 - val_accuracy: 0.5048 - val_loss: 2.3199 - learning_rate: 2.5974e-04
Epoch 26/300
785/785 - 93s - 119ms/step - accuracy: 0.3469 - loss: 3.1333 - val_accuracy: 0.5068 - val_loss: 2.3681 - learning_rate: 2.5974e-04
Epoch 27/300
785/785 - 93s - 119ms/step - accuracy: 0.3564 - loss: 3.1077 - val_accuracy: 0.4935 - val_loss: 2.3554 - learning_rate: 2.5974e-04
Epoch 28/300
785/785 - 92s - 117ms/step - accuracy: 0.3528 - loss: 3.0844 - val_accuracy: 0.5194 - val_loss: 2.2989 - learning_rate: 2.5974e-04
Epoch 29/300
785/785 - 93s - 119ms/step - accuracy: 0.3623 - loss: 3.0377 - val_accuracy: 0.5067 - val_loss: 2.3483 - learning_rate: 2.5974e-04
Epoch 30/300
785/785 - 93s - 118ms/step - accuracy: 0.3550 - loss: 3.0960 - val_accuracy: 0.5204 - val_loss: 2.2881 - learning_rate: 2.5974e-04
Epoch 31/300
785/785 - 90s - 114ms/step - accuracy: 0.3599 - loss: 3.0745 - val_accuracy: 0.5146 - val_loss: 2.2995 - learning_rate: 2.5974e-04
Epoch 32/300
785/785 - 92s - 117ms/step - accuracy: 0.3561 - loss: 3.0766 - val_accuracy: 0.5229 - val_loss: 2.3207 - learning_rate: 2.5974e-04
Epoch 33/300
785/785 - 92s - 117ms/step - accuracy: 0.3609 - loss: 3.0587 - val_accuracy: 0.5268 - val_loss: 2.3177 - learning_rate: 2.5974e-04
Epoch 34/300
785/785 - 94s - 120ms/step - accuracy: 0.3695 - loss: 2.9928 - val_accuracy: 0.5135 - val_loss: 2.2691 - learning_rate: 2.5974e-04
Epoch 35/300
785/785 - 96s - 122ms/step - accuracy: 0.3540 - loss: 3.0528 - val_accuracy: 0.5094 - val_loss: 2.3098 - learning_rate: 2.5974e-04
Epoch 36/300
785/785 - 95s - 121ms/step - accuracy: 0.3712 - loss: 2.9876 - val_accuracy: 0.5156 - val_loss: 2.2776 - learning_rate: 2.5974e-04
Epoch 37/300
785/785 - 95s - 121ms/step - accuracy: 0.3741 - loss: 3.0127 - val_accuracy: 0.5049 - val_loss: 2.3230 - learning_rate: 2.5974e-04
Epoch 38/300
785/785 - 96s - 122ms/step - accuracy: 0.3727 - loss: 3.0187 - val_accuracy: 0.5150 - val_loss: 2.2585 - learning_rate: 2.5974e-04
Epoch 39/300
785/785 - 95s - 121ms/step - accuracy: 0.3724 - loss: 3.0142 - val_accuracy: 0.5089 - val_loss: 2.2114 - learning_rate: 2.5974e-04
Epoch 40/300
785/785 - 96s - 123ms/step - accuracy: 0.3720 - loss: 2.9759 - val_accuracy: 0.5392 - val_loss: 2.2085 - learning_rate: 2.5974e-04
Epoch 41/300
785/785 - 95s - 121ms/step - accuracy: 0.3652 - loss: 3.0011 - val_accuracy: 0.5301 - val_loss: 2.1853 - learning_rate: 2.5974e-04
Epoch 42/300
785/785 - 96s - 123ms/step - accuracy: 0.3790 - loss: 2.9959 - val_accuracy: 0.5338 - val_loss: 2.1632 - learning_rate: 2.5974e-04
Epoch 43/300
785/785 - 96s - 122ms/step - accuracy: 0.3795 - loss: 2.9871 - val_accuracy: 0.5322 - val_loss: 2.2000 - learning_rate: 2.5974e-04
Epoch 44/300
785/785 - 95s - 122ms/step - accuracy: 0.3717 - loss: 2.9856 - val_accuracy: 0.5404 - val_loss: 2.1780 - learning_rate: 2.5974e-04
Epoch 45/300
785/785 - 94s - 120ms/step - accuracy: 0.3741 - loss: 2.9831 - val_accuracy: 0.5384 - val_loss: 2.1442 - learning_rate: 2.5974e-04
Epoch 46/300
785/785 - 93s - 119ms/step - accuracy: 0.3773 - loss: 2.9784 - val_accuracy: 0.5425 - val_loss: 2.1455 - learning_rate: 2.5974e-04
Epoch 47/300
785/785 - 93s - 119ms/step - accuracy: 0.3755 - loss: 2.9890 - val_accuracy: 0.5311 - val_loss: 2.2159 - learning_rate: 2.5974e-04
Epoch 48/300
785/785 - 94s - 120ms/step - accuracy: 0.3805 - loss: 2.9535 - val_accuracy: 0.5435 - val_loss: 2.1683 - learning_rate: 2.5974e-04
Epoch 49/300
785/785 - 93s - 118ms/step - accuracy: 0.3743 - loss: 2.9582 - val_accuracy: 0.5293 - val_loss: 2.1591 - learning_rate: 2.5974e-04
Epoch 50/300
785/785 - 94s - 120ms/step - accuracy: 0.3822 - loss: 2.9525 - val_accuracy: 0.5419 - val_loss: 2.1446 - learning_rate: 2.5974e-04
Epoch 51/300
785/785 - 92s - 117ms/step - accuracy: 0.3813 - loss: 2.9234 - val_accuracy: 0.5299 - val_loss: 2.1644 - learning_rate: 2.5974e-04
Epoch 52/300
785/785 - 97s - 124ms/step - accuracy: 0.3811 - loss: 2.9335 - val_accuracy: 0.5314 - val_loss: 2.1380 - learning_rate: 2.5974e-04
Epoch 53/300
785/785 - 93s - 118ms/step - accuracy: 0.3810 - loss: 2.9510 - val_accuracy: 0.5490 - val_loss: 2.1648 - learning_rate: 2.5974e-04
Epoch 54/300
785/785 - 91s - 116ms/step - accuracy: 0.3805 - loss: 2.9214 - val_accuracy: 0.5420 - val_loss: 2.1602 - learning_rate: 2.5974e-04
Epoch 55/300
785/785 - 93s - 119ms/step - accuracy: 0.3913 - loss: 2.9130 - val_accuracy: 0.5298 - val_loss: 2.2145 - learning_rate: 2.5974e-04
Epoch 56/300
785/785 - 93s - 118ms/step - accuracy: 0.3817 - loss: 2.9331 - val_accuracy: 0.5447 - val_loss: 2.1619 - learning_rate: 2.5974e-04
Epoch 57/300
785/785 - 97s - 124ms/step - accuracy: 0.3916 - loss: 2.9090 - val_accuracy: 0.5424 - val_loss: 2.1347 - learning_rate: 2.5974e-04
Epoch 58/300
785/785 - 94s - 119ms/step - accuracy: 0.3857 - loss: 2.9118 - val_accuracy: 0.5470 - val_loss: 2.1416 - learning_rate: 2.5974e-04
Epoch 59/300
785/785 - 92s - 118ms/step - accuracy: 0.3870 - loss: 2.9123 - val_accuracy: 0.5475 - val_loss: 2.0756 - learning_rate: 2.5974e-04
Epoch 60/300
785/785 - 94s - 120ms/step - accuracy: 0.3837 - loss: 2.9033 - val_accuracy: 0.5395 - val_loss: 2.1491 - learning_rate: 2.5974e-04
Epoch 61/300
785/785 - 92s - 118ms/step - accuracy: 0.3872 - loss: 2.9040 - val_accuracy: 0.5457 - val_loss: 2.0733 - learning_rate: 2.5974e-04
Epoch 62/300
785/785 - 92s - 118ms/step - accuracy: 0.3915 - loss: 2.8812 - val_accuracy: 0.5537 - val_loss: 2.1260 - learning_rate: 2.5974e-04
Epoch 63/300
785/785 - 92s - 118ms/step - accuracy: 0.3954 - loss: 2.8811 - val_accuracy: 0.5326 - val_loss: 2.0793 - learning_rate: 2.5974e-04
Epoch 64/300
785/785 - 91s - 116ms/step - accuracy: 0.3868 - loss: 2.9034 - val_accuracy: 0.5398 - val_loss: 2.1684 - learning_rate: 2.5974e-04
Epoch 65/300
785/785 - 92s - 117ms/step - accuracy: 0.3919 - loss: 2.8932 - val_accuracy: 0.5482 - val_loss: 2.1302 - learning_rate: 2.5974e-04
Epoch 66/300
785/785 - 93s - 119ms/step - accuracy: 0.3919 - loss: 2.8903 - val_accuracy: 0.5304 - val_loss: 2.0852 - learning_rate: 2.5974e-04
Epoch 67/300
785/785 - 92s - 118ms/step - accuracy: 0.3932 - loss: 2.8877 - val_accuracy: 0.5470 - val_loss: 2.0819 - learning_rate: 2.5974e-04
Epoch 68/300
785/785 - 95s - 120ms/step - accuracy: 0.3991 - loss: 2.8710 - val_accuracy: 0.5382 - val_loss: 2.1166 - learning_rate: 2.5974e-04
Epoch 69/300

Epoch 69: ReduceLROnPlateau reducing learning rate to 0.0001298690476687625.
785/785 - 93s - 118ms/step - accuracy: 0.3982 - loss: 2.8675 - val_accuracy: 0.5492 - val_loss: 2.0854 - learning_rate: 2.5974e-04
Epoch 70/300
785/785 - 94s - 120ms/step - accuracy: 0.4040 - loss: 2.8011 - val_accuracy: 0.5561 - val_loss: 2.0671 - learning_rate: 1.2987e-04
Epoch 71/300
785/785 - 98s - 125ms/step - accuracy: 0.4117 - loss: 2.7958 - val_accuracy: 0.5604 - val_loss: 2.0409 - learning_rate: 1.2987e-04
Epoch 72/300
785/785 - 94s - 120ms/step - accuracy: 0.3991 - loss: 2.8271 - val_accuracy: 0.5575 - val_loss: 2.0461 - learning_rate: 1.2987e-04
Epoch 73/300
785/785 - 93s - 119ms/step - accuracy: 0.4117 - loss: 2.7944 - val_accuracy: 0.5592 - val_loss: 2.0429 - learning_rate: 1.2987e-04
Epoch 74/300
785/785 - 92s - 118ms/step - accuracy: 0.4053 - loss: 2.7748 - val_accuracy: 0.5559 - val_loss: 2.0121 - learning_rate: 1.2987e-04
Epoch 75/300
785/785 - 92s - 117ms/step - accuracy: 0.3993 - loss: 2.8193 - val_accuracy: 0.5615 - val_loss: 2.0520 - learning_rate: 1.2987e-04
Epoch 76/300
785/785 - 91s - 116ms/step - accuracy: 0.4061 - loss: 2.7972 - val_accuracy: 0.5626 - val_loss: 2.0605 - learning_rate: 1.2987e-04
Epoch 77/300
785/785 - 93s - 119ms/step - accuracy: 0.4155 - loss: 2.7588 - val_accuracy: 0.5632 - val_loss: 2.0140 - learning_rate: 1.2987e-04
Epoch 78/300
785/785 - 93s - 119ms/step - accuracy: 0.4090 - loss: 2.7908 - val_accuracy: 0.5538 - val_loss: 2.0189 - learning_rate: 1.2987e-04
Epoch 79/300
785/785 - 93s - 118ms/step - accuracy: 0.4174 - loss: 2.7865 - val_accuracy: 0.5748 - val_loss: 2.0371 - learning_rate: 1.2987e-04
Epoch 80/300
785/785 - 92s - 118ms/step - accuracy: 0.4111 - loss: 2.7874 - val_accuracy: 0.5653 - val_loss: 2.0329 - learning_rate: 1.2987e-04
Epoch 81/300
785/785 - 94s - 119ms/step - accuracy: 0.4085 - loss: 2.7775 - val_accuracy: 0.5694 - val_loss: 2.0082 - learning_rate: 1.2987e-04
Epoch 82/300
785/785 - 93s - 119ms/step - accuracy: 0.4155 - loss: 2.7984 - val_accuracy: 0.5654 - val_loss: 2.0468 - learning_rate: 1.2987e-04
Epoch 83/300
785/785 - 94s - 119ms/step - accuracy: 0.4206 - loss: 2.7599 - val_accuracy: 0.5658 - val_loss: 1.9972 - learning_rate: 1.2987e-04
Epoch 84/300
785/785 - 142s - 181ms/step - accuracy: 0.4118 - loss: 2.7517 - val_accuracy: 0.5565 - val_loss: 2.0067 - learning_rate: 1.2987e-04
Epoch 85/300
785/785 - 92s - 117ms/step - accuracy: 0.4185 - loss: 2.7586 - val_accuracy: 0.5599 - val_loss: 2.0325 - learning_rate: 1.2987e-04
Epoch 86/300
785/785 - 92s - 117ms/step - accuracy: 0.4077 - loss: 2.7746 - val_accuracy: 0.5725 - val_loss: 1.9863 - learning_rate: 1.2987e-04
Epoch 87/300
785/785 - 93s - 119ms/step - accuracy: 0.4095 - loss: 2.7655 - val_accuracy: 0.5662 - val_loss: 1.9840 - learning_rate: 1.2987e-04
Epoch 88/300
785/785 - 93s - 119ms/step - accuracy: 0.4101 - loss: 2.7650 - val_accuracy: 0.5578 - val_loss: 2.0175 - learning_rate: 1.2987e-04
Epoch 89/300
785/785 - 92s - 117ms/step - accuracy: 0.4198 - loss: 2.7332 - val_accuracy: 0.5624 - val_loss: 2.0082 - learning_rate: 1.2987e-04
Epoch 90/300
785/785 - 94s - 120ms/step - accuracy: 0.4109 - loss: 2.7659 - val_accuracy: 0.5629 - val_loss: 1.9835 - learning_rate: 1.2987e-04
Epoch 91/300
785/785 - 141s - 179ms/step - accuracy: 0.4120 - loss: 2.7528 - val_accuracy: 0.5715 - val_loss: 2.0003 - learning_rate: 1.2987e-04
Epoch 92/300
785/785 - 93s - 119ms/step - accuracy: 0.4112 - loss: 2.7705 - val_accuracy: 0.5672 - val_loss: 2.0261 - learning_rate: 1.2987e-04
Epoch 93/300
785/785 - 92s - 118ms/step - accuracy: 0.4123 - loss: 2.7763 - val_accuracy: 0.5712 - val_loss: 2.0011 - learning_rate: 1.2987e-04
Epoch 94/300
785/785 - 97s - 124ms/step - accuracy: 0.4157 - loss: 2.7422 - val_accuracy: 0.5678 - val_loss: 1.9714 - learning_rate: 1.2987e-04
Epoch 95/300
785/785 - 93s - 118ms/step - accuracy: 0.4209 - loss: 2.7651 - val_accuracy: 0.5667 - val_loss: 2.0202 - learning_rate: 1.2987e-04
Epoch 96/300
785/785 - 91s - 116ms/step - accuracy: 0.4157 - loss: 2.7763 - val_accuracy: 0.5748 - val_loss: 1.9828 - learning_rate: 1.2987e-04
Epoch 97/300
785/785 - 93s - 119ms/step - accuracy: 0.4206 - loss: 2.7361 - val_accuracy: 0.5782 - val_loss: 2.0044 - learning_rate: 1.2987e-04
Epoch 98/300
785/785 - 93s - 118ms/step - accuracy: 0.4243 - loss: 2.7371 - val_accuracy: 0.5721 - val_loss: 1.9527 - learning_rate: 1.2987e-04
Epoch 99/300
785/785 - 92s - 118ms/step - accuracy: 0.4193 - loss: 2.7468 - val_accuracy: 0.5688 - val_loss: 2.0138 - learning_rate: 1.2987e-04
Epoch 100/300
785/785 - 93s - 119ms/step - accuracy: 0.4126 - loss: 2.7570 - val_accuracy: 0.5783 - val_loss: 1.9705 - learning_rate: 1.2987e-04
Epoch 101/300
785/785 - 142s - 180ms/step - accuracy: 0.4131 - loss: 2.7561 - val_accuracy: 0.5635 - val_loss: 1.9891 - learning_rate: 1.2987e-04
Epoch 102/300
785/785 - 141s - 180ms/step - accuracy: 0.4133 - loss: 2.7796 - val_accuracy: 0.5750 - val_loss: 2.0150 - learning_rate: 1.2987e-04
Epoch 103/300
785/785 - 93s - 118ms/step - accuracy: 0.4034 - loss: 2.8171 - val_accuracy: 0.5783 - val_loss: 1.9868 - learning_rate: 1.2987e-04
Epoch 104/300
785/785 - 93s - 118ms/step - accuracy: 0.4091 - loss: 2.7337 - val_accuracy: 0.5734 - val_loss: 1.9903 - learning_rate: 1.2987e-04
Epoch 105/300
785/785 - 91s - 116ms/step - accuracy: 0.4211 - loss: 2.7342 - val_accuracy: 0.5626 - val_loss: 1.9935 - learning_rate: 1.2987e-04
Epoch 106/300

Epoch 106: ReduceLROnPlateau reducing learning rate to 6.493452383438125e-05.
785/785 - 91s - 116ms/step - accuracy: 0.4123 - loss: 2.7350 - val_accuracy: 0.5798 - val_loss: 1.9756 - learning_rate: 1.2987e-04
Epoch 107/300
785/785 - 92s - 117ms/step - accuracy: 0.4276 - loss: 2.6784 - val_accuracy: 0.5740 - val_loss: 1.9492 - learning_rate: 6.4935e-05
Epoch 108/300
785/785 - 92s - 118ms/step - accuracy: 0.4128 - loss: 2.7436 - val_accuracy: 0.5771 - val_loss: 1.9806 - learning_rate: 6.4935e-05
Epoch 109/300
785/785 - 94s - 119ms/step - accuracy: 0.4192 - loss: 2.7199 - val_accuracy: 0.5782 - val_loss: 1.9623 - learning_rate: 6.4935e-05
Epoch 110/300
785/785 - 93s - 118ms/step - accuracy: 0.4271 - loss: 2.7007 - val_accuracy: 0.5758 - val_loss: 1.9450 - learning_rate: 6.4935e-05
Epoch 111/300
785/785 - 94s - 120ms/step - accuracy: 0.4230 - loss: 2.7033 - val_accuracy: 0.5718 - val_loss: 1.9616 - learning_rate: 6.4935e-05
Epoch 112/300
785/785 - 92s - 118ms/step - accuracy: 0.4298 - loss: 2.6717 - val_accuracy: 0.5811 - val_loss: 1.9406 - learning_rate: 6.4935e-05
Epoch 113/300
785/785 - 92s - 117ms/step - accuracy: 0.4220 - loss: 2.7165 - val_accuracy: 0.5783 - val_loss: 1.9593 - learning_rate: 6.4935e-05
Epoch 114/300
785/785 - 93s - 119ms/step - accuracy: 0.4247 - loss: 2.7023 - val_accuracy: 0.5818 - val_loss: 1.9203 - learning_rate: 6.4935e-05
Epoch 115/300
785/785 - 93s - 118ms/step - accuracy: 0.4303 - loss: 2.7254 - val_accuracy: 0.5823 - val_loss: 1.9458 - learning_rate: 6.4935e-05
Epoch 116/300
785/785 - 92s - 118ms/step - accuracy: 0.4354 - loss: 2.6809 - val_accuracy: 0.5803 - val_loss: 1.9489 - learning_rate: 6.4935e-05
Epoch 117/300
785/785 - 93s - 119ms/step - accuracy: 0.4300 - loss: 2.7173 - val_accuracy: 0.5737 - val_loss: 1.9418 - learning_rate: 6.4935e-05
Epoch 118/300
785/785 - 92s - 118ms/step - accuracy: 0.4278 - loss: 2.6610 - val_accuracy: 0.5782 - val_loss: 1.9543 - learning_rate: 6.4935e-05
Epoch 119/300
785/785 - 94s - 119ms/step - accuracy: 0.4214 - loss: 2.7071 - val_accuracy: 0.5798 - val_loss: 1.9361 - learning_rate: 6.4935e-05
Epoch 120/300
785/785 - 93s - 119ms/step - accuracy: 0.4246 - loss: 2.7026 - val_accuracy: 0.5761 - val_loss: 1.9562 - learning_rate: 6.4935e-05
Epoch 121/300
785/785 - 91s - 116ms/step - accuracy: 0.4421 - loss: 2.6574 - val_accuracy: 0.5785 - val_loss: 1.9262 - learning_rate: 6.4935e-05
Epoch 122/300

Epoch 122: ReduceLROnPlateau reducing learning rate to 3.2467261917190626e-05.
785/785 - 92s - 118ms/step - accuracy: 0.4300 - loss: 2.6650 - val_accuracy: 0.5817 - val_loss: 1.9302 - learning_rate: 6.4935e-05
Epoch 123/300
785/785 - 93s - 118ms/step - accuracy: 0.4227 - loss: 2.6802 - val_accuracy: 0.5729 - val_loss: 1.9265 - learning_rate: 3.2467e-05
Epoch 124/300
785/785 - 92s - 117ms/step - accuracy: 0.4276 - loss: 2.6841 - val_accuracy: 0.5818 - val_loss: 1.9277 - learning_rate: 3.2467e-05
Epoch 125/300
785/785 - 93s - 118ms/step - accuracy: 0.4378 - loss: 2.6570 - val_accuracy: 0.5814 - val_loss: 1.9253 - learning_rate: 3.2467e-05
Epoch 126/300
785/785 - 93s - 119ms/step - accuracy: 0.4330 - loss: 2.6885 - val_accuracy: 0.5865 - val_loss: 1.9260 - learning_rate: 3.2467e-05
Epoch 127/300
785/785 - 91s - 116ms/step - accuracy: 0.4321 - loss: 2.6754 - val_accuracy: 0.5834 - val_loss: 1.9257 - learning_rate: 3.2467e-05
Epoch 128/300
785/785 - 92s - 118ms/step - accuracy: 0.4270 - loss: 2.6652 - val_accuracy: 0.5826 - val_loss: 1.9448 - learning_rate: 3.2467e-05
Epoch 129/300
785/785 - 94s - 120ms/step - accuracy: 0.4316 - loss: 2.6862 - val_accuracy: 0.5858 - val_loss: 1.9269 - learning_rate: 3.2467e-05
Epoch 130/300

Epoch 130: ReduceLROnPlateau reducing learning rate to 1.6233630958595313e-05.
785/785 - 92s - 117ms/step - accuracy: 0.4349 - loss: 2.6637 - val_accuracy: 0.5811 - val_loss: 1.9220 - learning_rate: 3.2467e-05
Epoch 130: early stopping
Restoring model weights from the end of the best epoch: 114.
Fold 2_1 Evaluation results: [1.9233827590942383, 0.5818471312522888]
              precision    recall  f1-score   support

        1820       0.60      0.74      0.66       291
        1821       0.94      0.78      0.85       311
        1822       0.00      0.00      0.00         4
        1823       0.00      0.00      0.00         7
        1824       0.00      0.00      0.00         6
        1825       0.00      0.00      0.00        13
        1826       0.00      0.00      0.00        13
        1827       0.72      0.71      0.72       123
        1828       0.00      0.00      0.00        11
        1829       0.50      0.04      0.07        28
        1830       0.41      0.73      0.53       269
        1831       0.72      0.94      0.81       662
        1832       0.79      0.74      0.76       340
        1833       0.60      0.93      0.73        97
        1834       0.56      0.40      0.47       169
        1835       0.00      0.00      0.00        10
        1836       0.00      0.00      0.00        17
        1837       0.32      0.26      0.29        31
        1838       0.00      0.00      0.00        15
        1839       0.00      0.00      0.00         5
        1840       0.49      0.47      0.48       223
        1841       0.76      0.53      0.62       578
        1842       0.35      0.32      0.33        22
        1843       0.00      0.00      0.00        26
        1844       0.00      0.00      0.00         1
        1845       0.00      0.00      0.00         7
        1846       0.75      0.09      0.15        35
        1847       0.00      0.00      0.00        10
        1848       0.25      0.08      0.12        24
        1849       0.00      0.00      0.00        27
        1850       0.36      0.65      0.46       244
        1851       0.65      0.78      0.71       365
        1852       0.50      0.03      0.05        39
        1853       0.00      0.00      0.00        32
        1854       0.00      0.00      0.00         7
        1855       0.36      0.12      0.18       116
        1856       0.69      0.41      0.51        66
        1857       0.46      0.52      0.49       151
        1858       0.00      0.00      0.00        14
        1859       0.00      0.00      0.00        12
        1860       0.26      0.50      0.34       299
        1861       0.80      0.76      0.78       418
        1862       0.14      0.01      0.02        93
        1863       0.42      0.31      0.36        93
        1864       0.40      0.35      0.37        92
        1865       0.82      0.25      0.38        36
        1866       0.00      0.00      0.00        25
        1867       1.00      0.02      0.04        53
        1868       0.00      0.00      0.00        37
        1869       0.00      0.00      0.00        26
        1870       0.37      0.59      0.45       147
        1871       0.67      0.74      0.70       240
        1872       0.00      0.00      0.00        40
        1873       0.00      0.00      0.00        57
        1874       0.08      0.06      0.07        17
        1875       0.29      0.27      0.28        71
        1876       0.97      0.86      0.91        42
        1877       0.56      0.19      0.28        27
        1878       0.71      0.56      0.63        39
        1879       0.00      0.00      0.00         7

    accuracy                           0.58      6280
   macro avg       0.32      0.26      0.26      6280
weighted avg       0.57      0.58      0.55      6280

Matthews Correlation Coefficient: 0.561
Macro avg F1: 0.260
Weighted avg F1: 0.553
Micro avg F1: 0.582
Top-3 Accuracy: 0.825
Top-5 Accuracy: 0.889
Micro ROC AUC  = 0.98
Macro ROC AUC (present classes) = 0.97
Classification MAE (in years): 3.49

Fold 2_1 Misclassification Analysis:
Near misses (within 2 years): 522 out of 2626 misclassifications (19.88%)
Big misses (greater than 10 years): 1113
MAE with outliers: 3.49
MAE without outliers: 2.45 (improvement: 1.05)

10 Worst misclassifications:
Image: data/datasets/public/1870/1876_72washington.jpg, True: 1876, Predicted: 1820, Error: 56
Image: data/datasets/private/1870/1871_114etsy.jpg, True: 1871, Predicted: 1820, Error: 51
Image: data/datasets/private/1820/1820_031_Zrzut ekranu 2022-07-26 195637.png, True: 1820, Predicted: 1871, Error: 51
Image: data/datasets/public/1820/1820_12wikimedia2.jpg, True: 1820, Predicted: 1871, Error: 51
Image: data/datasets/private/1870/1871_404etsy.jpg, True: 1871, Predicted: 1821, Error: 50
Image: data/datasets/private/1820/1820_034_Zrzut ekranu 2022-07-26 203655.png, True: 1820, Predicted: 1870, Error: 50
Image: data/datasets/private/1870/1871_384etsy.jpg, True: 1871, Predicted: 1821, Error: 50
Image: data/datasets/private/1870/1871_267etsy.jpg, True: 1871, Predicted: 1821, Error: 50
Image: data/datasets/public/1870/1870_79wikimedia2.jpg, True: 1870, Predicted: 1820, Error: 50
Image: data/datasets/public/1860/1868_042met.jpg, True: 1868, Predicted: 1820, Error: 48

===== Fine Tuning 9 layers! =====
Epoch 1/300
785/785 - 116s - 147ms/step - accuracy: 0.1180 - loss: 4.4271 - val_accuracy: 0.1516 - val_loss: 3.8500 - learning_rate: 2.5974e-04
Epoch 2/300
785/785 - 93s - 118ms/step - accuracy: 0.1494 - loss: 4.1531 - val_accuracy: 0.2242 - val_loss: 3.6819 - learning_rate: 2.5974e-04
Epoch 3/300
785/785 - 94s - 119ms/step - accuracy: 0.1939 - loss: 3.9453 - val_accuracy: 0.3061 - val_loss: 3.5448 - learning_rate: 2.5974e-04
Epoch 4/300
785/785 - 91s - 116ms/step - accuracy: 0.2108 - loss: 3.8124 - val_accuracy: 0.3528 - val_loss: 3.3219 - learning_rate: 2.5974e-04
Epoch 5/300
785/785 - 93s - 118ms/step - accuracy: 0.2354 - loss: 3.7201 - val_accuracy: 0.3700 - val_loss: 3.1437 - learning_rate: 2.5974e-04
Epoch 6/300
785/785 - 93s - 118ms/step - accuracy: 0.2502 - loss: 3.6261 - val_accuracy: 0.3942 - val_loss: 3.0411 - learning_rate: 2.5974e-04
Epoch 7/300
785/785 - 92s - 118ms/step - accuracy: 0.2621 - loss: 3.5735 - val_accuracy: 0.4354 - val_loss: 2.9026 - learning_rate: 2.5974e-04
Epoch 8/300
785/785 - 94s - 120ms/step - accuracy: 0.2732 - loss: 3.5162 - val_accuracy: 0.4179 - val_loss: 2.8986 - learning_rate: 2.5974e-04
Epoch 9/300
785/785 - 92s - 117ms/step - accuracy: 0.2847 - loss: 3.4715 - val_accuracy: 0.4541 - val_loss: 2.7590 - learning_rate: 2.5974e-04
Epoch 10/300
785/785 - 94s - 119ms/step - accuracy: 0.2904 - loss: 3.4121 - val_accuracy: 0.4525 - val_loss: 2.6673 - learning_rate: 2.5974e-04
Epoch 11/300
785/785 - 92s - 118ms/step - accuracy: 0.2975 - loss: 3.3996 - val_accuracy: 0.4666 - val_loss: 2.6927 - learning_rate: 2.5974e-04
Epoch 12/300
785/785 - 91s - 116ms/step - accuracy: 0.2906 - loss: 3.3527 - val_accuracy: 0.4491 - val_loss: 2.6560 - learning_rate: 2.5974e-04
Epoch 13/300
785/785 - 98s - 125ms/step - accuracy: 0.3035 - loss: 3.3053 - val_accuracy: 0.4752 - val_loss: 2.6340 - learning_rate: 2.5974e-04
Epoch 14/300
785/785 - 92s - 117ms/step - accuracy: 0.3142 - loss: 3.2804 - val_accuracy: 0.4732 - val_loss: 2.5837 - learning_rate: 2.5974e-04
Epoch 15/300
785/785 - 91s - 116ms/step - accuracy: 0.3210 - loss: 3.2947 - val_accuracy: 0.4900 - val_loss: 2.5523 - learning_rate: 2.5974e-04
Epoch 16/300
785/785 - 93s - 118ms/step - accuracy: 0.3247 - loss: 3.2298 - val_accuracy: 0.4902 - val_loss: 2.4674 - learning_rate: 2.5974e-04
Epoch 17/300
785/785 - 92s - 118ms/step - accuracy: 0.3261 - loss: 3.2490 - val_accuracy: 0.4894 - val_loss: 2.4648 - learning_rate: 2.5974e-04
Epoch 18/300
785/785 - 93s - 118ms/step - accuracy: 0.3338 - loss: 3.2248 - val_accuracy: 0.4999 - val_loss: 2.4044 - learning_rate: 2.5974e-04
Epoch 19/300
785/785 - 93s - 118ms/step - accuracy: 0.3352 - loss: 3.1810 - val_accuracy: 0.5114 - val_loss: 2.4554 - learning_rate: 2.5974e-04
Epoch 20/300
785/785 - 92s - 118ms/step - accuracy: 0.3449 - loss: 3.1604 - val_accuracy: 0.5179 - val_loss: 2.3915 - learning_rate: 2.5974e-04
Epoch 21/300
785/785 - 98s - 125ms/step - accuracy: 0.3393 - loss: 3.1618 - val_accuracy: 0.5103 - val_loss: 2.4037 - learning_rate: 2.5974e-04
Epoch 22/300
785/785 - 92s - 118ms/step - accuracy: 0.3374 - loss: 3.1717 - val_accuracy: 0.5141 - val_loss: 2.3615 - learning_rate: 2.5974e-04
Epoch 23/300
785/785 - 92s - 117ms/step - accuracy: 0.3428 - loss: 3.1370 - val_accuracy: 0.5096 - val_loss: 2.3632 - learning_rate: 2.5974e-04
Epoch 24/300
785/785 - 95s - 121ms/step - accuracy: 0.3514 - loss: 3.1158 - val_accuracy: 0.4988 - val_loss: 2.3254 - learning_rate: 2.5974e-04
Epoch 25/300
785/785 - 93s - 119ms/step - accuracy: 0.3521 - loss: 3.1030 - val_accuracy: 0.5198 - val_loss: 2.3194 - learning_rate: 2.5974e-04
Epoch 26/300
785/785 - 92s - 117ms/step - accuracy: 0.3428 - loss: 3.1245 - val_accuracy: 0.5154 - val_loss: 2.2929 - learning_rate: 2.5974e-04
Epoch 27/300
785/785 - 88s - 112ms/step - accuracy: 0.3406 - loss: 3.0958 - val_accuracy: 0.5286 - val_loss: 2.2662 - learning_rate: 2.5974e-04
Epoch 28/300
785/785 - 93s - 118ms/step - accuracy: 0.3565 - loss: 3.0984 - val_accuracy: 0.5195 - val_loss: 2.2974 - learning_rate: 2.5974e-04
Epoch 29/300
785/785 - 92s - 117ms/step - accuracy: 0.3632 - loss: 3.0525 - val_accuracy: 0.5160 - val_loss: 2.2740 - learning_rate: 2.5974e-04
Epoch 30/300
785/785 - 93s - 119ms/step - accuracy: 0.3556 - loss: 3.0647 - val_accuracy: 0.5244 - val_loss: 2.2619 - learning_rate: 2.5974e-04
Epoch 31/300
785/785 - 97s - 124ms/step - accuracy: 0.3565 - loss: 3.0692 - val_accuracy: 0.5294 - val_loss: 2.2314 - learning_rate: 2.5974e-04
Epoch 32/300
785/785 - 138s - 176ms/step - accuracy: 0.3639 - loss: 3.0253 - val_accuracy: 0.5389 - val_loss: 2.1940 - learning_rate: 2.5974e-04
Epoch 33/300
785/785 - 93s - 118ms/step - accuracy: 0.3632 - loss: 3.0237 - val_accuracy: 0.5214 - val_loss: 2.2305 - learning_rate: 2.5974e-04
Epoch 34/300
785/785 - 91s - 116ms/step - accuracy: 0.3610 - loss: 3.0625 - val_accuracy: 0.5252 - val_loss: 2.2185 - learning_rate: 2.5974e-04
Epoch 35/300
785/785 - 90s - 115ms/step - accuracy: 0.3666 - loss: 3.0196 - val_accuracy: 0.5401 - val_loss: 2.2026 - learning_rate: 2.5974e-04
Epoch 36/300
785/785 - 91s - 116ms/step - accuracy: 0.3646 - loss: 2.9694 - val_accuracy: 0.5504 - val_loss: 2.1520 - learning_rate: 2.5974e-04
Epoch 37/300
785/785 - 96s - 123ms/step - accuracy: 0.3662 - loss: 3.0062 - val_accuracy: 0.5154 - val_loss: 2.2123 - learning_rate: 2.5974e-04
Epoch 38/300
785/785 - 92s - 117ms/step - accuracy: 0.3677 - loss: 3.0016 - val_accuracy: 0.5531 - val_loss: 2.1454 - learning_rate: 2.5974e-04
Epoch 39/300
785/785 - 93s - 118ms/step - accuracy: 0.3712 - loss: 3.0061 - val_accuracy: 0.5431 - val_loss: 2.1992 - learning_rate: 2.5974e-04
Epoch 40/300
785/785 - 93s - 118ms/step - accuracy: 0.3662 - loss: 3.0062 - val_accuracy: 0.5405 - val_loss: 2.1358 - learning_rate: 2.5974e-04
Epoch 41/300
785/785 - 92s - 117ms/step - accuracy: 0.3763 - loss: 2.9715 - val_accuracy: 0.5426 - val_loss: 2.1385 - learning_rate: 2.5974e-04
Epoch 42/300
785/785 - 92s - 117ms/step - accuracy: 0.3725 - loss: 2.9653 - val_accuracy: 0.5345 - val_loss: 2.1573 - learning_rate: 2.5974e-04
Epoch 43/300
785/785 - 92s - 118ms/step - accuracy: 0.3764 - loss: 2.9976 - val_accuracy: 0.5530 - val_loss: 2.1599 - learning_rate: 2.5974e-04
Epoch 44/300
785/785 - 92s - 117ms/step - accuracy: 0.3791 - loss: 2.9502 - val_accuracy: 0.5531 - val_loss: 2.1255 - learning_rate: 2.5974e-04
Epoch 45/300
785/785 - 91s - 116ms/step - accuracy: 0.3831 - loss: 2.9264 - val_accuracy: 0.5495 - val_loss: 2.1035 - learning_rate: 2.5974e-04
Epoch 46/300
785/785 - 91s - 116ms/step - accuracy: 0.3828 - loss: 2.9702 - val_accuracy: 0.5292 - val_loss: 2.1448 - learning_rate: 2.5974e-04
Epoch 47/300
785/785 - 93s - 119ms/step - accuracy: 0.3775 - loss: 2.9815 - val_accuracy: 0.5405 - val_loss: 2.1341 - learning_rate: 2.5974e-04
Epoch 48/300
785/785 - 92s - 117ms/step - accuracy: 0.3922 - loss: 2.9197 - val_accuracy: 0.5381 - val_loss: 2.0797 - learning_rate: 2.5974e-04
Epoch 49/300
785/785 - 93s - 118ms/step - accuracy: 0.3750 - loss: 2.9403 - val_accuracy: 0.5520 - val_loss: 2.0846 - learning_rate: 2.5974e-04
Epoch 50/300
785/785 - 92s - 118ms/step - accuracy: 0.3849 - loss: 2.9170 - val_accuracy: 0.5485 - val_loss: 2.0581 - learning_rate: 2.5974e-04
Epoch 51/300
785/785 - 92s - 118ms/step - accuracy: 0.3801 - loss: 2.9685 - val_accuracy: 0.5327 - val_loss: 2.1463 - learning_rate: 2.5974e-04
Epoch 52/300
785/785 - 92s - 118ms/step - accuracy: 0.3680 - loss: 2.9413 - val_accuracy: 0.5581 - val_loss: 2.0959 - learning_rate: 2.5974e-04
Epoch 53/300
785/785 - 92s - 117ms/step - accuracy: 0.3779 - loss: 2.9436 - val_accuracy: 0.5606 - val_loss: 2.0538 - learning_rate: 2.5974e-04
Epoch 54/300
785/785 - 92s - 117ms/step - accuracy: 0.3855 - loss: 2.9016 - val_accuracy: 0.5631 - val_loss: 2.0626 - learning_rate: 2.5974e-04
Epoch 55/300
785/785 - 92s - 117ms/step - accuracy: 0.3865 - loss: 2.9336 - val_accuracy: 0.5584 - val_loss: 2.0759 - learning_rate: 2.5974e-04
Epoch 56/300
785/785 - 93s - 118ms/step - accuracy: 0.3806 - loss: 2.9079 - val_accuracy: 0.5611 - val_loss: 2.0346 - learning_rate: 2.5974e-04
Epoch 57/300
785/785 - 92s - 117ms/step - accuracy: 0.3925 - loss: 2.9000 - val_accuracy: 0.5496 - val_loss: 2.1288 - learning_rate: 2.5974e-04
Epoch 58/300
785/785 - 91s - 116ms/step - accuracy: 0.3852 - loss: 2.9003 - val_accuracy: 0.5573 - val_loss: 2.0329 - learning_rate: 2.5974e-04
Epoch 59/300
785/785 - 93s - 118ms/step - accuracy: 0.3887 - loss: 2.8939 - val_accuracy: 0.5555 - val_loss: 2.0695 - learning_rate: 2.5974e-04
Epoch 60/300
785/785 - 93s - 118ms/step - accuracy: 0.3881 - loss: 2.9221 - val_accuracy: 0.5550 - val_loss: 2.0404 - learning_rate: 2.5974e-04
Epoch 61/300
785/785 - 92s - 117ms/step - accuracy: 0.3868 - loss: 2.9063 - val_accuracy: 0.5569 - val_loss: 2.0623 - learning_rate: 2.5974e-04
Epoch 62/300
785/785 - 93s - 118ms/step - accuracy: 0.3809 - loss: 2.8917 - val_accuracy: 0.5549 - val_loss: 2.0645 - learning_rate: 2.5974e-04
Epoch 63/300
785/785 - 92s - 117ms/step - accuracy: 0.4016 - loss: 2.8812 - val_accuracy: 0.5550 - val_loss: 2.0316 - learning_rate: 2.5974e-04
Epoch 64/300
785/785 - 92s - 117ms/step - accuracy: 0.4057 - loss: 2.8338 - val_accuracy: 0.5600 - val_loss: 2.0243 - learning_rate: 2.5974e-04
Epoch 65/300
785/785 - 92s - 118ms/step - accuracy: 0.3963 - loss: 2.8732 - val_accuracy: 0.5681 - val_loss: 1.9932 - learning_rate: 2.5974e-04
Epoch 66/300
785/785 - 91s - 116ms/step - accuracy: 0.3869 - loss: 2.8532 - val_accuracy: 0.5638 - val_loss: 2.0204 - learning_rate: 2.5974e-04
Epoch 67/300
785/785 - 93s - 119ms/step - accuracy: 0.3984 - loss: 2.8445 - val_accuracy: 0.5662 - val_loss: 2.0098 - learning_rate: 2.5974e-04
Epoch 68/300
785/785 - 92s - 118ms/step - accuracy: 0.3935 - loss: 2.8589 - val_accuracy: 0.5555 - val_loss: 2.0589 - learning_rate: 2.5974e-04
Epoch 69/300
785/785 - 91s - 117ms/step - accuracy: 0.3939 - loss: 2.8990 - val_accuracy: 0.5663 - val_loss: 2.0088 - learning_rate: 2.5974e-04
Epoch 70/300
785/785 - 93s - 118ms/step - accuracy: 0.4006 - loss: 2.8626 - val_accuracy: 0.5687 - val_loss: 2.0013 - learning_rate: 2.5974e-04
Epoch 71/300
785/785 - 92s - 117ms/step - accuracy: 0.3994 - loss: 2.8346 - val_accuracy: 0.5710 - val_loss: 2.0192 - learning_rate: 2.5974e-04
Epoch 72/300
785/785 - 93s - 118ms/step - accuracy: 0.3963 - loss: 2.8766 - val_accuracy: 0.5660 - val_loss: 2.0308 - learning_rate: 2.5974e-04
Epoch 73/300
785/785 - 92s - 117ms/step - accuracy: 0.3922 - loss: 2.8543 - val_accuracy: 0.5674 - val_loss: 1.9812 - learning_rate: 2.5974e-04
Epoch 74/300
785/785 - 91s - 116ms/step - accuracy: 0.4014 - loss: 2.8514 - val_accuracy: 0.5722 - val_loss: 1.9917 - learning_rate: 2.5974e-04
Epoch 75/300
785/785 - 91s - 116ms/step - accuracy: 0.3994 - loss: 2.8769 - val_accuracy: 0.5603 - val_loss: 2.0124 - learning_rate: 2.5974e-04
Epoch 76/300
785/785 - 93s - 118ms/step - accuracy: 0.4013 - loss: 2.8249 - val_accuracy: 0.5743 - val_loss: 2.0343 - learning_rate: 2.5974e-04
Epoch 77/300
785/785 - 92s - 117ms/step - accuracy: 0.4057 - loss: 2.8449 - val_accuracy: 0.5791 - val_loss: 1.9717 - learning_rate: 2.5974e-04
Epoch 78/300
785/785 - 91s - 116ms/step - accuracy: 0.4038 - loss: 2.8500 - val_accuracy: 0.5668 - val_loss: 2.0213 - learning_rate: 2.5974e-04
Epoch 79/300
785/785 - 93s - 119ms/step - accuracy: 0.4029 - loss: 2.7974 - val_accuracy: 0.5753 - val_loss: 1.9609 - learning_rate: 2.5974e-04
Epoch 80/300
785/785 - 92s - 117ms/step - accuracy: 0.4070 - loss: 2.8585 - val_accuracy: 0.5773 - val_loss: 1.9783 - learning_rate: 2.5974e-04
Epoch 81/300
785/785 - 92s - 118ms/step - accuracy: 0.4024 - loss: 2.8413 - val_accuracy: 0.5729 - val_loss: 1.9491 - learning_rate: 2.5974e-04
Epoch 82/300
785/785 - 92s - 117ms/step - accuracy: 0.3951 - loss: 2.8615 - val_accuracy: 0.5595 - val_loss: 2.0203 - learning_rate: 2.5974e-04
Epoch 83/300
785/785 - 92s - 117ms/step - accuracy: 0.4011 - loss: 2.8292 - val_accuracy: 0.5703 - val_loss: 2.0012 - learning_rate: 2.5974e-04
Epoch 84/300
785/785 - 93s - 119ms/step - accuracy: 0.4000 - loss: 2.8513 - val_accuracy: 0.5737 - val_loss: 1.9665 - learning_rate: 2.5974e-04
Epoch 85/300
785/785 - 92s - 117ms/step - accuracy: 0.4073 - loss: 2.8129 - val_accuracy: 0.5670 - val_loss: 2.0063 - learning_rate: 2.5974e-04
Epoch 86/300
785/785 - 93s - 118ms/step - accuracy: 0.4045 - loss: 2.8240 - val_accuracy: 0.5682 - val_loss: 1.9657 - learning_rate: 2.5974e-04
Epoch 87/300
785/785 - 92s - 118ms/step - accuracy: 0.3930 - loss: 2.8517 - val_accuracy: 0.5643 - val_loss: 1.9869 - learning_rate: 2.5974e-04
Epoch 88/300
785/785 - 91s - 117ms/step - accuracy: 0.4008 - loss: 2.8644 - val_accuracy: 0.5772 - val_loss: 1.9522 - learning_rate: 2.5974e-04
Epoch 89/300

Epoch 89: ReduceLROnPlateau reducing learning rate to 0.0001298690476687625.
785/785 - 93s - 118ms/step - accuracy: 0.4019 - loss: 2.8097 - val_accuracy: 0.5674 - val_loss: 1.9795 - learning_rate: 2.5974e-04
Epoch 90/300
785/785 - 91s - 116ms/step - accuracy: 0.4081 - loss: 2.7721 - val_accuracy: 0.5694 - val_loss: 1.9615 - learning_rate: 1.2987e-04
Epoch 91/300
785/785 - 93s - 119ms/step - accuracy: 0.4132 - loss: 2.7388 - val_accuracy: 0.5827 - val_loss: 1.9293 - learning_rate: 1.2987e-04
Epoch 92/300
785/785 - 92s - 117ms/step - accuracy: 0.4186 - loss: 2.7557 - val_accuracy: 0.5759 - val_loss: 1.9521 - learning_rate: 1.2987e-04
Epoch 93/300
785/785 - 93s - 118ms/step - accuracy: 0.4177 - loss: 2.7444 - val_accuracy: 0.5829 - val_loss: 1.9303 - learning_rate: 1.2987e-04
Epoch 94/300
785/785 - 94s - 119ms/step - accuracy: 0.4204 - loss: 2.7212 - val_accuracy: 0.5824 - val_loss: 1.9260 - learning_rate: 1.2987e-04
Epoch 95/300
785/785 - 92s - 118ms/step - accuracy: 0.4145 - loss: 2.7443 - val_accuracy: 0.5746 - val_loss: 1.9204 - learning_rate: 1.2987e-04
Epoch 96/300
785/785 - 93s - 119ms/step - accuracy: 0.4158 - loss: 2.7474 - val_accuracy: 0.5889 - val_loss: 1.9224 - learning_rate: 1.2987e-04
Epoch 97/300
785/785 - 141s - 180ms/step - accuracy: 0.4239 - loss: 2.7250 - val_accuracy: 0.5754 - val_loss: 1.9336 - learning_rate: 1.2987e-04
Epoch 98/300
785/785 - 92s - 118ms/step - accuracy: 0.4245 - loss: 2.7014 - val_accuracy: 0.5913 - val_loss: 1.9061 - learning_rate: 1.2987e-04
Epoch 99/300
785/785 - 92s - 117ms/step - accuracy: 0.4207 - loss: 2.7398 - val_accuracy: 0.5815 - val_loss: 1.9326 - learning_rate: 1.2987e-04
Epoch 100/300
785/785 - 92s - 117ms/step - accuracy: 0.4213 - loss: 2.7146 - val_accuracy: 0.5840 - val_loss: 1.9051 - learning_rate: 1.2987e-04
Epoch 101/300
785/785 - 92s - 117ms/step - accuracy: 0.4223 - loss: 2.7187 - val_accuracy: 0.5845 - val_loss: 1.9125 - learning_rate: 1.2987e-04
Epoch 102/300
785/785 - 92s - 118ms/step - accuracy: 0.4218 - loss: 2.7034 - val_accuracy: 0.5827 - val_loss: 1.9131 - learning_rate: 1.2987e-04
Epoch 103/300
785/785 - 93s - 119ms/step - accuracy: 0.4252 - loss: 2.7247 - val_accuracy: 0.5807 - val_loss: 1.9201 - learning_rate: 1.2987e-04
Epoch 104/300
785/785 - 93s - 118ms/step - accuracy: 0.4261 - loss: 2.7091 - val_accuracy: 0.5819 - val_loss: 1.9078 - learning_rate: 1.2987e-04
Epoch 105/300
785/785 - 93s - 118ms/step - accuracy: 0.4228 - loss: 2.6750 - val_accuracy: 0.5877 - val_loss: 1.9118 - learning_rate: 1.2987e-04
Epoch 106/300
785/785 - 93s - 118ms/step - accuracy: 0.4234 - loss: 2.7281 - val_accuracy: 0.5808 - val_loss: 1.9111 - learning_rate: 1.2987e-04
Epoch 107/300
785/785 - 97s - 123ms/step - accuracy: 0.4188 - loss: 2.7204 - val_accuracy: 0.5786 - val_loss: 1.9214 - learning_rate: 1.2987e-04
Epoch 108/300
785/785 - 93s - 119ms/step - accuracy: 0.4306 - loss: 2.7010 - val_accuracy: 0.5923 - val_loss: 1.8839 - learning_rate: 1.2987e-04
Epoch 109/300
785/785 - 92s - 117ms/step - accuracy: 0.4264 - loss: 2.7296 - val_accuracy: 0.5883 - val_loss: 1.8841 - learning_rate: 1.2987e-04
Epoch 110/300
785/785 - 92s - 118ms/step - accuracy: 0.4315 - loss: 2.7019 - val_accuracy: 0.5835 - val_loss: 1.9304 - learning_rate: 1.2987e-04
Epoch 111/300
785/785 - 93s - 118ms/step - accuracy: 0.4247 - loss: 2.7395 - val_accuracy: 0.5713 - val_loss: 1.9559 - learning_rate: 1.2987e-04
Epoch 112/300
785/785 - 92s - 117ms/step - accuracy: 0.4295 - loss: 2.7205 - val_accuracy: 0.5891 - val_loss: 1.8869 - learning_rate: 1.2987e-04
Epoch 113/300
785/785 - 93s - 119ms/step - accuracy: 0.4268 - loss: 2.7052 - val_accuracy: 0.5842 - val_loss: 1.9028 - learning_rate: 1.2987e-04
Epoch 114/300
785/785 - 92s - 117ms/step - accuracy: 0.4285 - loss: 2.7119 - val_accuracy: 0.5874 - val_loss: 1.8759 - learning_rate: 1.2987e-04
Epoch 115/300
785/785 - 93s - 118ms/step - accuracy: 0.4248 - loss: 2.7202 - val_accuracy: 0.5874 - val_loss: 1.8984 - learning_rate: 1.2987e-04
Epoch 116/300
785/785 - 92s - 118ms/step - accuracy: 0.4229 - loss: 2.7247 - val_accuracy: 0.5818 - val_loss: 1.9202 - learning_rate: 1.2987e-04
Epoch 117/300
785/785 - 92s - 118ms/step - accuracy: 0.4373 - loss: 2.6843 - val_accuracy: 0.5888 - val_loss: 1.8907 - learning_rate: 1.2987e-04
Epoch 118/300
785/785 - 93s - 118ms/step - accuracy: 0.4223 - loss: 2.6814 - val_accuracy: 0.5874 - val_loss: 1.8766 - learning_rate: 1.2987e-04
Epoch 119/300
785/785 - 93s - 118ms/step - accuracy: 0.4237 - loss: 2.6937 - val_accuracy: 0.5899 - val_loss: 1.8962 - learning_rate: 1.2987e-04
Epoch 120/300
785/785 - 92s - 117ms/step - accuracy: 0.4264 - loss: 2.6866 - val_accuracy: 0.5913 - val_loss: 1.8988 - learning_rate: 1.2987e-04
Epoch 121/300
785/785 - 93s - 118ms/step - accuracy: 0.4240 - loss: 2.6997 - val_accuracy: 0.5929 - val_loss: 1.8773 - learning_rate: 1.2987e-04
Epoch 122/300

Epoch 122: ReduceLROnPlateau reducing learning rate to 6.493452383438125e-05.
785/785 - 97s - 124ms/step - accuracy: 0.4309 - loss: 2.6783 - val_accuracy: 0.5741 - val_loss: 1.9147 - learning_rate: 1.2987e-04
Epoch 123/300
785/785 - 94s - 120ms/step - accuracy: 0.4326 - loss: 2.6641 - val_accuracy: 0.5862 - val_loss: 1.8609 - learning_rate: 6.4935e-05
Epoch 124/300
785/785 - 92s - 117ms/step - accuracy: 0.4277 - loss: 2.6929 - val_accuracy: 0.5907 - val_loss: 1.8709 - learning_rate: 6.4935e-05
Epoch 125/300
785/785 - 93s - 118ms/step - accuracy: 0.4339 - loss: 2.6535 - val_accuracy: 0.5971 - val_loss: 1.8682 - learning_rate: 6.4935e-05
Epoch 126/300
785/785 - 93s - 118ms/step - accuracy: 0.4322 - loss: 2.6662 - val_accuracy: 0.5929 - val_loss: 1.8661 - learning_rate: 6.4935e-05
Epoch 127/300
785/785 - 143s - 182ms/step - accuracy: 0.4373 - loss: 2.6456 - val_accuracy: 0.5902 - val_loss: 1.8698 - learning_rate: 6.4935e-05
Epoch 128/300
785/785 - 94s - 119ms/step - accuracy: 0.4354 - loss: 2.6663 - val_accuracy: 0.5983 - val_loss: 1.8609 - learning_rate: 6.4935e-05
Epoch 129/300
785/785 - 92s - 118ms/step - accuracy: 0.4326 - loss: 2.6554 - val_accuracy: 0.5928 - val_loss: 1.8580 - learning_rate: 6.4935e-05
Epoch 130/300
785/785 - 92s - 118ms/step - accuracy: 0.4369 - loss: 2.6610 - val_accuracy: 0.5904 - val_loss: 1.8802 - learning_rate: 6.4935e-05
Epoch 131/300
785/785 - 92s - 118ms/step - accuracy: 0.4411 - loss: 2.6387 - val_accuracy: 0.5939 - val_loss: 1.8672 - learning_rate: 6.4935e-05
Epoch 132/300
785/785 - 93s - 118ms/step - accuracy: 0.4387 - loss: 2.6201 - val_accuracy: 0.5891 - val_loss: 1.8738 - learning_rate: 6.4935e-05
Epoch 133/300
785/785 - 92s - 117ms/step - accuracy: 0.4311 - loss: 2.6390 - val_accuracy: 0.5926 - val_loss: 1.8726 - learning_rate: 6.4935e-05
Epoch 134/300
785/785 - 97s - 124ms/step - accuracy: 0.4417 - loss: 2.6478 - val_accuracy: 0.5934 - val_loss: 1.8480 - learning_rate: 6.4935e-05
Epoch 135/300
785/785 - 94s - 120ms/step - accuracy: 0.4381 - loss: 2.6423 - val_accuracy: 0.5891 - val_loss: 1.8440 - learning_rate: 6.4935e-05
Epoch 136/300
785/785 - 91s - 116ms/step - accuracy: 0.4274 - loss: 2.6530 - val_accuracy: 0.5923 - val_loss: 1.8573 - learning_rate: 6.4935e-05
Epoch 137/300
785/785 - 92s - 117ms/step - accuracy: 0.4309 - loss: 2.6315 - val_accuracy: 0.5960 - val_loss: 1.8578 - learning_rate: 6.4935e-05
Epoch 138/300
785/785 - 91s - 116ms/step - accuracy: 0.4325 - loss: 2.6786 - val_accuracy: 0.5971 - val_loss: 1.8463 - learning_rate: 6.4935e-05
Epoch 139/300
785/785 - 93s - 118ms/step - accuracy: 0.4416 - loss: 2.6312 - val_accuracy: 0.5961 - val_loss: 1.8442 - learning_rate: 6.4935e-05
Epoch 140/300
785/785 - 93s - 119ms/step - accuracy: 0.4459 - loss: 2.6218 - val_accuracy: 0.5950 - val_loss: 1.8434 - learning_rate: 6.4935e-05
Epoch 141/300
785/785 - 92s - 117ms/step - accuracy: 0.4398 - loss: 2.6343 - val_accuracy: 0.5963 - val_loss: 1.8448 - learning_rate: 6.4935e-05
Epoch 142/300
785/785 - 93s - 118ms/step - accuracy: 0.4296 - loss: 2.6478 - val_accuracy: 0.5960 - val_loss: 1.8585 - learning_rate: 6.4935e-05
Epoch 143/300
785/785 - 93s - 119ms/step - accuracy: 0.4357 - loss: 2.6823 - val_accuracy: 0.5968 - val_loss: 1.8548 - learning_rate: 6.4935e-05
Epoch 144/300
785/785 - 92s - 117ms/step - accuracy: 0.4478 - loss: 2.6275 - val_accuracy: 0.5969 - val_loss: 1.8592 - learning_rate: 6.4935e-05
Epoch 145/300
785/785 - 94s - 119ms/step - accuracy: 0.4371 - loss: 2.6124 - val_accuracy: 0.5934 - val_loss: 1.8456 - learning_rate: 6.4935e-05
Epoch 146/300
785/785 - 92s - 117ms/step - accuracy: 0.4506 - loss: 2.5898 - val_accuracy: 0.5929 - val_loss: 1.8580 - learning_rate: 6.4935e-05
Epoch 147/300
785/785 - 92s - 117ms/step - accuracy: 0.4449 - loss: 2.6356 - val_accuracy: 0.5918 - val_loss: 1.8628 - learning_rate: 6.4935e-05
Epoch 148/300
785/785 - 93s - 118ms/step - accuracy: 0.4379 - loss: 2.6095 - val_accuracy: 0.5963 - val_loss: 1.8264 - learning_rate: 6.4935e-05
Epoch 149/300
785/785 - 92s - 118ms/step - accuracy: 0.4435 - loss: 2.6413 - val_accuracy: 0.5952 - val_loss: 1.8635 - learning_rate: 6.4935e-05
Epoch 150/300
785/785 - 93s - 118ms/step - accuracy: 0.4382 - loss: 2.6195 - val_accuracy: 0.5956 - val_loss: 1.8523 - learning_rate: 6.4935e-05
Epoch 151/300
785/785 - 92s - 117ms/step - accuracy: 0.4451 - loss: 2.6268 - val_accuracy: 0.5971 - val_loss: 1.8456 - learning_rate: 6.4935e-05
Epoch 152/300
785/785 - 92s - 117ms/step - accuracy: 0.4417 - loss: 2.6365 - val_accuracy: 0.6011 - val_loss: 1.8338 - learning_rate: 6.4935e-05
Epoch 153/300
785/785 - 93s - 118ms/step - accuracy: 0.4376 - loss: 2.6351 - val_accuracy: 0.6034 - val_loss: 1.8366 - learning_rate: 6.4935e-05
Epoch 154/300
785/785 - 92s - 117ms/step - accuracy: 0.4385 - loss: 2.5827 - val_accuracy: 0.5975 - val_loss: 1.8434 - learning_rate: 6.4935e-05
Epoch 155/300
785/785 - 148s - 188ms/step - accuracy: 0.4439 - loss: 2.6154 - val_accuracy: 0.5934 - val_loss: 1.8320 - learning_rate: 6.4935e-05
Epoch 156/300

Epoch 156: ReduceLROnPlateau reducing learning rate to 3.2467261917190626e-05.
785/785 - 92s - 117ms/step - accuracy: 0.4417 - loss: 2.6380 - val_accuracy: 0.5953 - val_loss: 1.8358 - learning_rate: 6.4935e-05
Epoch 157/300
785/785 - 93s - 119ms/step - accuracy: 0.4433 - loss: 2.6328 - val_accuracy: 0.5968 - val_loss: 1.8456 - learning_rate: 3.2467e-05
Epoch 158/300
785/785 - 91s - 116ms/step - accuracy: 0.4417 - loss: 2.5971 - val_accuracy: 0.5937 - val_loss: 1.8336 - learning_rate: 3.2467e-05
Epoch 159/300
785/785 - 92s - 117ms/step - accuracy: 0.4374 - loss: 2.6045 - val_accuracy: 0.6003 - val_loss: 1.8373 - learning_rate: 3.2467e-05
Epoch 160/300
785/785 - 93s - 118ms/step - accuracy: 0.4522 - loss: 2.6078 - val_accuracy: 0.5956 - val_loss: 1.8366 - learning_rate: 3.2467e-05
Epoch 161/300
785/785 - 92s - 117ms/step - accuracy: 0.4470 - loss: 2.6218 - val_accuracy: 0.5987 - val_loss: 1.8308 - learning_rate: 3.2467e-05
Epoch 162/300
785/785 - 93s - 118ms/step - accuracy: 0.4384 - loss: 2.6025 - val_accuracy: 0.5987 - val_loss: 1.8435 - learning_rate: 3.2467e-05
Epoch 163/300
785/785 - 93s - 119ms/step - accuracy: 0.4482 - loss: 2.5825 - val_accuracy: 0.5974 - val_loss: 1.8333 - learning_rate: 3.2467e-05
Epoch 164/300

Epoch 164: ReduceLROnPlateau reducing learning rate to 1.6233630958595313e-05.
785/785 - 91s - 116ms/step - accuracy: 0.4525 - loss: 2.5944 - val_accuracy: 0.5995 - val_loss: 1.8279 - learning_rate: 3.2467e-05
Epoch 164: early stopping
Restoring model weights from the end of the best epoch: 148.
Fold 2_2 Evaluation results: [1.8311171531677246, 0.5962733030319214]
              precision    recall  f1-score   support

        1820       0.77      0.79      0.78       326
        1821       0.88      0.84      0.86       263
        1822       0.00      0.00      0.00        10
        1823       0.00      0.00      0.00         6
        1824       0.00      0.00      0.00         4
        1825       0.00      0.00      0.00         8
        1826       0.50      0.20      0.29        10
        1827       0.74      0.80      0.77       127
        1828       0.50      0.33      0.40         6
        1829       0.56      0.31      0.40        16
        1830       0.53      0.65      0.58       291
        1831       0.77      0.91      0.83       682
        1832       0.78      0.72      0.75       339
        1833       0.76      0.89      0.82        93
        1834       0.37      0.77      0.50       123
        1835       0.00      0.00      0.00        11
        1836       0.14      0.06      0.08        18
        1837       0.32      0.24      0.28        33
        1838       0.00      0.00      0.00        23
        1839       0.00      0.00      0.00         3
        1840       0.49      0.57      0.53       204
        1841       0.70      0.54      0.61       497
        1842       0.86      0.18      0.30        33
        1843       0.36      0.12      0.19        32
        1844       0.00      0.00      0.00         2
        1845       0.00      0.00      0.00         4
        1846       0.17      0.05      0.07        22
        1847       0.00      0.00      0.00        10
        1848       1.00      0.03      0.06        31
        1849       0.25      0.04      0.07        26
        1850       0.35      0.58      0.44       233
        1851       0.74      0.68      0.71       405
        1852       0.22      0.11      0.15        35
        1853       0.00      0.00      0.00        31
        1854       0.00      0.00      0.00        17
        1855       0.36      0.11      0.17       116
        1856       0.65      0.67      0.66        54
        1857       0.36      0.62      0.46       156
        1858       0.00      0.00      0.00         9
        1859       0.00      0.00      0.00        13
        1860       0.35      0.35      0.35       347
        1861       0.77      0.82      0.79       432
        1862       0.34      0.12      0.18        96
        1863       0.35      0.48      0.41        91
        1864       0.19      0.19      0.19        78
        1865       0.50      0.27      0.35        30
        1866       0.00      0.00      0.00        32
        1867       0.33      0.16      0.21        51
        1868       0.00      0.00      0.00        36
        1869       0.00      0.00      0.00        27
        1870       0.41      0.53      0.46       160
        1871       0.70      0.79      0.74       251
        1872       0.22      0.32      0.26        31
        1873       0.20      0.04      0.07        49
        1874       0.00      0.00      0.00        35
        1875       0.26      0.43      0.32        68
        1876       0.87      0.83      0.85        58
        1877       0.27      0.44      0.33        27
        1878       0.38      0.25      0.31        51
        1879       0.00      0.00      0.00         7

    accuracy                           0.60      6279
   macro avg       0.34      0.30      0.29      6279
weighted avg       0.58      0.60      0.57      6279

Matthews Correlation Coefficient: 0.576
Macro avg F1: 0.293
Weighted avg F1: 0.575
Micro avg F1: 0.596
Top-3 Accuracy: 0.844
Top-5 Accuracy: 0.901
Micro ROC AUC  = 0.98
Macro ROC AUC (present classes) = 0.97
Classification MAE (in years): 3.22

Fold 2_2 Misclassification Analysis:
Near misses (within 2 years): 586 out of 2535 misclassifications (23.12%)
Big misses (greater than 10 years): 1035
MAE with outliers: 3.22
MAE without outliers: 2.32 (improvement: 0.90)

10 Worst misclassifications:
Image: data/datasets/public/1870/1879_26wikimedia2.jpg, True: 1879, Predicted: 1820, Error: 59
Image: data/datasets/public/1870/1877_035met.jpg, True: 1877, Predicted: 1820, Error: 57
Image: data/datasets/public/1820/1820_10wikimedia2.jpg, True: 1820, Predicted: 1876, Error: 56
Image: data/datasets/public/1870/1876_379vna.jpg, True: 1876, Predicted: 1825, Error: 51
Image: data/datasets/public/1870/1870_75wikimedia2.jpg, True: 1870, Predicted: 1820, Error: 50
Image: data/datasets/private/1870/1871_398etsy.jpg, True: 1871, Predicted: 1821, Error: 50
Image: data/datasets/private/1820/1821_580etsy.jpg, True: 1821, Predicted: 1871, Error: 50
Image: data/datasets/private/1870/1871_358etsy.jpg, True: 1871, Predicted: 1821, Error: 50
Image: data/datasets/private/1820/1821_486etsy.jpg, True: 1821, Predicted: 1871, Error: 50
Image: data/datasets/private/1870/1871_53etsy.jpg, True: 1871, Predicted: 1821, Error: 50

===== Iteration 4/5 =====
=== Training Base Model ===

===== Fine Tuning 9 layers! =====
Epoch 1/300
785/785 - 119s - 151ms/step - accuracy: 0.1186 - loss: 4.3975 - val_accuracy: 0.1737 - val_loss: 3.8950 - learning_rate: 2.5974e-04
Epoch 2/300
785/785 - 93s - 119ms/step - accuracy: 0.1631 - loss: 4.1335 - val_accuracy: 0.2119 - val_loss: 3.6894 - learning_rate: 2.5974e-04
Epoch 3/300
785/785 - 92s - 118ms/step - accuracy: 0.2054 - loss: 3.9413 - val_accuracy: 0.3057 - val_loss: 3.5636 - learning_rate: 2.5974e-04
Epoch 4/300
785/785 - 93s - 119ms/step - accuracy: 0.2279 - loss: 3.8092 - val_accuracy: 0.3307 - val_loss: 3.3611 - learning_rate: 2.5974e-04
Epoch 5/300
785/785 - 92s - 118ms/step - accuracy: 0.2507 - loss: 3.6815 - val_accuracy: 0.3559 - val_loss: 3.1254 - learning_rate: 2.5974e-04
Epoch 6/300
785/785 - 93s - 119ms/step - accuracy: 0.2551 - loss: 3.6154 - val_accuracy: 0.3626 - val_loss: 3.0039 - learning_rate: 2.5974e-04
Epoch 7/300
785/785 - 93s - 119ms/step - accuracy: 0.2704 - loss: 3.5410 - val_accuracy: 0.3938 - val_loss: 2.9449 - learning_rate: 2.5974e-04
Epoch 8/300
785/785 - 92s - 117ms/step - accuracy: 0.2940 - loss: 3.4669 - val_accuracy: 0.3914 - val_loss: 2.7833 - learning_rate: 2.5974e-04
Epoch 9/300
785/785 - 92s - 118ms/step - accuracy: 0.2954 - loss: 3.4260 - val_accuracy: 0.4309 - val_loss: 2.8297 - learning_rate: 2.5974e-04
Epoch 10/300
785/785 - 93s - 119ms/step - accuracy: 0.3020 - loss: 3.3800 - val_accuracy: 0.4365 - val_loss: 2.8652 - learning_rate: 2.5974e-04
Epoch 11/300
785/785 - 92s - 118ms/step - accuracy: 0.3072 - loss: 3.3437 - val_accuracy: 0.4591 - val_loss: 2.7333 - learning_rate: 2.5974e-04
Epoch 12/300
785/785 - 93s - 119ms/step - accuracy: 0.3149 - loss: 3.3173 - val_accuracy: 0.4682 - val_loss: 2.6534 - learning_rate: 2.5974e-04
Epoch 13/300
785/785 - 93s - 118ms/step - accuracy: 0.3158 - loss: 3.2776 - val_accuracy: 0.4715 - val_loss: 2.5938 - learning_rate: 2.5974e-04
Epoch 14/300
785/785 - 92s - 117ms/step - accuracy: 0.3225 - loss: 3.2849 - val_accuracy: 0.4635 - val_loss: 2.5353 - learning_rate: 2.5974e-04
Epoch 15/300
785/785 - 92s - 118ms/step - accuracy: 0.3389 - loss: 3.2085 - val_accuracy: 0.4839 - val_loss: 2.5569 - learning_rate: 2.5974e-04
Epoch 16/300
785/785 - 91s - 116ms/step - accuracy: 0.3400 - loss: 3.2346 - val_accuracy: 0.4761 - val_loss: 2.5190 - learning_rate: 2.5974e-04
Epoch 17/300
785/785 - 97s - 123ms/step - accuracy: 0.3311 - loss: 3.2032 - val_accuracy: 0.4729 - val_loss: 2.5303 - learning_rate: 2.5974e-04
Epoch 18/300
785/785 - 92s - 117ms/step - accuracy: 0.3512 - loss: 3.1549 - val_accuracy: 0.5018 - val_loss: 2.4202 - learning_rate: 2.5974e-04
Epoch 19/300
785/785 - 92s - 117ms/step - accuracy: 0.3502 - loss: 3.1479 - val_accuracy: 0.4965 - val_loss: 2.4772 - learning_rate: 2.5974e-04
Epoch 20/300
785/785 - 93s - 118ms/step - accuracy: 0.3459 - loss: 3.1814 - val_accuracy: 0.5132 - val_loss: 2.4554 - learning_rate: 2.5974e-04
Epoch 21/300
785/785 - 93s - 118ms/step - accuracy: 0.3552 - loss: 3.0967 - val_accuracy: 0.5049 - val_loss: 2.3933 - learning_rate: 2.5974e-04
Epoch 22/300
785/785 - 97s - 124ms/step - accuracy: 0.3515 - loss: 3.1297 - val_accuracy: 0.5220 - val_loss: 2.3819 - learning_rate: 2.5974e-04
Epoch 23/300
785/785 - 93s - 119ms/step - accuracy: 0.3488 - loss: 3.1063 - val_accuracy: 0.5119 - val_loss: 2.3333 - learning_rate: 2.5974e-04
Epoch 24/300
785/785 - 93s - 118ms/step - accuracy: 0.3563 - loss: 3.0922 - val_accuracy: 0.5209 - val_loss: 2.3151 - learning_rate: 2.5974e-04
Epoch 25/300
785/785 - 141s - 180ms/step - accuracy: 0.3585 - loss: 3.0924 - val_accuracy: 0.4992 - val_loss: 2.3264 - learning_rate: 2.5974e-04
Epoch 26/300
785/785 - 93s - 118ms/step - accuracy: 0.3596 - loss: 3.0430 - val_accuracy: 0.5094 - val_loss: 2.3328 - learning_rate: 2.5974e-04
Epoch 27/300
785/785 - 94s - 119ms/step - accuracy: 0.3599 - loss: 3.0591 - val_accuracy: 0.5097 - val_loss: 2.3537 - learning_rate: 2.5974e-04
Epoch 28/300
785/785 - 92s - 117ms/step - accuracy: 0.3688 - loss: 3.0265 - val_accuracy: 0.5204 - val_loss: 2.2774 - learning_rate: 2.5974e-04
Epoch 29/300
785/785 - 94s - 120ms/step - accuracy: 0.3567 - loss: 3.0477 - val_accuracy: 0.5291 - val_loss: 2.2646 - learning_rate: 2.5974e-04
Epoch 30/300
785/785 - 97s - 124ms/step - accuracy: 0.3660 - loss: 3.0369 - val_accuracy: 0.5232 - val_loss: 2.2835 - learning_rate: 2.5974e-04
Epoch 31/300
785/785 - 98s - 125ms/step - accuracy: 0.3751 - loss: 3.0096 - val_accuracy: 0.5252 - val_loss: 2.2609 - learning_rate: 2.5974e-04
Epoch 32/300
785/785 - 94s - 120ms/step - accuracy: 0.3696 - loss: 3.0231 - val_accuracy: 0.5078 - val_loss: 2.3212 - learning_rate: 2.5974e-04
Epoch 33/300
785/785 - 93s - 119ms/step - accuracy: 0.3754 - loss: 2.9759 - val_accuracy: 0.5239 - val_loss: 2.2256 - learning_rate: 2.5974e-04
Epoch 34/300
785/785 - 95s - 120ms/step - accuracy: 0.3813 - loss: 2.9957 - val_accuracy: 0.5306 - val_loss: 2.2052 - learning_rate: 2.5974e-04
Epoch 35/300
785/785 - 91s - 116ms/step - accuracy: 0.3789 - loss: 3.0076 - val_accuracy: 0.5344 - val_loss: 2.2021 - learning_rate: 2.5974e-04
Epoch 36/300
785/785 - 93s - 118ms/step - accuracy: 0.3660 - loss: 3.0230 - val_accuracy: 0.5331 - val_loss: 2.2547 - learning_rate: 2.5974e-04
Epoch 37/300
785/785 - 93s - 118ms/step - accuracy: 0.3773 - loss: 2.9690 - val_accuracy: 0.5263 - val_loss: 2.2071 - learning_rate: 2.5974e-04
Epoch 38/300
785/785 - 93s - 118ms/step - accuracy: 0.3751 - loss: 2.9684 - val_accuracy: 0.5341 - val_loss: 2.1814 - learning_rate: 2.5974e-04
Epoch 39/300
785/785 - 93s - 119ms/step - accuracy: 0.3819 - loss: 2.9766 - val_accuracy: 0.5339 - val_loss: 2.2061 - learning_rate: 2.5974e-04
Epoch 40/300
785/785 - 92s - 118ms/step - accuracy: 0.3770 - loss: 2.9673 - val_accuracy: 0.5325 - val_loss: 2.1896 - learning_rate: 2.5974e-04
Epoch 41/300
785/785 - 92s - 117ms/step - accuracy: 0.3846 - loss: 2.9190 - val_accuracy: 0.5283 - val_loss: 2.1954 - learning_rate: 2.5974e-04
Epoch 42/300
785/785 - 94s - 119ms/step - accuracy: 0.3789 - loss: 2.9214 - val_accuracy: 0.5180 - val_loss: 2.2458 - learning_rate: 2.5974e-04
Epoch 43/300
785/785 - 93s - 119ms/step - accuracy: 0.3817 - loss: 2.9248 - val_accuracy: 0.5510 - val_loss: 2.1499 - learning_rate: 2.5974e-04
Epoch 44/300
785/785 - 94s - 120ms/step - accuracy: 0.3825 - loss: 2.9259 - val_accuracy: 0.5311 - val_loss: 2.1893 - learning_rate: 2.5974e-04
Epoch 45/300
785/785 - 93s - 118ms/step - accuracy: 0.3851 - loss: 2.9521 - val_accuracy: 0.5396 - val_loss: 2.1490 - learning_rate: 2.5974e-04
Epoch 46/300
785/785 - 93s - 118ms/step - accuracy: 0.3888 - loss: 2.9041 - val_accuracy: 0.5392 - val_loss: 2.1545 - learning_rate: 2.5974e-04
Epoch 47/300
785/785 - 93s - 118ms/step - accuracy: 0.3776 - loss: 2.8904 - val_accuracy: 0.5311 - val_loss: 2.1480 - learning_rate: 2.5974e-04
Epoch 48/300
785/785 - 92s - 117ms/step - accuracy: 0.3942 - loss: 2.8916 - val_accuracy: 0.5334 - val_loss: 2.1592 - learning_rate: 2.5974e-04
Epoch 49/300
785/785 - 93s - 119ms/step - accuracy: 0.3892 - loss: 2.9059 - val_accuracy: 0.5438 - val_loss: 2.1751 - learning_rate: 2.5974e-04
Epoch 50/300
785/785 - 93s - 118ms/step - accuracy: 0.3854 - loss: 2.9212 - val_accuracy: 0.5404 - val_loss: 2.1595 - learning_rate: 2.5974e-04
Epoch 51/300
785/785 - 92s - 117ms/step - accuracy: 0.3935 - loss: 2.9019 - val_accuracy: 0.5331 - val_loss: 2.1534 - learning_rate: 2.5974e-04
Epoch 52/300
785/785 - 93s - 119ms/step - accuracy: 0.3873 - loss: 2.9139 - val_accuracy: 0.5185 - val_loss: 2.2678 - learning_rate: 2.5974e-04
Epoch 53/300
785/785 - 93s - 118ms/step - accuracy: 0.3948 - loss: 2.9186 - val_accuracy: 0.5396 - val_loss: 2.1268 - learning_rate: 2.5974e-04
Epoch 54/300
785/785 - 98s - 124ms/step - accuracy: 0.3919 - loss: 2.8956 - val_accuracy: 0.5570 - val_loss: 2.1107 - learning_rate: 2.5974e-04
Epoch 55/300
785/785 - 92s - 117ms/step - accuracy: 0.3910 - loss: 2.9098 - val_accuracy: 0.5470 - val_loss: 2.1628 - learning_rate: 2.5974e-04
Epoch 56/300
785/785 - 93s - 119ms/step - accuracy: 0.3884 - loss: 2.9163 - val_accuracy: 0.5347 - val_loss: 2.1722 - learning_rate: 2.5974e-04
Epoch 57/300
785/785 - 92s - 117ms/step - accuracy: 0.3948 - loss: 2.8695 - val_accuracy: 0.5417 - val_loss: 2.1296 - learning_rate: 2.5974e-04
Epoch 58/300
785/785 - 93s - 119ms/step - accuracy: 0.3967 - loss: 2.8543 - val_accuracy: 0.5384 - val_loss: 2.1494 - learning_rate: 2.5974e-04
Epoch 59/300
785/785 - 94s - 120ms/step - accuracy: 0.3969 - loss: 2.8661 - val_accuracy: 0.5412 - val_loss: 2.1687 - learning_rate: 2.5974e-04
Epoch 60/300
785/785 - 93s - 118ms/step - accuracy: 0.3969 - loss: 2.9062 - val_accuracy: 0.5393 - val_loss: 2.1700 - learning_rate: 2.5974e-04
Epoch 61/300
785/785 - 93s - 118ms/step - accuracy: 0.3970 - loss: 2.8876 - val_accuracy: 0.5428 - val_loss: 2.1300 - learning_rate: 2.5974e-04
Epoch 62/300

Epoch 62: ReduceLROnPlateau reducing learning rate to 0.0001298690476687625.
785/785 - 93s - 118ms/step - accuracy: 0.3860 - loss: 2.8727 - val_accuracy: 0.5400 - val_loss: 2.1722 - learning_rate: 2.5974e-04
Epoch 63/300
785/785 - 92s - 117ms/step - accuracy: 0.4037 - loss: 2.8084 - val_accuracy: 0.5600 - val_loss: 2.0788 - learning_rate: 1.2987e-04
Epoch 64/300
785/785 - 94s - 120ms/step - accuracy: 0.4002 - loss: 2.8130 - val_accuracy: 0.5522 - val_loss: 2.0584 - learning_rate: 1.2987e-04
Epoch 65/300
785/785 - 92s - 118ms/step - accuracy: 0.4106 - loss: 2.7768 - val_accuracy: 0.5580 - val_loss: 2.0812 - learning_rate: 1.2987e-04
Epoch 66/300
785/785 - 94s - 119ms/step - accuracy: 0.4233 - loss: 2.7783 - val_accuracy: 0.5589 - val_loss: 2.0678 - learning_rate: 1.2987e-04
Epoch 67/300
785/785 - 94s - 119ms/step - accuracy: 0.4037 - loss: 2.8054 - val_accuracy: 0.5549 - val_loss: 2.0974 - learning_rate: 1.2987e-04
Epoch 68/300
785/785 - 93s - 118ms/step - accuracy: 0.4106 - loss: 2.7855 - val_accuracy: 0.5613 - val_loss: 2.0448 - learning_rate: 1.2987e-04
Epoch 69/300
785/785 - 94s - 120ms/step - accuracy: 0.4112 - loss: 2.7800 - val_accuracy: 0.5568 - val_loss: 2.0849 - learning_rate: 1.2987e-04
Epoch 70/300
785/785 - 92s - 118ms/step - accuracy: 0.4126 - loss: 2.7922 - val_accuracy: 0.5648 - val_loss: 2.0369 - learning_rate: 1.2987e-04
Epoch 71/300
785/785 - 93s - 119ms/step - accuracy: 0.4045 - loss: 2.7847 - val_accuracy: 0.5562 - val_loss: 2.0752 - learning_rate: 1.2987e-04
Epoch 72/300
785/785 - 93s - 118ms/step - accuracy: 0.4185 - loss: 2.7213 - val_accuracy: 0.5680 - val_loss: 2.0326 - learning_rate: 1.2987e-04
Epoch 73/300
785/785 - 97s - 124ms/step - accuracy: 0.4144 - loss: 2.7527 - val_accuracy: 0.5592 - val_loss: 2.0283 - learning_rate: 1.2987e-04
Epoch 74/300
785/785 - 93s - 119ms/step - accuracy: 0.4141 - loss: 2.7523 - val_accuracy: 0.5615 - val_loss: 2.0652 - learning_rate: 1.2987e-04
Epoch 75/300
785/785 - 92s - 117ms/step - accuracy: 0.4212 - loss: 2.7469 - val_accuracy: 0.5646 - val_loss: 2.0218 - learning_rate: 1.2987e-04
Epoch 76/300
785/785 - 94s - 120ms/step - accuracy: 0.4214 - loss: 2.7440 - val_accuracy: 0.5650 - val_loss: 2.0349 - learning_rate: 1.2987e-04
Epoch 77/300
785/785 - 93s - 118ms/step - accuracy: 0.4200 - loss: 2.7296 - val_accuracy: 0.5680 - val_loss: 2.0364 - learning_rate: 1.2987e-04
Epoch 78/300
785/785 - 92s - 117ms/step - accuracy: 0.4018 - loss: 2.7900 - val_accuracy: 0.5669 - val_loss: 2.0188 - learning_rate: 1.2987e-04
Epoch 79/300
785/785 - 93s - 119ms/step - accuracy: 0.4338 - loss: 2.7081 - val_accuracy: 0.5651 - val_loss: 2.0287 - learning_rate: 1.2987e-04
Epoch 80/300
785/785 - 93s - 118ms/step - accuracy: 0.4224 - loss: 2.7568 - val_accuracy: 0.5658 - val_loss: 2.0147 - learning_rate: 1.2987e-04
Epoch 81/300
785/785 - 92s - 117ms/step - accuracy: 0.4185 - loss: 2.7516 - val_accuracy: 0.5650 - val_loss: 2.0242 - learning_rate: 1.2987e-04
Epoch 82/300
785/785 - 92s - 117ms/step - accuracy: 0.4236 - loss: 2.7495 - val_accuracy: 0.5629 - val_loss: 2.0267 - learning_rate: 1.2987e-04
Epoch 83/300
785/785 - 97s - 124ms/step - accuracy: 0.4241 - loss: 2.7314 - val_accuracy: 0.5632 - val_loss: 2.0158 - learning_rate: 1.2987e-04
Epoch 84/300
785/785 - 94s - 120ms/step - accuracy: 0.4195 - loss: 2.7430 - val_accuracy: 0.5740 - val_loss: 2.0169 - learning_rate: 1.2987e-04
Epoch 85/300
785/785 - 92s - 117ms/step - accuracy: 0.4177 - loss: 2.7672 - val_accuracy: 0.5656 - val_loss: 2.0240 - learning_rate: 1.2987e-04
Epoch 86/300
785/785 - 94s - 120ms/step - accuracy: 0.4190 - loss: 2.7544 - val_accuracy: 0.5693 - val_loss: 1.9892 - learning_rate: 1.2987e-04
Epoch 87/300
785/785 - 97s - 124ms/step - accuracy: 0.4254 - loss: 2.7354 - val_accuracy: 0.5753 - val_loss: 2.0145 - learning_rate: 1.2987e-04
Epoch 88/300
785/785 - 93s - 119ms/step - accuracy: 0.4208 - loss: 2.7409 - val_accuracy: 0.5713 - val_loss: 2.0330 - learning_rate: 1.2987e-04
Epoch 89/300
785/785 - 92s - 117ms/step - accuracy: 0.4278 - loss: 2.7001 - val_accuracy: 0.5745 - val_loss: 1.9750 - learning_rate: 1.2987e-04
Epoch 90/300
785/785 - 92s - 118ms/step - accuracy: 0.4267 - loss: 2.7397 - val_accuracy: 0.5729 - val_loss: 2.0276 - learning_rate: 1.2987e-04
Epoch 91/300
785/785 - 94s - 120ms/step - accuracy: 0.4158 - loss: 2.7579 - val_accuracy: 0.5634 - val_loss: 2.0202 - learning_rate: 1.2987e-04
Epoch 92/300
785/785 - 97s - 124ms/step - accuracy: 0.4155 - loss: 2.7570 - val_accuracy: 0.5710 - val_loss: 2.0011 - learning_rate: 1.2987e-04
Epoch 93/300
785/785 - 95s - 121ms/step - accuracy: 0.4329 - loss: 2.7228 - val_accuracy: 0.5785 - val_loss: 1.9915 - learning_rate: 1.2987e-04
Epoch 94/300
785/785 - 95s - 120ms/step - accuracy: 0.4211 - loss: 2.7544 - val_accuracy: 0.5688 - val_loss: 2.0237 - learning_rate: 1.2987e-04
Epoch 95/300
785/785 - 93s - 119ms/step - accuracy: 0.4279 - loss: 2.7138 - val_accuracy: 0.5674 - val_loss: 2.0091 - learning_rate: 1.2987e-04
Epoch 96/300
785/785 - 94s - 120ms/step - accuracy: 0.4219 - loss: 2.7405 - val_accuracy: 0.5686 - val_loss: 2.0320 - learning_rate: 1.2987e-04
Epoch 97/300

Epoch 97: ReduceLROnPlateau reducing learning rate to 6.493452383438125e-05.
785/785 - 94s - 120ms/step - accuracy: 0.4230 - loss: 2.7040 - val_accuracy: 0.5651 - val_loss: 2.0138 - learning_rate: 1.2987e-04
Epoch 98/300
785/785 - 94s - 120ms/step - accuracy: 0.4388 - loss: 2.6582 - val_accuracy: 0.5725 - val_loss: 1.9979 - learning_rate: 6.4935e-05
Epoch 99/300
785/785 - 93s - 119ms/step - accuracy: 0.4349 - loss: 2.6532 - val_accuracy: 0.5752 - val_loss: 1.9797 - learning_rate: 6.4935e-05
Epoch 100/300
785/785 - 95s - 121ms/step - accuracy: 0.4281 - loss: 2.6778 - val_accuracy: 0.5823 - val_loss: 1.9682 - learning_rate: 6.4935e-05
Epoch 101/300
785/785 - 96s - 122ms/step - accuracy: 0.4306 - loss: 2.6900 - val_accuracy: 0.5763 - val_loss: 1.9585 - learning_rate: 6.4935e-05
Epoch 102/300
785/785 - 94s - 120ms/step - accuracy: 0.4265 - loss: 2.6807 - val_accuracy: 0.5825 - val_loss: 1.9505 - learning_rate: 6.4935e-05
Epoch 103/300
785/785 - 97s - 123ms/step - accuracy: 0.4255 - loss: 2.6746 - val_accuracy: 0.5763 - val_loss: 1.9853 - learning_rate: 6.4935e-05
Epoch 104/300
785/785 - 96s - 123ms/step - accuracy: 0.4273 - loss: 2.6947 - val_accuracy: 0.5774 - val_loss: 1.9642 - learning_rate: 6.4935e-05
Epoch 105/300
785/785 - 96s - 122ms/step - accuracy: 0.4391 - loss: 2.6866 - val_accuracy: 0.5830 - val_loss: 1.9574 - learning_rate: 6.4935e-05
Epoch 106/300
785/785 - 98s - 125ms/step - accuracy: 0.4357 - loss: 2.6590 - val_accuracy: 0.5806 - val_loss: 1.9649 - learning_rate: 6.4935e-05
Epoch 107/300
785/785 - 140s - 178ms/step - accuracy: 0.4345 - loss: 2.6621 - val_accuracy: 0.5764 - val_loss: 1.9564 - learning_rate: 6.4935e-05
Epoch 108/300
785/785 - 97s - 124ms/step - accuracy: 0.4337 - loss: 2.6484 - val_accuracy: 0.5782 - val_loss: 1.9555 - learning_rate: 6.4935e-05
Epoch 109/300
785/785 - 96s - 122ms/step - accuracy: 0.4357 - loss: 2.6626 - val_accuracy: 0.5764 - val_loss: 1.9577 - learning_rate: 6.4935e-05
Epoch 110/300

Epoch 110: ReduceLROnPlateau reducing learning rate to 3.2467261917190626e-05.
785/785 - 95s - 121ms/step - accuracy: 0.4396 - loss: 2.6447 - val_accuracy: 0.5748 - val_loss: 1.9568 - learning_rate: 6.4935e-05
Epoch 111/300
785/785 - 96s - 123ms/step - accuracy: 0.4416 - loss: 2.6090 - val_accuracy: 0.5822 - val_loss: 1.9467 - learning_rate: 3.2467e-05
Epoch 112/300
785/785 - 95s - 121ms/step - accuracy: 0.4373 - loss: 2.6529 - val_accuracy: 0.5814 - val_loss: 1.9333 - learning_rate: 3.2467e-05
Epoch 113/300
785/785 - 142s - 181ms/step - accuracy: 0.4397 - loss: 2.6193 - val_accuracy: 0.5798 - val_loss: 1.9546 - learning_rate: 3.2467e-05
Epoch 114/300
785/785 - 94s - 120ms/step - accuracy: 0.4310 - loss: 2.6868 - val_accuracy: 0.5846 - val_loss: 1.9452 - learning_rate: 3.2467e-05
Epoch 115/300
785/785 - 94s - 120ms/step - accuracy: 0.4337 - loss: 2.6666 - val_accuracy: 0.5804 - val_loss: 1.9503 - learning_rate: 3.2467e-05
Epoch 116/300
785/785 - 97s - 123ms/step - accuracy: 0.4405 - loss: 2.6529 - val_accuracy: 0.5799 - val_loss: 1.9437 - learning_rate: 3.2467e-05
Epoch 117/300
785/785 - 95s - 121ms/step - accuracy: 0.4400 - loss: 2.6306 - val_accuracy: 0.5831 - val_loss: 1.9479 - learning_rate: 3.2467e-05
Epoch 118/300
785/785 - 95s - 121ms/step - accuracy: 0.4504 - loss: 2.6005 - val_accuracy: 0.5823 - val_loss: 1.9421 - learning_rate: 3.2467e-05
Epoch 119/300
785/785 - 95s - 121ms/step - accuracy: 0.4278 - loss: 2.6673 - val_accuracy: 0.5812 - val_loss: 1.9398 - learning_rate: 3.2467e-05
Epoch 120/300

Epoch 120: ReduceLROnPlateau reducing learning rate to 1.6233630958595313e-05.
785/785 - 95s - 120ms/step - accuracy: 0.4338 - loss: 2.6434 - val_accuracy: 0.5828 - val_loss: 1.9411 - learning_rate: 3.2467e-05
Epoch 121/300
785/785 - 142s - 181ms/step - accuracy: 0.4494 - loss: 2.6125 - val_accuracy: 0.5830 - val_loss: 1.9364 - learning_rate: 1.6234e-05
Epoch 122/300
785/785 - 96s - 122ms/step - accuracy: 0.4394 - loss: 2.6547 - val_accuracy: 0.5812 - val_loss: 1.9406 - learning_rate: 1.6234e-05
Epoch 123/300
785/785 - 92s - 118ms/step - accuracy: 0.4415 - loss: 2.6274 - val_accuracy: 0.5799 - val_loss: 1.9380 - learning_rate: 1.6234e-05
Epoch 124/300
785/785 - 147s - 187ms/step - accuracy: 0.4453 - loss: 2.6194 - val_accuracy: 0.5815 - val_loss: 1.9330 - learning_rate: 1.6234e-05
Epoch 125/300
785/785 - 94s - 120ms/step - accuracy: 0.4456 - loss: 2.6248 - val_accuracy: 0.5820 - val_loss: 1.9323 - learning_rate: 1.6234e-05
Epoch 126/300
785/785 - 97s - 123ms/step - accuracy: 0.4359 - loss: 2.6268 - val_accuracy: 0.5814 - val_loss: 1.9370 - learning_rate: 1.6234e-05
Epoch 127/300
785/785 - 95s - 120ms/step - accuracy: 0.4456 - loss: 2.6770 - val_accuracy: 0.5831 - val_loss: 1.9343 - learning_rate: 1.6234e-05
Epoch 128/300
785/785 - 96s - 122ms/step - accuracy: 0.4338 - loss: 2.6391 - val_accuracy: 0.5833 - val_loss: 1.9427 - learning_rate: 1.6234e-05
Epoch 129/300
785/785 - 96s - 123ms/step - accuracy: 0.4450 - loss: 2.6224 - val_accuracy: 0.5828 - val_loss: 1.9296 - learning_rate: 1.6234e-05
Epoch 130/300
785/785 - 95s - 121ms/step - accuracy: 0.4443 - loss: 2.6246 - val_accuracy: 0.5839 - val_loss: 1.9327 - learning_rate: 1.6234e-05
Epoch 131/300
785/785 - 97s - 123ms/step - accuracy: 0.4477 - loss: 2.6148 - val_accuracy: 0.5849 - val_loss: 1.9299 - learning_rate: 1.6234e-05
Epoch 132/300
785/785 - 92s - 117ms/step - accuracy: 0.4321 - loss: 2.6435 - val_accuracy: 0.5846 - val_loss: 1.9331 - learning_rate: 1.6234e-05
Epoch 133/300
785/785 - 99s - 126ms/step - accuracy: 0.4505 - loss: 2.5972 - val_accuracy: 0.5844 - val_loss: 1.9322 - learning_rate: 1.6234e-05
Epoch 134/300
785/785 - 95s - 121ms/step - accuracy: 0.4434 - loss: 2.6281 - val_accuracy: 0.5844 - val_loss: 1.9323 - learning_rate: 1.6234e-05
Epoch 135/300
785/785 - 97s - 123ms/step - accuracy: 0.4408 - loss: 2.6368 - val_accuracy: 0.5860 - val_loss: 1.9309 - learning_rate: 1.6234e-05
Epoch 136/300
785/785 - 98s - 124ms/step - accuracy: 0.4456 - loss: 2.5875 - val_accuracy: 0.5834 - val_loss: 1.9282 - learning_rate: 1.6234e-05
Epoch 137/300
785/785 - 95s - 121ms/step - accuracy: 0.4424 - loss: 2.6368 - val_accuracy: 0.5828 - val_loss: 1.9253 - learning_rate: 1.6234e-05
Epoch 138/300
785/785 - 96s - 122ms/step - accuracy: 0.4389 - loss: 2.6205 - val_accuracy: 0.5828 - val_loss: 1.9253 - learning_rate: 1.6234e-05
Epoch 139/300
785/785 - 94s - 119ms/step - accuracy: 0.4392 - loss: 2.6310 - val_accuracy: 0.5818 - val_loss: 1.9296 - learning_rate: 1.6234e-05
Epoch 140/300
785/785 - 95s - 121ms/step - accuracy: 0.4456 - loss: 2.6341 - val_accuracy: 0.5855 - val_loss: 1.9323 - learning_rate: 1.6234e-05
Epoch 141/300
785/785 - 95s - 121ms/step - accuracy: 0.4475 - loss: 2.6155 - val_accuracy: 0.5860 - val_loss: 1.9316 - learning_rate: 1.6234e-05
Epoch 142/300
785/785 - 139s - 177ms/step - accuracy: 0.4423 - loss: 2.6202 - val_accuracy: 0.5849 - val_loss: 1.9266 - learning_rate: 1.6234e-05
Epoch 143/300
785/785 - 92s - 117ms/step - accuracy: 0.4461 - loss: 2.5717 - val_accuracy: 0.5838 - val_loss: 1.9248 - learning_rate: 1.6234e-05
Epoch 144/300
785/785 - 92s - 118ms/step - accuracy: 0.4485 - loss: 2.6381 - val_accuracy: 0.5849 - val_loss: 1.9283 - learning_rate: 1.6234e-05
Epoch 145/300
785/785 - 93s - 119ms/step - accuracy: 0.4357 - loss: 2.6416 - val_accuracy: 0.5865 - val_loss: 1.9413 - learning_rate: 1.6234e-05
Epoch 146/300
785/785 - 142s - 181ms/step - accuracy: 0.4439 - loss: 2.6332 - val_accuracy: 0.5847 - val_loss: 1.9248 - learning_rate: 1.6234e-05
Epoch 147/300
785/785 - 92s - 117ms/step - accuracy: 0.4507 - loss: 2.6276 - val_accuracy: 0.5847 - val_loss: 1.9346 - learning_rate: 1.6234e-05
Epoch 148/300
785/785 - 93s - 118ms/step - accuracy: 0.4415 - loss: 2.5921 - val_accuracy: 0.5850 - val_loss: 1.9368 - learning_rate: 1.6234e-05
Epoch 149/300
785/785 - 94s - 119ms/step - accuracy: 0.4448 - loss: 2.6101 - val_accuracy: 0.5860 - val_loss: 1.9347 - learning_rate: 1.6234e-05
Epoch 150/300
785/785 - 93s - 118ms/step - accuracy: 0.4434 - loss: 2.6305 - val_accuracy: 0.5831 - val_loss: 1.9260 - learning_rate: 1.6234e-05
Epoch 151/300

Epoch 151: ReduceLROnPlateau reducing learning rate to 8.116815479297657e-06.
785/785 - 97s - 124ms/step - accuracy: 0.4510 - loss: 2.6189 - val_accuracy: 0.5850 - val_loss: 1.9249 - learning_rate: 1.6234e-05
Epoch 152/300
785/785 - 94s - 120ms/step - accuracy: 0.4442 - loss: 2.5864 - val_accuracy: 0.5852 - val_loss: 1.9276 - learning_rate: 8.1168e-06
Epoch 153/300
785/785 - 96s - 123ms/step - accuracy: 0.4380 - loss: 2.6170 - val_accuracy: 0.5823 - val_loss: 1.9296 - learning_rate: 8.1168e-06
Epoch 154/300
785/785 - 142s - 181ms/step - accuracy: 0.4459 - loss: 2.6351 - val_accuracy: 0.5849 - val_loss: 1.9307 - learning_rate: 8.1168e-06
Epoch 155/300
785/785 - 96s - 122ms/step - accuracy: 0.4470 - loss: 2.6015 - val_accuracy: 0.5846 - val_loss: 1.9210 - learning_rate: 8.1168e-06
Epoch 156/300
785/785 - 97s - 123ms/step - accuracy: 0.4459 - loss: 2.5901 - val_accuracy: 0.5849 - val_loss: 1.9262 - learning_rate: 8.1168e-06
Epoch 157/300
785/785 - 92s - 118ms/step - accuracy: 0.4439 - loss: 2.5894 - val_accuracy: 0.5852 - val_loss: 1.9285 - learning_rate: 8.1168e-06
Epoch 158/300
785/785 - 98s - 124ms/step - accuracy: 0.4423 - loss: 2.6327 - val_accuracy: 0.5842 - val_loss: 1.9243 - learning_rate: 8.1168e-06
Epoch 159/300
785/785 - 95s - 121ms/step - accuracy: 0.4490 - loss: 2.6305 - val_accuracy: 0.5860 - val_loss: 1.9238 - learning_rate: 8.1168e-06
Epoch 160/300
785/785 - 97s - 123ms/step - accuracy: 0.4384 - loss: 2.5941 - val_accuracy: 0.5871 - val_loss: 1.9305 - learning_rate: 8.1168e-06
Epoch 161/300
785/785 - 96s - 122ms/step - accuracy: 0.4483 - loss: 2.6041 - val_accuracy: 0.5863 - val_loss: 1.9278 - learning_rate: 8.1168e-06
Epoch 162/300
785/785 - 95s - 121ms/step - accuracy: 0.4474 - loss: 2.5915 - val_accuracy: 0.5852 - val_loss: 1.9308 - learning_rate: 8.1168e-06
Epoch 163/300

Epoch 163: ReduceLROnPlateau reducing learning rate to 4.058407739648828e-06.
785/785 - 93s - 118ms/step - accuracy: 0.4447 - loss: 2.6208 - val_accuracy: 0.5847 - val_loss: 1.9226 - learning_rate: 8.1168e-06
Epoch 164/300
785/785 - 95s - 121ms/step - accuracy: 0.4477 - loss: 2.6124 - val_accuracy: 0.5860 - val_loss: 1.9226 - learning_rate: 4.0584e-06
Epoch 165/300
785/785 - 94s - 120ms/step - accuracy: 0.4512 - loss: 2.5713 - val_accuracy: 0.5850 - val_loss: 1.9207 - learning_rate: 4.0584e-06
Epoch 166/300
785/785 - 89s - 113ms/step - accuracy: 0.4399 - loss: 2.6132 - val_accuracy: 0.5868 - val_loss: 1.9253 - learning_rate: 4.0584e-06
Epoch 167/300
785/785 - 94s - 119ms/step - accuracy: 0.4388 - loss: 2.6129 - val_accuracy: 0.5861 - val_loss: 1.9261 - learning_rate: 4.0584e-06
Epoch 168/300
785/785 - 93s - 118ms/step - accuracy: 0.4475 - loss: 2.6025 - val_accuracy: 0.5858 - val_loss: 1.9252 - learning_rate: 4.0584e-06
Epoch 169/300
785/785 - 93s - 118ms/step - accuracy: 0.4445 - loss: 2.6330 - val_accuracy: 0.5879 - val_loss: 1.9231 - learning_rate: 4.0584e-06
Epoch 170/300
785/785 - 93s - 119ms/step - accuracy: 0.4372 - loss: 2.5956 - val_accuracy: 0.5852 - val_loss: 1.9193 - learning_rate: 4.0584e-06
Epoch 171/300
785/785 - 91s - 116ms/step - accuracy: 0.4421 - loss: 2.6013 - val_accuracy: 0.5854 - val_loss: 1.9193 - learning_rate: 4.0584e-06
Epoch 172/300
785/785 - 94s - 119ms/step - accuracy: 0.4456 - loss: 2.6012 - val_accuracy: 0.5860 - val_loss: 1.9170 - learning_rate: 4.0584e-06
Epoch 173/300
785/785 - 92s - 117ms/step - accuracy: 0.4552 - loss: 2.5805 - val_accuracy: 0.5857 - val_loss: 1.9219 - learning_rate: 4.0584e-06
Epoch 174/300
785/785 - 94s - 119ms/step - accuracy: 0.4405 - loss: 2.6364 - val_accuracy: 0.5855 - val_loss: 1.9227 - learning_rate: 4.0584e-06
Epoch 175/300
785/785 - 93s - 118ms/step - accuracy: 0.4372 - loss: 2.6576 - val_accuracy: 0.5858 - val_loss: 1.9194 - learning_rate: 4.0584e-06
Epoch 176/300
785/785 - 95s - 121ms/step - accuracy: 0.4507 - loss: 2.5782 - val_accuracy: 0.5842 - val_loss: 1.9192 - learning_rate: 4.0584e-06
Epoch 177/300
785/785 - 96s - 122ms/step - accuracy: 0.4419 - loss: 2.6269 - val_accuracy: 0.5849 - val_loss: 1.9251 - learning_rate: 4.0584e-06
Epoch 178/300
785/785 - 96s - 122ms/step - accuracy: 0.4380 - loss: 2.6212 - val_accuracy: 0.5866 - val_loss: 1.9213 - learning_rate: 4.0584e-06
Epoch 179/300
785/785 - 94s - 120ms/step - accuracy: 0.4459 - loss: 2.6004 - val_accuracy: 0.5858 - val_loss: 1.9280 - learning_rate: 4.0584e-06
Epoch 180/300

Epoch 180: ReduceLROnPlateau reducing learning rate to 2.029203869824414e-06.
785/785 - 98s - 125ms/step - accuracy: 0.4437 - loss: 2.6320 - val_accuracy: 0.5855 - val_loss: 1.9309 - learning_rate: 4.0584e-06
Epoch 181/300
785/785 - 96s - 122ms/step - accuracy: 0.4412 - loss: 2.6026 - val_accuracy: 0.5857 - val_loss: 1.9197 - learning_rate: 2.0292e-06
Epoch 182/300
785/785 - 97s - 123ms/step - accuracy: 0.4507 - loss: 2.6136 - val_accuracy: 0.5852 - val_loss: 1.9207 - learning_rate: 2.0292e-06
Epoch 183/300
785/785 - 94s - 120ms/step - accuracy: 0.4413 - loss: 2.6488 - val_accuracy: 0.5863 - val_loss: 1.9225 - learning_rate: 2.0292e-06
Epoch 184/300
785/785 - 97s - 124ms/step - accuracy: 0.4451 - loss: 2.6340 - val_accuracy: 0.5857 - val_loss: 1.9227 - learning_rate: 2.0292e-06
Epoch 185/300
785/785 - 96s - 122ms/step - accuracy: 0.4442 - loss: 2.6192 - val_accuracy: 0.5861 - val_loss: 1.9234 - learning_rate: 2.0292e-06
Epoch 186/300
785/785 - 97s - 123ms/step - accuracy: 0.4478 - loss: 2.6173 - val_accuracy: 0.5858 - val_loss: 1.9223 - learning_rate: 2.0292e-06
Epoch 187/300
785/785 - 139s - 177ms/step - accuracy: 0.4429 - loss: 2.5952 - val_accuracy: 0.5849 - val_loss: 1.9180 - learning_rate: 2.0292e-06
Epoch 188/300

Epoch 188: ReduceLROnPlateau reducing learning rate to 1.014601934912207e-06.
785/785 - 95s - 121ms/step - accuracy: 0.4351 - loss: 2.6565 - val_accuracy: 0.5865 - val_loss: 1.9223 - learning_rate: 2.0292e-06
Epoch 188: early stopping
Restoring model weights from the end of the best epoch: 172.
Fold 3_1 Evaluation results: [1.917883276939392, 0.5859872698783875]
              precision    recall  f1-score   support

        1820       0.68      0.79      0.73       306
        1821       0.91      0.84      0.87       294
        1822       0.00      0.00      0.00         8
        1823       0.00      0.00      0.00         5
        1824       0.00      0.00      0.00         7
        1825       0.00      0.00      0.00        12
        1826       0.10      0.22      0.14         9
        1827       0.75      0.71      0.73       131
        1828       0.00      0.00      0.00        12
        1829       0.00      0.00      0.00        27
        1830       0.56      0.63      0.59       294
        1831       0.75      0.91      0.82       647
        1832       0.83      0.68      0.75       337
        1833       0.77      0.91      0.84       103
        1834       0.38      0.66      0.48       138
        1835       0.00      0.00      0.00        12
        1836       0.00      0.00      0.00        20
        1837       0.26      0.46      0.33        26
        1838       0.00      0.00      0.00        17
        1839       0.00      0.00      0.00         4
        1840       0.41      0.60      0.49       200
        1841       0.74      0.54      0.62       541
        1842       0.70      0.23      0.35        30
        1843       0.00      0.00      0.00        33
        1844       0.00      0.00      0.00         0
        1845       0.00      0.00      0.00         8
        1846       0.50      0.03      0.06        32
        1847       0.00      0.00      0.00        11
        1848       0.20      0.07      0.11        27
        1849       0.00      0.00      0.00        34
        1850       0.35      0.59      0.44       236
        1851       0.70      0.72      0.71       390
        1852       0.08      0.03      0.04        34
        1853       0.23      0.10      0.14        29
        1854       0.00      0.00      0.00        11
        1855       0.29      0.02      0.03       117
        1856       0.58      0.55      0.56        60
        1857       0.39      0.68      0.50       161
        1858       0.00      0.00      0.00        10
        1859       0.00      0.00      0.00        12
        1860       0.32      0.34      0.33       343
        1861       0.77      0.76      0.77       434
        1862       0.22      0.09      0.13        95
        1863       0.36      0.53      0.43       104
        1864       0.30      0.32      0.31        74
        1865       0.60      0.09      0.16        32
        1866       0.18      0.09      0.12        22
        1867       0.31      0.21      0.25        39
        1868       0.00      0.00      0.00        33
        1869       0.00      0.00      0.00        35
        1870       0.33      0.62      0.43       133
        1871       0.63      0.79      0.70       220
        1872       0.00      0.00      0.00        48
        1873       1.00      0.04      0.07        52
        1874       0.00      0.00      0.00        25
        1875       0.34      0.29      0.31        75
        1876       0.93      0.86      0.90        50
        1877       0.40      0.27      0.32        30
        1878       0.56      0.44      0.49        45
        1879       0.00      0.00      0.00         6

    accuracy                           0.59      6280
   macro avg       0.31      0.28      0.27      6280
weighted avg       0.57      0.59      0.56      6280

Matthews Correlation Coefficient: 0.565
Macro avg F1: 0.268
Weighted avg F1: 0.559
Micro avg F1: 0.586
Top-3 Accuracy: 0.824
Top-5 Accuracy: 0.883
Micro ROC AUC  = 0.98
Macro ROC AUC (present classes) = 0.97
Classification MAE (in years): 3.35

Fold 3_1 Misclassification Analysis:
Near misses (within 2 years): 604 out of 2600 misclassifications (23.23%)
Big misses (greater than 10 years): 1054
MAE with outliers: 3.35
MAE without outliers: 2.38 (improvement: 0.97)

10 Worst misclassifications:
Image: data/datasets/public/1870/1876_53washington.jpg, True: 1876, Predicted: 1820, Error: 56
Image: data/datasets/private/1820/1820_031_Zrzut ekranu 2022-07-26 195637.png, True: 1820, Predicted: 1871, Error: 51
Image: data/datasets/public/1870/1870_75wikimedia2.jpg, True: 1870, Predicted: 1820, Error: 50
Image: data/datasets/private/1870/1871_384etsy.jpg, True: 1871, Predicted: 1821, Error: 50
Image: data/datasets/private/1820/1821_462etsy.jpg, True: 1821, Predicted: 1871, Error: 50
Image: data/datasets/public/1820/1820_033_001met.jpg, True: 1820, Predicted: 1870, Error: 50
Image: data/datasets/public/1870/1876_70washington.jpg, True: 1876, Predicted: 1826, Error: 50
Image: data/datasets/public/1860/1868_007met.jpg, True: 1868, Predicted: 1820, Error: 48
Image: data/datasets/public/1870/1878_1258vna.jpg, True: 1878, Predicted: 1832, Error: 46
Image: data/datasets/public/1860/1865_690vna.jpg, True: 1865, Predicted: 1820, Error: 45

===== Fine Tuning 9 layers! =====
Epoch 1/300
785/785 - 123s - 156ms/step - accuracy: 0.1124 - loss: 4.4860 - val_accuracy: 0.1964 - val_loss: 3.9756 - learning_rate: 2.5974e-04
Epoch 2/300
785/785 - 94s - 120ms/step - accuracy: 0.1604 - loss: 4.2449 - val_accuracy: 0.2542 - val_loss: 3.8375 - learning_rate: 2.5974e-04
Epoch 3/300
785/785 - 140s - 178ms/step - accuracy: 0.1914 - loss: 4.0018 - val_accuracy: 0.2903 - val_loss: 3.4846 - learning_rate: 2.5974e-04
Epoch 4/300
785/785 - 97s - 124ms/step - accuracy: 0.2178 - loss: 3.8459 - val_accuracy: 0.3289 - val_loss: 3.2667 - learning_rate: 2.5974e-04
Epoch 5/300
785/785 - 94s - 120ms/step - accuracy: 0.2299 - loss: 3.7001 - val_accuracy: 0.3493 - val_loss: 3.0520 - learning_rate: 2.5974e-04
Epoch 6/300
785/785 - 94s - 119ms/step - accuracy: 0.2428 - loss: 3.6409 - val_accuracy: 0.4050 - val_loss: 2.9901 - learning_rate: 2.5974e-04
Epoch 7/300
785/785 - 93s - 118ms/step - accuracy: 0.2467 - loss: 3.6066 - val_accuracy: 0.4050 - val_loss: 2.9903 - learning_rate: 2.5974e-04
Epoch 8/300
785/785 - 98s - 125ms/step - accuracy: 0.2613 - loss: 3.5208 - val_accuracy: 0.4150 - val_loss: 2.9051 - learning_rate: 2.5974e-04
Epoch 9/300
785/785 - 91s - 117ms/step - accuracy: 0.2744 - loss: 3.4785 - val_accuracy: 0.4182 - val_loss: 2.7897 - learning_rate: 2.5974e-04
Epoch 10/300
785/785 - 96s - 123ms/step - accuracy: 0.2850 - loss: 3.4385 - val_accuracy: 0.4372 - val_loss: 2.7942 - learning_rate: 2.5974e-04
Epoch 11/300
785/785 - 96s - 123ms/step - accuracy: 0.2838 - loss: 3.4487 - val_accuracy: 0.4389 - val_loss: 2.7397 - learning_rate: 2.5974e-04
Epoch 12/300
785/785 - 94s - 120ms/step - accuracy: 0.2917 - loss: 3.4049 - val_accuracy: 0.4370 - val_loss: 2.6242 - learning_rate: 2.5974e-04
Epoch 13/300
785/785 - 94s - 120ms/step - accuracy: 0.2957 - loss: 3.3745 - val_accuracy: 0.4599 - val_loss: 2.5789 - learning_rate: 2.5974e-04
Epoch 14/300
785/785 - 98s - 125ms/step - accuracy: 0.3091 - loss: 3.3361 - val_accuracy: 0.4630 - val_loss: 2.5727 - learning_rate: 2.5974e-04
Epoch 15/300
785/785 - 92s - 117ms/step - accuracy: 0.3062 - loss: 3.3259 - val_accuracy: 0.4783 - val_loss: 2.5827 - learning_rate: 2.5974e-04
Epoch 16/300
785/785 - 145s - 185ms/step - accuracy: 0.3119 - loss: 3.3378 - val_accuracy: 0.4784 - val_loss: 2.5480 - learning_rate: 2.5974e-04
Epoch 17/300
785/785 - 97s - 123ms/step - accuracy: 0.3088 - loss: 3.2984 - val_accuracy: 0.4966 - val_loss: 2.4989 - learning_rate: 2.5974e-04
Epoch 18/300
785/785 - 95s - 121ms/step - accuracy: 0.3239 - loss: 3.2293 - val_accuracy: 0.5069 - val_loss: 2.4588 - learning_rate: 2.5974e-04
Epoch 19/300
785/785 - 93s - 118ms/step - accuracy: 0.3108 - loss: 3.2677 - val_accuracy: 0.5039 - val_loss: 2.4787 - learning_rate: 2.5974e-04
Epoch 20/300
785/785 - 93s - 119ms/step - accuracy: 0.3228 - loss: 3.2541 - val_accuracy: 0.5049 - val_loss: 2.4088 - learning_rate: 2.5974e-04
Epoch 21/300
785/785 - 94s - 119ms/step - accuracy: 0.3237 - loss: 3.2050 - val_accuracy: 0.5033 - val_loss: 2.3802 - learning_rate: 2.5974e-04
Epoch 22/300
785/785 - 93s - 118ms/step - accuracy: 0.3306 - loss: 3.2212 - val_accuracy: 0.4915 - val_loss: 2.4111 - learning_rate: 2.5974e-04
Epoch 23/300
785/785 - 92s - 118ms/step - accuracy: 0.3312 - loss: 3.2043 - val_accuracy: 0.5041 - val_loss: 2.3582 - learning_rate: 2.5974e-04
Epoch 24/300
785/785 - 93s - 118ms/step - accuracy: 0.3309 - loss: 3.1974 - val_accuracy: 0.5015 - val_loss: 2.4019 - learning_rate: 2.5974e-04
Epoch 25/300
785/785 - 94s - 120ms/step - accuracy: 0.3202 - loss: 3.2041 - val_accuracy: 0.5095 - val_loss: 2.3816 - learning_rate: 2.5974e-04
Epoch 26/300
785/785 - 95s - 120ms/step - accuracy: 0.3409 - loss: 3.1549 - val_accuracy: 0.4999 - val_loss: 2.2719 - learning_rate: 2.5974e-04
Epoch 27/300
785/785 - 94s - 120ms/step - accuracy: 0.3299 - loss: 3.1820 - val_accuracy: 0.4967 - val_loss: 2.3414 - learning_rate: 2.5974e-04
Epoch 28/300
785/785 - 91s - 116ms/step - accuracy: 0.3435 - loss: 3.1627 - val_accuracy: 0.5115 - val_loss: 2.3374 - learning_rate: 2.5974e-04
Epoch 29/300
785/785 - 92s - 118ms/step - accuracy: 0.3452 - loss: 3.1356 - val_accuracy: 0.4959 - val_loss: 2.4565 - learning_rate: 2.5974e-04
Epoch 30/300
785/785 - 92s - 117ms/step - accuracy: 0.3460 - loss: 3.1463 - val_accuracy: 0.5162 - val_loss: 2.2779 - learning_rate: 2.5974e-04
Epoch 31/300
785/785 - 94s - 120ms/step - accuracy: 0.3455 - loss: 3.1092 - val_accuracy: 0.5208 - val_loss: 2.2737 - learning_rate: 2.5974e-04
Epoch 32/300
785/785 - 91s - 116ms/step - accuracy: 0.3481 - loss: 3.1020 - val_accuracy: 0.5289 - val_loss: 2.2990 - learning_rate: 2.5974e-04
Epoch 33/300
785/785 - 93s - 119ms/step - accuracy: 0.3492 - loss: 3.1019 - val_accuracy: 0.5313 - val_loss: 2.2799 - learning_rate: 2.5974e-04
Epoch 34/300

Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0001298690476687625.
785/785 - 93s - 118ms/step - accuracy: 0.3494 - loss: 3.1083 - val_accuracy: 0.5297 - val_loss: 2.2805 - learning_rate: 2.5974e-04
Epoch 35/300
785/785 - 94s - 120ms/step - accuracy: 0.3659 - loss: 3.0279 - val_accuracy: 0.5319 - val_loss: 2.2300 - learning_rate: 1.2987e-04
Epoch 36/300
785/785 - 93s - 118ms/step - accuracy: 0.3605 - loss: 3.0596 - val_accuracy: 0.5240 - val_loss: 2.2598 - learning_rate: 1.2987e-04
Epoch 37/300
785/785 - 93s - 118ms/step - accuracy: 0.3717 - loss: 3.0288 - val_accuracy: 0.5377 - val_loss: 2.2257 - learning_rate: 1.2987e-04
Epoch 38/300
785/785 - 94s - 120ms/step - accuracy: 0.3656 - loss: 3.0280 - val_accuracy: 0.5472 - val_loss: 2.1855 - learning_rate: 1.2987e-04
Epoch 39/300
785/785 - 97s - 124ms/step - accuracy: 0.3608 - loss: 3.0052 - val_accuracy: 0.5377 - val_loss: 2.1865 - learning_rate: 1.2987e-04
Epoch 40/300
785/785 - 95s - 121ms/step - accuracy: 0.3666 - loss: 3.0363 - val_accuracy: 0.5385 - val_loss: 2.1899 - learning_rate: 1.2987e-04
Epoch 41/300
785/785 - 95s - 121ms/step - accuracy: 0.3678 - loss: 2.9848 - val_accuracy: 0.5447 - val_loss: 2.1706 - learning_rate: 1.2987e-04
Epoch 42/300
785/785 - 97s - 123ms/step - accuracy: 0.3744 - loss: 2.9991 - val_accuracy: 0.5405 - val_loss: 2.1959 - learning_rate: 1.2987e-04
Epoch 43/300
785/785 - 96s - 122ms/step - accuracy: 0.3728 - loss: 2.9967 - val_accuracy: 0.5426 - val_loss: 2.1909 - learning_rate: 1.2987e-04
Epoch 44/300
785/785 - 94s - 119ms/step - accuracy: 0.3718 - loss: 2.9817 - val_accuracy: 0.5444 - val_loss: 2.1597 - learning_rate: 1.2987e-04
Epoch 45/300
785/785 - 92s - 117ms/step - accuracy: 0.3675 - loss: 3.0263 - val_accuracy: 0.5496 - val_loss: 2.1966 - learning_rate: 1.2987e-04
Epoch 46/300
785/785 - 97s - 123ms/step - accuracy: 0.3717 - loss: 2.9840 - val_accuracy: 0.5504 - val_loss: 2.1678 - learning_rate: 1.2987e-04
Epoch 47/300
785/785 - 96s - 122ms/step - accuracy: 0.3619 - loss: 2.9991 - val_accuracy: 0.5491 - val_loss: 2.1391 - learning_rate: 1.2987e-04
Epoch 48/300
785/785 - 96s - 123ms/step - accuracy: 0.3672 - loss: 2.9620 - val_accuracy: 0.5588 - val_loss: 2.1618 - learning_rate: 1.2987e-04
Epoch 49/300
785/785 - 93s - 119ms/step - accuracy: 0.3785 - loss: 2.9779 - val_accuracy: 0.5410 - val_loss: 2.1638 - learning_rate: 1.2987e-04
Epoch 50/300
785/785 - 94s - 120ms/step - accuracy: 0.3672 - loss: 2.9555 - val_accuracy: 0.5483 - val_loss: 2.1385 - learning_rate: 1.2987e-04
Epoch 51/300
785/785 - 94s - 119ms/step - accuracy: 0.3838 - loss: 2.9462 - val_accuracy: 0.5502 - val_loss: 2.1117 - learning_rate: 1.2987e-04
Epoch 52/300
785/785 - 90s - 115ms/step - accuracy: 0.3747 - loss: 2.9547 - val_accuracy: 0.5504 - val_loss: 2.1099 - learning_rate: 1.2987e-04
Epoch 53/300
785/785 - 94s - 119ms/step - accuracy: 0.3807 - loss: 2.9689 - val_accuracy: 0.5579 - val_loss: 2.1019 - learning_rate: 1.2987e-04
Epoch 54/300
785/785 - 90s - 115ms/step - accuracy: 0.3930 - loss: 2.8998 - val_accuracy: 0.5515 - val_loss: 2.0896 - learning_rate: 1.2987e-04
Epoch 55/300
785/785 - 92s - 118ms/step - accuracy: 0.3822 - loss: 2.9363 - val_accuracy: 0.5585 - val_loss: 2.1150 - learning_rate: 1.2987e-04
Epoch 56/300
785/785 - 93s - 118ms/step - accuracy: 0.3772 - loss: 2.9714 - val_accuracy: 0.5542 - val_loss: 2.0942 - learning_rate: 1.2987e-04
Epoch 57/300
785/785 - 93s - 118ms/step - accuracy: 0.3834 - loss: 2.8910 - val_accuracy: 0.5544 - val_loss: 2.1101 - learning_rate: 1.2987e-04
Epoch 58/300
785/785 - 95s - 121ms/step - accuracy: 0.3822 - loss: 2.9481 - val_accuracy: 0.5649 - val_loss: 2.1091 - learning_rate: 1.2987e-04
Epoch 59/300
785/785 - 95s - 121ms/step - accuracy: 0.3841 - loss: 2.9186 - val_accuracy: 0.5536 - val_loss: 2.1023 - learning_rate: 1.2987e-04
Epoch 60/300
785/785 - 93s - 119ms/step - accuracy: 0.3780 - loss: 2.9601 - val_accuracy: 0.5617 - val_loss: 2.1040 - learning_rate: 1.2987e-04
Epoch 61/300
785/785 - 93s - 118ms/step - accuracy: 0.3783 - loss: 2.9202 - val_accuracy: 0.5525 - val_loss: 2.1139 - learning_rate: 1.2987e-04
Epoch 62/300

Epoch 62: ReduceLROnPlateau reducing learning rate to 6.493452383438125e-05.
785/785 - 97s - 124ms/step - accuracy: 0.3858 - loss: 2.9098 - val_accuracy: 0.5674 - val_loss: 2.0897 - learning_rate: 1.2987e-04
Epoch 63/300
785/785 - 92s - 117ms/step - accuracy: 0.3771 - loss: 2.9259 - val_accuracy: 0.5558 - val_loss: 2.0778 - learning_rate: 6.4935e-05
Epoch 64/300
785/785 - 93s - 118ms/step - accuracy: 0.3874 - loss: 2.9218 - val_accuracy: 0.5584 - val_loss: 2.0453 - learning_rate: 6.4935e-05
Epoch 65/300
785/785 - 95s - 121ms/step - accuracy: 0.3947 - loss: 2.9156 - val_accuracy: 0.5665 - val_loss: 2.0429 - learning_rate: 6.4935e-05
Epoch 66/300
785/785 - 98s - 125ms/step - accuracy: 0.3928 - loss: 2.8816 - val_accuracy: 0.5698 - val_loss: 2.0642 - learning_rate: 6.4935e-05
Epoch 67/300
785/785 - 94s - 119ms/step - accuracy: 0.3932 - loss: 2.8796 - val_accuracy: 0.5633 - val_loss: 2.0542 - learning_rate: 6.4935e-05
Epoch 68/300
785/785 - 143s - 182ms/step - accuracy: 0.3890 - loss: 2.8901 - val_accuracy: 0.5608 - val_loss: 2.0464 - learning_rate: 6.4935e-05
Epoch 69/300
785/785 - 94s - 120ms/step - accuracy: 0.3892 - loss: 2.8813 - val_accuracy: 0.5710 - val_loss: 2.0637 - learning_rate: 6.4935e-05
Epoch 70/300
785/785 - 95s - 121ms/step - accuracy: 0.3823 - loss: 2.8722 - val_accuracy: 0.5676 - val_loss: 2.0497 - learning_rate: 6.4935e-05
Epoch 71/300
785/785 - 94s - 120ms/step - accuracy: 0.4045 - loss: 2.8372 - val_accuracy: 0.5655 - val_loss: 2.0350 - learning_rate: 6.4935e-05
Epoch 72/300
785/785 - 95s - 121ms/step - accuracy: 0.3852 - loss: 2.9205 - val_accuracy: 0.5643 - val_loss: 2.0287 - learning_rate: 6.4935e-05
Epoch 73/300
785/785 - 94s - 120ms/step - accuracy: 0.3975 - loss: 2.8664 - val_accuracy: 0.5649 - val_loss: 2.0446 - learning_rate: 6.4935e-05
Epoch 74/300
785/785 - 90s - 114ms/step - accuracy: 0.3930 - loss: 2.8809 - val_accuracy: 0.5687 - val_loss: 2.0360 - learning_rate: 6.4935e-05
Epoch 75/300
785/785 - 94s - 120ms/step - accuracy: 0.4046 - loss: 2.8390 - val_accuracy: 0.5702 - val_loss: 2.0491 - learning_rate: 6.4935e-05
Epoch 76/300
785/785 - 93s - 118ms/step - accuracy: 0.4005 - loss: 2.8239 - val_accuracy: 0.5714 - val_loss: 2.0270 - learning_rate: 6.4935e-05
Epoch 77/300
785/785 - 91s - 117ms/step - accuracy: 0.3984 - loss: 2.8696 - val_accuracy: 0.5698 - val_loss: 2.0502 - learning_rate: 6.4935e-05
Epoch 78/300
785/785 - 96s - 122ms/step - accuracy: 0.4024 - loss: 2.8627 - val_accuracy: 0.5741 - val_loss: 2.0259 - learning_rate: 6.4935e-05
Epoch 79/300
785/785 - 92s - 117ms/step - accuracy: 0.4054 - loss: 2.8255 - val_accuracy: 0.5740 - val_loss: 2.0130 - learning_rate: 6.4935e-05
Epoch 80/300
785/785 - 94s - 120ms/step - accuracy: 0.3984 - loss: 2.8377 - val_accuracy: 0.5697 - val_loss: 2.0043 - learning_rate: 6.4935e-05
Epoch 81/300
785/785 - 94s - 119ms/step - accuracy: 0.3896 - loss: 2.8459 - val_accuracy: 0.5773 - val_loss: 2.0216 - learning_rate: 6.4935e-05
Epoch 82/300
785/785 - 93s - 118ms/step - accuracy: 0.3978 - loss: 2.8615 - val_accuracy: 0.5757 - val_loss: 2.0184 - learning_rate: 6.4935e-05
Epoch 83/300
785/785 - 91s - 116ms/step - accuracy: 0.3938 - loss: 2.8743 - val_accuracy: 0.5725 - val_loss: 2.0426 - learning_rate: 6.4935e-05
Epoch 84/300
785/785 - 90s - 114ms/step - accuracy: 0.3922 - loss: 2.8615 - val_accuracy: 0.5710 - val_loss: 2.0347 - learning_rate: 6.4935e-05
Epoch 85/300
785/785 - 96s - 122ms/step - accuracy: 0.3982 - loss: 2.8551 - val_accuracy: 0.5756 - val_loss: 2.0296 - learning_rate: 6.4935e-05
Epoch 86/300
785/785 - 90s - 115ms/step - accuracy: 0.4002 - loss: 2.8605 - val_accuracy: 0.5663 - val_loss: 2.0213 - learning_rate: 6.4935e-05
Epoch 87/300
785/785 - 92s - 117ms/step - accuracy: 0.3965 - loss: 2.8585 - val_accuracy: 0.5770 - val_loss: 2.0285 - learning_rate: 6.4935e-05
Epoch 88/300

Epoch 88: ReduceLROnPlateau reducing learning rate to 3.2467261917190626e-05.
785/785 - 91s - 115ms/step - accuracy: 0.3874 - loss: 2.8648 - val_accuracy: 0.5708 - val_loss: 2.0257 - learning_rate: 6.4935e-05
Epoch 89/300
785/785 - 143s - 182ms/step - accuracy: 0.4110 - loss: 2.8092 - val_accuracy: 0.5759 - val_loss: 2.0134 - learning_rate: 3.2467e-05
Epoch 90/300
785/785 - 91s - 116ms/step - accuracy: 0.3982 - loss: 2.8171 - val_accuracy: 0.5792 - val_loss: 2.0126 - learning_rate: 3.2467e-05
Epoch 91/300
785/785 - 93s - 118ms/step - accuracy: 0.4056 - loss: 2.8224 - val_accuracy: 0.5792 - val_loss: 1.9996 - learning_rate: 3.2467e-05
Epoch 92/300
785/785 - 91s - 115ms/step - accuracy: 0.4053 - loss: 2.7816 - val_accuracy: 0.5788 - val_loss: 1.9815 - learning_rate: 3.2467e-05
Epoch 93/300
785/785 - 93s - 119ms/step - accuracy: 0.4006 - loss: 2.8129 - val_accuracy: 0.5768 - val_loss: 1.9879 - learning_rate: 3.2467e-05
Epoch 94/300
785/785 - 93s - 118ms/step - accuracy: 0.4005 - loss: 2.8216 - val_accuracy: 0.5792 - val_loss: 1.9801 - learning_rate: 3.2467e-05
Epoch 95/300
785/785 - 94s - 120ms/step - accuracy: 0.3970 - loss: 2.8473 - val_accuracy: 0.5802 - val_loss: 1.9930 - learning_rate: 3.2467e-05
Epoch 96/300
785/785 - 92s - 117ms/step - accuracy: 0.3904 - loss: 2.8461 - val_accuracy: 0.5784 - val_loss: 2.0076 - learning_rate: 3.2467e-05
Epoch 97/300
785/785 - 92s - 117ms/step - accuracy: 0.4037 - loss: 2.8214 - val_accuracy: 0.5762 - val_loss: 2.0037 - learning_rate: 3.2467e-05
Epoch 98/300
785/785 - 91s - 115ms/step - accuracy: 0.3989 - loss: 2.8095 - val_accuracy: 0.5796 - val_loss: 1.9901 - learning_rate: 3.2467e-05
Epoch 99/300
785/785 - 91s - 116ms/step - accuracy: 0.3963 - loss: 2.8466 - val_accuracy: 0.5757 - val_loss: 1.9908 - learning_rate: 3.2467e-05
Epoch 100/300
785/785 - 91s - 115ms/step - accuracy: 0.4037 - loss: 2.8083 - val_accuracy: 0.5815 - val_loss: 2.0006 - learning_rate: 3.2467e-05
Epoch 101/300
785/785 - 94s - 120ms/step - accuracy: 0.4010 - loss: 2.8017 - val_accuracy: 0.5802 - val_loss: 1.9938 - learning_rate: 3.2467e-05
Epoch 102/300

Epoch 102: ReduceLROnPlateau reducing learning rate to 1.6233630958595313e-05.
785/785 - 140s - 178ms/step - accuracy: 0.4041 - loss: 2.7975 - val_accuracy: 0.5759 - val_loss: 1.9942 - learning_rate: 3.2467e-05
Epoch 103/300
785/785 - 90s - 115ms/step - accuracy: 0.4033 - loss: 2.7889 - val_accuracy: 0.5842 - val_loss: 1.9837 - learning_rate: 1.6234e-05
Epoch 104/300
785/785 - 91s - 115ms/step - accuracy: 0.4061 - loss: 2.8199 - val_accuracy: 0.5824 - val_loss: 1.9990 - learning_rate: 1.6234e-05
Epoch 105/300
785/785 - 90s - 115ms/step - accuracy: 0.4084 - loss: 2.8065 - val_accuracy: 0.5808 - val_loss: 1.9917 - learning_rate: 1.6234e-05
Epoch 106/300
785/785 - 91s - 116ms/step - accuracy: 0.3981 - loss: 2.7989 - val_accuracy: 0.5788 - val_loss: 1.9922 - learning_rate: 1.6234e-05
Epoch 107/300
785/785 - 92s - 117ms/step - accuracy: 0.3992 - loss: 2.8086 - val_accuracy: 0.5834 - val_loss: 1.9888 - learning_rate: 1.6234e-05
Epoch 108/300
785/785 - 143s - 183ms/step - accuracy: 0.4100 - loss: 2.8145 - val_accuracy: 0.5846 - val_loss: 1.9817 - learning_rate: 1.6234e-05
Epoch 109/300
785/785 - 92s - 117ms/step - accuracy: 0.3952 - loss: 2.8411 - val_accuracy: 0.5802 - val_loss: 1.9804 - learning_rate: 1.6234e-05
Epoch 110/300

Epoch 110: ReduceLROnPlateau reducing learning rate to 8.116815479297657e-06.
785/785 - 92s - 118ms/step - accuracy: 0.4076 - loss: 2.8000 - val_accuracy: 0.5788 - val_loss: 1.9922 - learning_rate: 1.6234e-05
Epoch 110: early stopping
Restoring model weights from the end of the best epoch: 94.
Fold 3_2 Evaluation results: [1.9830695390701294, 0.5792323350906372]
              precision    recall  f1-score   support

        1820       0.63      0.80      0.70       311
        1821       0.83      0.84      0.83       280
        1822       0.00      0.00      0.00         6
        1823       0.00      0.00      0.00         8
        1824       0.00      0.00      0.00         3
        1825       0.00      0.00      0.00         9
        1826       0.00      0.00      0.00        14
        1827       0.72      0.76      0.74       119
        1828       0.00      0.00      0.00         5
        1829       0.00      0.00      0.00        17
        1830       0.43      0.65      0.52       266
        1831       0.72      0.92      0.81       697
        1832       0.72      0.76      0.74       342
        1833       0.74      0.90      0.81        87
        1834       0.46      0.49      0.47       154
        1835       0.00      0.00      0.00         9
        1836       0.00      0.00      0.00        15
        1837       1.00      0.08      0.15        38
        1838       0.00      0.00      0.00        21
        1839       0.00      0.00      0.00         4
        1840       0.48      0.52      0.50       227
        1841       0.68      0.47      0.56       534
        1842       0.89      0.32      0.47        25
        1843       0.00      0.00      0.00        25
        1844       0.00      0.00      0.00         3
        1845       0.00      0.00      0.00         3
        1846       1.00      0.08      0.15        25
        1847       0.00      0.00      0.00         9
        1848       0.00      0.00      0.00        28
        1849       0.50      0.05      0.10        19
        1850       0.33      0.59      0.42       241
        1851       0.71      0.76      0.73       380
        1852       0.00      0.00      0.00        40
        1853       0.00      0.00      0.00        34
        1854       0.00      0.00      0.00        13
        1855       0.29      0.02      0.03       115
        1856       0.59      0.27      0.37        60
        1857       0.44      0.67      0.53       146
        1858       0.00      0.00      0.00        13
        1859       0.00      0.00      0.00        13
        1860       0.26      0.45      0.33       303
        1861       0.80      0.80      0.80       416
        1862       0.00      0.00      0.00        94
        1863       0.32      0.41      0.36        80
        1864       0.21      0.04      0.07        96
        1865       0.00      0.00      0.00        34
        1866       0.00      0.00      0.00        35
        1867       1.00      0.02      0.03        65
        1868       0.00      0.00      0.00        40
        1869       0.00      0.00      0.00        18
        1870       0.39      0.53      0.45       174
        1871       0.68      0.79      0.73       271
        1872       0.12      0.09      0.10        23
        1873       0.00      0.00      0.00        54
        1874       0.00      0.00      0.00        27
        1875       0.32      0.70      0.44        64
        1876       0.85      0.80      0.82        50
        1877       0.27      0.12      0.17        24
        1878       0.67      0.09      0.16        45
        1879       0.00      0.00      0.00         8

    accuracy                           0.58      6279
   macro avg       0.30      0.25      0.24      6279
weighted avg       0.55      0.58      0.54      6279

Matthews Correlation Coefficient: 0.557
Macro avg F1: 0.235
Weighted avg F1: 0.539
Micro avg F1: 0.579
Top-3 Accuracy: 0.813
Top-5 Accuracy: 0.873
Micro ROC AUC  = 0.98
Macro ROC AUC (present classes) = 0.96
Classification MAE (in years): 3.62

Fold 3_2 Misclassification Analysis:
Near misses (within 2 years): 489 out of 2642 misclassifications (18.51%)
Big misses (greater than 10 years): 1176
MAE with outliers: 3.62
MAE without outliers: 2.60 (improvement: 1.02)

10 Worst misclassifications:
Image: data/datasets/public/1870/1879_26wikimedia2.jpg, True: 1879, Predicted: 1820, Error: 59
Image: data/datasets/public/1870/1879_39wikimedia2.jpg, True: 1879, Predicted: 1820, Error: 59
Image: data/datasets/public/1870/1877_035met.jpg, True: 1877, Predicted: 1820, Error: 57
Image: data/datasets/public/1820/1820_12wikimedia2.jpg, True: 1820, Predicted: 1871, Error: 51
Image: data/datasets/private/1870/1871_114etsy.jpg, True: 1871, Predicted: 1820, Error: 51
Image: data/datasets/private/1820/1821_580etsy.jpg, True: 1821, Predicted: 1871, Error: 50
Image: data/datasets/public/1870/1870_79wikimedia2.jpg, True: 1870, Predicted: 1820, Error: 50
Image: data/datasets/private/1870/1871_404etsy.jpg, True: 1871, Predicted: 1821, Error: 50
Image: data/datasets/private/1870/1871_53etsy.jpg, True: 1871, Predicted: 1821, Error: 50
Image: data/datasets/private/1820/1821_486etsy.jpg, True: 1821, Predicted: 1871, Error: 50
=== Training Alternative Model ===

===== Fine Tuning 9 layers! =====
Epoch 1/300
785/785 - 121s - 154ms/step - accuracy: 0.1072 - loss: 4.4772 - val_accuracy: 0.1666 - val_loss: 3.9460 - learning_rate: 2.5974e-04
Epoch 2/300
785/785 - 93s - 118ms/step - accuracy: 0.1609 - loss: 4.1974 - val_accuracy: 0.2584 - val_loss: 3.9061 - learning_rate: 2.5974e-04
Epoch 3/300
785/785 - 92s - 117ms/step - accuracy: 0.1925 - loss: 3.9966 - val_accuracy: 0.2793 - val_loss: 3.5406 - learning_rate: 2.5974e-04
Epoch 4/300
785/785 - 92s - 117ms/step - accuracy: 0.2070 - loss: 3.8595 - val_accuracy: 0.2990 - val_loss: 3.6301 - learning_rate: 2.5974e-04
Epoch 5/300
785/785 - 92s - 118ms/step - accuracy: 0.2363 - loss: 3.7504 - val_accuracy: 0.3518 - val_loss: 3.3146 - learning_rate: 2.5974e-04
Epoch 6/300
785/785 - 95s - 121ms/step - accuracy: 0.2470 - loss: 3.6565 - val_accuracy: 0.3252 - val_loss: 3.1817 - learning_rate: 2.5974e-04
Epoch 7/300
785/785 - 90s - 115ms/step - accuracy: 0.2633 - loss: 3.6114 - val_accuracy: 0.4189 - val_loss: 3.0091 - learning_rate: 2.5974e-04
Epoch 8/300
785/785 - 91s - 115ms/step - accuracy: 0.2666 - loss: 3.5407 - val_accuracy: 0.3962 - val_loss: 2.9245 - learning_rate: 2.5974e-04
Epoch 9/300
785/785 - 92s - 117ms/step - accuracy: 0.2884 - loss: 3.4937 - val_accuracy: 0.4317 - val_loss: 2.8567 - learning_rate: 2.5974e-04
Epoch 10/300
785/785 - 92s - 117ms/step - accuracy: 0.2951 - loss: 3.4626 - val_accuracy: 0.4518 - val_loss: 2.7610 - learning_rate: 2.5974e-04
Epoch 11/300
785/785 - 90s - 115ms/step - accuracy: 0.3067 - loss: 3.3943 - val_accuracy: 0.4656 - val_loss: 2.7143 - learning_rate: 2.5974e-04
Epoch 12/300
785/785 - 93s - 118ms/step - accuracy: 0.3098 - loss: 3.3922 - val_accuracy: 0.4549 - val_loss: 2.6985 - learning_rate: 2.5974e-04
Epoch 13/300
785/785 - 94s - 120ms/step - accuracy: 0.3141 - loss: 3.3328 - val_accuracy: 0.4487 - val_loss: 2.6668 - learning_rate: 2.5974e-04
Epoch 14/300
785/785 - 94s - 120ms/step - accuracy: 0.3145 - loss: 3.3060 - val_accuracy: 0.4804 - val_loss: 2.6083 - learning_rate: 2.5974e-04
Epoch 15/300
785/785 - 93s - 118ms/step - accuracy: 0.3203 - loss: 3.3055 - val_accuracy: 0.4865 - val_loss: 2.5541 - learning_rate: 2.5974e-04
Epoch 16/300
785/785 - 90s - 114ms/step - accuracy: 0.3212 - loss: 3.2707 - val_accuracy: 0.4707 - val_loss: 2.5571 - learning_rate: 2.5974e-04
Epoch 17/300
785/785 - 91s - 116ms/step - accuracy: 0.3182 - loss: 3.2737 - val_accuracy: 0.4812 - val_loss: 2.5464 - learning_rate: 2.5974e-04
Epoch 18/300
785/785 - 91s - 116ms/step - accuracy: 0.3378 - loss: 3.2122 - val_accuracy: 0.4922 - val_loss: 2.4585 - learning_rate: 2.5974e-04
Epoch 19/300
785/785 - 92s - 117ms/step - accuracy: 0.3354 - loss: 3.2087 - val_accuracy: 0.5013 - val_loss: 2.4492 - learning_rate: 2.5974e-04
Epoch 20/300
785/785 - 92s - 118ms/step - accuracy: 0.3348 - loss: 3.2203 - val_accuracy: 0.5081 - val_loss: 2.4928 - learning_rate: 2.5974e-04
Epoch 21/300
785/785 - 95s - 121ms/step - accuracy: 0.3427 - loss: 3.1722 - val_accuracy: 0.5035 - val_loss: 2.3916 - learning_rate: 2.5974e-04
Epoch 22/300
785/785 - 95s - 121ms/step - accuracy: 0.3475 - loss: 3.1629 - val_accuracy: 0.5005 - val_loss: 2.4334 - learning_rate: 2.5974e-04
Epoch 23/300
785/785 - 91s - 116ms/step - accuracy: 0.3520 - loss: 3.1431 - val_accuracy: 0.4930 - val_loss: 2.4384 - learning_rate: 2.5974e-04
Epoch 24/300
785/785 - 141s - 180ms/step - accuracy: 0.3542 - loss: 3.1166 - val_accuracy: 0.5143 - val_loss: 2.3775 - learning_rate: 2.5974e-04
Epoch 25/300
785/785 - 90s - 115ms/step - accuracy: 0.3518 - loss: 3.1156 - val_accuracy: 0.5067 - val_loss: 2.3590 - learning_rate: 2.5974e-04
Epoch 26/300
785/785 - 143s - 183ms/step - accuracy: 0.3540 - loss: 3.1177 - val_accuracy: 0.5024 - val_loss: 2.3929 - learning_rate: 2.5974e-04
Epoch 27/300
785/785 - 92s - 117ms/step - accuracy: 0.3610 - loss: 3.0691 - val_accuracy: 0.5089 - val_loss: 2.3187 - learning_rate: 2.5974e-04
Epoch 28/300
785/785 - 94s - 120ms/step - accuracy: 0.3550 - loss: 3.0786 - val_accuracy: 0.5081 - val_loss: 2.3292 - learning_rate: 2.5974e-04
Epoch 29/300
785/785 - 91s - 116ms/step - accuracy: 0.3587 - loss: 3.0686 - val_accuracy: 0.5283 - val_loss: 2.2714 - learning_rate: 2.5974e-04
Epoch 30/300
785/785 - 92s - 117ms/step - accuracy: 0.3569 - loss: 3.0672 - val_accuracy: 0.5201 - val_loss: 2.2582 - learning_rate: 2.5974e-04
Epoch 31/300
785/785 - 92s - 117ms/step - accuracy: 0.3712 - loss: 3.0553 - val_accuracy: 0.5180 - val_loss: 2.3173 - learning_rate: 2.5974e-04
Epoch 32/300
785/785 - 90s - 114ms/step - accuracy: 0.3676 - loss: 3.0276 - val_accuracy: 0.5104 - val_loss: 2.3151 - learning_rate: 2.5974e-04
Epoch 33/300
785/785 - 92s - 117ms/step - accuracy: 0.3620 - loss: 3.0273 - val_accuracy: 0.5232 - val_loss: 2.2576 - learning_rate: 2.5974e-04
Epoch 34/300
785/785 - 96s - 122ms/step - accuracy: 0.3724 - loss: 3.0214 - val_accuracy: 0.5210 - val_loss: 2.3854 - learning_rate: 2.5974e-04
Epoch 35/300
785/785 - 92s - 118ms/step - accuracy: 0.3738 - loss: 3.0156 - val_accuracy: 0.5183 - val_loss: 2.2847 - learning_rate: 2.5974e-04
Epoch 36/300
785/785 - 97s - 123ms/step - accuracy: 0.3660 - loss: 3.0572 - val_accuracy: 0.5223 - val_loss: 2.2612 - learning_rate: 2.5974e-04
Epoch 37/300
785/785 - 94s - 120ms/step - accuracy: 0.3658 - loss: 3.0175 - val_accuracy: 0.5330 - val_loss: 2.2351 - learning_rate: 2.5974e-04
Epoch 38/300
785/785 - 94s - 120ms/step - accuracy: 0.3720 - loss: 3.0053 - val_accuracy: 0.5172 - val_loss: 2.2642 - learning_rate: 2.5974e-04
Epoch 39/300
785/785 - 95s - 121ms/step - accuracy: 0.3735 - loss: 3.0048 - val_accuracy: 0.5253 - val_loss: 2.2257 - learning_rate: 2.5974e-04
Epoch 40/300
785/785 - 143s - 182ms/step - accuracy: 0.3798 - loss: 3.0086 - val_accuracy: 0.5311 - val_loss: 2.2638 - learning_rate: 2.5974e-04
Epoch 41/300
785/785 - 96s - 122ms/step - accuracy: 0.3743 - loss: 3.0020 - val_accuracy: 0.5326 - val_loss: 2.2117 - learning_rate: 2.5974e-04
Epoch 42/300
785/785 - 92s - 117ms/step - accuracy: 0.3698 - loss: 2.9644 - val_accuracy: 0.5318 - val_loss: 2.2823 - learning_rate: 2.5974e-04
Epoch 43/300
785/785 - 144s - 183ms/step - accuracy: 0.3685 - loss: 2.9668 - val_accuracy: 0.5404 - val_loss: 2.2005 - learning_rate: 2.5974e-04
Epoch 44/300
785/785 - 95s - 120ms/step - accuracy: 0.3776 - loss: 3.0121 - val_accuracy: 0.5354 - val_loss: 2.1848 - learning_rate: 2.5974e-04
Epoch 45/300
785/785 - 93s - 119ms/step - accuracy: 0.3802 - loss: 2.9478 - val_accuracy: 0.5271 - val_loss: 2.2291 - learning_rate: 2.5974e-04
Epoch 46/300
785/785 - 91s - 116ms/step - accuracy: 0.3894 - loss: 2.9336 - val_accuracy: 0.5158 - val_loss: 2.2040 - learning_rate: 2.5974e-04
Epoch 47/300
785/785 - 92s - 117ms/step - accuracy: 0.3786 - loss: 2.9803 - val_accuracy: 0.5393 - val_loss: 2.2231 - learning_rate: 2.5974e-04
Epoch 48/300
785/785 - 142s - 182ms/step - accuracy: 0.3883 - loss: 2.9394 - val_accuracy: 0.5344 - val_loss: 2.2086 - learning_rate: 2.5974e-04
Epoch 49/300
785/785 - 93s - 118ms/step - accuracy: 0.3816 - loss: 2.9864 - val_accuracy: 0.5471 - val_loss: 2.1621 - learning_rate: 2.5974e-04
Epoch 50/300
785/785 - 91s - 116ms/step - accuracy: 0.3794 - loss: 2.9435 - val_accuracy: 0.5304 - val_loss: 2.2134 - learning_rate: 2.5974e-04
Epoch 51/300
785/785 - 93s - 119ms/step - accuracy: 0.3770 - loss: 2.9385 - val_accuracy: 0.5396 - val_loss: 2.2102 - learning_rate: 2.5974e-04
Epoch 52/300
785/785 - 92s - 117ms/step - accuracy: 0.3875 - loss: 2.9436 - val_accuracy: 0.5425 - val_loss: 2.1564 - learning_rate: 2.5974e-04
Epoch 53/300
785/785 - 91s - 116ms/step - accuracy: 0.3810 - loss: 2.9799 - val_accuracy: 0.5283 - val_loss: 2.1899 - learning_rate: 2.5974e-04
Epoch 54/300
785/785 - 90s - 115ms/step - accuracy: 0.3926 - loss: 2.9211 - val_accuracy: 0.5564 - val_loss: 2.1760 - learning_rate: 2.5974e-04
Epoch 55/300
785/785 - 87s - 111ms/step - accuracy: 0.3923 - loss: 2.9155 - val_accuracy: 0.5427 - val_loss: 2.1402 - learning_rate: 2.5974e-04
Epoch 56/300
785/785 - 90s - 114ms/step - accuracy: 0.3946 - loss: 2.9151 - val_accuracy: 0.5492 - val_loss: 2.1085 - learning_rate: 2.5974e-04
Epoch 57/300
785/785 - 92s - 117ms/step - accuracy: 0.3813 - loss: 2.9314 - val_accuracy: 0.5301 - val_loss: 2.1443 - learning_rate: 2.5974e-04
Epoch 58/300
785/785 - 93s - 118ms/step - accuracy: 0.3862 - loss: 2.9345 - val_accuracy: 0.5516 - val_loss: 2.1251 - learning_rate: 2.5974e-04
Epoch 59/300
785/785 - 94s - 120ms/step - accuracy: 0.3975 - loss: 2.8814 - val_accuracy: 0.5505 - val_loss: 2.1310 - learning_rate: 2.5974e-04
Epoch 60/300
785/785 - 95s - 121ms/step - accuracy: 0.3840 - loss: 2.9548 - val_accuracy: 0.5443 - val_loss: 2.1612 - learning_rate: 2.5974e-04
Epoch 61/300
785/785 - 92s - 118ms/step - accuracy: 0.3926 - loss: 2.9194 - val_accuracy: 0.5250 - val_loss: 2.2103 - learning_rate: 2.5974e-04
Epoch 62/300
785/785 - 93s - 119ms/step - accuracy: 0.3886 - loss: 2.8685 - val_accuracy: 0.5588 - val_loss: 2.1237 - learning_rate: 2.5974e-04
Epoch 63/300
785/785 - 92s - 117ms/step - accuracy: 0.4001 - loss: 2.8950 - val_accuracy: 0.5532 - val_loss: 2.0933 - learning_rate: 2.5974e-04
Epoch 64/300
785/785 - 94s - 119ms/step - accuracy: 0.3972 - loss: 2.9073 - val_accuracy: 0.5543 - val_loss: 2.1305 - learning_rate: 2.5974e-04
Epoch 65/300
785/785 - 97s - 124ms/step - accuracy: 0.3939 - loss: 2.9227 - val_accuracy: 0.5546 - val_loss: 2.1093 - learning_rate: 2.5974e-04
Epoch 66/300
785/785 - 93s - 118ms/step - accuracy: 0.3986 - loss: 2.9216 - val_accuracy: 0.5454 - val_loss: 2.1462 - learning_rate: 2.5974e-04
Epoch 67/300
785/785 - 141s - 179ms/step - accuracy: 0.3939 - loss: 2.8892 - val_accuracy: 0.5567 - val_loss: 2.1358 - learning_rate: 2.5974e-04
Epoch 68/300
785/785 - 93s - 118ms/step - accuracy: 0.3946 - loss: 2.8739 - val_accuracy: 0.5581 - val_loss: 2.0670 - learning_rate: 2.5974e-04
Epoch 69/300
785/785 - 93s - 118ms/step - accuracy: 0.3953 - loss: 2.8541 - val_accuracy: 0.5481 - val_loss: 2.0872 - learning_rate: 2.5974e-04
Epoch 70/300
785/785 - 95s - 121ms/step - accuracy: 0.3905 - loss: 2.8898 - val_accuracy: 0.5519 - val_loss: 2.1233 - learning_rate: 2.5974e-04
Epoch 71/300
785/785 - 92s - 117ms/step - accuracy: 0.4012 - loss: 2.8730 - val_accuracy: 0.5475 - val_loss: 2.1157 - learning_rate: 2.5974e-04
Epoch 72/300
785/785 - 89s - 113ms/step - accuracy: 0.4068 - loss: 2.8383 - val_accuracy: 0.5546 - val_loss: 2.1374 - learning_rate: 2.5974e-04
Epoch 73/300
785/785 - 88s - 113ms/step - accuracy: 0.4109 - loss: 2.8460 - val_accuracy: 0.5533 - val_loss: 2.0776 - learning_rate: 2.5974e-04
Epoch 74/300
785/785 - 90s - 115ms/step - accuracy: 0.3974 - loss: 2.8641 - val_accuracy: 0.5580 - val_loss: 2.0602 - learning_rate: 2.5974e-04
Epoch 75/300
785/785 - 90s - 115ms/step - accuracy: 0.3862 - loss: 2.8956 - val_accuracy: 0.5524 - val_loss: 2.1057 - learning_rate: 2.5974e-04
Epoch 76/300
785/785 - 91s - 116ms/step - accuracy: 0.3908 - loss: 2.8864 - val_accuracy: 0.5508 - val_loss: 2.0624 - learning_rate: 2.5974e-04
Epoch 77/300
785/785 - 92s - 118ms/step - accuracy: 0.3937 - loss: 2.8625 - val_accuracy: 0.5553 - val_loss: 2.0836 - learning_rate: 2.5974e-04
Epoch 78/300
785/785 - 139s - 177ms/step - accuracy: 0.3835 - loss: 2.9148 - val_accuracy: 0.5459 - val_loss: 2.1079 - learning_rate: 2.5974e-04
Epoch 79/300
785/785 - 143s - 182ms/step - accuracy: 0.3985 - loss: 2.8930 - val_accuracy: 0.5457 - val_loss: 2.1366 - learning_rate: 2.5974e-04
Epoch 80/300
785/785 - 94s - 120ms/step - accuracy: 0.3950 - loss: 2.8663 - val_accuracy: 0.5467 - val_loss: 2.1114 - learning_rate: 2.5974e-04
Epoch 81/300
785/785 - 90s - 115ms/step - accuracy: 0.3974 - loss: 2.8837 - val_accuracy: 0.5632 - val_loss: 2.0628 - learning_rate: 2.5974e-04
Epoch 82/300

Epoch 82: ReduceLROnPlateau reducing learning rate to 0.0001298690476687625.
785/785 - 93s - 118ms/step - accuracy: 0.3934 - loss: 2.8183 - val_accuracy: 0.5463 - val_loss: 2.0866 - learning_rate: 2.5974e-04
Epoch 83/300
785/785 - 141s - 180ms/step - accuracy: 0.4174 - loss: 2.7966 - val_accuracy: 0.5565 - val_loss: 2.0762 - learning_rate: 1.2987e-04
Epoch 84/300
785/785 - 91s - 116ms/step - accuracy: 0.4085 - loss: 2.7951 - val_accuracy: 0.5600 - val_loss: 2.0405 - learning_rate: 1.2987e-04
Epoch 85/300
785/785 - 91s - 116ms/step - accuracy: 0.4152 - loss: 2.7919 - val_accuracy: 0.5618 - val_loss: 2.0327 - learning_rate: 1.2987e-04
Epoch 86/300
785/785 - 93s - 118ms/step - accuracy: 0.4192 - loss: 2.7994 - val_accuracy: 0.5631 - val_loss: 2.0291 - learning_rate: 1.2987e-04
Epoch 87/300
785/785 - 94s - 120ms/step - accuracy: 0.4247 - loss: 2.7360 - val_accuracy: 0.5578 - val_loss: 2.0057 - learning_rate: 1.2987e-04
Epoch 88/300
785/785 - 93s - 118ms/step - accuracy: 0.4103 - loss: 2.7782 - val_accuracy: 0.5680 - val_loss: 2.0272 - learning_rate: 1.2987e-04
Epoch 89/300
785/785 - 91s - 116ms/step - accuracy: 0.3989 - loss: 2.8122 - val_accuracy: 0.5646 - val_loss: 2.0386 - learning_rate: 1.2987e-04
Epoch 90/300
785/785 - 90s - 114ms/step - accuracy: 0.4224 - loss: 2.7368 - val_accuracy: 0.5662 - val_loss: 2.0233 - learning_rate: 1.2987e-04
Epoch 91/300
785/785 - 91s - 116ms/step - accuracy: 0.4158 - loss: 2.7765 - val_accuracy: 0.5650 - val_loss: 2.0117 - learning_rate: 1.2987e-04
Epoch 92/300
785/785 - 92s - 118ms/step - accuracy: 0.4255 - loss: 2.7470 - val_accuracy: 0.5648 - val_loss: 2.0106 - learning_rate: 1.2987e-04
Epoch 93/300
785/785 - 92s - 118ms/step - accuracy: 0.4240 - loss: 2.7644 - val_accuracy: 0.5645 - val_loss: 2.0298 - learning_rate: 1.2987e-04
Epoch 94/300
785/785 - 96s - 123ms/step - accuracy: 0.4189 - loss: 2.7383 - val_accuracy: 0.5635 - val_loss: 1.9893 - learning_rate: 1.2987e-04
Epoch 95/300
785/785 - 89s - 113ms/step - accuracy: 0.4254 - loss: 2.7506 - val_accuracy: 0.5648 - val_loss: 2.0110 - learning_rate: 1.2987e-04
Epoch 96/300
785/785 - 89s - 114ms/step - accuracy: 0.4134 - loss: 2.7499 - val_accuracy: 0.5551 - val_loss: 2.0267 - learning_rate: 1.2987e-04
Epoch 97/300
785/785 - 89s - 114ms/step - accuracy: 0.4109 - loss: 2.8010 - val_accuracy: 0.5648 - val_loss: 2.0238 - learning_rate: 1.2987e-04
Epoch 98/300
785/785 - 90s - 115ms/step - accuracy: 0.4146 - loss: 2.7726 - val_accuracy: 0.5626 - val_loss: 2.0153 - learning_rate: 1.2987e-04
Epoch 99/300
785/785 - 90s - 115ms/step - accuracy: 0.4204 - loss: 2.7635 - val_accuracy: 0.5718 - val_loss: 2.0145 - learning_rate: 1.2987e-04
Epoch 100/300
785/785 - 92s - 117ms/step - accuracy: 0.4103 - loss: 2.7447 - val_accuracy: 0.5699 - val_loss: 2.0062 - learning_rate: 1.2987e-04
Epoch 101/300
785/785 - 144s - 184ms/step - accuracy: 0.4160 - loss: 2.7652 - val_accuracy: 0.5686 - val_loss: 1.9952 - learning_rate: 1.2987e-04
Epoch 102/300

Epoch 102: ReduceLROnPlateau reducing learning rate to 6.493452383438125e-05.
785/785 - 91s - 116ms/step - accuracy: 0.4198 - loss: 2.7688 - val_accuracy: 0.5642 - val_loss: 2.0191 - learning_rate: 1.2987e-04
Epoch 103/300
785/785 - 91s - 116ms/step - accuracy: 0.4338 - loss: 2.6939 - val_accuracy: 0.5705 - val_loss: 1.9970 - learning_rate: 6.4935e-05
Epoch 104/300
785/785 - 91s - 116ms/step - accuracy: 0.4359 - loss: 2.7012 - val_accuracy: 0.5682 - val_loss: 1.9848 - learning_rate: 6.4935e-05
Epoch 105/300
785/785 - 93s - 118ms/step - accuracy: 0.4354 - loss: 2.6802 - val_accuracy: 0.5744 - val_loss: 1.9818 - learning_rate: 6.4935e-05
Epoch 106/300
785/785 - 92s - 118ms/step - accuracy: 0.4155 - loss: 2.7372 - val_accuracy: 0.5737 - val_loss: 1.9744 - learning_rate: 6.4935e-05
Epoch 107/300
785/785 - 90s - 115ms/step - accuracy: 0.4281 - loss: 2.7233 - val_accuracy: 0.5740 - val_loss: 1.9852 - learning_rate: 6.4935e-05
Epoch 108/300
785/785 - 92s - 117ms/step - accuracy: 0.4316 - loss: 2.7266 - val_accuracy: 0.5713 - val_loss: 1.9870 - learning_rate: 6.4935e-05
Epoch 109/300
785/785 - 91s - 116ms/step - accuracy: 0.4319 - loss: 2.6903 - val_accuracy: 0.5661 - val_loss: 1.9837 - learning_rate: 6.4935e-05
Epoch 110/300
785/785 - 86s - 109ms/step - accuracy: 0.4351 - loss: 2.6684 - val_accuracy: 0.5686 - val_loss: 1.9632 - learning_rate: 6.4935e-05
Epoch 111/300
785/785 - 92s - 118ms/step - accuracy: 0.4240 - loss: 2.6998 - val_accuracy: 0.5670 - val_loss: 1.9939 - learning_rate: 6.4935e-05
Epoch 112/300
785/785 - 93s - 118ms/step - accuracy: 0.4236 - loss: 2.7209 - val_accuracy: 0.5683 - val_loss: 1.9982 - learning_rate: 6.4935e-05
Epoch 113/300
785/785 - 90s - 114ms/step - accuracy: 0.4246 - loss: 2.7279 - val_accuracy: 0.5621 - val_loss: 1.9850 - learning_rate: 6.4935e-05
Epoch 114/300
785/785 - 87s - 111ms/step - accuracy: 0.4252 - loss: 2.7076 - val_accuracy: 0.5678 - val_loss: 1.9930 - learning_rate: 6.4935e-05
Epoch 115/300
785/785 - 85s - 108ms/step - accuracy: 0.4343 - loss: 2.6951 - val_accuracy: 0.5723 - val_loss: 1.9796 - learning_rate: 6.4935e-05
Epoch 116/300
785/785 - 87s - 110ms/step - accuracy: 0.4276 - loss: 2.6990 - val_accuracy: 0.5624 - val_loss: 1.9691 - learning_rate: 6.4935e-05
Epoch 117/300
785/785 - 86s - 109ms/step - accuracy: 0.4318 - loss: 2.6850 - val_accuracy: 0.5651 - val_loss: 1.9721 - learning_rate: 6.4935e-05
Epoch 118/300

Epoch 118: ReduceLROnPlateau reducing learning rate to 3.2467261917190626e-05.
785/785 - 86s - 110ms/step - accuracy: 0.4337 - loss: 2.6789 - val_accuracy: 0.5691 - val_loss: 1.9928 - learning_rate: 6.4935e-05
Epoch 119/300
785/785 - 87s - 111ms/step - accuracy: 0.4254 - loss: 2.7101 - val_accuracy: 0.5678 - val_loss: 1.9670 - learning_rate: 3.2467e-05
Epoch 120/300
785/785 - 90s - 114ms/step - accuracy: 0.4434 - loss: 2.6450 - val_accuracy: 0.5740 - val_loss: 1.9578 - learning_rate: 3.2467e-05
Epoch 121/300
785/785 - 88s - 113ms/step - accuracy: 0.4359 - loss: 2.6643 - val_accuracy: 0.5697 - val_loss: 1.9553 - learning_rate: 3.2467e-05
Epoch 122/300
785/785 - 91s - 116ms/step - accuracy: 0.4362 - loss: 2.6622 - val_accuracy: 0.5707 - val_loss: 1.9669 - learning_rate: 3.2467e-05
Epoch 123/300
785/785 - 138s - 176ms/step - accuracy: 0.4337 - loss: 2.6526 - val_accuracy: 0.5712 - val_loss: 1.9774 - learning_rate: 3.2467e-05
Epoch 124/300
785/785 - 92s - 117ms/step - accuracy: 0.4322 - loss: 2.6724 - val_accuracy: 0.5740 - val_loss: 1.9675 - learning_rate: 3.2467e-05
Epoch 125/300
785/785 - 87s - 111ms/step - accuracy: 0.4329 - loss: 2.6872 - val_accuracy: 0.5729 - val_loss: 1.9594 - learning_rate: 3.2467e-05
Epoch 126/300
785/785 - 87s - 111ms/step - accuracy: 0.4359 - loss: 2.6522 - val_accuracy: 0.5736 - val_loss: 1.9589 - learning_rate: 3.2467e-05
Epoch 127/300
785/785 - 88s - 112ms/step - accuracy: 0.4362 - loss: 2.6783 - val_accuracy: 0.5764 - val_loss: 1.9705 - learning_rate: 3.2467e-05
Epoch 128/300
785/785 - 89s - 114ms/step - accuracy: 0.4273 - loss: 2.7054 - val_accuracy: 0.5702 - val_loss: 1.9601 - learning_rate: 3.2467e-05
Epoch 129/300
785/785 - 90s - 114ms/step - accuracy: 0.4333 - loss: 2.6451 - val_accuracy: 0.5729 - val_loss: 1.9503 - learning_rate: 3.2467e-05
Epoch 130/300
785/785 - 90s - 114ms/step - accuracy: 0.4294 - loss: 2.6844 - val_accuracy: 0.5707 - val_loss: 1.9673 - learning_rate: 3.2467e-05
Epoch 131/300
785/785 - 88s - 112ms/step - accuracy: 0.4295 - loss: 2.6489 - val_accuracy: 0.5744 - val_loss: 1.9613 - learning_rate: 3.2467e-05
Epoch 132/300
785/785 - 88s - 112ms/step - accuracy: 0.4348 - loss: 2.6910 - val_accuracy: 0.5731 - val_loss: 1.9624 - learning_rate: 3.2467e-05
Epoch 133/300
785/785 - 143s - 183ms/step - accuracy: 0.4289 - loss: 2.6708 - val_accuracy: 0.5745 - val_loss: 1.9596 - learning_rate: 3.2467e-05
Epoch 134/300
785/785 - 89s - 114ms/step - accuracy: 0.4302 - loss: 2.6783 - val_accuracy: 0.5748 - val_loss: 1.9630 - learning_rate: 3.2467e-05
Epoch 135/300
785/785 - 89s - 113ms/step - accuracy: 0.4367 - loss: 2.6969 - val_accuracy: 0.5728 - val_loss: 1.9557 - learning_rate: 3.2467e-05
Epoch 136/300
785/785 - 90s - 114ms/step - accuracy: 0.4392 - loss: 2.6313 - val_accuracy: 0.5717 - val_loss: 1.9593 - learning_rate: 3.2467e-05
Epoch 137/300

Epoch 137: ReduceLROnPlateau reducing learning rate to 1.6233630958595313e-05.
785/785 - 89s - 113ms/step - accuracy: 0.4367 - loss: 2.6564 - val_accuracy: 0.5771 - val_loss: 1.9620 - learning_rate: 3.2467e-05
Epoch 138/300
785/785 - 88s - 112ms/step - accuracy: 0.4353 - loss: 2.6459 - val_accuracy: 0.5713 - val_loss: 1.9529 - learning_rate: 1.6234e-05
Epoch 139/300
785/785 - 86s - 110ms/step - accuracy: 0.4461 - loss: 2.6426 - val_accuracy: 0.5750 - val_loss: 1.9509 - learning_rate: 1.6234e-05
Epoch 140/300
785/785 - 91s - 115ms/step - accuracy: 0.4324 - loss: 2.6384 - val_accuracy: 0.5740 - val_loss: 1.9483 - learning_rate: 1.6234e-05
Epoch 141/300
785/785 - 91s - 116ms/step - accuracy: 0.4321 - loss: 2.6475 - val_accuracy: 0.5769 - val_loss: 1.9470 - learning_rate: 1.6234e-05
Epoch 142/300
785/785 - 94s - 120ms/step - accuracy: 0.4348 - loss: 2.6857 - val_accuracy: 0.5761 - val_loss: 1.9548 - learning_rate: 1.6234e-05
Epoch 143/300
785/785 - 86s - 110ms/step - accuracy: 0.4381 - loss: 2.6698 - val_accuracy: 0.5742 - val_loss: 1.9587 - learning_rate: 1.6234e-05
Epoch 144/300
785/785 - 90s - 115ms/step - accuracy: 0.4437 - loss: 2.6452 - val_accuracy: 0.5758 - val_loss: 1.9416 - learning_rate: 1.6234e-05
Epoch 145/300
785/785 - 89s - 113ms/step - accuracy: 0.4397 - loss: 2.6654 - val_accuracy: 0.5745 - val_loss: 1.9467 - learning_rate: 1.6234e-05
Epoch 146/300
785/785 - 90s - 114ms/step - accuracy: 0.4267 - loss: 2.6516 - val_accuracy: 0.5764 - val_loss: 1.9541 - learning_rate: 1.6234e-05
Epoch 147/300
785/785 - 145s - 185ms/step - accuracy: 0.4373 - loss: 2.6465 - val_accuracy: 0.5742 - val_loss: 1.9501 - learning_rate: 1.6234e-05
Epoch 148/300
785/785 - 90s - 115ms/step - accuracy: 0.4357 - loss: 2.6358 - val_accuracy: 0.5755 - val_loss: 1.9459 - learning_rate: 1.6234e-05
Epoch 149/300
785/785 - 141s - 179ms/step - accuracy: 0.4445 - loss: 2.6203 - val_accuracy: 0.5761 - val_loss: 1.9401 - learning_rate: 1.6234e-05
Epoch 150/300
785/785 - 90s - 114ms/step - accuracy: 0.4326 - loss: 2.6302 - val_accuracy: 0.5753 - val_loss: 1.9523 - learning_rate: 1.6234e-05
Epoch 151/300
785/785 - 90s - 114ms/step - accuracy: 0.4365 - loss: 2.6514 - val_accuracy: 0.5729 - val_loss: 1.9358 - learning_rate: 1.6234e-05
Epoch 152/300
785/785 - 88s - 113ms/step - accuracy: 0.4413 - loss: 2.6352 - val_accuracy: 0.5772 - val_loss: 1.9462 - learning_rate: 1.6234e-05
Epoch 153/300
785/785 - 87s - 111ms/step - accuracy: 0.4302 - loss: 2.6911 - val_accuracy: 0.5758 - val_loss: 1.9523 - learning_rate: 1.6234e-05
Epoch 154/300
785/785 - 89s - 113ms/step - accuracy: 0.4322 - loss: 2.6896 - val_accuracy: 0.5764 - val_loss: 1.9462 - learning_rate: 1.6234e-05
Epoch 155/300
785/785 - 89s - 113ms/step - accuracy: 0.4410 - loss: 2.6354 - val_accuracy: 0.5763 - val_loss: 1.9394 - learning_rate: 1.6234e-05
Epoch 156/300
785/785 - 90s - 114ms/step - accuracy: 0.4364 - loss: 2.6574 - val_accuracy: 0.5761 - val_loss: 1.9382 - learning_rate: 1.6234e-05
Epoch 157/300
785/785 - 87s - 111ms/step - accuracy: 0.4389 - loss: 2.6544 - val_accuracy: 0.5737 - val_loss: 1.9469 - learning_rate: 1.6234e-05
Epoch 158/300
785/785 - 89s - 113ms/step - accuracy: 0.4424 - loss: 2.6673 - val_accuracy: 0.5777 - val_loss: 1.9379 - learning_rate: 1.6234e-05
Epoch 159/300

Epoch 159: ReduceLROnPlateau reducing learning rate to 8.116815479297657e-06.
785/785 - 90s - 114ms/step - accuracy: 0.4300 - loss: 2.6873 - val_accuracy: 0.5774 - val_loss: 1.9472 - learning_rate: 1.6234e-05
Epoch 160/300
785/785 - 88s - 113ms/step - accuracy: 0.4448 - loss: 2.6184 - val_accuracy: 0.5791 - val_loss: 1.9408 - learning_rate: 8.1168e-06
Epoch 161/300
785/785 - 90s - 115ms/step - accuracy: 0.4341 - loss: 2.6579 - val_accuracy: 0.5761 - val_loss: 1.9482 - learning_rate: 8.1168e-06
Epoch 162/300
785/785 - 95s - 121ms/step - accuracy: 0.4351 - loss: 2.6487 - val_accuracy: 0.5755 - val_loss: 1.9475 - learning_rate: 8.1168e-06
Epoch 163/300
785/785 - 89s - 114ms/step - accuracy: 0.4416 - loss: 2.6301 - val_accuracy: 0.5755 - val_loss: 1.9461 - learning_rate: 8.1168e-06
Epoch 164/300
785/785 - 89s - 113ms/step - accuracy: 0.4442 - loss: 2.6504 - val_accuracy: 0.5766 - val_loss: 1.9392 - learning_rate: 8.1168e-06
Epoch 165/300
785/785 - 88s - 112ms/step - accuracy: 0.4373 - loss: 2.6421 - val_accuracy: 0.5760 - val_loss: 1.9376 - learning_rate: 8.1168e-06
Epoch 166/300
785/785 - 88s - 112ms/step - accuracy: 0.4418 - loss: 2.6394 - val_accuracy: 0.5764 - val_loss: 1.9403 - learning_rate: 8.1168e-06
Epoch 167/300

Epoch 167: ReduceLROnPlateau reducing learning rate to 4.058407739648828e-06.
785/785 - 88s - 112ms/step - accuracy: 0.4402 - loss: 2.6555 - val_accuracy: 0.5744 - val_loss: 1.9470 - learning_rate: 8.1168e-06
Epoch 167: early stopping
Restoring model weights from the end of the best epoch: 151.
Fold 3_1 Evaluation results: [1.9412965774536133, 0.5729299187660217]
              precision    recall  f1-score   support

        1820       0.69      0.75      0.72       306
        1821       0.88      0.88      0.88       294
        1822       0.00      0.00      0.00         8
        1823       0.00      0.00      0.00         5
        1824       0.00      0.00      0.00         7
        1825       0.00      0.00      0.00        12
        1826       0.00      0.00      0.00         9
        1827       0.64      0.73      0.68       131
        1828       0.00      0.00      0.00        12
        1829       0.00      0.00      0.00        27
        1830       0.51      0.64      0.57       294
        1831       0.76      0.90      0.82       647
        1832       0.75      0.68      0.71       337
        1833       0.75      0.91      0.82       103
        1834       0.34      0.57      0.42       138
        1835       0.00      0.00      0.00        12
        1836       0.00      0.00      0.00        20
        1837       0.23      0.23      0.23        26
        1838       0.00      0.00      0.00        17
        1839       0.00      0.00      0.00         4
        1840       0.42      0.59      0.49       200
        1841       0.72      0.53      0.61       541
        1842       1.00      0.13      0.24        30
        1843       0.00      0.00      0.00        33
        1844       0.00      0.00      0.00         0
        1845       0.00      0.00      0.00         8
        1846       0.75      0.09      0.17        32
        1847       0.00      0.00      0.00        11
        1848       0.11      0.07      0.09        27
        1849       0.00      0.00      0.00        34
        1850       0.34      0.62      0.44       236
        1851       0.72      0.65      0.69       390
        1852       0.00      0.00      0.00        34
        1853       1.00      0.07      0.13        29
        1854       0.00      0.00      0.00        11
        1855       0.33      0.01      0.02       117
        1856       0.60      0.47      0.52        60
        1857       0.36      0.67      0.47       161
        1858       0.00      0.00      0.00        10
        1859       0.00      0.00      0.00        12
        1860       0.29      0.32      0.31       343
        1861       0.74      0.80      0.77       434
        1862       0.21      0.09      0.13        95
        1863       0.37      0.47      0.41       104
        1864       0.27      0.38      0.32        74
        1865       0.50      0.06      0.11        32
        1866       0.67      0.09      0.16        22
        1867       0.29      0.15      0.20        39
        1868       0.00      0.00      0.00        33
        1869       0.00      0.00      0.00        35
        1870       0.31      0.59      0.41       133
        1871       0.65      0.76      0.70       220
        1872       0.00      0.00      0.00        48
        1873       0.00      0.00      0.00        52
        1874       0.00      0.00      0.00        25
        1875       0.32      0.25      0.28        75
        1876       0.92      0.90      0.91        50
        1877       0.33      0.17      0.22        30
        1878       0.46      0.27      0.34        45
        1879       0.00      0.00      0.00         6

    accuracy                           0.57      6280
   macro avg       0.30      0.26      0.25      6280
weighted avg       0.55      0.57      0.54      6280

Matthews Correlation Coefficient: 0.552
Macro avg F1: 0.250
Weighted avg F1: 0.544
Micro avg F1: 0.573
Top-3 Accuracy: 0.819
Top-5 Accuracy: 0.881
Micro ROC AUC  = 0.98
Macro ROC AUC (present classes) = 0.97
Classification MAE (in years): 3.43

Fold 3_1 Misclassification Analysis:
Near misses (within 2 years): 595 out of 2682 misclassifications (22.18%)
Big misses (greater than 10 years): 1061
MAE with outliers: 3.43
MAE without outliers: 2.47 (improvement: 0.96)

10 Worst misclassifications:
Image: data/datasets/public/1870/1877_033met.jpg, True: 1877, Predicted: 1820, Error: 57
Image: data/datasets/public/1820/1820_6wikimedia2.jpg, True: 1820, Predicted: 1876, Error: 56
Image: data/datasets/private/1820/1820_034_Zrzut ekranu 2022-07-26 203655.png, True: 1820, Predicted: 1871, Error: 51
Image: data/datasets/private/1870/1871_384etsy.jpg, True: 1871, Predicted: 1821, Error: 50
Image: data/datasets/private/1870/1871_358etsy.jpg, True: 1871, Predicted: 1821, Error: 50
Image: data/datasets/public/1870/1870_75wikimedia2.jpg, True: 1870, Predicted: 1820, Error: 50
Image: data/datasets/public/1860/1868_007met.jpg, True: 1868, Predicted: 1820, Error: 48
Image: data/datasets/public/1870/1878_1258vna.jpg, True: 1878, Predicted: 1832, Error: 46
Image: data/datasets/public/1870/1876_1953vna.jpg, True: 1876, Predicted: 1832, Error: 44
Image: data/datasets/public/1870/1876_53washington.jpg, True: 1876, Predicted: 1832, Error: 44

===== Fine Tuning 9 layers! =====
Epoch 1/300
785/785 - 113s - 145ms/step - accuracy: 0.1099 - loss: 4.4487 - val_accuracy: 0.2305 - val_loss: 4.3496 - learning_rate: 2.5974e-04
Epoch 2/300
785/785 - 89s - 113ms/step - accuracy: 0.1705 - loss: 4.1088 - val_accuracy: 0.2663 - val_loss: 3.6935 - learning_rate: 2.5974e-04
Epoch 3/300
785/785 - 90s - 115ms/step - accuracy: 0.1881 - loss: 3.9803 - val_accuracy: 0.2864 - val_loss: 3.5225 - learning_rate: 2.5974e-04
Epoch 4/300
785/785 - 91s - 116ms/step - accuracy: 0.2223 - loss: 3.8436 - val_accuracy: 0.3677 - val_loss: 3.3489 - learning_rate: 2.5974e-04
Epoch 5/300
785/785 - 141s - 179ms/step - accuracy: 0.2344 - loss: 3.7272 - val_accuracy: 0.3599 - val_loss: 3.0648 - learning_rate: 2.5974e-04
Epoch 6/300
785/785 - 90s - 115ms/step - accuracy: 0.2503 - loss: 3.6633 - val_accuracy: 0.4029 - val_loss: 3.0150 - learning_rate: 2.5974e-04
Epoch 7/300
785/785 - 89s - 114ms/step - accuracy: 0.2584 - loss: 3.5826 - val_accuracy: 0.4302 - val_loss: 2.8528 - learning_rate: 2.5974e-04
Epoch 8/300
785/785 - 90s - 114ms/step - accuracy: 0.2607 - loss: 3.5629 - val_accuracy: 0.4330 - val_loss: 2.8260 - learning_rate: 2.5974e-04
Epoch 9/300
785/785 - 89s - 113ms/step - accuracy: 0.2785 - loss: 3.4813 - val_accuracy: 0.4308 - val_loss: 2.7683 - learning_rate: 2.5974e-04
Epoch 10/300
785/785 - 88s - 113ms/step - accuracy: 0.2826 - loss: 3.4494 - val_accuracy: 0.4563 - val_loss: 2.7869 - learning_rate: 2.5974e-04
Epoch 11/300
785/785 - 90s - 114ms/step - accuracy: 0.2947 - loss: 3.4109 - val_accuracy: 0.4741 - val_loss: 2.6575 - learning_rate: 2.5974e-04
Epoch 12/300
785/785 - 90s - 114ms/step - accuracy: 0.2971 - loss: 3.3843 - val_accuracy: 0.4615 - val_loss: 2.6529 - learning_rate: 2.5974e-04
Epoch 13/300
785/785 - 91s - 116ms/step - accuracy: 0.3049 - loss: 3.3110 - val_accuracy: 0.4744 - val_loss: 2.6028 - learning_rate: 2.5974e-04
Epoch 14/300
785/785 - 140s - 179ms/step - accuracy: 0.3038 - loss: 3.3456 - val_accuracy: 0.4775 - val_loss: 2.4871 - learning_rate: 2.5974e-04
Epoch 15/300
785/785 - 90s - 115ms/step - accuracy: 0.3151 - loss: 3.2700 - val_accuracy: 0.4861 - val_loss: 2.5246 - learning_rate: 2.5974e-04
Epoch 16/300
785/785 - 90s - 114ms/step - accuracy: 0.3189 - loss: 3.2907 - val_accuracy: 0.5014 - val_loss: 2.5222 - learning_rate: 2.5974e-04
Epoch 17/300
785/785 - 89s - 113ms/step - accuracy: 0.3231 - loss: 3.2372 - val_accuracy: 0.4907 - val_loss: 2.4064 - learning_rate: 2.5974e-04
Epoch 18/300
785/785 - 90s - 115ms/step - accuracy: 0.3283 - loss: 3.2370 - val_accuracy: 0.4924 - val_loss: 2.4277 - learning_rate: 2.5974e-04
Epoch 19/300
785/785 - 90s - 114ms/step - accuracy: 0.3296 - loss: 3.2463 - val_accuracy: 0.4939 - val_loss: 2.3926 - learning_rate: 2.5974e-04
Epoch 20/300
785/785 - 90s - 114ms/step - accuracy: 0.3339 - loss: 3.1867 - val_accuracy: 0.5109 - val_loss: 2.4153 - learning_rate: 2.5974e-04
Epoch 21/300
785/785 - 88s - 112ms/step - accuracy: 0.3328 - loss: 3.1921 - val_accuracy: 0.5076 - val_loss: 2.4050 - learning_rate: 2.5974e-04
Epoch 22/300
785/785 - 89s - 113ms/step - accuracy: 0.3479 - loss: 3.1670 - val_accuracy: 0.5259 - val_loss: 2.3312 - learning_rate: 2.5974e-04
Epoch 23/300
785/785 - 90s - 115ms/step - accuracy: 0.3500 - loss: 3.1384 - val_accuracy: 0.5136 - val_loss: 2.3423 - learning_rate: 2.5974e-04
Epoch 24/300
785/785 - 89s - 114ms/step - accuracy: 0.3373 - loss: 3.1460 - val_accuracy: 0.5108 - val_loss: 2.3180 - learning_rate: 2.5974e-04
Epoch 25/300
785/785 - 89s - 113ms/step - accuracy: 0.3427 - loss: 3.1153 - val_accuracy: 0.5257 - val_loss: 2.2769 - learning_rate: 2.5974e-04
Epoch 26/300
785/785 - 88s - 112ms/step - accuracy: 0.3455 - loss: 3.1012 - val_accuracy: 0.5350 - val_loss: 2.2935 - learning_rate: 2.5974e-04
Epoch 27/300
785/785 - 89s - 113ms/step - accuracy: 0.3433 - loss: 3.1214 - val_accuracy: 0.5219 - val_loss: 2.3112 - learning_rate: 2.5974e-04
Epoch 28/300
785/785 - 91s - 115ms/step - accuracy: 0.3529 - loss: 3.1094 - val_accuracy: 0.5225 - val_loss: 2.2354 - learning_rate: 2.5974e-04
Epoch 29/300
785/785 - 90s - 115ms/step - accuracy: 0.3564 - loss: 3.0960 - val_accuracy: 0.5224 - val_loss: 2.2007 - learning_rate: 2.5974e-04
Epoch 30/300
785/785 - 89s - 113ms/step - accuracy: 0.3470 - loss: 3.1063 - val_accuracy: 0.5272 - val_loss: 2.2648 - learning_rate: 2.5974e-04
Epoch 31/300
785/785 - 144s - 183ms/step - accuracy: 0.3518 - loss: 3.0933 - val_accuracy: 0.5370 - val_loss: 2.2672 - learning_rate: 2.5974e-04
Epoch 32/300
785/785 - 89s - 113ms/step - accuracy: 0.3463 - loss: 3.1035 - val_accuracy: 0.5424 - val_loss: 2.2484 - learning_rate: 2.5974e-04
Epoch 33/300
785/785 - 90s - 114ms/step - accuracy: 0.3646 - loss: 3.0473 - val_accuracy: 0.4939 - val_loss: 2.2750 - learning_rate: 2.5974e-04
Epoch 34/300
785/785 - 89s - 114ms/step - accuracy: 0.3607 - loss: 3.0354 - val_accuracy: 0.5345 - val_loss: 2.2176 - learning_rate: 2.5974e-04
Epoch 35/300
785/785 - 91s - 116ms/step - accuracy: 0.3666 - loss: 3.0441 - val_accuracy: 0.5380 - val_loss: 2.1900 - learning_rate: 2.5974e-04
Epoch 36/300
785/785 - 89s - 113ms/step - accuracy: 0.3597 - loss: 3.0344 - val_accuracy: 0.5496 - val_loss: 2.1420 - learning_rate: 2.5974e-04
Epoch 37/300
785/785 - 87s - 111ms/step - accuracy: 0.3643 - loss: 3.0313 - val_accuracy: 0.5375 - val_loss: 2.1559 - learning_rate: 2.5974e-04
Epoch 38/300
785/785 - 88s - 112ms/step - accuracy: 0.3511 - loss: 3.0312 - val_accuracy: 0.5272 - val_loss: 2.1867 - learning_rate: 2.5974e-04
Epoch 39/300
785/785 - 90s - 114ms/step - accuracy: 0.3651 - loss: 3.0358 - val_accuracy: 0.5483 - val_loss: 2.1260 - learning_rate: 2.5974e-04
Epoch 40/300
785/785 - 90s - 115ms/step - accuracy: 0.3661 - loss: 3.0561 - val_accuracy: 0.5257 - val_loss: 2.1969 - learning_rate: 2.5974e-04
Epoch 41/300
785/785 - 89s - 114ms/step - accuracy: 0.3702 - loss: 2.9948 - val_accuracy: 0.5413 - val_loss: 2.1258 - learning_rate: 2.5974e-04
Epoch 42/300
785/785 - 89s - 114ms/step - accuracy: 0.3758 - loss: 2.9954 - val_accuracy: 0.5479 - val_loss: 2.1037 - learning_rate: 2.5974e-04
Epoch 43/300
785/785 - 89s - 114ms/step - accuracy: 0.3736 - loss: 2.9917 - val_accuracy: 0.5467 - val_loss: 2.1375 - learning_rate: 2.5974e-04
Epoch 44/300
785/785 - 90s - 115ms/step - accuracy: 0.3729 - loss: 2.9808 - val_accuracy: 0.5456 - val_loss: 2.1747 - learning_rate: 2.5974e-04
Epoch 45/300
785/785 - 95s - 121ms/step - accuracy: 0.3771 - loss: 2.9564 - val_accuracy: 0.5588 - val_loss: 2.1217 - learning_rate: 2.5974e-04
Epoch 46/300
785/785 - 90s - 114ms/step - accuracy: 0.3747 - loss: 2.9789 - val_accuracy: 0.5598 - val_loss: 2.1508 - learning_rate: 2.5974e-04
Epoch 47/300
785/785 - 89s - 113ms/step - accuracy: 0.3728 - loss: 3.0116 - val_accuracy: 0.5452 - val_loss: 2.1576 - learning_rate: 2.5974e-04
Epoch 48/300
785/785 - 91s - 115ms/step - accuracy: 0.3788 - loss: 2.9749 - val_accuracy: 0.5614 - val_loss: 2.0836 - learning_rate: 2.5974e-04
Epoch 49/300
785/785 - 88s - 112ms/step - accuracy: 0.3669 - loss: 3.0075 - val_accuracy: 0.5584 - val_loss: 2.1030 - learning_rate: 2.5974e-04
Epoch 50/300
785/785 - 89s - 114ms/step - accuracy: 0.3788 - loss: 2.9493 - val_accuracy: 0.5447 - val_loss: 2.1232 - learning_rate: 2.5974e-04
Epoch 51/300
785/785 - 88s - 113ms/step - accuracy: 0.3871 - loss: 2.9593 - val_accuracy: 0.5416 - val_loss: 2.1317 - learning_rate: 2.5974e-04
Epoch 52/300
785/785 - 89s - 114ms/step - accuracy: 0.3817 - loss: 2.9722 - val_accuracy: 0.5528 - val_loss: 2.0729 - learning_rate: 2.5974e-04
Epoch 53/300
785/785 - 90s - 114ms/step - accuracy: 0.3806 - loss: 2.9373 - val_accuracy: 0.5531 - val_loss: 2.1289 - learning_rate: 2.5974e-04
Epoch 54/300
785/785 - 88s - 112ms/step - accuracy: 0.3815 - loss: 2.9557 - val_accuracy: 0.5686 - val_loss: 2.1015 - learning_rate: 2.5974e-04
Epoch 55/300
785/785 - 89s - 113ms/step - accuracy: 0.3747 - loss: 2.9515 - val_accuracy: 0.5601 - val_loss: 2.1048 - learning_rate: 2.5974e-04
Epoch 56/300
785/785 - 90s - 115ms/step - accuracy: 0.3693 - loss: 2.9748 - val_accuracy: 0.5694 - val_loss: 2.0797 - learning_rate: 2.5974e-04
Epoch 57/300
785/785 - 89s - 114ms/step - accuracy: 0.3795 - loss: 2.9403 - val_accuracy: 0.5652 - val_loss: 2.0504 - learning_rate: 2.5974e-04
Epoch 58/300
785/785 - 91s - 116ms/step - accuracy: 0.3696 - loss: 2.9454 - val_accuracy: 0.5657 - val_loss: 2.0409 - learning_rate: 2.5974e-04
Epoch 59/300
785/785 - 90s - 114ms/step - accuracy: 0.3866 - loss: 2.9134 - val_accuracy: 0.5668 - val_loss: 2.0467 - learning_rate: 2.5974e-04
Epoch 60/300
785/785 - 89s - 114ms/step - accuracy: 0.3807 - loss: 2.9542 - val_accuracy: 0.5686 - val_loss: 2.0429 - learning_rate: 2.5974e-04
Epoch 61/300
785/785 - 89s - 114ms/step - accuracy: 0.3825 - loss: 2.9252 - val_accuracy: 0.5600 - val_loss: 2.0785 - learning_rate: 2.5974e-04
Epoch 62/300
785/785 - 88s - 112ms/step - accuracy: 0.3822 - loss: 2.9317 - val_accuracy: 0.5499 - val_loss: 2.0618 - learning_rate: 2.5974e-04
Epoch 63/300
785/785 - 90s - 115ms/step - accuracy: 0.3871 - loss: 2.9046 - val_accuracy: 0.5467 - val_loss: 2.1108 - learning_rate: 2.5974e-04
Epoch 64/300
785/785 - 88s - 112ms/step - accuracy: 0.3887 - loss: 2.8673 - val_accuracy: 0.5643 - val_loss: 2.0356 - learning_rate: 2.5974e-04
Epoch 65/300
785/785 - 89s - 113ms/step - accuracy: 0.3768 - loss: 2.9227 - val_accuracy: 0.5690 - val_loss: 2.0761 - learning_rate: 2.5974e-04
Epoch 66/300
785/785 - 90s - 114ms/step - accuracy: 0.3925 - loss: 2.9175 - val_accuracy: 0.5738 - val_loss: 2.0607 - learning_rate: 2.5974e-04
Epoch 67/300
785/785 - 89s - 113ms/step - accuracy: 0.3788 - loss: 2.9001 - val_accuracy: 0.5721 - val_loss: 2.0563 - learning_rate: 2.5974e-04
Epoch 68/300
785/785 - 90s - 114ms/step - accuracy: 0.3852 - loss: 2.9459 - val_accuracy: 0.5721 - val_loss: 2.0658 - learning_rate: 2.5974e-04
Epoch 69/300
785/785 - 90s - 114ms/step - accuracy: 0.3857 - loss: 2.8829 - val_accuracy: 0.5444 - val_loss: 2.0560 - learning_rate: 2.5974e-04
Epoch 70/300
785/785 - 88s - 113ms/step - accuracy: 0.3877 - loss: 2.8990 - val_accuracy: 0.5689 - val_loss: 2.0242 - learning_rate: 2.5974e-04
Epoch 71/300
785/785 - 91s - 116ms/step - accuracy: 0.3881 - loss: 2.9197 - val_accuracy: 0.5616 - val_loss: 2.0803 - learning_rate: 2.5974e-04
Epoch 72/300
785/785 - 89s - 114ms/step - accuracy: 0.3889 - loss: 2.8787 - val_accuracy: 0.5560 - val_loss: 2.0227 - learning_rate: 2.5974e-04
Epoch 73/300
785/785 - 90s - 114ms/step - accuracy: 0.3908 - loss: 2.8688 - val_accuracy: 0.5741 - val_loss: 2.0239 - learning_rate: 2.5974e-04
Epoch 74/300
785/785 - 90s - 114ms/step - accuracy: 0.3922 - loss: 2.8946 - val_accuracy: 0.5757 - val_loss: 2.0569 - learning_rate: 2.5974e-04
Epoch 75/300
785/785 - 88s - 112ms/step - accuracy: 0.3978 - loss: 2.8706 - val_accuracy: 0.5557 - val_loss: 2.0678 - learning_rate: 2.5974e-04
Epoch 76/300
785/785 - 90s - 114ms/step - accuracy: 0.3919 - loss: 2.9082 - val_accuracy: 0.5708 - val_loss: 2.0044 - learning_rate: 2.5974e-04
Epoch 77/300
785/785 - 89s - 113ms/step - accuracy: 0.3911 - loss: 2.8975 - val_accuracy: 0.5703 - val_loss: 2.0491 - learning_rate: 2.5974e-04
Epoch 78/300
785/785 - 89s - 113ms/step - accuracy: 0.3936 - loss: 2.8723 - val_accuracy: 0.5741 - val_loss: 2.0362 - learning_rate: 2.5974e-04
Epoch 79/300
785/785 - 89s - 113ms/step - accuracy: 0.3971 - loss: 2.8454 - val_accuracy: 0.5794 - val_loss: 2.0252 - learning_rate: 2.5974e-04
Epoch 80/300
785/785 - 88s - 113ms/step - accuracy: 0.3882 - loss: 2.9060 - val_accuracy: 0.5729 - val_loss: 2.0080 - learning_rate: 2.5974e-04
Epoch 81/300
785/785 - 91s - 116ms/step - accuracy: 0.3920 - loss: 2.8892 - val_accuracy: 0.5754 - val_loss: 1.9924 - learning_rate: 2.5974e-04
Epoch 82/300
785/785 - 90s - 114ms/step - accuracy: 0.3951 - loss: 2.8618 - val_accuracy: 0.5644 - val_loss: 2.0141 - learning_rate: 2.5974e-04
Epoch 83/300
785/785 - 89s - 114ms/step - accuracy: 0.3887 - loss: 2.8674 - val_accuracy: 0.5676 - val_loss: 2.0152 - learning_rate: 2.5974e-04
Epoch 84/300
785/785 - 88s - 112ms/step - accuracy: 0.3861 - loss: 2.8951 - val_accuracy: 0.5716 - val_loss: 2.0087 - learning_rate: 2.5974e-04
Epoch 85/300
785/785 - 89s - 113ms/step - accuracy: 0.3912 - loss: 2.8471 - val_accuracy: 0.5517 - val_loss: 2.0556 - learning_rate: 2.5974e-04
Epoch 86/300
785/785 - 90s - 115ms/step - accuracy: 0.3941 - loss: 2.8739 - val_accuracy: 0.5721 - val_loss: 1.9837 - learning_rate: 2.5974e-04
Epoch 87/300
785/785 - 89s - 114ms/step - accuracy: 0.3900 - loss: 2.8457 - val_accuracy: 0.5856 - val_loss: 1.9927 - learning_rate: 2.5974e-04
Epoch 88/300
785/785 - 90s - 115ms/step - accuracy: 0.3957 - loss: 2.8493 - val_accuracy: 0.5697 - val_loss: 2.0539 - learning_rate: 2.5974e-04
Epoch 89/300
785/785 - 89s - 113ms/step - accuracy: 0.4003 - loss: 2.8369 - val_accuracy: 0.5818 - val_loss: 1.9763 - learning_rate: 2.5974e-04
Epoch 90/300
785/785 - 91s - 115ms/step - accuracy: 0.3904 - loss: 2.8402 - val_accuracy: 0.5749 - val_loss: 2.0425 - learning_rate: 2.5974e-04
Epoch 91/300
785/785 - 90s - 115ms/step - accuracy: 0.3939 - loss: 2.8593 - val_accuracy: 0.5748 - val_loss: 2.0450 - learning_rate: 2.5974e-04
Epoch 92/300
785/785 - 94s - 119ms/step - accuracy: 0.3938 - loss: 2.8622 - val_accuracy: 0.5773 - val_loss: 2.0155 - learning_rate: 2.5974e-04
Epoch 93/300
785/785 - 88s - 112ms/step - accuracy: 0.3973 - loss: 2.8277 - val_accuracy: 0.5753 - val_loss: 1.9980 - learning_rate: 2.5974e-04
Epoch 94/300
785/785 - 90s - 114ms/step - accuracy: 0.3971 - loss: 2.8591 - val_accuracy: 0.5730 - val_loss: 2.0372 - learning_rate: 2.5974e-04
Epoch 95/300
785/785 - 89s - 114ms/step - accuracy: 0.3912 - loss: 2.8791 - val_accuracy: 0.5775 - val_loss: 2.0128 - learning_rate: 2.5974e-04
Epoch 96/300
785/785 - 89s - 114ms/step - accuracy: 0.3978 - loss: 2.8631 - val_accuracy: 0.5748 - val_loss: 1.9987 - learning_rate: 2.5974e-04
Epoch 97/300

Epoch 97: ReduceLROnPlateau reducing learning rate to 0.0001298690476687625.
785/785 - 88s - 113ms/step - accuracy: 0.4006 - loss: 2.8607 - val_accuracy: 0.5921 - val_loss: 2.0158 - learning_rate: 2.5974e-04
Epoch 98/300
785/785 - 89s - 113ms/step - accuracy: 0.4003 - loss: 2.7953 - val_accuracy: 0.5937 - val_loss: 1.9498 - learning_rate: 1.2987e-04
Epoch 99/300
785/785 - 88s - 113ms/step - accuracy: 0.4089 - loss: 2.7703 - val_accuracy: 0.5878 - val_loss: 1.9920 - learning_rate: 1.2987e-04
Epoch 100/300
785/785 - 89s - 114ms/step - accuracy: 0.4038 - loss: 2.7684 - val_accuracy: 0.5872 - val_loss: 1.9561 - learning_rate: 1.2987e-04
Epoch 101/300
785/785 - 90s - 115ms/step - accuracy: 0.4154 - loss: 2.7960 - val_accuracy: 0.5904 - val_loss: 1.9677 - learning_rate: 1.2987e-04
Epoch 102/300
785/785 - 89s - 113ms/step - accuracy: 0.4183 - loss: 2.7268 - val_accuracy: 0.5853 - val_loss: 1.9654 - learning_rate: 1.2987e-04
Epoch 103/300
785/785 - 88s - 112ms/step - accuracy: 0.4148 - loss: 2.7745 - val_accuracy: 0.5862 - val_loss: 1.9542 - learning_rate: 1.2987e-04
Epoch 104/300
785/785 - 88s - 112ms/step - accuracy: 0.4158 - loss: 2.7250 - val_accuracy: 0.5955 - val_loss: 1.9377 - learning_rate: 1.2987e-04
Epoch 105/300
785/785 - 88s - 113ms/step - accuracy: 0.4118 - loss: 2.7567 - val_accuracy: 0.5952 - val_loss: 1.9248 - learning_rate: 1.2987e-04
Epoch 106/300
785/785 - 90s - 115ms/step - accuracy: 0.4193 - loss: 2.7427 - val_accuracy: 0.6001 - val_loss: 1.9323 - learning_rate: 1.2987e-04
Epoch 107/300
785/785 - 89s - 114ms/step - accuracy: 0.4118 - loss: 2.7696 - val_accuracy: 0.5878 - val_loss: 1.9245 - learning_rate: 1.2987e-04
Epoch 108/300
785/785 - 89s - 113ms/step - accuracy: 0.4189 - loss: 2.7356 - val_accuracy: 0.5874 - val_loss: 1.9277 - learning_rate: 1.2987e-04
Epoch 109/300
785/785 - 90s - 114ms/step - accuracy: 0.4194 - loss: 2.7539 - val_accuracy: 0.5902 - val_loss: 1.9372 - learning_rate: 1.2987e-04
Epoch 110/300
785/785 - 89s - 114ms/step - accuracy: 0.4148 - loss: 2.7511 - val_accuracy: 0.5960 - val_loss: 1.9341 - learning_rate: 1.2987e-04
Epoch 111/300
785/785 - 90s - 115ms/step - accuracy: 0.4161 - loss: 2.7322 - val_accuracy: 0.5971 - val_loss: 1.9295 - learning_rate: 1.2987e-04
Epoch 112/300
785/785 - 88s - 112ms/step - accuracy: 0.4189 - loss: 2.7686 - val_accuracy: 0.5950 - val_loss: 1.9659 - learning_rate: 1.2987e-04
Epoch 113/300
785/785 - 88s - 112ms/step - accuracy: 0.4237 - loss: 2.7345 - val_accuracy: 0.5948 - val_loss: 1.9494 - learning_rate: 1.2987e-04
Epoch 114/300
785/785 - 89s - 114ms/step - accuracy: 0.4126 - loss: 2.7655 - val_accuracy: 0.5955 - val_loss: 1.9191 - learning_rate: 1.2987e-04
Epoch 115/300
785/785 - 90s - 115ms/step - accuracy: 0.4170 - loss: 2.7517 - val_accuracy: 0.5937 - val_loss: 1.9037 - learning_rate: 1.2987e-04
Epoch 116/300
785/785 - 89s - 113ms/step - accuracy: 0.4261 - loss: 2.7132 - val_accuracy: 0.5907 - val_loss: 1.9136 - learning_rate: 1.2987e-04
Epoch 117/300
785/785 - 89s - 114ms/step - accuracy: 0.4127 - loss: 2.7815 - val_accuracy: 0.5912 - val_loss: 1.9583 - learning_rate: 1.2987e-04
Epoch 118/300
785/785 - 89s - 113ms/step - accuracy: 0.4146 - loss: 2.7340 - val_accuracy: 0.5923 - val_loss: 1.9376 - learning_rate: 1.2987e-04
Epoch 119/300
785/785 - 91s - 115ms/step - accuracy: 0.4143 - loss: 2.7415 - val_accuracy: 0.5891 - val_loss: 1.9415 - learning_rate: 1.2987e-04
Epoch 120/300
785/785 - 88s - 112ms/step - accuracy: 0.4215 - loss: 2.7552 - val_accuracy: 0.5950 - val_loss: 1.9154 - learning_rate: 1.2987e-04
Epoch 121/300
785/785 - 89s - 114ms/step - accuracy: 0.4212 - loss: 2.7251 - val_accuracy: 0.5952 - val_loss: 1.9414 - learning_rate: 1.2987e-04
Epoch 122/300
785/785 - 90s - 115ms/step - accuracy: 0.4229 - loss: 2.7363 - val_accuracy: 0.5950 - val_loss: 1.8937 - learning_rate: 1.2987e-04
Epoch 123/300
785/785 - 88s - 113ms/step - accuracy: 0.4167 - loss: 2.7454 - val_accuracy: 0.5897 - val_loss: 1.9337 - learning_rate: 1.2987e-04
Epoch 124/300
785/785 - 90s - 115ms/step - accuracy: 0.4154 - loss: 2.7372 - val_accuracy: 0.6014 - val_loss: 1.9213 - learning_rate: 1.2987e-04
Epoch 125/300
785/785 - 91s - 116ms/step - accuracy: 0.4225 - loss: 2.7245 - val_accuracy: 0.5925 - val_loss: 1.9209 - learning_rate: 1.2987e-04
Epoch 126/300
785/785 - 89s - 113ms/step - accuracy: 0.4167 - loss: 2.7323 - val_accuracy: 0.5918 - val_loss: 1.9251 - learning_rate: 1.2987e-04
Epoch 127/300
785/785 - 89s - 113ms/step - accuracy: 0.4237 - loss: 2.7183 - val_accuracy: 0.5982 - val_loss: 1.9283 - learning_rate: 1.2987e-04
Epoch 128/300
785/785 - 89s - 113ms/step - accuracy: 0.4159 - loss: 2.7093 - val_accuracy: 0.5886 - val_loss: 1.9107 - learning_rate: 1.2987e-04
Epoch 129/300
785/785 - 91s - 116ms/step - accuracy: 0.4234 - loss: 2.7102 - val_accuracy: 0.6066 - val_loss: 1.8968 - learning_rate: 1.2987e-04
Epoch 130/300

Epoch 130: ReduceLROnPlateau reducing learning rate to 6.493452383438125e-05.
785/785 - 90s - 114ms/step - accuracy: 0.4274 - loss: 2.7206 - val_accuracy: 0.5968 - val_loss: 1.9155 - learning_rate: 1.2987e-04
Epoch 131/300
785/785 - 88s - 113ms/step - accuracy: 0.4261 - loss: 2.7124 - val_accuracy: 0.5998 - val_loss: 1.8873 - learning_rate: 6.4935e-05
Epoch 132/300
785/785 - 88s - 112ms/step - accuracy: 0.4264 - loss: 2.6950 - val_accuracy: 0.6033 - val_loss: 1.8893 - learning_rate: 6.4935e-05
Epoch 133/300
785/785 - 87s - 111ms/step - accuracy: 0.4287 - loss: 2.6767 - val_accuracy: 0.5968 - val_loss: 1.8983 - learning_rate: 6.4935e-05
Epoch 134/300
785/785 - 90s - 115ms/step - accuracy: 0.4231 - loss: 2.7164 - val_accuracy: 0.6098 - val_loss: 1.8978 - learning_rate: 6.4935e-05
Epoch 135/300
785/785 - 90s - 115ms/step - accuracy: 0.4358 - loss: 2.6681 - val_accuracy: 0.6033 - val_loss: 1.8895 - learning_rate: 6.4935e-05
Epoch 136/300
785/785 - 90s - 115ms/step - accuracy: 0.4303 - loss: 2.6747 - val_accuracy: 0.5998 - val_loss: 1.8853 - learning_rate: 6.4935e-05
Epoch 137/300
785/785 - 147s - 188ms/step - accuracy: 0.4299 - loss: 2.6283 - val_accuracy: 0.5979 - val_loss: 1.8825 - learning_rate: 6.4935e-05
Epoch 138/300
785/785 - 89s - 114ms/step - accuracy: 0.4263 - loss: 2.6969 - val_accuracy: 0.6014 - val_loss: 1.8912 - learning_rate: 6.4935e-05
Epoch 139/300
785/785 - 89s - 114ms/step - accuracy: 0.4225 - loss: 2.6999 - val_accuracy: 0.6031 - val_loss: 1.8904 - learning_rate: 6.4935e-05
Epoch 140/300
785/785 - 91s - 116ms/step - accuracy: 0.4245 - loss: 2.6680 - val_accuracy: 0.6014 - val_loss: 1.8819 - learning_rate: 6.4935e-05
Epoch 141/300
785/785 - 89s - 113ms/step - accuracy: 0.4277 - loss: 2.6906 - val_accuracy: 0.6036 - val_loss: 1.8829 - learning_rate: 6.4935e-05
Epoch 142/300
785/785 - 88s - 113ms/step - accuracy: 0.4307 - loss: 2.6771 - val_accuracy: 0.5982 - val_loss: 1.8780 - learning_rate: 6.4935e-05
Epoch 143/300
785/785 - 90s - 114ms/step - accuracy: 0.4409 - loss: 2.6468 - val_accuracy: 0.5969 - val_loss: 1.8696 - learning_rate: 6.4935e-05
Epoch 144/300
785/785 - 89s - 114ms/step - accuracy: 0.4266 - loss: 2.6786 - val_accuracy: 0.5960 - val_loss: 1.8838 - learning_rate: 6.4935e-05
Epoch 145/300
785/785 - 90s - 114ms/step - accuracy: 0.4354 - loss: 2.6504 - val_accuracy: 0.5991 - val_loss: 1.8751 - learning_rate: 6.4935e-05
Epoch 146/300
785/785 - 89s - 114ms/step - accuracy: 0.4323 - loss: 2.6760 - val_accuracy: 0.5932 - val_loss: 1.8771 - learning_rate: 6.4935e-05
Epoch 147/300
785/785 - 87s - 111ms/step - accuracy: 0.4272 - loss: 2.6665 - val_accuracy: 0.5929 - val_loss: 1.9095 - learning_rate: 6.4935e-05
Epoch 148/300
785/785 - 89s - 113ms/step - accuracy: 0.4296 - loss: 2.6942 - val_accuracy: 0.5991 - val_loss: 1.8950 - learning_rate: 6.4935e-05
Epoch 149/300
785/785 - 89s - 113ms/step - accuracy: 0.4277 - loss: 2.6867 - val_accuracy: 0.5988 - val_loss: 1.8811 - learning_rate: 6.4935e-05
Epoch 150/300
785/785 - 89s - 113ms/step - accuracy: 0.4298 - loss: 2.6949 - val_accuracy: 0.6004 - val_loss: 1.8909 - learning_rate: 6.4935e-05
Epoch 151/300

Epoch 151: ReduceLROnPlateau reducing learning rate to 3.2467261917190626e-05.
785/785 - 91s - 116ms/step - accuracy: 0.4323 - loss: 2.6968 - val_accuracy: 0.5977 - val_loss: 1.8805 - learning_rate: 6.4935e-05
Epoch 152/300
785/785 - 89s - 114ms/step - accuracy: 0.4358 - loss: 2.6698 - val_accuracy: 0.6018 - val_loss: 1.8782 - learning_rate: 3.2467e-05
Epoch 153/300
785/785 - 90s - 115ms/step - accuracy: 0.4299 - loss: 2.6747 - val_accuracy: 0.5991 - val_loss: 1.8754 - learning_rate: 3.2467e-05
Epoch 154/300
785/785 - 90s - 115ms/step - accuracy: 0.4347 - loss: 2.6669 - val_accuracy: 0.6022 - val_loss: 1.8825 - learning_rate: 3.2467e-05
Epoch 155/300
785/785 - 91s - 116ms/step - accuracy: 0.4315 - loss: 2.6645 - val_accuracy: 0.6009 - val_loss: 1.8693 - learning_rate: 3.2467e-05
Epoch 156/300
785/785 - 89s - 114ms/step - accuracy: 0.4274 - loss: 2.6566 - val_accuracy: 0.6063 - val_loss: 1.8635 - learning_rate: 3.2467e-05
Epoch 157/300
785/785 - 95s - 121ms/step - accuracy: 0.4307 - loss: 2.6903 - val_accuracy: 0.6017 - val_loss: 1.8755 - learning_rate: 3.2467e-05
Epoch 158/300
785/785 - 89s - 113ms/step - accuracy: 0.4355 - loss: 2.6645 - val_accuracy: 0.6057 - val_loss: 1.8765 - learning_rate: 3.2467e-05
Epoch 159/300
785/785 - 88s - 113ms/step - accuracy: 0.4283 - loss: 2.7047 - val_accuracy: 0.6047 - val_loss: 1.8834 - learning_rate: 3.2467e-05
Epoch 160/300
785/785 - 89s - 113ms/step - accuracy: 0.4411 - loss: 2.6716 - val_accuracy: 0.6054 - val_loss: 1.8617 - learning_rate: 3.2467e-05
Epoch 161/300
785/785 - 91s - 116ms/step - accuracy: 0.4317 - loss: 2.6467 - val_accuracy: 0.6034 - val_loss: 1.8630 - learning_rate: 3.2467e-05
Epoch 162/300
785/785 - 91s - 115ms/step - accuracy: 0.4342 - loss: 2.6756 - val_accuracy: 0.6036 - val_loss: 1.8617 - learning_rate: 3.2467e-05
Epoch 163/300
785/785 - 89s - 114ms/step - accuracy: 0.4279 - loss: 2.6806 - val_accuracy: 0.6018 - val_loss: 1.8798 - learning_rate: 3.2467e-05
Epoch 164/300
785/785 - 90s - 115ms/step - accuracy: 0.4349 - loss: 2.6490 - val_accuracy: 0.6014 - val_loss: 1.8631 - learning_rate: 3.2467e-05
Epoch 165/300
785/785 - 95s - 121ms/step - accuracy: 0.4365 - loss: 2.6357 - val_accuracy: 0.6079 - val_loss: 1.8617 - learning_rate: 3.2467e-05
Epoch 166/300
785/785 - 90s - 115ms/step - accuracy: 0.4301 - loss: 2.6775 - val_accuracy: 0.6039 - val_loss: 1.8713 - learning_rate: 3.2467e-05
Epoch 167/300
785/785 - 89s - 114ms/step - accuracy: 0.4299 - loss: 2.6585 - val_accuracy: 0.6011 - val_loss: 1.8715 - learning_rate: 3.2467e-05
Epoch 168/300

Epoch 168: ReduceLROnPlateau reducing learning rate to 1.6233630958595313e-05.
785/785 - 89s - 113ms/step - accuracy: 0.4377 - loss: 2.6410 - val_accuracy: 0.6065 - val_loss: 1.8735 - learning_rate: 3.2467e-05
Epoch 169/300
785/785 - 88s - 113ms/step - accuracy: 0.4385 - loss: 2.6217 - val_accuracy: 0.6084 - val_loss: 1.8607 - learning_rate: 1.6234e-05
Epoch 170/300
785/785 - 89s - 113ms/step - accuracy: 0.4309 - loss: 2.6834 - val_accuracy: 0.6093 - val_loss: 1.8627 - learning_rate: 1.6234e-05
Epoch 171/300
785/785 - 91s - 116ms/step - accuracy: 0.4412 - loss: 2.6190 - val_accuracy: 0.6084 - val_loss: 1.8645 - learning_rate: 1.6234e-05
Epoch 172/300
785/785 - 89s - 114ms/step - accuracy: 0.4398 - loss: 2.6369 - val_accuracy: 0.6065 - val_loss: 1.8588 - learning_rate: 1.6234e-05
Epoch 173/300
785/785 - 90s - 114ms/step - accuracy: 0.4379 - loss: 2.6283 - val_accuracy: 0.6089 - val_loss: 1.8556 - learning_rate: 1.6234e-05
Epoch 174/300
785/785 - 90s - 114ms/step - accuracy: 0.4322 - loss: 2.6427 - val_accuracy: 0.6060 - val_loss: 1.8552 - learning_rate: 1.6234e-05
Epoch 175/300
785/785 - 89s - 113ms/step - accuracy: 0.4427 - loss: 2.6346 - val_accuracy: 0.6044 - val_loss: 1.8649 - learning_rate: 1.6234e-05
Epoch 176/300
785/785 - 89s - 113ms/step - accuracy: 0.4377 - loss: 2.6157 - val_accuracy: 0.6068 - val_loss: 1.8485 - learning_rate: 1.6234e-05
Epoch 177/300
785/785 - 90s - 114ms/step - accuracy: 0.4291 - loss: 2.6512 - val_accuracy: 0.6065 - val_loss: 1.8559 - learning_rate: 1.6234e-05
Epoch 178/300
785/785 - 91s - 115ms/step - accuracy: 0.4390 - loss: 2.6251 - val_accuracy: 0.6079 - val_loss: 1.8533 - learning_rate: 1.6234e-05
Epoch 179/300
785/785 - 90s - 115ms/step - accuracy: 0.4325 - loss: 2.6440 - val_accuracy: 0.6038 - val_loss: 1.8503 - learning_rate: 1.6234e-05
Epoch 180/300
785/785 - 91s - 116ms/step - accuracy: 0.4331 - loss: 2.6382 - val_accuracy: 0.6058 - val_loss: 1.8562 - learning_rate: 1.6234e-05
Epoch 181/300
785/785 - 91s - 116ms/step - accuracy: 0.4398 - loss: 2.6413 - val_accuracy: 0.6041 - val_loss: 1.8507 - learning_rate: 1.6234e-05
Epoch 182/300
785/785 - 89s - 113ms/step - accuracy: 0.4295 - loss: 2.6322 - val_accuracy: 0.6055 - val_loss: 1.8480 - learning_rate: 1.6234e-05
Epoch 183/300
785/785 - 90s - 115ms/step - accuracy: 0.4381 - loss: 2.6511 - val_accuracy: 0.6087 - val_loss: 1.8607 - learning_rate: 1.6234e-05
Epoch 184/300
785/785 - 90s - 114ms/step - accuracy: 0.4384 - loss: 2.6219 - val_accuracy: 0.6052 - val_loss: 1.8523 - learning_rate: 1.6234e-05
Epoch 185/300
785/785 - 89s - 113ms/step - accuracy: 0.4288 - loss: 2.6825 - val_accuracy: 0.6054 - val_loss: 1.8572 - learning_rate: 1.6234e-05
Epoch 186/300
785/785 - 87s - 111ms/step - accuracy: 0.4408 - loss: 2.6236 - val_accuracy: 0.6039 - val_loss: 1.8487 - learning_rate: 1.6234e-05
Epoch 187/300
785/785 - 87s - 111ms/step - accuracy: 0.4373 - loss: 2.6567 - val_accuracy: 0.6050 - val_loss: 1.8442 - learning_rate: 1.6234e-05
Epoch 188/300
785/785 - 89s - 114ms/step - accuracy: 0.4330 - loss: 2.6500 - val_accuracy: 0.6098 - val_loss: 1.8546 - learning_rate: 1.6234e-05
Epoch 189/300
785/785 - 93s - 119ms/step - accuracy: 0.4352 - loss: 2.6554 - val_accuracy: 0.6049 - val_loss: 1.8534 - learning_rate: 1.6234e-05
Epoch 190/300
785/785 - 92s - 118ms/step - accuracy: 0.4419 - loss: 2.6167 - val_accuracy: 0.6041 - val_loss: 1.8558 - learning_rate: 1.6234e-05
Epoch 191/300
785/785 - 90s - 114ms/step - accuracy: 0.4358 - loss: 2.6443 - val_accuracy: 0.6060 - val_loss: 1.8584 - learning_rate: 1.6234e-05
Epoch 192/300
785/785 - 89s - 114ms/step - accuracy: 0.4373 - loss: 2.6669 - val_accuracy: 0.6055 - val_loss: 1.8546 - learning_rate: 1.6234e-05
Epoch 193/300
785/785 - 143s - 182ms/step - accuracy: 0.4495 - loss: 2.5954 - val_accuracy: 0.6084 - val_loss: 1.8544 - learning_rate: 1.6234e-05
Epoch 194/300
785/785 - 89s - 113ms/step - accuracy: 0.4357 - loss: 2.6661 - val_accuracy: 0.6069 - val_loss: 1.8480 - learning_rate: 1.6234e-05
Epoch 195/300

Epoch 195: ReduceLROnPlateau reducing learning rate to 8.116815479297657e-06.
785/785 - 90s - 115ms/step - accuracy: 0.4419 - loss: 2.6256 - val_accuracy: 0.6057 - val_loss: 1.8490 - learning_rate: 1.6234e-05
Epoch 196/300
785/785 - 89s - 113ms/step - accuracy: 0.4441 - loss: 2.6281 - val_accuracy: 0.6071 - val_loss: 1.8466 - learning_rate: 8.1168e-06
Epoch 197/300
785/785 - 89s - 114ms/step - accuracy: 0.4417 - loss: 2.6297 - val_accuracy: 0.6069 - val_loss: 1.8468 - learning_rate: 8.1168e-06
Epoch 198/300
785/785 - 90s - 115ms/step - accuracy: 0.4320 - loss: 2.6515 - val_accuracy: 0.6073 - val_loss: 1.8528 - learning_rate: 8.1168e-06
Epoch 199/300
785/785 - 89s - 113ms/step - accuracy: 0.4425 - loss: 2.6295 - val_accuracy: 0.6074 - val_loss: 1.8491 - learning_rate: 8.1168e-06
Epoch 200/300
785/785 - 90s - 114ms/step - accuracy: 0.4390 - loss: 2.6357 - val_accuracy: 0.6058 - val_loss: 1.8496 - learning_rate: 8.1168e-06
Epoch 201/300
785/785 - 91s - 115ms/step - accuracy: 0.4438 - loss: 2.6263 - val_accuracy: 0.6071 - val_loss: 1.8516 - learning_rate: 8.1168e-06
Epoch 202/300
785/785 - 87s - 111ms/step - accuracy: 0.4428 - loss: 2.6363 - val_accuracy: 0.6066 - val_loss: 1.8552 - learning_rate: 8.1168e-06
Epoch 203/300

Epoch 203: ReduceLROnPlateau reducing learning rate to 4.058407739648828e-06.
785/785 - 88s - 112ms/step - accuracy: 0.4412 - loss: 2.6314 - val_accuracy: 0.6068 - val_loss: 1.8517 - learning_rate: 8.1168e-06
Epoch 203: early stopping
Restoring model weights from the end of the best epoch: 187.
Fold 3_2 Evaluation results: [1.8470220565795898, 0.6050326228141785]
              precision    recall  f1-score   support

        1820       0.71      0.81      0.76       311
        1821       0.88      0.81      0.85       280
        1822       0.00      0.00      0.00         6
        1823       0.00      0.00      0.00         8
        1824       0.17      0.33      0.22         3
        1825       0.00      0.00      0.00         9
        1826       0.00      0.00      0.00        14
        1827       0.74      0.76      0.75       119
        1828       0.33      0.60      0.43         5
        1829       0.80      0.47      0.59        17
        1830       0.48      0.65      0.55       266
        1831       0.73      0.93      0.82       697
        1832       0.82      0.80      0.81       342
        1833       0.81      0.90      0.85        87
        1834       0.52      0.69      0.60       154
        1835       0.00      0.00      0.00         9
        1836       0.33      0.07      0.11        15
        1837       0.45      0.24      0.31        38
        1838       0.00      0.00      0.00        21
        1839       0.00      0.00      0.00         4
        1840       0.49      0.49      0.49       227
        1841       0.71      0.50      0.59       534
        1842       0.90      0.36      0.51        25
        1843       0.33      0.08      0.13        25
        1844       0.00      0.00      0.00         3
        1845       0.00      0.00      0.00         3
        1846       0.38      0.12      0.18        25
        1847       0.00      0.00      0.00         9
        1848       1.00      0.04      0.07        28
        1849       0.32      0.37      0.34        19
        1850       0.35      0.62      0.44       241
        1851       0.77      0.70      0.73       380
        1852       0.00      0.00      0.00        40
        1853       0.00      0.00      0.00        34
        1854       0.00      0.00      0.00        13
        1855       0.41      0.08      0.13       115
        1856       0.68      0.67      0.67        60
        1857       0.45      0.56      0.50       146
        1858       0.00      0.00      0.00        13
        1859       0.00      0.00      0.00        13
        1860       0.29      0.47      0.36       303
        1861       0.77      0.86      0.81       416
        1862       0.40      0.09      0.14        94
        1863       0.34      0.54      0.41        80
        1864       0.29      0.11      0.16        96
        1865       0.75      0.09      0.16        34
        1866       1.00      0.03      0.06        35
        1867       0.40      0.03      0.06        65
        1868       0.00      0.00      0.00        40
        1869       0.00      0.00      0.00        18
        1870       0.43      0.55      0.48       174
        1871       0.78      0.75      0.76       271
        1872       0.19      0.39      0.26        23
        1873       0.50      0.04      0.07        54
        1874       1.00      0.07      0.14        27
        1875       0.26      0.61      0.37        64
        1876       0.90      0.88      0.89        50
        1877       0.50      0.08      0.14        24
        1878       0.54      0.44      0.49        45
        1879       0.00      0.00      0.00         8

    accuracy                           0.61      6279
   macro avg       0.40      0.31      0.30      6279
weighted avg       0.60      0.61      0.58      6279

Matthews Correlation Coefficient: 0.585
Macro avg F1: 0.303
Weighted avg F1: 0.578
Micro avg F1: 0.605
Top-3 Accuracy: 0.846
Top-5 Accuracy: 0.900
Micro ROC AUC  = 0.98
Macro ROC AUC (present classes) = 0.97
Classification MAE (in years): 3.19

Fold 3_2 Misclassification Analysis:
Near misses (within 2 years): 526 out of 2480 misclassifications (21.21%)
Big misses (greater than 10 years): 1077
MAE with outliers: 3.19
MAE without outliers: 2.37 (improvement: 0.83)

10 Worst misclassifications:
Image: data/datasets/public/1870/1879_26wikimedia2.jpg, True: 1879, Predicted: 1820, Error: 59
Image: data/datasets/public/1870/1877_035met.jpg, True: 1877, Predicted: 1820, Error: 57
Image: data/datasets/private/1870/1871_114etsy.jpg, True: 1871, Predicted: 1820, Error: 51
Image: data/datasets/public/1820/1820_12wikimedia2.jpg, True: 1820, Predicted: 1871, Error: 51
Image: data/datasets/private/1870/1871_53etsy.jpg, True: 1871, Predicted: 1821, Error: 50
Image: data/datasets/private/1870/1871_404etsy.jpg, True: 1871, Predicted: 1821, Error: 50
Image: data/datasets/private/1820/1826_036_Zrzut ekranu 2022-07-26 210151.png, True: 1826, Predicted: 1876, Error: 50
Image: data/datasets/private/1820/1821_486etsy.jpg, True: 1821, Predicted: 1871, Error: 50
Image: data/datasets/public/1870/1870_79wikimedia2.jpg, True: 1870, Predicted: 1820, Error: 50
Image: data/datasets/private/1820/1821_580etsy.jpg, True: 1821, Predicted: 1871, Error: 50

===== Iteration 5/5 =====
=== Training Base Model ===

===== Fine Tuning 9 layers! =====
Epoch 1/300
785/785 - 112s - 143ms/step - accuracy: 0.1057 - loss: 4.5534 - val_accuracy: 0.1890 - val_loss: 4.3089 - learning_rate: 2.5974e-04
Epoch 2/300
785/785 - 86s - 109ms/step - accuracy: 0.1634 - loss: 4.2183 - val_accuracy: 0.2682 - val_loss: 3.8350 - learning_rate: 2.5974e-04
Epoch 3/300
785/785 - 84s - 107ms/step - accuracy: 0.1855 - loss: 4.0887 - val_accuracy: 0.3428 - val_loss: 3.5681 - learning_rate: 2.5974e-04
Epoch 4/300
785/785 - 85s - 108ms/step - accuracy: 0.2140 - loss: 3.9212 - val_accuracy: 0.3656 - val_loss: 3.2312 - learning_rate: 2.5974e-04
Epoch 5/300
785/785 - 86s - 109ms/step - accuracy: 0.2293 - loss: 3.8194 - val_accuracy: 0.3979 - val_loss: 3.2050 - learning_rate: 2.5974e-04
Epoch 6/300
785/785 - 84s - 107ms/step - accuracy: 0.2547 - loss: 3.6911 - val_accuracy: 0.4162 - val_loss: 3.0061 - learning_rate: 2.5974e-04
Epoch 7/300
785/785 - 84s - 107ms/step - accuracy: 0.2516 - loss: 3.6561 - val_accuracy: 0.4215 - val_loss: 2.9074 - learning_rate: 2.5974e-04
Epoch 8/300
785/785 - 83s - 106ms/step - accuracy: 0.2639 - loss: 3.5680 - val_accuracy: 0.4393 - val_loss: 2.8125 - learning_rate: 2.5974e-04
Epoch 9/300
785/785 - 84s - 107ms/step - accuracy: 0.2698 - loss: 3.5316 - val_accuracy: 0.4556 - val_loss: 2.7963 - learning_rate: 2.5974e-04
Epoch 10/300
785/785 - 141s - 179ms/step - accuracy: 0.2747 - loss: 3.5277 - val_accuracy: 0.4600 - val_loss: 2.6515 - learning_rate: 2.5974e-04
Epoch 11/300
785/785 - 84s - 107ms/step - accuracy: 0.2873 - loss: 3.4442 - val_accuracy: 0.4602 - val_loss: 2.6869 - learning_rate: 2.5974e-04
Epoch 12/300
785/785 - 85s - 108ms/step - accuracy: 0.2997 - loss: 3.3999 - val_accuracy: 0.4677 - val_loss: 2.5978 - learning_rate: 2.5974e-04
Epoch 13/300
785/785 - 85s - 108ms/step - accuracy: 0.3144 - loss: 3.3509 - val_accuracy: 0.4607 - val_loss: 2.5871 - learning_rate: 2.5974e-04
Epoch 14/300
785/785 - 84s - 107ms/step - accuracy: 0.3079 - loss: 3.3838 - val_accuracy: 0.4932 - val_loss: 2.4731 - learning_rate: 2.5974e-04
Epoch 15/300
785/785 - 85s - 108ms/step - accuracy: 0.3206 - loss: 3.3015 - val_accuracy: 0.4917 - val_loss: 2.4708 - learning_rate: 2.5974e-04
Epoch 16/300
785/785 - 83s - 106ms/step - accuracy: 0.3107 - loss: 3.3007 - val_accuracy: 0.5091 - val_loss: 2.4356 - learning_rate: 2.5974e-04
Epoch 17/300
785/785 - 84s - 107ms/step - accuracy: 0.3147 - loss: 3.3195 - val_accuracy: 0.4962 - val_loss: 2.4434 - learning_rate: 2.5974e-04
Epoch 18/300
785/785 - 83s - 106ms/step - accuracy: 0.3251 - loss: 3.2727 - val_accuracy: 0.5019 - val_loss: 2.3764 - learning_rate: 2.5974e-04
Epoch 19/300
785/785 - 83s - 106ms/step - accuracy: 0.3351 - loss: 3.2479 - val_accuracy: 0.4986 - val_loss: 2.3534 - learning_rate: 2.5974e-04
Epoch 20/300
785/785 - 86s - 109ms/step - accuracy: 0.3239 - loss: 3.2599 - val_accuracy: 0.5002 - val_loss: 2.4409 - learning_rate: 2.5974e-04
Epoch 21/300
785/785 - 84s - 107ms/step - accuracy: 0.3365 - loss: 3.1886 - val_accuracy: 0.5054 - val_loss: 2.3995 - learning_rate: 2.5974e-04
Epoch 22/300
785/785 - 86s - 109ms/step - accuracy: 0.3338 - loss: 3.2152 - val_accuracy: 0.5275 - val_loss: 2.2972 - learning_rate: 2.5974e-04
Epoch 23/300
785/785 - 84s - 107ms/step - accuracy: 0.3434 - loss: 3.1799 - val_accuracy: 0.5053 - val_loss: 2.3370 - learning_rate: 2.5974e-04
Epoch 24/300
785/785 - 84s - 107ms/step - accuracy: 0.3402 - loss: 3.1896 - val_accuracy: 0.5248 - val_loss: 2.3023 - learning_rate: 2.5974e-04
Epoch 25/300
785/785 - 86s - 110ms/step - accuracy: 0.3493 - loss: 3.1765 - val_accuracy: 0.5172 - val_loss: 2.2829 - learning_rate: 2.5974e-04
Epoch 26/300
785/785 - 84s - 107ms/step - accuracy: 0.3494 - loss: 3.1782 - val_accuracy: 0.5196 - val_loss: 2.2904 - learning_rate: 2.5974e-04
Epoch 27/300
785/785 - 84s - 108ms/step - accuracy: 0.3505 - loss: 3.1493 - val_accuracy: 0.4782 - val_loss: 2.4252 - learning_rate: 2.5974e-04
Epoch 28/300
785/785 - 84s - 108ms/step - accuracy: 0.3462 - loss: 3.1437 - val_accuracy: 0.5304 - val_loss: 2.2481 - learning_rate: 2.5974e-04
Epoch 29/300
785/785 - 84s - 108ms/step - accuracy: 0.3454 - loss: 3.1266 - val_accuracy: 0.5306 - val_loss: 2.2260 - learning_rate: 2.5974e-04
Epoch 30/300
785/785 - 92s - 117ms/step - accuracy: 0.3577 - loss: 3.1088 - val_accuracy: 0.5065 - val_loss: 2.2670 - learning_rate: 2.5974e-04
Epoch 31/300
785/785 - 85s - 108ms/step - accuracy: 0.3561 - loss: 3.1226 - val_accuracy: 0.5275 - val_loss: 2.2486 - learning_rate: 2.5974e-04
Epoch 32/300
785/785 - 86s - 109ms/step - accuracy: 0.3644 - loss: 3.0914 - val_accuracy: 0.5361 - val_loss: 2.1756 - learning_rate: 2.5974e-04
Epoch 33/300
785/785 - 86s - 110ms/step - accuracy: 0.3649 - loss: 3.0774 - val_accuracy: 0.5457 - val_loss: 2.1827 - learning_rate: 2.5974e-04
Epoch 34/300
785/785 - 85s - 108ms/step - accuracy: 0.3610 - loss: 3.0755 - val_accuracy: 0.5105 - val_loss: 2.2375 - learning_rate: 2.5974e-04
Epoch 35/300
785/785 - 85s - 109ms/step - accuracy: 0.3493 - loss: 3.0978 - val_accuracy: 0.5317 - val_loss: 2.1626 - learning_rate: 2.5974e-04
Epoch 36/300
785/785 - 83s - 106ms/step - accuracy: 0.3544 - loss: 3.1049 - val_accuracy: 0.5406 - val_loss: 2.1723 - learning_rate: 2.5974e-04
Epoch 37/300
785/785 - 89s - 114ms/step - accuracy: 0.3606 - loss: 3.0425 - val_accuracy: 0.5357 - val_loss: 2.1803 - learning_rate: 2.5974e-04
Epoch 38/300
785/785 - 84s - 107ms/step - accuracy: 0.3628 - loss: 3.0939 - val_accuracy: 0.5433 - val_loss: 2.1133 - learning_rate: 2.5974e-04
Epoch 39/300
785/785 - 84s - 107ms/step - accuracy: 0.3679 - loss: 3.0355 - val_accuracy: 0.5376 - val_loss: 2.1432 - learning_rate: 2.5974e-04
Epoch 40/300
785/785 - 85s - 108ms/step - accuracy: 0.3671 - loss: 3.0609 - val_accuracy: 0.5473 - val_loss: 2.1484 - learning_rate: 2.5974e-04
Epoch 41/300
785/785 - 86s - 110ms/step - accuracy: 0.3669 - loss: 3.0491 - val_accuracy: 0.5387 - val_loss: 2.2805 - learning_rate: 2.5974e-04
Epoch 42/300
785/785 - 85s - 108ms/step - accuracy: 0.3712 - loss: 3.0605 - val_accuracy: 0.5317 - val_loss: 2.1646 - learning_rate: 2.5974e-04
Epoch 43/300
785/785 - 87s - 110ms/step - accuracy: 0.3625 - loss: 3.0507 - val_accuracy: 0.5572 - val_loss: 2.1310 - learning_rate: 2.5974e-04
Epoch 44/300
785/785 - 84s - 107ms/step - accuracy: 0.3717 - loss: 3.0100 - val_accuracy: 0.5457 - val_loss: 2.0994 - learning_rate: 2.5974e-04
Epoch 45/300
785/785 - 84s - 107ms/step - accuracy: 0.3797 - loss: 3.0178 - val_accuracy: 0.5482 - val_loss: 2.1058 - learning_rate: 2.5974e-04
Epoch 46/300
785/785 - 85s - 108ms/step - accuracy: 0.3725 - loss: 3.0458 - val_accuracy: 0.5290 - val_loss: 2.1641 - learning_rate: 2.5974e-04
Epoch 47/300
785/785 - 84s - 107ms/step - accuracy: 0.3803 - loss: 2.9843 - val_accuracy: 0.5565 - val_loss: 2.1011 - learning_rate: 2.5974e-04
Epoch 48/300
785/785 - 91s - 116ms/step - accuracy: 0.3618 - loss: 3.0253 - val_accuracy: 0.5468 - val_loss: 2.0925 - learning_rate: 2.5974e-04
Epoch 49/300
785/785 - 84s - 107ms/step - accuracy: 0.3784 - loss: 2.9665 - val_accuracy: 0.5331 - val_loss: 2.1068 - learning_rate: 2.5974e-04
Epoch 50/300
785/785 - 83s - 106ms/step - accuracy: 0.3747 - loss: 2.9552 - val_accuracy: 0.5455 - val_loss: 2.0471 - learning_rate: 2.5974e-04
Epoch 51/300
785/785 - 84s - 107ms/step - accuracy: 0.3802 - loss: 2.9667 - val_accuracy: 0.5543 - val_loss: 2.0845 - learning_rate: 2.5974e-04
Epoch 52/300
785/785 - 85s - 109ms/step - accuracy: 0.3884 - loss: 2.9473 - val_accuracy: 0.5553 - val_loss: 2.1092 - learning_rate: 2.5974e-04
Epoch 53/300
785/785 - 86s - 109ms/step - accuracy: 0.3789 - loss: 2.9838 - val_accuracy: 0.5524 - val_loss: 2.0404 - learning_rate: 2.5974e-04
Epoch 54/300
785/785 - 85s - 108ms/step - accuracy: 0.3719 - loss: 3.0044 - val_accuracy: 0.5417 - val_loss: 2.0603 - learning_rate: 2.5974e-04
Epoch 55/300
785/785 - 85s - 109ms/step - accuracy: 0.3896 - loss: 2.9528 - val_accuracy: 0.5513 - val_loss: 2.0455 - learning_rate: 2.5974e-04
Epoch 56/300
785/785 - 84s - 107ms/step - accuracy: 0.3805 - loss: 2.9536 - val_accuracy: 0.5518 - val_loss: 2.0672 - learning_rate: 2.5974e-04
Epoch 57/300
785/785 - 91s - 116ms/step - accuracy: 0.3786 - loss: 2.9477 - val_accuracy: 0.5545 - val_loss: 2.0383 - learning_rate: 2.5974e-04
Epoch 58/300
785/785 - 86s - 110ms/step - accuracy: 0.3878 - loss: 2.9544 - val_accuracy: 0.5594 - val_loss: 2.0292 - learning_rate: 2.5974e-04
Epoch 59/300
785/785 - 84s - 107ms/step - accuracy: 0.3848 - loss: 2.9307 - val_accuracy: 0.5664 - val_loss: 2.0484 - learning_rate: 2.5974e-04
Epoch 60/300
785/785 - 85s - 108ms/step - accuracy: 0.3937 - loss: 2.9456 - val_accuracy: 0.5611 - val_loss: 2.0754 - learning_rate: 2.5974e-04
Epoch 61/300
785/785 - 86s - 110ms/step - accuracy: 0.3814 - loss: 2.9782 - val_accuracy: 0.5619 - val_loss: 2.0469 - learning_rate: 2.5974e-04
Epoch 62/300
785/785 - 84s - 108ms/step - accuracy: 0.3926 - loss: 2.9299 - val_accuracy: 0.5568 - val_loss: 2.0118 - learning_rate: 2.5974e-04
Epoch 63/300
785/785 - 85s - 109ms/step - accuracy: 0.3857 - loss: 2.9571 - val_accuracy: 0.5495 - val_loss: 2.1124 - learning_rate: 2.5974e-04
Epoch 64/300
785/785 - 91s - 116ms/step - accuracy: 0.3918 - loss: 2.9224 - val_accuracy: 0.5602 - val_loss: 2.1195 - learning_rate: 2.5974e-04
Epoch 65/300
785/785 - 83s - 106ms/step - accuracy: 0.3860 - loss: 2.9615 - val_accuracy: 0.5621 - val_loss: 2.0204 - learning_rate: 2.5974e-04
Epoch 66/300
785/785 - 85s - 108ms/step - accuracy: 0.3888 - loss: 2.9031 - val_accuracy: 0.5627 - val_loss: 2.0115 - learning_rate: 2.5974e-04
Epoch 67/300
785/785 - 83s - 106ms/step - accuracy: 0.3862 - loss: 2.9233 - val_accuracy: 0.5510 - val_loss: 2.0300 - learning_rate: 2.5974e-04
Epoch 68/300
785/785 - 83s - 106ms/step - accuracy: 0.3865 - loss: 2.9262 - val_accuracy: 0.5513 - val_loss: 2.0350 - learning_rate: 2.5974e-04
Epoch 69/300
785/785 - 92s - 117ms/step - accuracy: 0.4004 - loss: 2.9149 - val_accuracy: 0.5654 - val_loss: 2.0278 - learning_rate: 2.5974e-04
Epoch 70/300
785/785 - 92s - 117ms/step - accuracy: 0.3908 - loss: 2.9440 - val_accuracy: 0.5656 - val_loss: 1.9907 - learning_rate: 2.5974e-04
Epoch 71/300
785/785 - 86s - 110ms/step - accuracy: 0.3872 - loss: 2.9202 - val_accuracy: 0.5725 - val_loss: 2.0248 - learning_rate: 2.5974e-04
Epoch 72/300
785/785 - 84s - 107ms/step - accuracy: 0.3950 - loss: 2.9006 - val_accuracy: 0.5578 - val_loss: 2.0322 - learning_rate: 2.5974e-04
Epoch 73/300
785/785 - 84s - 108ms/step - accuracy: 0.3835 - loss: 2.9317 - val_accuracy: 0.5568 - val_loss: 2.0257 - learning_rate: 2.5974e-04
Epoch 74/300
785/785 - 82s - 105ms/step - accuracy: 0.3789 - loss: 2.9631 - val_accuracy: 0.5618 - val_loss: 2.0472 - learning_rate: 2.5974e-04
Epoch 75/300
785/785 - 83s - 106ms/step - accuracy: 0.3894 - loss: 2.8789 - val_accuracy: 0.5721 - val_loss: 1.9912 - learning_rate: 2.5974e-04
Epoch 76/300
785/785 - 85s - 109ms/step - accuracy: 0.3868 - loss: 2.9351 - val_accuracy: 0.5686 - val_loss: 2.0281 - learning_rate: 2.5974e-04
Epoch 77/300
785/785 - 83s - 106ms/step - accuracy: 0.3867 - loss: 2.9201 - val_accuracy: 0.5640 - val_loss: 2.0337 - learning_rate: 2.5974e-04
Epoch 78/300
785/785 - 84s - 107ms/step - accuracy: 0.3886 - loss: 2.8966 - val_accuracy: 0.5693 - val_loss: 1.9549 - learning_rate: 2.5974e-04
Epoch 79/300
785/785 - 85s - 109ms/step - accuracy: 0.4005 - loss: 2.8688 - val_accuracy: 0.5686 - val_loss: 1.9922 - learning_rate: 2.5974e-04
Epoch 80/300
785/785 - 85s - 109ms/step - accuracy: 0.3832 - loss: 2.8973 - val_accuracy: 0.5744 - val_loss: 1.9966 - learning_rate: 2.5974e-04
Epoch 81/300
785/785 - 86s - 110ms/step - accuracy: 0.3913 - loss: 2.8952 - val_accuracy: 0.5801 - val_loss: 1.9947 - learning_rate: 2.5974e-04
Epoch 82/300
785/785 - 85s - 108ms/step - accuracy: 0.3962 - loss: 2.9127 - val_accuracy: 0.5710 - val_loss: 1.9788 - learning_rate: 2.5974e-04
Epoch 83/300
785/785 - 84s - 108ms/step - accuracy: 0.3970 - loss: 2.8926 - val_accuracy: 0.5804 - val_loss: 1.9862 - learning_rate: 2.5974e-04
Epoch 84/300
785/785 - 86s - 109ms/step - accuracy: 0.4013 - loss: 2.8917 - val_accuracy: 0.5841 - val_loss: 1.9775 - learning_rate: 2.5974e-04
Epoch 85/300
785/785 - 84s - 107ms/step - accuracy: 0.3931 - loss: 2.8975 - val_accuracy: 0.5737 - val_loss: 2.0327 - learning_rate: 2.5974e-04
Epoch 86/300

Epoch 86: ReduceLROnPlateau reducing learning rate to 0.0001298690476687625.
785/785 - 85s - 109ms/step - accuracy: 0.3951 - loss: 2.8486 - val_accuracy: 0.5713 - val_loss: 1.9673 - learning_rate: 2.5974e-04
Epoch 87/300
785/785 - 85s - 108ms/step - accuracy: 0.4117 - loss: 2.8194 - val_accuracy: 0.5747 - val_loss: 1.9312 - learning_rate: 1.2987e-04
Epoch 88/300
785/785 - 84s - 107ms/step - accuracy: 0.4103 - loss: 2.8250 - val_accuracy: 0.5793 - val_loss: 1.9498 - learning_rate: 1.2987e-04
Epoch 89/300
785/785 - 91s - 115ms/step - accuracy: 0.4061 - loss: 2.8239 - val_accuracy: 0.5718 - val_loss: 1.9326 - learning_rate: 1.2987e-04
Epoch 90/300
785/785 - 136s - 173ms/step - accuracy: 0.4055 - loss: 2.7976 - val_accuracy: 0.5826 - val_loss: 1.9436 - learning_rate: 1.2987e-04
Epoch 91/300
785/785 - 86s - 109ms/step - accuracy: 0.4023 - loss: 2.8321 - val_accuracy: 0.5728 - val_loss: 1.9474 - learning_rate: 1.2987e-04
Epoch 92/300
785/785 - 85s - 108ms/step - accuracy: 0.4142 - loss: 2.7844 - val_accuracy: 0.5836 - val_loss: 1.9223 - learning_rate: 1.2987e-04
Epoch 93/300
785/785 - 85s - 108ms/step - accuracy: 0.4117 - loss: 2.7887 - val_accuracy: 0.5881 - val_loss: 1.9252 - learning_rate: 1.2987e-04
Epoch 94/300
785/785 - 86s - 110ms/step - accuracy: 0.4090 - loss: 2.8153 - val_accuracy: 0.5858 - val_loss: 1.9356 - learning_rate: 1.2987e-04
Epoch 95/300
785/785 - 84s - 107ms/step - accuracy: 0.4147 - loss: 2.8056 - val_accuracy: 0.5807 - val_loss: 1.9655 - learning_rate: 1.2987e-04
Epoch 96/300
785/785 - 142s - 181ms/step - accuracy: 0.4209 - loss: 2.8001 - val_accuracy: 0.5889 - val_loss: 1.9391 - learning_rate: 1.2987e-04
Epoch 97/300
785/785 - 90s - 115ms/step - accuracy: 0.4111 - loss: 2.7964 - val_accuracy: 0.5836 - val_loss: 1.9261 - learning_rate: 1.2987e-04
Epoch 98/300
785/785 - 86s - 110ms/step - accuracy: 0.4206 - loss: 2.7627 - val_accuracy: 0.5791 - val_loss: 1.8984 - learning_rate: 1.2987e-04
Epoch 99/300
785/785 - 84s - 107ms/step - accuracy: 0.4154 - loss: 2.7937 - val_accuracy: 0.5852 - val_loss: 1.9237 - learning_rate: 1.2987e-04
Epoch 100/300
785/785 - 143s - 183ms/step - accuracy: 0.4042 - loss: 2.8209 - val_accuracy: 0.5833 - val_loss: 1.9237 - learning_rate: 1.2987e-04
Epoch 101/300
785/785 - 84s - 108ms/step - accuracy: 0.4193 - loss: 2.7817 - val_accuracy: 0.5774 - val_loss: 1.9192 - learning_rate: 1.2987e-04
Epoch 102/300
785/785 - 86s - 109ms/step - accuracy: 0.4176 - loss: 2.7748 - val_accuracy: 0.5796 - val_loss: 1.9057 - learning_rate: 1.2987e-04
Epoch 103/300
785/785 - 84s - 108ms/step - accuracy: 0.4203 - loss: 2.7615 - val_accuracy: 0.5863 - val_loss: 1.9199 - learning_rate: 1.2987e-04
Epoch 104/300
785/785 - 83s - 106ms/step - accuracy: 0.4179 - loss: 2.7836 - val_accuracy: 0.5775 - val_loss: 1.8949 - learning_rate: 1.2987e-04
Epoch 105/300
785/785 - 86s - 110ms/step - accuracy: 0.4165 - loss: 2.7776 - val_accuracy: 0.5785 - val_loss: 1.9065 - learning_rate: 1.2987e-04
Epoch 106/300
785/785 - 84s - 107ms/step - accuracy: 0.4171 - loss: 2.7671 - val_accuracy: 0.5803 - val_loss: 1.9212 - learning_rate: 1.2987e-04
Epoch 107/300
785/785 - 85s - 108ms/step - accuracy: 0.4109 - loss: 2.7987 - val_accuracy: 0.5869 - val_loss: 1.9377 - learning_rate: 1.2987e-04
Epoch 108/300
785/785 - 92s - 118ms/step - accuracy: 0.4114 - loss: 2.7777 - val_accuracy: 0.5884 - val_loss: 1.8827 - learning_rate: 1.2987e-04
Epoch 109/300
785/785 - 83s - 106ms/step - accuracy: 0.4206 - loss: 2.7605 - val_accuracy: 0.5917 - val_loss: 1.8878 - learning_rate: 1.2987e-04
Epoch 110/300
785/785 - 86s - 109ms/step - accuracy: 0.4155 - loss: 2.7618 - val_accuracy: 0.5814 - val_loss: 1.9146 - learning_rate: 1.2987e-04
Epoch 111/300
785/785 - 85s - 108ms/step - accuracy: 0.4181 - loss: 2.7585 - val_accuracy: 0.5850 - val_loss: 1.8894 - learning_rate: 1.2987e-04
Epoch 112/300
785/785 - 85s - 108ms/step - accuracy: 0.4165 - loss: 2.7651 - val_accuracy: 0.5932 - val_loss: 1.8904 - learning_rate: 1.2987e-04
Epoch 113/300
785/785 - 92s - 118ms/step - accuracy: 0.4211 - loss: 2.7721 - val_accuracy: 0.5904 - val_loss: 1.9107 - learning_rate: 1.2987e-04
Epoch 114/300
785/785 - 85s - 108ms/step - accuracy: 0.4271 - loss: 2.7567 - val_accuracy: 0.5882 - val_loss: 1.8932 - learning_rate: 1.2987e-04
Epoch 115/300
785/785 - 86s - 109ms/step - accuracy: 0.4189 - loss: 2.7343 - val_accuracy: 0.5946 - val_loss: 1.9070 - learning_rate: 1.2987e-04
Epoch 116/300

Epoch 116: ReduceLROnPlateau reducing learning rate to 6.493452383438125e-05.
785/785 - 141s - 180ms/step - accuracy: 0.4179 - loss: 2.7740 - val_accuracy: 0.5828 - val_loss: 1.9058 - learning_rate: 1.2987e-04
Epoch 117/300
785/785 - 85s - 109ms/step - accuracy: 0.4211 - loss: 2.7855 - val_accuracy: 0.5874 - val_loss: 1.8872 - learning_rate: 6.4935e-05
Epoch 118/300
785/785 - 85s - 108ms/step - accuracy: 0.4255 - loss: 2.7216 - val_accuracy: 0.5884 - val_loss: 1.8875 - learning_rate: 6.4935e-05
Epoch 119/300
785/785 - 143s - 182ms/step - accuracy: 0.4354 - loss: 2.6991 - val_accuracy: 0.5814 - val_loss: 1.8961 - learning_rate: 6.4935e-05
Epoch 120/300
785/785 - 85s - 108ms/step - accuracy: 0.4262 - loss: 2.7095 - val_accuracy: 0.5935 - val_loss: 1.8765 - learning_rate: 6.4935e-05
Epoch 121/300
785/785 - 85s - 108ms/step - accuracy: 0.4216 - loss: 2.7536 - val_accuracy: 0.5920 - val_loss: 1.8839 - learning_rate: 6.4935e-05
Epoch 122/300
785/785 - 86s - 110ms/step - accuracy: 0.4306 - loss: 2.7426 - val_accuracy: 0.5963 - val_loss: 1.8756 - learning_rate: 6.4935e-05
Epoch 123/300
785/785 - 83s - 105ms/step - accuracy: 0.4192 - loss: 2.7435 - val_accuracy: 0.5970 - val_loss: 1.8785 - learning_rate: 6.4935e-05
Epoch 124/300
785/785 - 82s - 104ms/step - accuracy: 0.4224 - loss: 2.7448 - val_accuracy: 0.5951 - val_loss: 1.8880 - learning_rate: 6.4935e-05
Epoch 125/300
785/785 - 83s - 106ms/step - accuracy: 0.4287 - loss: 2.7290 - val_accuracy: 0.5951 - val_loss: 1.8789 - learning_rate: 6.4935e-05
Epoch 126/300
785/785 - 85s - 108ms/step - accuracy: 0.4310 - loss: 2.7066 - val_accuracy: 0.5877 - val_loss: 1.8616 - learning_rate: 6.4935e-05
Epoch 127/300
785/785 - 85s - 108ms/step - accuracy: 0.4243 - loss: 2.7028 - val_accuracy: 0.5904 - val_loss: 1.8734 - learning_rate: 6.4935e-05
Epoch 128/300
785/785 - 85s - 109ms/step - accuracy: 0.4233 - loss: 2.7291 - val_accuracy: 0.5941 - val_loss: 1.8890 - learning_rate: 6.4935e-05
Epoch 129/300
785/785 - 84s - 107ms/step - accuracy: 0.4233 - loss: 2.7460 - val_accuracy: 0.5941 - val_loss: 1.8873 - learning_rate: 6.4935e-05
Epoch 130/300
785/785 - 84s - 107ms/step - accuracy: 0.4238 - loss: 2.7254 - val_accuracy: 0.5919 - val_loss: 1.8732 - learning_rate: 6.4935e-05
Epoch 131/300
785/785 - 84s - 107ms/step - accuracy: 0.4273 - loss: 2.7206 - val_accuracy: 0.5911 - val_loss: 1.8814 - learning_rate: 6.4935e-05
Epoch 132/300
785/785 - 92s - 117ms/step - accuracy: 0.4289 - loss: 2.7072 - val_accuracy: 0.5873 - val_loss: 1.8710 - learning_rate: 6.4935e-05
Epoch 133/300
785/785 - 84s - 107ms/step - accuracy: 0.4255 - loss: 2.7515 - val_accuracy: 0.5962 - val_loss: 1.8758 - learning_rate: 6.4935e-05
Epoch 134/300

Epoch 134: ReduceLROnPlateau reducing learning rate to 3.2467261917190626e-05.
785/785 - 84s - 108ms/step - accuracy: 0.4297 - loss: 2.7180 - val_accuracy: 0.5927 - val_loss: 1.8662 - learning_rate: 6.4935e-05
Epoch 135/300
785/785 - 92s - 118ms/step - accuracy: 0.4271 - loss: 2.6949 - val_accuracy: 0.5989 - val_loss: 1.8578 - learning_rate: 3.2467e-05
Epoch 136/300
785/785 - 84s - 107ms/step - accuracy: 0.4332 - loss: 2.7504 - val_accuracy: 0.5939 - val_loss: 1.8659 - learning_rate: 3.2467e-05
Epoch 137/300
785/785 - 85s - 109ms/step - accuracy: 0.4238 - loss: 2.7241 - val_accuracy: 0.5933 - val_loss: 1.8486 - learning_rate: 3.2467e-05
Epoch 138/300
785/785 - 85s - 108ms/step - accuracy: 0.4284 - loss: 2.6729 - val_accuracy: 0.5968 - val_loss: 1.8685 - learning_rate: 3.2467e-05
Epoch 139/300
785/785 - 84s - 107ms/step - accuracy: 0.4431 - loss: 2.6479 - val_accuracy: 0.5927 - val_loss: 1.8745 - learning_rate: 3.2467e-05
Epoch 140/300
785/785 - 86s - 110ms/step - accuracy: 0.4306 - loss: 2.6840 - val_accuracy: 0.5949 - val_loss: 1.8712 - learning_rate: 3.2467e-05
Epoch 141/300
785/785 - 140s - 179ms/step - accuracy: 0.4357 - loss: 2.6590 - val_accuracy: 0.5936 - val_loss: 1.8534 - learning_rate: 3.2467e-05
Epoch 142/300
785/785 - 92s - 117ms/step - accuracy: 0.4356 - loss: 2.6800 - val_accuracy: 0.5939 - val_loss: 1.8721 - learning_rate: 3.2467e-05
Epoch 143/300
785/785 - 91s - 117ms/step - accuracy: 0.4286 - loss: 2.6894 - val_accuracy: 0.5941 - val_loss: 1.8597 - learning_rate: 3.2467e-05
Epoch 144/300
785/785 - 85s - 108ms/step - accuracy: 0.4219 - loss: 2.7059 - val_accuracy: 0.5960 - val_loss: 1.8544 - learning_rate: 3.2467e-05
Epoch 145/300

Epoch 145: ReduceLROnPlateau reducing learning rate to 1.6233630958595313e-05.
785/785 - 84s - 107ms/step - accuracy: 0.4386 - loss: 2.6548 - val_accuracy: 0.5911 - val_loss: 1.8588 - learning_rate: 3.2467e-05
Epoch 146/300
785/785 - 84s - 107ms/step - accuracy: 0.4329 - loss: 2.6663 - val_accuracy: 0.5973 - val_loss: 1.8504 - learning_rate: 1.6234e-05
Epoch 147/300
785/785 - 86s - 110ms/step - accuracy: 0.4343 - loss: 2.6821 - val_accuracy: 0.5959 - val_loss: 1.8551 - learning_rate: 1.6234e-05
Epoch 148/300
785/785 - 84s - 107ms/step - accuracy: 0.4311 - loss: 2.6986 - val_accuracy: 0.5954 - val_loss: 1.8552 - learning_rate: 1.6234e-05
Epoch 149/300
785/785 - 143s - 182ms/step - accuracy: 0.4236 - loss: 2.6990 - val_accuracy: 0.5986 - val_loss: 1.8521 - learning_rate: 1.6234e-05
Epoch 150/300
785/785 - 84s - 107ms/step - accuracy: 0.4330 - loss: 2.6730 - val_accuracy: 0.5959 - val_loss: 1.8498 - learning_rate: 1.6234e-05
Epoch 151/300
785/785 - 83s - 106ms/step - accuracy: 0.4346 - loss: 2.6716 - val_accuracy: 0.5960 - val_loss: 1.8430 - learning_rate: 1.6234e-05
Epoch 152/300
785/785 - 83s - 106ms/step - accuracy: 0.4314 - loss: 2.6674 - val_accuracy: 0.5938 - val_loss: 1.8512 - learning_rate: 1.6234e-05
Epoch 153/300
785/785 - 82s - 105ms/step - accuracy: 0.4251 - loss: 2.6995 - val_accuracy: 0.5976 - val_loss: 1.8581 - learning_rate: 1.6234e-05
Epoch 154/300
785/785 - 85s - 108ms/step - accuracy: 0.4439 - loss: 2.6721 - val_accuracy: 0.5982 - val_loss: 1.8546 - learning_rate: 1.6234e-05
Epoch 155/300
785/785 - 84s - 107ms/step - accuracy: 0.4346 - loss: 2.7011 - val_accuracy: 0.5968 - val_loss: 1.8581 - learning_rate: 1.6234e-05
Epoch 156/300
785/785 - 82s - 105ms/step - accuracy: 0.4322 - loss: 2.7028 - val_accuracy: 0.5990 - val_loss: 1.8535 - learning_rate: 1.6234e-05
Epoch 157/300
785/785 - 85s - 108ms/step - accuracy: 0.4179 - loss: 2.7094 - val_accuracy: 0.6002 - val_loss: 1.8474 - learning_rate: 1.6234e-05
Epoch 158/300
785/785 - 84s - 107ms/step - accuracy: 0.4318 - loss: 2.7044 - val_accuracy: 0.5962 - val_loss: 1.8580 - learning_rate: 1.6234e-05
Epoch 159/300

Epoch 159: ReduceLROnPlateau reducing learning rate to 8.116815479297657e-06.
785/785 - 85s - 108ms/step - accuracy: 0.4341 - loss: 2.6799 - val_accuracy: 0.5994 - val_loss: 1.8546 - learning_rate: 1.6234e-05
Epoch 160/300
785/785 - 85s - 109ms/step - accuracy: 0.4437 - loss: 2.6637 - val_accuracy: 0.6013 - val_loss: 1.8511 - learning_rate: 8.1168e-06
Epoch 161/300
785/785 - 85s - 108ms/step - accuracy: 0.4467 - loss: 2.6275 - val_accuracy: 0.6010 - val_loss: 1.8514 - learning_rate: 8.1168e-06
Epoch 162/300
785/785 - 85s - 108ms/step - accuracy: 0.4298 - loss: 2.6775 - val_accuracy: 0.5998 - val_loss: 1.8433 - learning_rate: 8.1168e-06
Epoch 163/300
785/785 - 85s - 109ms/step - accuracy: 0.4388 - loss: 2.6613 - val_accuracy: 0.5994 - val_loss: 1.8434 - learning_rate: 8.1168e-06
Epoch 164/300
785/785 - 85s - 108ms/step - accuracy: 0.4397 - loss: 2.6805 - val_accuracy: 0.5990 - val_loss: 1.8450 - learning_rate: 8.1168e-06
Epoch 165/300
785/785 - 92s - 117ms/step - accuracy: 0.4362 - loss: 2.6716 - val_accuracy: 0.5975 - val_loss: 1.8414 - learning_rate: 8.1168e-06
Epoch 166/300
785/785 - 84s - 108ms/step - accuracy: 0.4284 - loss: 2.6603 - val_accuracy: 0.5975 - val_loss: 1.8467 - learning_rate: 8.1168e-06
Epoch 167/300
785/785 - 86s - 110ms/step - accuracy: 0.4313 - loss: 2.6816 - val_accuracy: 0.5989 - val_loss: 1.8469 - learning_rate: 8.1168e-06
Epoch 168/300
785/785 - 85s - 108ms/step - accuracy: 0.4340 - loss: 2.7190 - val_accuracy: 0.5997 - val_loss: 1.8396 - learning_rate: 8.1168e-06
Epoch 169/300
785/785 - 85s - 108ms/step - accuracy: 0.4343 - loss: 2.6471 - val_accuracy: 0.6006 - val_loss: 1.8422 - learning_rate: 8.1168e-06
Epoch 170/300
785/785 - 85s - 108ms/step - accuracy: 0.4327 - loss: 2.6893 - val_accuracy: 0.6000 - val_loss: 1.8449 - learning_rate: 8.1168e-06
Epoch 171/300
785/785 - 84s - 107ms/step - accuracy: 0.4367 - loss: 2.6741 - val_accuracy: 0.6002 - val_loss: 1.8442 - learning_rate: 8.1168e-06
Epoch 172/300
785/785 - 85s - 109ms/step - accuracy: 0.4351 - loss: 2.7115 - val_accuracy: 0.6016 - val_loss: 1.8457 - learning_rate: 8.1168e-06
Epoch 173/300
785/785 - 85s - 109ms/step - accuracy: 0.4335 - loss: 2.6808 - val_accuracy: 0.6008 - val_loss: 1.8465 - learning_rate: 8.1168e-06
Epoch 174/300
785/785 - 85s - 108ms/step - accuracy: 0.4233 - loss: 2.7194 - val_accuracy: 0.6008 - val_loss: 1.8502 - learning_rate: 8.1168e-06
Epoch 175/300
785/785 - 86s - 109ms/step - accuracy: 0.4431 - loss: 2.6740 - val_accuracy: 0.5997 - val_loss: 1.8468 - learning_rate: 8.1168e-06
Epoch 176/300

Epoch 176: ReduceLROnPlateau reducing learning rate to 4.058407739648828e-06.
785/785 - 84s - 108ms/step - accuracy: 0.4370 - loss: 2.6485 - val_accuracy: 0.6006 - val_loss: 1.8449 - learning_rate: 8.1168e-06
Epoch 177/300
785/785 - 85s - 108ms/step - accuracy: 0.4351 - loss: 2.6947 - val_accuracy: 0.5989 - val_loss: 1.8391 - learning_rate: 4.0584e-06
Epoch 178/300
785/785 - 84s - 106ms/step - accuracy: 0.4359 - loss: 2.6868 - val_accuracy: 0.5986 - val_loss: 1.8462 - learning_rate: 4.0584e-06
Epoch 179/300
785/785 - 84s - 107ms/step - accuracy: 0.4462 - loss: 2.6644 - val_accuracy: 0.5994 - val_loss: 1.8483 - learning_rate: 4.0584e-06
Epoch 180/300
785/785 - 92s - 118ms/step - accuracy: 0.4389 - loss: 2.6714 - val_accuracy: 0.5982 - val_loss: 1.8420 - learning_rate: 4.0584e-06
Epoch 181/300
785/785 - 84s - 107ms/step - accuracy: 0.4392 - loss: 2.6263 - val_accuracy: 0.5995 - val_loss: 1.8411 - learning_rate: 4.0584e-06
Epoch 182/300
785/785 - 85s - 108ms/step - accuracy: 0.4450 - loss: 2.6747 - val_accuracy: 0.5976 - val_loss: 1.8437 - learning_rate: 4.0584e-06
Epoch 183/300
785/785 - 84s - 107ms/step - accuracy: 0.4335 - loss: 2.6485 - val_accuracy: 0.5982 - val_loss: 1.8391 - learning_rate: 4.0584e-06
Epoch 184/300
785/785 - 82s - 105ms/step - accuracy: 0.4394 - loss: 2.6531 - val_accuracy: 0.5976 - val_loss: 1.8393 - learning_rate: 4.0584e-06
Epoch 185/300

Epoch 185: ReduceLROnPlateau reducing learning rate to 2.029203869824414e-06.
785/785 - 85s - 108ms/step - accuracy: 0.4318 - loss: 2.6851 - val_accuracy: 0.5992 - val_loss: 1.8409 - learning_rate: 4.0584e-06
Epoch 186/300
785/785 - 86s - 109ms/step - accuracy: 0.4412 - loss: 2.6528 - val_accuracy: 0.5989 - val_loss: 1.8359 - learning_rate: 2.0292e-06
Epoch 187/300
785/785 - 85s - 108ms/step - accuracy: 0.4365 - loss: 2.6965 - val_accuracy: 0.5989 - val_loss: 1.8407 - learning_rate: 2.0292e-06
Epoch 188/300
785/785 - 85s - 109ms/step - accuracy: 0.4378 - loss: 2.6679 - val_accuracy: 0.6005 - val_loss: 1.8391 - learning_rate: 2.0292e-06
Epoch 189/300
785/785 - 84s - 107ms/step - accuracy: 0.4303 - loss: 2.6935 - val_accuracy: 0.5995 - val_loss: 1.8394 - learning_rate: 2.0292e-06
Epoch 190/300
785/785 - 85s - 108ms/step - accuracy: 0.4381 - loss: 2.6388 - val_accuracy: 0.5987 - val_loss: 1.8390 - learning_rate: 2.0292e-06
Epoch 191/300
785/785 - 84s - 107ms/step - accuracy: 0.4429 - loss: 2.6838 - val_accuracy: 0.5978 - val_loss: 1.8413 - learning_rate: 2.0292e-06
Epoch 192/300
785/785 - 84s - 107ms/step - accuracy: 0.4361 - loss: 2.6705 - val_accuracy: 0.5995 - val_loss: 1.8387 - learning_rate: 2.0292e-06
Epoch 193/300
785/785 - 84s - 107ms/step - accuracy: 0.4354 - loss: 2.6664 - val_accuracy: 0.5986 - val_loss: 1.8434 - learning_rate: 2.0292e-06
Epoch 194/300

Epoch 194: ReduceLROnPlateau reducing learning rate to 1.014601934912207e-06.
785/785 - 92s - 117ms/step - accuracy: 0.4408 - loss: 2.6452 - val_accuracy: 0.5987 - val_loss: 1.8392 - learning_rate: 2.0292e-06
Epoch 195/300
785/785 - 84s - 107ms/step - accuracy: 0.4380 - loss: 2.6728 - val_accuracy: 0.5981 - val_loss: 1.8419 - learning_rate: 1.0146e-06
Epoch 196/300
785/785 - 87s - 111ms/step - accuracy: 0.4397 - loss: 2.6487 - val_accuracy: 0.5986 - val_loss: 1.8418 - learning_rate: 1.0146e-06
Epoch 197/300
785/785 - 84s - 108ms/step - accuracy: 0.4386 - loss: 2.6436 - val_accuracy: 0.5981 - val_loss: 1.8432 - learning_rate: 1.0146e-06
Epoch 198/300
785/785 - 85s - 108ms/step - accuracy: 0.4391 - loss: 2.6600 - val_accuracy: 0.5987 - val_loss: 1.8422 - learning_rate: 1.0146e-06
Epoch 199/300
785/785 - 85s - 108ms/step - accuracy: 0.4400 - loss: 2.6879 - val_accuracy: 0.5995 - val_loss: 1.8410 - learning_rate: 1.0146e-06
Epoch 200/300
785/785 - 85s - 108ms/step - accuracy: 0.4343 - loss: 2.6728 - val_accuracy: 0.5992 - val_loss: 1.8438 - learning_rate: 1.0146e-06
Epoch 201/300
785/785 - 86s - 110ms/step - accuracy: 0.4362 - loss: 2.6910 - val_accuracy: 0.5984 - val_loss: 1.8419 - learning_rate: 1.0146e-06
Epoch 202/300

Epoch 202: ReduceLROnPlateau reducing learning rate to 1e-06.
785/785 - 85s - 108ms/step - accuracy: 0.4329 - loss: 2.6571 - val_accuracy: 0.5989 - val_loss: 1.8396 - learning_rate: 1.0146e-06
Epoch 202: early stopping
Restoring model weights from the end of the best epoch: 186.
Fold 4_1 Evaluation results: [1.8386062383651733, 0.5988853573799133]
              precision    recall  f1-score   support

        1820       0.68      0.82      0.74       312
        1821       0.87      0.83      0.85       277
        1822       0.00      0.00      0.00         9
        1823       0.00      0.00      0.00         5
        1824       0.00      0.00      0.00         2
        1825       0.33      0.10      0.15        10
        1826       0.00      0.00      0.00        11
        1827       0.82      0.78      0.80       129
        1828       0.33      0.67      0.44         3
        1829       0.50      0.08      0.14        24
        1830       0.52      0.69      0.59       270
        1831       0.77      0.90      0.83       705
        1832       0.85      0.76      0.80       355
        1833       0.83      0.93      0.88        86
        1834       0.47      0.69      0.56       141
        1835       0.00      0.00      0.00        14
        1836       0.20      0.20      0.20        15
        1837       0.57      0.12      0.21        32
        1838       0.00      0.00      0.00        20
        1839       0.00      0.00      0.00         4
        1840       0.44      0.62      0.52       199
        1841       0.69      0.56      0.62       530
        1842       0.39      0.27      0.32        26
        1843       0.00      0.00      0.00        27
        1844       0.00      0.00      0.00         0
        1845       0.00      0.00      0.00         4
        1846       0.20      0.09      0.12        22
        1847       0.00      0.00      0.00         6
        1848       0.11      0.03      0.05        31
        1849       1.00      0.04      0.07        28
        1850       0.40      0.55      0.47       258
        1851       0.76      0.65      0.70       395
        1852       0.00      0.00      0.00        39
        1853       0.00      0.00      0.00        34
        1854       0.00      0.00      0.00        11
        1855       0.18      0.03      0.05       124
        1856       0.47      0.47      0.47        59
        1857       0.44      0.51      0.48       167
        1858       0.00      0.00      0.00        13
        1859       0.00      0.00      0.00         8
        1860       0.25      0.48      0.33       307
        1861       0.76      0.82      0.79       441
        1862       1.00      0.01      0.02        91
        1863       0.38      0.48      0.42        89
        1864       0.32      0.40      0.35        82
        1865       1.00      0.08      0.15        38
        1866       0.33      0.04      0.07        24
        1867       0.31      0.09      0.13        47
        1868       0.00      0.00      0.00        36
        1869       0.00      0.00      0.00        24
        1870       0.44      0.53      0.48       158
        1871       0.67      0.81      0.73       231
        1872       0.44      0.11      0.18        35
        1873       0.12      0.12      0.12        41
        1874       0.33      0.12      0.18        25
        1875       0.25      0.23      0.24        69
        1876       0.91      0.84      0.88        50
        1877       0.33      0.03      0.06        33
        1878       0.50      0.22      0.31        49
        1879       0.00      0.00      0.00         5

    accuracy                           0.60      6280
   macro avg       0.35      0.28      0.28      6280
weighted avg       0.59      0.60      0.57      6280

Matthews Correlation Coefficient: 0.578
Macro avg F1: 0.275
Weighted avg F1: 0.573
Micro avg F1: 0.599
Top-3 Accuracy: 0.842
Top-5 Accuracy: 0.900
Micro ROC AUC  = 0.98
Macro ROC AUC (present classes) = 0.97
Classification MAE (in years): 3.29

Fold 4_1 Misclassification Analysis:
Near misses (within 2 years): 528 out of 2519 misclassifications (20.96%)
Big misses (greater than 10 years): 1082
MAE with outliers: 3.29
MAE without outliers: 2.37 (improvement: 0.92)

10 Worst misclassifications:
Image: data/datasets/public/1870/1877_035met.jpg, True: 1877, Predicted: 1820, Error: 57
Image: data/datasets/public/1870/1877_033met.jpg, True: 1877, Predicted: 1820, Error: 57
Image: data/datasets/public/1870/1876_71washington.jpg, True: 1876, Predicted: 1820, Error: 56
Image: data/datasets/public/1870/1876_70washington.jpg, True: 1876, Predicted: 1820, Error: 56
Image: data/datasets/private/1870/1871_404etsy.jpg, True: 1871, Predicted: 1821, Error: 50
Image: data/datasets/private/1870/1871_384etsy.jpg, True: 1871, Predicted: 1821, Error: 50
Image: data/datasets/public/1870/1870_79wikimedia2.jpg, True: 1870, Predicted: 1820, Error: 50
Image: data/datasets/public/1870/1870_75wikimedia2.jpg, True: 1870, Predicted: 1820, Error: 50
Image: data/datasets/public/1860/1868_007met.jpg, True: 1868, Predicted: 1820, Error: 48
Image: data/datasets/public/1870/1876_53washington.jpg, True: 1876, Predicted: 1829, Error: 47

===== Fine Tuning 9 layers! =====
Epoch 1/300
785/785 - 108s - 137ms/step - accuracy: 0.1148 - loss: 4.3795 - val_accuracy: 0.2090 - val_loss: 4.4874 - learning_rate: 2.5974e-04
Epoch 2/300
785/785 - 85s - 109ms/step - accuracy: 0.1670 - loss: 4.1168 - val_accuracy: 0.2255 - val_loss: 3.8079 - learning_rate: 2.5974e-04
Epoch 3/300
785/785 - 84s - 107ms/step - accuracy: 0.2032 - loss: 3.9470 - val_accuracy: 0.2857 - val_loss: 3.5230 - learning_rate: 2.5974e-04
Epoch 4/300
785/785 - 85s - 108ms/step - accuracy: 0.2244 - loss: 3.8161 - val_accuracy: 0.3195 - val_loss: 3.3866 - learning_rate: 2.5974e-04
Epoch 5/300
785/785 - 84s - 106ms/step - accuracy: 0.2392 - loss: 3.6694 - val_accuracy: 0.3478 - val_loss: 3.1685 - learning_rate: 2.5974e-04
Epoch 6/300
785/785 - 91s - 115ms/step - accuracy: 0.2604 - loss: 3.5493 - val_accuracy: 0.3903 - val_loss: 3.0793 - learning_rate: 2.5974e-04
Epoch 7/300
785/785 - 81s - 104ms/step - accuracy: 0.2685 - loss: 3.4993 - val_accuracy: 0.4165 - val_loss: 2.9810 - learning_rate: 2.5974e-04
Epoch 8/300
785/785 - 82s - 104ms/step - accuracy: 0.2806 - loss: 3.4332 - val_accuracy: 0.4290 - val_loss: 2.9124 - learning_rate: 2.5974e-04
Epoch 9/300
785/785 - 84s - 107ms/step - accuracy: 0.2892 - loss: 3.4164 - val_accuracy: 0.4118 - val_loss: 2.8155 - learning_rate: 2.5974e-04
Epoch 10/300
785/785 - 83s - 106ms/step - accuracy: 0.2952 - loss: 3.3570 - val_accuracy: 0.4330 - val_loss: 2.8105 - learning_rate: 2.5974e-04
Epoch 11/300
785/785 - 85s - 108ms/step - accuracy: 0.3070 - loss: 3.3224 - val_accuracy: 0.4539 - val_loss: 2.7130 - learning_rate: 2.5974e-04
Epoch 12/300
785/785 - 84s - 107ms/step - accuracy: 0.3081 - loss: 3.3166 - val_accuracy: 0.4751 - val_loss: 2.6940 - learning_rate: 2.5974e-04
Epoch 13/300
785/785 - 84s - 107ms/step - accuracy: 0.3145 - loss: 3.2820 - val_accuracy: 0.4619 - val_loss: 2.6270 - learning_rate: 2.5974e-04
Epoch 14/300
785/785 - 87s - 110ms/step - accuracy: 0.3223 - loss: 3.2446 - val_accuracy: 0.4587 - val_loss: 2.6228 - learning_rate: 2.5974e-04
Epoch 15/300
785/785 - 146s - 187ms/step - accuracy: 0.3326 - loss: 3.2132 - val_accuracy: 0.4496 - val_loss: 2.6000 - learning_rate: 2.5974e-04
Epoch 16/300
785/785 - 135s - 172ms/step - accuracy: 0.3277 - loss: 3.1974 - val_accuracy: 0.4677 - val_loss: 2.5739 - learning_rate: 2.5974e-04
Epoch 17/300
785/785 - 84s - 107ms/step - accuracy: 0.3389 - loss: 3.1853 - val_accuracy: 0.4760 - val_loss: 2.4806 - learning_rate: 2.5974e-04
Epoch 18/300
785/785 - 85s - 108ms/step - accuracy: 0.3459 - loss: 3.1524 - val_accuracy: 0.4966 - val_loss: 2.4866 - learning_rate: 2.5974e-04
Epoch 19/300
785/785 - 84s - 106ms/step - accuracy: 0.3502 - loss: 3.1235 - val_accuracy: 0.4838 - val_loss: 2.4617 - learning_rate: 2.5974e-04
Epoch 20/300
785/785 - 85s - 108ms/step - accuracy: 0.3516 - loss: 3.1292 - val_accuracy: 0.4859 - val_loss: 2.4317 - learning_rate: 2.5974e-04
Epoch 21/300
785/785 - 91s - 116ms/step - accuracy: 0.3430 - loss: 3.1060 - val_accuracy: 0.4861 - val_loss: 2.5158 - learning_rate: 2.5974e-04
Epoch 22/300
785/785 - 83s - 106ms/step - accuracy: 0.3449 - loss: 3.0813 - val_accuracy: 0.4956 - val_loss: 2.3465 - learning_rate: 2.5974e-04
Epoch 23/300
785/785 - 86s - 110ms/step - accuracy: 0.3567 - loss: 3.0634 - val_accuracy: 0.5014 - val_loss: 2.3481 - learning_rate: 2.5974e-04
Epoch 24/300
785/785 - 85s - 109ms/step - accuracy: 0.3548 - loss: 3.0911 - val_accuracy: 0.5072 - val_loss: 2.3396 - learning_rate: 2.5974e-04
Epoch 25/300
785/785 - 85s - 108ms/step - accuracy: 0.3554 - loss: 3.0575 - val_accuracy: 0.5106 - val_loss: 2.3444 - learning_rate: 2.5974e-04
Epoch 26/300
785/785 - 84s - 107ms/step - accuracy: 0.3637 - loss: 3.0452 - val_accuracy: 0.5090 - val_loss: 2.3821 - learning_rate: 2.5974e-04
Epoch 27/300
785/785 - 91s - 116ms/step - accuracy: 0.3556 - loss: 3.0615 - val_accuracy: 0.5260 - val_loss: 2.3059 - learning_rate: 2.5974e-04
Epoch 28/300
785/785 - 135s - 172ms/step - accuracy: 0.3740 - loss: 2.9905 - val_accuracy: 0.5179 - val_loss: 2.3027 - learning_rate: 2.5974e-04
Epoch 29/300
785/785 - 83s - 106ms/step - accuracy: 0.3672 - loss: 3.0194 - val_accuracy: 0.5114 - val_loss: 2.3226 - learning_rate: 2.5974e-04
Epoch 30/300
785/785 - 86s - 109ms/step - accuracy: 0.3768 - loss: 3.0087 - val_accuracy: 0.5131 - val_loss: 2.2944 - learning_rate: 2.5974e-04
Epoch 31/300
785/785 - 84s - 107ms/step - accuracy: 0.3658 - loss: 3.0036 - val_accuracy: 0.4892 - val_loss: 2.3828 - learning_rate: 2.5974e-04
Epoch 32/300
785/785 - 85s - 108ms/step - accuracy: 0.3674 - loss: 3.0280 - val_accuracy: 0.5221 - val_loss: 2.2822 - learning_rate: 2.5974e-04
Epoch 33/300
785/785 - 84s - 107ms/step - accuracy: 0.3804 - loss: 2.9974 - val_accuracy: 0.5264 - val_loss: 2.2485 - learning_rate: 2.5974e-04
Epoch 34/300
785/785 - 82s - 104ms/step - accuracy: 0.3815 - loss: 2.9810 - val_accuracy: 0.5359 - val_loss: 2.2484 - learning_rate: 2.5974e-04
Epoch 35/300
785/785 - 83s - 106ms/step - accuracy: 0.3830 - loss: 2.9724 - val_accuracy: 0.5233 - val_loss: 2.2160 - learning_rate: 2.5974e-04
Epoch 36/300
785/785 - 83s - 106ms/step - accuracy: 0.3812 - loss: 2.9637 - val_accuracy: 0.5249 - val_loss: 2.1829 - learning_rate: 2.5974e-04
Epoch 37/300
785/785 - 82s - 104ms/step - accuracy: 0.3796 - loss: 2.9269 - val_accuracy: 0.5444 - val_loss: 2.2298 - learning_rate: 2.5974e-04
Epoch 38/300
785/785 - 82s - 105ms/step - accuracy: 0.3726 - loss: 2.9668 - val_accuracy: 0.5318 - val_loss: 2.1937 - learning_rate: 2.5974e-04
Epoch 39/300
785/785 - 84s - 107ms/step - accuracy: 0.3860 - loss: 2.9122 - val_accuracy: 0.5359 - val_loss: 2.1958 - learning_rate: 2.5974e-04
Epoch 40/300
785/785 - 84s - 107ms/step - accuracy: 0.3742 - loss: 2.9538 - val_accuracy: 0.5248 - val_loss: 2.2195 - learning_rate: 2.5974e-04
Epoch 41/300
785/785 - 85s - 109ms/step - accuracy: 0.3796 - loss: 2.9720 - val_accuracy: 0.5217 - val_loss: 2.2191 - learning_rate: 2.5974e-04
Epoch 42/300
785/785 - 84s - 107ms/step - accuracy: 0.3932 - loss: 2.9111 - val_accuracy: 0.5330 - val_loss: 2.1875 - learning_rate: 2.5974e-04
Epoch 43/300
785/785 - 143s - 182ms/step - accuracy: 0.3804 - loss: 2.9402 - val_accuracy: 0.5383 - val_loss: 2.2104 - learning_rate: 2.5974e-04
Epoch 44/300
785/785 - 84s - 107ms/step - accuracy: 0.3901 - loss: 2.9151 - val_accuracy: 0.5354 - val_loss: 2.1302 - learning_rate: 2.5974e-04
Epoch 45/300
785/785 - 84s - 107ms/step - accuracy: 0.3839 - loss: 2.9172 - val_accuracy: 0.5181 - val_loss: 2.2041 - learning_rate: 2.5974e-04
Epoch 46/300
785/785 - 84s - 108ms/step - accuracy: 0.3831 - loss: 2.9183 - val_accuracy: 0.5429 - val_loss: 2.1841 - learning_rate: 2.5974e-04
Epoch 47/300
785/785 - 83s - 106ms/step - accuracy: 0.3842 - loss: 2.9104 - val_accuracy: 0.5311 - val_loss: 2.2118 - learning_rate: 2.5974e-04
Epoch 48/300
785/785 - 85s - 109ms/step - accuracy: 0.3920 - loss: 2.9030 - val_accuracy: 0.5404 - val_loss: 2.1927 - learning_rate: 2.5974e-04
Epoch 49/300
785/785 - 84s - 107ms/step - accuracy: 0.3922 - loss: 2.8788 - val_accuracy: 0.5362 - val_loss: 2.1182 - learning_rate: 2.5974e-04
Epoch 50/300
785/785 - 84s - 107ms/step - accuracy: 0.3989 - loss: 2.8725 - val_accuracy: 0.5436 - val_loss: 2.1505 - learning_rate: 2.5974e-04
Epoch 51/300
785/785 - 84s - 107ms/step - accuracy: 0.3854 - loss: 2.8947 - val_accuracy: 0.5181 - val_loss: 2.2271 - learning_rate: 2.5974e-04
Epoch 52/300
785/785 - 141s - 180ms/step - accuracy: 0.3825 - loss: 2.8934 - val_accuracy: 0.5364 - val_loss: 2.0918 - learning_rate: 2.5974e-04
Epoch 53/300
785/785 - 84s - 108ms/step - accuracy: 0.3911 - loss: 2.8938 - val_accuracy: 0.5401 - val_loss: 2.1382 - learning_rate: 2.5974e-04
Epoch 54/300
785/785 - 83s - 106ms/step - accuracy: 0.3831 - loss: 2.8978 - val_accuracy: 0.5407 - val_loss: 2.1503 - learning_rate: 2.5974e-04
Epoch 55/300
785/785 - 91s - 116ms/step - accuracy: 0.4019 - loss: 2.8589 - val_accuracy: 0.5345 - val_loss: 2.1097 - learning_rate: 2.5974e-04
Epoch 56/300
785/785 - 84s - 107ms/step - accuracy: 0.4016 - loss: 2.8174 - val_accuracy: 0.5477 - val_loss: 2.1245 - learning_rate: 2.5974e-04
Epoch 57/300
785/785 - 91s - 116ms/step - accuracy: 0.3930 - loss: 2.8648 - val_accuracy: 0.5397 - val_loss: 2.1132 - learning_rate: 2.5974e-04
Epoch 58/300
785/785 - 85s - 109ms/step - accuracy: 0.3914 - loss: 2.8718 - val_accuracy: 0.5308 - val_loss: 2.1076 - learning_rate: 2.5974e-04
Epoch 59/300
785/785 - 83s - 106ms/step - accuracy: 0.4011 - loss: 2.8227 - val_accuracy: 0.5421 - val_loss: 2.1156 - learning_rate: 2.5974e-04
Epoch 60/300

Epoch 60: ReduceLROnPlateau reducing learning rate to 0.0001298690476687625.
785/785 - 84s - 107ms/step - accuracy: 0.3992 - loss: 2.8752 - val_accuracy: 0.5466 - val_loss: 2.1088 - learning_rate: 2.5974e-04
Epoch 61/300
785/785 - 83s - 106ms/step - accuracy: 0.4059 - loss: 2.8116 - val_accuracy: 0.5461 - val_loss: 2.0864 - learning_rate: 1.2987e-04
Epoch 62/300
785/785 - 84s - 107ms/step - accuracy: 0.4145 - loss: 2.7743 - val_accuracy: 0.5569 - val_loss: 2.0646 - learning_rate: 1.2987e-04
Epoch 63/300
785/785 - 85s - 109ms/step - accuracy: 0.4097 - loss: 2.8016 - val_accuracy: 0.5432 - val_loss: 2.0815 - learning_rate: 1.2987e-04
Epoch 64/300
785/785 - 83s - 106ms/step - accuracy: 0.4116 - loss: 2.7887 - val_accuracy: 0.5452 - val_loss: 2.0577 - learning_rate: 1.2987e-04
Epoch 65/300
785/785 - 90s - 115ms/step - accuracy: 0.4115 - loss: 2.7442 - val_accuracy: 0.5528 - val_loss: 2.0495 - learning_rate: 1.2987e-04
Epoch 66/300
785/785 - 83s - 106ms/step - accuracy: 0.4064 - loss: 2.7867 - val_accuracy: 0.5510 - val_loss: 2.0603 - learning_rate: 1.2987e-04
Epoch 67/300
785/785 - 83s - 105ms/step - accuracy: 0.4153 - loss: 2.7630 - val_accuracy: 0.5619 - val_loss: 2.0551 - learning_rate: 1.2987e-04
Epoch 68/300
785/785 - 85s - 109ms/step - accuracy: 0.4213 - loss: 2.7256 - val_accuracy: 0.5534 - val_loss: 2.0659 - learning_rate: 1.2987e-04
Epoch 69/300
785/785 - 84s - 107ms/step - accuracy: 0.4283 - loss: 2.7324 - val_accuracy: 0.5668 - val_loss: 2.0360 - learning_rate: 1.2987e-04
Epoch 70/300
785/785 - 84s - 107ms/step - accuracy: 0.4124 - loss: 2.7816 - val_accuracy: 0.5568 - val_loss: 2.0732 - learning_rate: 1.2987e-04
Epoch 71/300
785/785 - 85s - 108ms/step - accuracy: 0.4065 - loss: 2.7500 - val_accuracy: 0.5522 - val_loss: 2.0676 - learning_rate: 1.2987e-04
Epoch 72/300
785/785 - 84s - 107ms/step - accuracy: 0.4186 - loss: 2.7382 - val_accuracy: 0.5584 - val_loss: 2.0426 - learning_rate: 1.2987e-04
Epoch 73/300
785/785 - 84s - 107ms/step - accuracy: 0.4229 - loss: 2.7187 - val_accuracy: 0.5681 - val_loss: 2.0226 - learning_rate: 1.2987e-04
Epoch 74/300
785/785 - 83s - 106ms/step - accuracy: 0.4172 - loss: 2.7783 - val_accuracy: 0.5638 - val_loss: 2.0528 - learning_rate: 1.2987e-04
Epoch 75/300
785/785 - 83s - 106ms/step - accuracy: 0.4248 - loss: 2.7278 - val_accuracy: 0.5619 - val_loss: 2.0209 - learning_rate: 1.2987e-04
Epoch 76/300
785/785 - 84s - 108ms/step - accuracy: 0.4140 - loss: 2.7630 - val_accuracy: 0.5504 - val_loss: 2.0336 - learning_rate: 1.2987e-04
Epoch 77/300
785/785 - 83s - 106ms/step - accuracy: 0.4234 - loss: 2.7458 - val_accuracy: 0.5553 - val_loss: 2.0211 - learning_rate: 1.2987e-04
Epoch 78/300
785/785 - 84s - 108ms/step - accuracy: 0.4167 - loss: 2.7336 - val_accuracy: 0.5587 - val_loss: 2.0326 - learning_rate: 1.2987e-04
Epoch 79/300
785/785 - 83s - 106ms/step - accuracy: 0.4264 - loss: 2.7097 - val_accuracy: 0.5593 - val_loss: 2.0271 - learning_rate: 1.2987e-04
Epoch 80/300
785/785 - 84s - 107ms/step - accuracy: 0.4221 - loss: 2.6963 - val_accuracy: 0.5576 - val_loss: 2.0323 - learning_rate: 1.2987e-04
Epoch 81/300
785/785 - 85s - 108ms/step - accuracy: 0.4156 - loss: 2.7381 - val_accuracy: 0.5485 - val_loss: 2.0567 - learning_rate: 1.2987e-04
Epoch 82/300
785/785 - 84s - 107ms/step - accuracy: 0.4186 - loss: 2.7503 - val_accuracy: 0.5617 - val_loss: 2.0201 - learning_rate: 1.2987e-04
Epoch 83/300
785/785 - 83s - 106ms/step - accuracy: 0.4205 - loss: 2.7414 - val_accuracy: 0.5571 - val_loss: 2.0255 - learning_rate: 1.2987e-04
Epoch 84/300
785/785 - 85s - 108ms/step - accuracy: 0.4256 - loss: 2.7094 - val_accuracy: 0.5536 - val_loss: 2.0402 - learning_rate: 1.2987e-04
Epoch 85/300
785/785 - 91s - 116ms/step - accuracy: 0.4303 - loss: 2.7251 - val_accuracy: 0.5673 - val_loss: 2.0075 - learning_rate: 1.2987e-04
Epoch 86/300
785/785 - 86s - 110ms/step - accuracy: 0.4237 - loss: 2.7054 - val_accuracy: 0.5738 - val_loss: 2.0092 - learning_rate: 1.2987e-04
Epoch 87/300
785/785 - 91s - 115ms/step - accuracy: 0.4283 - loss: 2.7067 - val_accuracy: 0.5628 - val_loss: 2.0223 - learning_rate: 1.2987e-04
Epoch 88/300
785/785 - 83s - 105ms/step - accuracy: 0.4174 - loss: 2.7227 - val_accuracy: 0.5625 - val_loss: 2.0061 - learning_rate: 1.2987e-04
Epoch 89/300
785/785 - 84s - 107ms/step - accuracy: 0.4261 - loss: 2.6999 - val_accuracy: 0.5619 - val_loss: 2.0160 - learning_rate: 1.2987e-04
Epoch 90/300
785/785 - 83s - 105ms/step - accuracy: 0.4239 - loss: 2.7235 - val_accuracy: 0.5643 - val_loss: 2.0313 - learning_rate: 1.2987e-04
Epoch 91/300
785/785 - 85s - 108ms/step - accuracy: 0.4322 - loss: 2.7421 - val_accuracy: 0.5644 - val_loss: 2.0347 - learning_rate: 1.2987e-04
Epoch 92/300
785/785 - 83s - 106ms/step - accuracy: 0.4193 - loss: 2.7321 - val_accuracy: 0.5627 - val_loss: 2.0028 - learning_rate: 1.2987e-04
Epoch 93/300
785/785 - 90s - 115ms/step - accuracy: 0.4240 - loss: 2.7256 - val_accuracy: 0.5643 - val_loss: 2.0140 - learning_rate: 1.2987e-04
Epoch 94/300
785/785 - 84s - 107ms/step - accuracy: 0.4260 - loss: 2.7135 - val_accuracy: 0.5665 - val_loss: 2.0043 - learning_rate: 1.2987e-04
Epoch 95/300
785/785 - 83s - 106ms/step - accuracy: 0.4204 - loss: 2.7266 - val_accuracy: 0.5732 - val_loss: 1.9961 - learning_rate: 1.2987e-04
Epoch 96/300
785/785 - 83s - 106ms/step - accuracy: 0.4369 - loss: 2.6799 - val_accuracy: 0.5657 - val_loss: 2.0315 - learning_rate: 1.2987e-04
Epoch 97/300
785/785 - 84s - 107ms/step - accuracy: 0.4275 - loss: 2.6922 - val_accuracy: 0.5668 - val_loss: 1.9817 - learning_rate: 1.2987e-04
Epoch 98/300
785/785 - 84s - 107ms/step - accuracy: 0.4030 - loss: 2.7411 - val_accuracy: 0.5711 - val_loss: 1.9987 - learning_rate: 1.2987e-04
Epoch 99/300
785/785 - 85s - 108ms/step - accuracy: 0.4261 - loss: 2.6887 - val_accuracy: 0.5740 - val_loss: 1.9821 - learning_rate: 1.2987e-04
Epoch 100/300
785/785 - 83s - 106ms/step - accuracy: 0.4248 - loss: 2.7184 - val_accuracy: 0.5702 - val_loss: 2.0077 - learning_rate: 1.2987e-04
Epoch 101/300
785/785 - 86s - 109ms/step - accuracy: 0.4240 - loss: 2.7122 - val_accuracy: 0.5767 - val_loss: 1.9724 - learning_rate: 1.2987e-04
Epoch 102/300
785/785 - 84s - 107ms/step - accuracy: 0.4336 - loss: 2.7035 - val_accuracy: 0.5792 - val_loss: 1.9716 - learning_rate: 1.2987e-04
Epoch 103/300
785/785 - 84s - 107ms/step - accuracy: 0.4303 - loss: 2.6947 - val_accuracy: 0.5697 - val_loss: 2.0194 - learning_rate: 1.2987e-04
Epoch 104/300
785/785 - 85s - 108ms/step - accuracy: 0.4253 - loss: 2.6946 - val_accuracy: 0.5756 - val_loss: 1.9799 - learning_rate: 1.2987e-04
Epoch 105/300
785/785 - 85s - 108ms/step - accuracy: 0.4196 - loss: 2.7038 - val_accuracy: 0.5783 - val_loss: 1.9752 - learning_rate: 1.2987e-04
Epoch 106/300
785/785 - 85s - 108ms/step - accuracy: 0.4296 - loss: 2.6967 - val_accuracy: 0.5808 - val_loss: 1.9862 - learning_rate: 1.2987e-04
Epoch 107/300
785/785 - 85s - 108ms/step - accuracy: 0.4401 - loss: 2.6679 - val_accuracy: 0.5698 - val_loss: 1.9867 - learning_rate: 1.2987e-04
Epoch 108/300
785/785 - 83s - 105ms/step - accuracy: 0.4318 - loss: 2.6827 - val_accuracy: 0.5783 - val_loss: 1.9578 - learning_rate: 1.2987e-04
Epoch 109/300
785/785 - 91s - 115ms/step - accuracy: 0.4342 - loss: 2.6980 - val_accuracy: 0.5757 - val_loss: 1.9908 - learning_rate: 1.2987e-04
Epoch 110/300
785/785 - 85s - 108ms/step - accuracy: 0.4295 - loss: 2.6960 - val_accuracy: 0.5781 - val_loss: 1.9623 - learning_rate: 1.2987e-04
Epoch 111/300
785/785 - 84s - 107ms/step - accuracy: 0.4268 - loss: 2.7116 - val_accuracy: 0.5759 - val_loss: 1.9695 - learning_rate: 1.2987e-04
Epoch 112/300
785/785 - 84s - 108ms/step - accuracy: 0.4290 - loss: 2.6931 - val_accuracy: 0.5797 - val_loss: 1.9760 - learning_rate: 1.2987e-04
Epoch 113/300
785/785 - 84s - 107ms/step - accuracy: 0.4314 - loss: 2.6673 - val_accuracy: 0.5772 - val_loss: 1.9744 - learning_rate: 1.2987e-04
Epoch 114/300
785/785 - 91s - 116ms/step - accuracy: 0.4382 - loss: 2.6385 - val_accuracy: 0.5749 - val_loss: 1.9817 - learning_rate: 1.2987e-04
Epoch 115/300
785/785 - 86s - 109ms/step - accuracy: 0.4209 - loss: 2.7087 - val_accuracy: 0.5823 - val_loss: 1.9628 - learning_rate: 1.2987e-04
Epoch 116/300

Epoch 116: ReduceLROnPlateau reducing learning rate to 6.493452383438125e-05.
785/785 - 84s - 107ms/step - accuracy: 0.4288 - loss: 2.7022 - val_accuracy: 0.5753 - val_loss: 1.9967 - learning_rate: 1.2987e-04
Epoch 117/300
785/785 - 86s - 110ms/step - accuracy: 0.4368 - loss: 2.6538 - val_accuracy: 0.5808 - val_loss: 1.9422 - learning_rate: 6.4935e-05
Epoch 118/300
785/785 - 84s - 106ms/step - accuracy: 0.4420 - loss: 2.6065 - val_accuracy: 0.5882 - val_loss: 1.9440 - learning_rate: 6.4935e-05
Epoch 119/300
785/785 - 83s - 105ms/step - accuracy: 0.4346 - loss: 2.6463 - val_accuracy: 0.5773 - val_loss: 1.9318 - learning_rate: 6.4935e-05
Epoch 120/300
785/785 - 91s - 116ms/step - accuracy: 0.4266 - loss: 2.6430 - val_accuracy: 0.5882 - val_loss: 1.9393 - learning_rate: 6.4935e-05
Epoch 121/300
785/785 - 83s - 106ms/step - accuracy: 0.4468 - loss: 2.6280 - val_accuracy: 0.5773 - val_loss: 1.9421 - learning_rate: 6.4935e-05
Epoch 122/300
785/785 - 84s - 107ms/step - accuracy: 0.4424 - loss: 2.6198 - val_accuracy: 0.5802 - val_loss: 1.9287 - learning_rate: 6.4935e-05
Epoch 123/300
785/785 - 83s - 106ms/step - accuracy: 0.4361 - loss: 2.6245 - val_accuracy: 0.5854 - val_loss: 1.9317 - learning_rate: 6.4935e-05
Epoch 124/300
785/785 - 90s - 114ms/step - accuracy: 0.4288 - loss: 2.6604 - val_accuracy: 0.5837 - val_loss: 1.9389 - learning_rate: 6.4935e-05
Epoch 125/300
785/785 - 84s - 106ms/step - accuracy: 0.4303 - loss: 2.6572 - val_accuracy: 0.5858 - val_loss: 1.9492 - learning_rate: 6.4935e-05
Epoch 126/300
785/785 - 84s - 106ms/step - accuracy: 0.4475 - loss: 2.6397 - val_accuracy: 0.5845 - val_loss: 1.9542 - learning_rate: 6.4935e-05
Epoch 127/300
785/785 - 85s - 108ms/step - accuracy: 0.4422 - loss: 2.6178 - val_accuracy: 0.5888 - val_loss: 1.9376 - learning_rate: 6.4935e-05
Epoch 128/300
785/785 - 84s - 107ms/step - accuracy: 0.4379 - loss: 2.6326 - val_accuracy: 0.5861 - val_loss: 1.9358 - learning_rate: 6.4935e-05
Epoch 129/300
785/785 - 85s - 108ms/step - accuracy: 0.4409 - loss: 2.6309 - val_accuracy: 0.5821 - val_loss: 1.9221 - learning_rate: 6.4935e-05
Epoch 130/300
785/785 - 84s - 108ms/step - accuracy: 0.4395 - loss: 2.6156 - val_accuracy: 0.5843 - val_loss: 1.9255 - learning_rate: 6.4935e-05
Epoch 131/300
785/785 - 84s - 107ms/step - accuracy: 0.4459 - loss: 2.6078 - val_accuracy: 0.5829 - val_loss: 1.9318 - learning_rate: 6.4935e-05
Epoch 132/300
785/785 - 84s - 107ms/step - accuracy: 0.4432 - loss: 2.6006 - val_accuracy: 0.5859 - val_loss: 1.9089 - learning_rate: 6.4935e-05
Epoch 133/300
785/785 - 86s - 109ms/step - accuracy: 0.4425 - loss: 2.6055 - val_accuracy: 0.5819 - val_loss: 1.9258 - learning_rate: 6.4935e-05
Epoch 134/300
785/785 - 83s - 105ms/step - accuracy: 0.4368 - loss: 2.6463 - val_accuracy: 0.5832 - val_loss: 1.9259 - learning_rate: 6.4935e-05
Epoch 135/300
785/785 - 83s - 106ms/step - accuracy: 0.4481 - loss: 2.6071 - val_accuracy: 0.5839 - val_loss: 1.9231 - learning_rate: 6.4935e-05
Epoch 136/300
785/785 - 84s - 108ms/step - accuracy: 0.4460 - loss: 2.6129 - val_accuracy: 0.5866 - val_loss: 1.9036 - learning_rate: 6.4935e-05
Epoch 137/300
785/785 - 84s - 107ms/step - accuracy: 0.4441 - loss: 2.6139 - val_accuracy: 0.5789 - val_loss: 1.9312 - learning_rate: 6.4935e-05
Epoch 138/300
785/785 - 84s - 107ms/step - accuracy: 0.4408 - loss: 2.6341 - val_accuracy: 0.5880 - val_loss: 1.9194 - learning_rate: 6.4935e-05
Epoch 139/300
785/785 - 85s - 108ms/step - accuracy: 0.4475 - loss: 2.6190 - val_accuracy: 0.5869 - val_loss: 1.9167 - learning_rate: 6.4935e-05
Epoch 140/300
785/785 - 84s - 106ms/step - accuracy: 0.4291 - loss: 2.6223 - val_accuracy: 0.5848 - val_loss: 1.9138 - learning_rate: 6.4935e-05
Epoch 141/300
785/785 - 84s - 108ms/step - accuracy: 0.4385 - loss: 2.6259 - val_accuracy: 0.5839 - val_loss: 1.9121 - learning_rate: 6.4935e-05
Epoch 142/300
785/785 - 83s - 106ms/step - accuracy: 0.4459 - loss: 2.5738 - val_accuracy: 0.5843 - val_loss: 1.9083 - learning_rate: 6.4935e-05
Epoch 143/300
785/785 - 85s - 108ms/step - accuracy: 0.4400 - loss: 2.6385 - val_accuracy: 0.5842 - val_loss: 1.9203 - learning_rate: 6.4935e-05
Epoch 144/300

Epoch 144: ReduceLROnPlateau reducing learning rate to 3.2467261917190626e-05.
785/785 - 83s - 106ms/step - accuracy: 0.4470 - loss: 2.5944 - val_accuracy: 0.5832 - val_loss: 1.9093 - learning_rate: 6.4935e-05
Epoch 145/300
785/785 - 84s - 107ms/step - accuracy: 0.4522 - loss: 2.5959 - val_accuracy: 0.5883 - val_loss: 1.9128 - learning_rate: 3.2467e-05
Epoch 146/300
785/785 - 142s - 181ms/step - accuracy: 0.4419 - loss: 2.6258 - val_accuracy: 0.5846 - val_loss: 1.9044 - learning_rate: 3.2467e-05
Epoch 147/300
785/785 - 83s - 106ms/step - accuracy: 0.4518 - loss: 2.5931 - val_accuracy: 0.5858 - val_loss: 1.9163 - learning_rate: 3.2467e-05
Epoch 148/300
785/785 - 83s - 106ms/step - accuracy: 0.4427 - loss: 2.5848 - val_accuracy: 0.5872 - val_loss: 1.9030 - learning_rate: 3.2467e-05
Epoch 149/300
785/785 - 82s - 104ms/step - accuracy: 0.4414 - loss: 2.5973 - val_accuracy: 0.5872 - val_loss: 1.9151 - learning_rate: 3.2467e-05
Epoch 150/300
785/785 - 83s - 106ms/step - accuracy: 0.4439 - loss: 2.5912 - val_accuracy: 0.5824 - val_loss: 1.9212 - learning_rate: 3.2467e-05
Epoch 151/300
785/785 - 91s - 116ms/step - accuracy: 0.4473 - loss: 2.6018 - val_accuracy: 0.5858 - val_loss: 1.9059 - learning_rate: 3.2467e-05
Epoch 152/300
785/785 - 83s - 106ms/step - accuracy: 0.4376 - loss: 2.5730 - val_accuracy: 0.5839 - val_loss: 1.9083 - learning_rate: 3.2467e-05
Epoch 153/300
785/785 - 90s - 115ms/step - accuracy: 0.4432 - loss: 2.6084 - val_accuracy: 0.5845 - val_loss: 1.9088 - learning_rate: 3.2467e-05
Epoch 154/300
785/785 - 87s - 111ms/step - accuracy: 0.4428 - loss: 2.6092 - val_accuracy: 0.5878 - val_loss: 1.9070 - learning_rate: 3.2467e-05
Epoch 155/300
785/785 - 139s - 177ms/step - accuracy: 0.4537 - loss: 2.5901 - val_accuracy: 0.5861 - val_loss: 1.9173 - learning_rate: 3.2467e-05
Epoch 156/300

Epoch 156: ReduceLROnPlateau reducing learning rate to 1.6233630958595313e-05.
785/785 - 91s - 116ms/step - accuracy: 0.4422 - loss: 2.5999 - val_accuracy: 0.5867 - val_loss: 1.9203 - learning_rate: 3.2467e-05
Epoch 157/300
785/785 - 89s - 114ms/step - accuracy: 0.4475 - loss: 2.5906 - val_accuracy: 0.5853 - val_loss: 1.9063 - learning_rate: 1.6234e-05
Epoch 158/300
785/785 - 91s - 116ms/step - accuracy: 0.4518 - loss: 2.6258 - val_accuracy: 0.5878 - val_loss: 1.8997 - learning_rate: 1.6234e-05
Epoch 159/300
785/785 - 84s - 107ms/step - accuracy: 0.4533 - loss: 2.5582 - val_accuracy: 0.5878 - val_loss: 1.8919 - learning_rate: 1.6234e-05
Epoch 160/300
785/785 - 87s - 111ms/step - accuracy: 0.4395 - loss: 2.5578 - val_accuracy: 0.5867 - val_loss: 1.9014 - learning_rate: 1.6234e-05
Epoch 161/300
785/785 - 89s - 113ms/step - accuracy: 0.4424 - loss: 2.5954 - val_accuracy: 0.5861 - val_loss: 1.9030 - learning_rate: 1.6234e-05
Epoch 162/300
785/785 - 141s - 179ms/step - accuracy: 0.4492 - loss: 2.5755 - val_accuracy: 0.5861 - val_loss: 1.9087 - learning_rate: 1.6234e-05
Epoch 163/300
785/785 - 83s - 106ms/step - accuracy: 0.4519 - loss: 2.5672 - val_accuracy: 0.5845 - val_loss: 1.8977 - learning_rate: 1.6234e-05
Epoch 164/300
785/785 - 83s - 106ms/step - accuracy: 0.4548 - loss: 2.5966 - val_accuracy: 0.5899 - val_loss: 1.8998 - learning_rate: 1.6234e-05
Epoch 165/300
785/785 - 85s - 108ms/step - accuracy: 0.4559 - loss: 2.5803 - val_accuracy: 0.5880 - val_loss: 1.8988 - learning_rate: 1.6234e-05
Epoch 166/300
785/785 - 91s - 116ms/step - accuracy: 0.4549 - loss: 2.5676 - val_accuracy: 0.5869 - val_loss: 1.9020 - learning_rate: 1.6234e-05
Epoch 167/300

Epoch 167: ReduceLROnPlateau reducing learning rate to 8.116815479297657e-06.
785/785 - 86s - 109ms/step - accuracy: 0.4518 - loss: 2.5986 - val_accuracy: 0.5885 - val_loss: 1.9081 - learning_rate: 1.6234e-05
Epoch 168/300
785/785 - 84s - 106ms/step - accuracy: 0.4562 - loss: 2.5791 - val_accuracy: 0.5888 - val_loss: 1.8975 - learning_rate: 8.1168e-06
Epoch 169/300
785/785 - 89s - 114ms/step - accuracy: 0.4490 - loss: 2.5815 - val_accuracy: 0.5878 - val_loss: 1.8939 - learning_rate: 8.1168e-06
Epoch 170/300
785/785 - 142s - 181ms/step - accuracy: 0.4522 - loss: 2.5751 - val_accuracy: 0.5872 - val_loss: 1.9021 - learning_rate: 8.1168e-06
Epoch 171/300
785/785 - 87s - 110ms/step - accuracy: 0.4447 - loss: 2.5822 - val_accuracy: 0.5893 - val_loss: 1.8992 - learning_rate: 8.1168e-06
Epoch 172/300
785/785 - 86s - 110ms/step - accuracy: 0.4478 - loss: 2.5768 - val_accuracy: 0.5866 - val_loss: 1.9007 - learning_rate: 8.1168e-06
Epoch 173/300
785/785 - 88s - 112ms/step - accuracy: 0.4535 - loss: 2.5794 - val_accuracy: 0.5872 - val_loss: 1.8992 - learning_rate: 8.1168e-06
Epoch 174/300
785/785 - 89s - 113ms/step - accuracy: 0.4452 - loss: 2.5851 - val_accuracy: 0.5875 - val_loss: 1.8992 - learning_rate: 8.1168e-06
Epoch 175/300

Epoch 175: ReduceLROnPlateau reducing learning rate to 4.058407739648828e-06.
785/785 - 94s - 119ms/step - accuracy: 0.4545 - loss: 2.5553 - val_accuracy: 0.5885 - val_loss: 1.8985 - learning_rate: 8.1168e-06
Epoch 175: early stopping
Restoring model weights from the end of the best epoch: 159.
Fold 4_2 Evaluation results: [1.8914270401000977, 0.5878324508666992]
              precision    recall  f1-score   support

        1820       0.72      0.74      0.73       305
        1821       0.88      0.86      0.87       297
        1822       0.00      0.00      0.00         5
        1823       0.00      0.00      0.00         8
        1824       0.00      0.00      0.00         8
        1825       0.00      0.00      0.00        11
        1826       0.00      0.00      0.00        12
        1827       0.72      0.70      0.71       121
        1828       0.00      0.00      0.00        14
        1829       0.77      0.50      0.61        20
        1830       0.56      0.64      0.59       290
        1831       0.73      0.91      0.81       639
        1832       0.77      0.76      0.76       324
        1833       0.71      0.91      0.80       104
        1834       0.46      0.66      0.54       151
        1835       0.00      0.00      0.00         7
        1836       0.00      0.00      0.00        20
        1837       0.32      0.44      0.37        32
        1838       0.00      0.00      0.00        18
        1839       0.00      0.00      0.00         4
        1840       0.46      0.59      0.52       228
        1841       0.75      0.55      0.64       545
        1842       0.62      0.34      0.44        29
        1843       0.00      0.00      0.00        31
        1844       0.00      0.00      0.00         3
        1845       0.00      0.00      0.00         7
        1846       1.00      0.09      0.16        35
        1847       0.00      0.00      0.00        14
        1848       0.00      0.00      0.00        24
        1849       0.33      0.08      0.13        25
        1850       0.31      0.65      0.42       219
        1851       0.75      0.64      0.69       375
        1852       0.11      0.06      0.08        35
        1853       0.00      0.00      0.00        29
        1854       0.00      0.00      0.00        13
        1855       0.46      0.06      0.10       108
        1856       0.93      0.41      0.57        61
        1857       0.35      0.64      0.45       140
        1858       0.00      0.00      0.00        10
        1859       0.00      0.00      0.00        17
        1860       0.32      0.31      0.32       339
        1861       0.75      0.84      0.79       409
        1862       0.25      0.22      0.24        98
        1863       0.39      0.42      0.40        95
        1864       0.16      0.08      0.11        88
        1865       0.71      0.18      0.29        28
        1866       0.00      0.00      0.00        33
        1867       0.36      0.16      0.22        57
        1868       0.00      0.00      0.00        37
        1869       0.00      0.00      0.00        29
        1870       0.31      0.66      0.42       149
        1871       0.78      0.70      0.74       260
        1872       0.40      0.17      0.24        36
        1873       0.00      0.00      0.00        65
        1874       0.00      0.00      0.00        27
        1875       0.37      0.66      0.47        70
        1876       0.86      0.86      0.86        50
        1877       0.27      0.33      0.30        21
        1878       0.42      0.61      0.50        41
        1879       0.00      0.00      0.00         9

    accuracy                           0.59      6279
   macro avg       0.32      0.29      0.28      6279
weighted avg       0.57      0.59      0.56      6279

Matthews Correlation Coefficient: 0.568
Macro avg F1: 0.281
Weighted avg F1: 0.562
Micro avg F1: 0.588
Top-3 Accuracy: 0.834
Top-5 Accuracy: 0.894
Micro ROC AUC  = 0.98
Macro ROC AUC (present classes) = 0.97
Classification MAE (in years): 3.36

Fold 4_2 Misclassification Analysis:
Near misses (within 2 years): 587 out of 2588 misclassifications (22.68%)
Big misses (greater than 10 years): 1060
MAE with outliers: 3.36
MAE without outliers: 2.35 (improvement: 1.01)

10 Worst misclassifications:
Image: data/datasets/public/1870/1879_26wikimedia2.jpg, True: 1879, Predicted: 1820, Error: 59
Image: data/datasets/private/1820/1820_038_Zrzut ekranu 2022-07-26 210339.png, True: 1820, Predicted: 1871, Error: 51
Image: data/datasets/private/1820/1820_031_Zrzut ekranu 2022-07-26 195637.png, True: 1820, Predicted: 1871, Error: 51
Image: data/datasets/private/1820/1820_034_Zrzut ekranu 2022-07-26 203655.png, True: 1820, Predicted: 1870, Error: 50
Image: data/datasets/public/1820/1820_12wikimedia2.jpg, True: 1820, Predicted: 1870, Error: 50
Image: data/datasets/private/1820/1821_486etsy.jpg, True: 1821, Predicted: 1871, Error: 50
Image: data/datasets/private/1820/1821_580etsy.jpg, True: 1821, Predicted: 1871, Error: 50
Image: data/datasets/public/1820/1820_10wikimedia2.jpg, True: 1820, Predicted: 1870, Error: 50
Image: data/datasets/public/1820/1827_2washington.jpg, True: 1827, Predicted: 1876, Error: 49
Image: data/datasets/public/1870/1879_9wikimedia2.jpg, True: 1879, Predicted: 1830, Error: 49
=== Training Alternative Model ===

===== Fine Tuning 9 layers! =====
Epoch 1/300
785/785 - 167s - 213ms/step - accuracy: 0.1085 - loss: 4.5585 - val_accuracy: 0.2279 - val_loss: 3.9042 - learning_rate: 2.5974e-04
Epoch 2/300
785/785 - 91s - 116ms/step - accuracy: 0.1562 - loss: 4.2407 - val_accuracy: 0.2604 - val_loss: 3.9739 - learning_rate: 2.5974e-04
Epoch 3/300
785/785 - 90s - 114ms/step - accuracy: 0.1906 - loss: 4.0590 - val_accuracy: 0.2935 - val_loss: 3.4594 - learning_rate: 2.5974e-04
Epoch 4/300
785/785 - 93s - 118ms/step - accuracy: 0.2128 - loss: 3.8837 - val_accuracy: 0.3645 - val_loss: 3.2755 - learning_rate: 2.5974e-04
Epoch 5/300
785/785 - 91s - 116ms/step - accuracy: 0.2269 - loss: 3.8189 - val_accuracy: 0.3545 - val_loss: 3.1005 - learning_rate: 2.5974e-04
Epoch 6/300
785/785 - 93s - 118ms/step - accuracy: 0.2475 - loss: 3.7118 - val_accuracy: 0.3732 - val_loss: 2.9907 - learning_rate: 2.5974e-04
Epoch 7/300
785/785 - 142s - 181ms/step - accuracy: 0.2588 - loss: 3.6370 - val_accuracy: 0.4318 - val_loss: 2.8618 - learning_rate: 2.5974e-04
Epoch 8/300
785/785 - 95s - 121ms/step - accuracy: 0.2677 - loss: 3.5924 - val_accuracy: 0.4107 - val_loss: 2.8479 - learning_rate: 2.5974e-04
Epoch 9/300
785/785 - 94s - 120ms/step - accuracy: 0.2744 - loss: 3.5246 - val_accuracy: 0.4139 - val_loss: 2.7620 - learning_rate: 2.5974e-04
Epoch 10/300
785/785 - 138s - 175ms/step - accuracy: 0.2892 - loss: 3.4731 - val_accuracy: 0.4561 - val_loss: 2.7673 - learning_rate: 2.5974e-04
Epoch 11/300
785/785 - 88s - 112ms/step - accuracy: 0.2951 - loss: 3.4699 - val_accuracy: 0.4769 - val_loss: 2.6417 - learning_rate: 2.5974e-04
Epoch 12/300
785/785 - 92s - 117ms/step - accuracy: 0.2965 - loss: 3.4093 - val_accuracy: 0.4602 - val_loss: 2.6048 - learning_rate: 2.5974e-04
Epoch 13/300
785/785 - 92s - 117ms/step - accuracy: 0.3008 - loss: 3.4086 - val_accuracy: 0.4804 - val_loss: 2.5756 - learning_rate: 2.5974e-04
Epoch 14/300
785/785 - 96s - 122ms/step - accuracy: 0.3147 - loss: 3.3431 - val_accuracy: 0.4904 - val_loss: 2.5126 - learning_rate: 2.5974e-04
Epoch 15/300
785/785 - 97s - 123ms/step - accuracy: 0.3133 - loss: 3.2898 - val_accuracy: 0.4841 - val_loss: 2.4146 - learning_rate: 2.5974e-04
Epoch 16/300
785/785 - 96s - 122ms/step - accuracy: 0.3125 - loss: 3.3046 - val_accuracy: 0.4769 - val_loss: 2.4546 - learning_rate: 2.5974e-04
Epoch 17/300
785/785 - 96s - 123ms/step - accuracy: 0.3192 - loss: 3.2808 - val_accuracy: 0.4834 - val_loss: 2.3988 - learning_rate: 2.5974e-04
Epoch 18/300
785/785 - 91s - 116ms/step - accuracy: 0.3236 - loss: 3.2521 - val_accuracy: 0.4968 - val_loss: 2.3473 - learning_rate: 2.5974e-04
Epoch 19/300
785/785 - 92s - 117ms/step - accuracy: 0.3290 - loss: 3.2391 - val_accuracy: 0.4809 - val_loss: 2.4095 - learning_rate: 2.5974e-04
Epoch 20/300
785/785 - 96s - 122ms/step - accuracy: 0.3357 - loss: 3.2371 - val_accuracy: 0.5215 - val_loss: 2.3320 - learning_rate: 2.5974e-04
Epoch 21/300
785/785 - 92s - 117ms/step - accuracy: 0.3357 - loss: 3.2617 - val_accuracy: 0.5104 - val_loss: 2.3290 - learning_rate: 2.5974e-04
Epoch 22/300
785/785 - 94s - 120ms/step - accuracy: 0.3456 - loss: 3.1616 - val_accuracy: 0.5080 - val_loss: 2.2964 - learning_rate: 2.5974e-04
Epoch 23/300
785/785 - 95s - 121ms/step - accuracy: 0.3550 - loss: 3.1559 - val_accuracy: 0.5040 - val_loss: 2.3364 - learning_rate: 2.5974e-04
Epoch 24/300
785/785 - 94s - 120ms/step - accuracy: 0.3416 - loss: 3.1626 - val_accuracy: 0.5314 - val_loss: 2.2411 - learning_rate: 2.5974e-04
Epoch 25/300
785/785 - 94s - 120ms/step - accuracy: 0.3442 - loss: 3.1699 - val_accuracy: 0.5210 - val_loss: 2.2714 - learning_rate: 2.5974e-04
Epoch 26/300
785/785 - 140s - 178ms/step - accuracy: 0.3502 - loss: 3.1025 - val_accuracy: 0.5108 - val_loss: 2.2320 - learning_rate: 2.5974e-04
Epoch 27/300
785/785 - 90s - 115ms/step - accuracy: 0.3429 - loss: 3.1392 - val_accuracy: 0.5275 - val_loss: 2.2242 - learning_rate: 2.5974e-04
Epoch 28/300
785/785 - 91s - 115ms/step - accuracy: 0.3602 - loss: 3.1017 - val_accuracy: 0.5255 - val_loss: 2.2252 - learning_rate: 2.5974e-04
Epoch 29/300
785/785 - 91s - 116ms/step - accuracy: 0.3515 - loss: 3.1722 - val_accuracy: 0.5266 - val_loss: 2.2438 - learning_rate: 2.5974e-04
Epoch 30/300
785/785 - 92s - 117ms/step - accuracy: 0.3577 - loss: 3.1120 - val_accuracy: 0.5334 - val_loss: 2.1506 - learning_rate: 2.5974e-04
Epoch 31/300
785/785 - 95s - 121ms/step - accuracy: 0.3518 - loss: 3.1123 - val_accuracy: 0.5449 - val_loss: 2.1774 - learning_rate: 2.5974e-04
Epoch 32/300
785/785 - 88s - 112ms/step - accuracy: 0.3599 - loss: 3.0543 - val_accuracy: 0.5384 - val_loss: 2.2036 - learning_rate: 2.5974e-04
Epoch 33/300
785/785 - 94s - 120ms/step - accuracy: 0.3588 - loss: 3.0741 - val_accuracy: 0.5232 - val_loss: 2.1872 - learning_rate: 2.5974e-04
Epoch 34/300
785/785 - 93s - 119ms/step - accuracy: 0.3639 - loss: 3.0629 - val_accuracy: 0.5330 - val_loss: 2.1530 - learning_rate: 2.5974e-04
Epoch 35/300
785/785 - 88s - 112ms/step - accuracy: 0.3590 - loss: 3.0812 - val_accuracy: 0.5341 - val_loss: 2.1183 - learning_rate: 2.5974e-04
Epoch 36/300
785/785 - 87s - 111ms/step - accuracy: 0.3602 - loss: 3.0611 - val_accuracy: 0.5277 - val_loss: 2.1341 - learning_rate: 2.5974e-04
Epoch 37/300
785/785 - 85s - 108ms/step - accuracy: 0.3676 - loss: 3.0349 - val_accuracy: 0.5457 - val_loss: 2.1404 - learning_rate: 2.5974e-04
Epoch 38/300
785/785 - 83s - 106ms/step - accuracy: 0.3733 - loss: 3.0132 - val_accuracy: 0.5427 - val_loss: 2.1549 - learning_rate: 2.5974e-04
Epoch 39/300
785/785 - 85s - 109ms/step - accuracy: 0.3682 - loss: 3.0297 - val_accuracy: 0.5342 - val_loss: 2.1257 - learning_rate: 2.5974e-04
Epoch 40/300
785/785 - 83s - 106ms/step - accuracy: 0.3712 - loss: 3.0622 - val_accuracy: 0.5384 - val_loss: 2.1196 - learning_rate: 2.5974e-04
Epoch 41/300
785/785 - 84s - 107ms/step - accuracy: 0.3741 - loss: 3.0082 - val_accuracy: 0.5467 - val_loss: 2.0850 - learning_rate: 2.5974e-04
Epoch 42/300
785/785 - 84s - 107ms/step - accuracy: 0.3830 - loss: 2.9892 - val_accuracy: 0.5548 - val_loss: 2.1136 - learning_rate: 2.5974e-04
Epoch 43/300
785/785 - 84s - 107ms/step - accuracy: 0.3684 - loss: 3.0199 - val_accuracy: 0.5594 - val_loss: 2.1232 - learning_rate: 2.5974e-04
Epoch 44/300
785/785 - 91s - 116ms/step - accuracy: 0.3759 - loss: 3.0077 - val_accuracy: 0.5465 - val_loss: 2.0712 - learning_rate: 2.5974e-04
Epoch 45/300
785/785 - 82s - 105ms/step - accuracy: 0.3849 - loss: 3.0066 - val_accuracy: 0.5412 - val_loss: 2.0787 - learning_rate: 2.5974e-04
Epoch 46/300
785/785 - 82s - 105ms/step - accuracy: 0.3704 - loss: 3.0173 - val_accuracy: 0.5561 - val_loss: 2.0608 - learning_rate: 2.5974e-04
Epoch 47/300
785/785 - 84s - 107ms/step - accuracy: 0.3763 - loss: 2.9869 - val_accuracy: 0.5518 - val_loss: 2.0751 - learning_rate: 2.5974e-04
Epoch 48/300
785/785 - 84s - 107ms/step - accuracy: 0.3821 - loss: 2.9772 - val_accuracy: 0.5631 - val_loss: 2.0512 - learning_rate: 2.5974e-04
Epoch 49/300
785/785 - 84s - 107ms/step - accuracy: 0.3776 - loss: 2.9780 - val_accuracy: 0.5489 - val_loss: 2.0320 - learning_rate: 2.5974e-04
Epoch 50/300
785/785 - 84s - 107ms/step - accuracy: 0.3854 - loss: 2.9572 - val_accuracy: 0.5322 - val_loss: 2.1176 - learning_rate: 2.5974e-04
Epoch 51/300
785/785 - 144s - 183ms/step - accuracy: 0.3835 - loss: 2.9581 - val_accuracy: 0.5535 - val_loss: 2.0686 - learning_rate: 2.5974e-04
Epoch 52/300
785/785 - 140s - 178ms/step - accuracy: 0.3860 - loss: 2.9538 - val_accuracy: 0.5592 - val_loss: 2.0738 - learning_rate: 2.5974e-04
Epoch 53/300
785/785 - 84s - 107ms/step - accuracy: 0.3798 - loss: 2.9579 - val_accuracy: 0.5538 - val_loss: 2.0650 - learning_rate: 2.5974e-04
Epoch 54/300
785/785 - 84s - 107ms/step - accuracy: 0.3819 - loss: 2.9429 - val_accuracy: 0.5506 - val_loss: 2.0505 - learning_rate: 2.5974e-04
Epoch 55/300
785/785 - 84s - 107ms/step - accuracy: 0.3868 - loss: 2.9433 - val_accuracy: 0.5599 - val_loss: 2.0652 - learning_rate: 2.5974e-04
Epoch 56/300
785/785 - 85s - 108ms/step - accuracy: 0.3934 - loss: 2.9132 - val_accuracy: 0.5621 - val_loss: 2.0674 - learning_rate: 2.5974e-04
Epoch 57/300

Epoch 57: ReduceLROnPlateau reducing learning rate to 0.0001298690476687625.
785/785 - 92s - 117ms/step - accuracy: 0.3927 - loss: 2.9512 - val_accuracy: 0.5543 - val_loss: 2.0703 - learning_rate: 2.5974e-04
Epoch 58/300
785/785 - 84s - 107ms/step - accuracy: 0.4004 - loss: 2.8435 - val_accuracy: 0.5728 - val_loss: 1.9793 - learning_rate: 1.2987e-04
Epoch 59/300
785/785 - 85s - 108ms/step - accuracy: 0.3946 - loss: 2.8730 - val_accuracy: 0.5758 - val_loss: 1.9728 - learning_rate: 1.2987e-04
Epoch 60/300
785/785 - 83s - 105ms/step - accuracy: 0.3997 - loss: 2.8775 - val_accuracy: 0.5712 - val_loss: 1.9896 - learning_rate: 1.2987e-04
Epoch 61/300
785/785 - 84s - 107ms/step - accuracy: 0.3939 - loss: 2.8684 - val_accuracy: 0.5761 - val_loss: 1.9695 - learning_rate: 1.2987e-04
Epoch 62/300
785/785 - 85s - 108ms/step - accuracy: 0.4048 - loss: 2.8356 - val_accuracy: 0.5742 - val_loss: 1.9726 - learning_rate: 1.2987e-04
Epoch 63/300
785/785 - 84s - 107ms/step - accuracy: 0.3997 - loss: 2.8536 - val_accuracy: 0.5841 - val_loss: 1.9592 - learning_rate: 1.2987e-04
Epoch 64/300
785/785 - 85s - 108ms/step - accuracy: 0.4005 - loss: 2.8296 - val_accuracy: 0.5753 - val_loss: 1.9502 - learning_rate: 1.2987e-04
Epoch 65/300
785/785 - 83s - 106ms/step - accuracy: 0.3985 - loss: 2.8401 - val_accuracy: 0.5777 - val_loss: 1.9331 - learning_rate: 1.2987e-04
Epoch 66/300
785/785 - 89s - 114ms/step - accuracy: 0.4058 - loss: 2.8380 - val_accuracy: 0.5761 - val_loss: 1.9379 - learning_rate: 1.2987e-04
Epoch 67/300
785/785 - 84s - 107ms/step - accuracy: 0.3923 - loss: 2.8418 - val_accuracy: 0.5747 - val_loss: 1.9592 - learning_rate: 1.2987e-04
Epoch 68/300
785/785 - 142s - 181ms/step - accuracy: 0.4012 - loss: 2.8368 - val_accuracy: 0.5758 - val_loss: 1.9769 - learning_rate: 1.2987e-04
Epoch 69/300
785/785 - 84s - 107ms/step - accuracy: 0.4005 - loss: 2.8523 - val_accuracy: 0.5791 - val_loss: 1.9483 - learning_rate: 1.2987e-04
Epoch 70/300
785/785 - 84s - 107ms/step - accuracy: 0.4034 - loss: 2.8081 - val_accuracy: 0.5748 - val_loss: 1.9504 - learning_rate: 1.2987e-04
Epoch 71/300
785/785 - 83s - 106ms/step - accuracy: 0.4109 - loss: 2.8144 - val_accuracy: 0.5752 - val_loss: 1.9746 - learning_rate: 1.2987e-04
Epoch 72/300
785/785 - 86s - 110ms/step - accuracy: 0.4047 - loss: 2.8210 - val_accuracy: 0.5771 - val_loss: 1.9257 - learning_rate: 1.2987e-04
Epoch 73/300
785/785 - 83s - 106ms/step - accuracy: 0.4032 - loss: 2.7983 - val_accuracy: 0.5785 - val_loss: 1.9186 - learning_rate: 1.2987e-04
Epoch 74/300
785/785 - 86s - 110ms/step - accuracy: 0.4005 - loss: 2.8028 - val_accuracy: 0.5818 - val_loss: 1.9213 - learning_rate: 1.2987e-04
Epoch 75/300
785/785 - 88s - 112ms/step - accuracy: 0.4055 - loss: 2.8074 - val_accuracy: 0.5806 - val_loss: 1.9310 - learning_rate: 1.2987e-04
Epoch 76/300
785/785 - 88s - 112ms/step - accuracy: 0.4082 - loss: 2.8388 - val_accuracy: 0.5807 - val_loss: 1.9447 - learning_rate: 1.2987e-04
Epoch 77/300
785/785 - 89s - 113ms/step - accuracy: 0.4136 - loss: 2.7972 - val_accuracy: 0.5873 - val_loss: 1.9078 - learning_rate: 1.2987e-04
Epoch 78/300
785/785 - 88s - 112ms/step - accuracy: 0.4106 - loss: 2.7913 - val_accuracy: 0.5725 - val_loss: 1.9266 - learning_rate: 1.2987e-04
Epoch 79/300
785/785 - 89s - 113ms/step - accuracy: 0.4069 - loss: 2.8353 - val_accuracy: 0.5865 - val_loss: 1.9058 - learning_rate: 1.2987e-04
Epoch 80/300
785/785 - 89s - 113ms/step - accuracy: 0.4104 - loss: 2.8285 - val_accuracy: 0.5779 - val_loss: 1.9327 - learning_rate: 1.2987e-04
Epoch 81/300
785/785 - 89s - 113ms/step - accuracy: 0.4029 - loss: 2.7864 - val_accuracy: 0.5849 - val_loss: 1.9098 - learning_rate: 1.2987e-04
Epoch 82/300
785/785 - 90s - 115ms/step - accuracy: 0.4209 - loss: 2.7755 - val_accuracy: 0.5868 - val_loss: 1.9224 - learning_rate: 1.2987e-04
Epoch 83/300
785/785 - 88s - 113ms/step - accuracy: 0.4090 - loss: 2.7889 - val_accuracy: 0.5731 - val_loss: 1.9354 - learning_rate: 1.2987e-04
Epoch 84/300
785/785 - 88s - 113ms/step - accuracy: 0.4074 - loss: 2.8135 - val_accuracy: 0.5884 - val_loss: 1.8922 - learning_rate: 1.2987e-04
Epoch 85/300
785/785 - 88s - 112ms/step - accuracy: 0.4091 - loss: 2.7906 - val_accuracy: 0.5863 - val_loss: 1.9098 - learning_rate: 1.2987e-04
Epoch 86/300
785/785 - 94s - 119ms/step - accuracy: 0.4042 - loss: 2.8188 - val_accuracy: 0.5791 - val_loss: 1.8971 - learning_rate: 1.2987e-04
Epoch 87/300
785/785 - 88s - 112ms/step - accuracy: 0.4096 - loss: 2.8084 - val_accuracy: 0.5825 - val_loss: 1.9188 - learning_rate: 1.2987e-04
Epoch 88/300
785/785 - 89s - 113ms/step - accuracy: 0.4063 - loss: 2.8103 - val_accuracy: 0.5838 - val_loss: 1.9079 - learning_rate: 1.2987e-04
Epoch 89/300
785/785 - 89s - 113ms/step - accuracy: 0.4197 - loss: 2.7379 - val_accuracy: 0.5914 - val_loss: 1.8714 - learning_rate: 1.2987e-04
Epoch 90/300
785/785 - 89s - 113ms/step - accuracy: 0.4174 - loss: 2.7991 - val_accuracy: 0.5887 - val_loss: 1.9244 - learning_rate: 1.2987e-04
Epoch 91/300
785/785 - 89s - 113ms/step - accuracy: 0.4115 - loss: 2.7959 - val_accuracy: 0.5873 - val_loss: 1.9139 - learning_rate: 1.2987e-04
Epoch 92/300
785/785 - 89s - 113ms/step - accuracy: 0.4157 - loss: 2.7895 - val_accuracy: 0.5787 - val_loss: 1.9059 - learning_rate: 1.2987e-04
Epoch 93/300
785/785 - 89s - 114ms/step - accuracy: 0.4311 - loss: 2.7504 - val_accuracy: 0.5791 - val_loss: 1.8704 - learning_rate: 1.2987e-04
Epoch 94/300
785/785 - 88s - 112ms/step - accuracy: 0.4198 - loss: 2.7799 - val_accuracy: 0.5884 - val_loss: 1.8709 - learning_rate: 1.2987e-04
Epoch 95/300
785/785 - 87s - 111ms/step - accuracy: 0.4161 - loss: 2.7690 - val_accuracy: 0.5849 - val_loss: 1.8925 - learning_rate: 1.2987e-04
Epoch 96/300
785/785 - 88s - 112ms/step - accuracy: 0.4118 - loss: 2.7662 - val_accuracy: 0.5814 - val_loss: 1.8999 - learning_rate: 1.2987e-04
Epoch 97/300
785/785 - 89s - 114ms/step - accuracy: 0.4053 - loss: 2.8306 - val_accuracy: 0.5850 - val_loss: 1.8743 - learning_rate: 1.2987e-04
Epoch 98/300
785/785 - 90s - 114ms/step - accuracy: 0.4185 - loss: 2.7946 - val_accuracy: 0.5912 - val_loss: 1.8659 - learning_rate: 1.2987e-04
Epoch 99/300
785/785 - 94s - 120ms/step - accuracy: 0.4176 - loss: 2.7884 - val_accuracy: 0.5861 - val_loss: 1.8930 - learning_rate: 1.2987e-04
Epoch 100/300
785/785 - 89s - 114ms/step - accuracy: 0.4217 - loss: 2.7529 - val_accuracy: 0.5839 - val_loss: 1.8638 - learning_rate: 1.2987e-04
Epoch 101/300
785/785 - 88s - 113ms/step - accuracy: 0.4168 - loss: 2.7597 - val_accuracy: 0.5895 - val_loss: 1.8708 - learning_rate: 1.2987e-04
Epoch 102/300
785/785 - 94s - 120ms/step - accuracy: 0.4185 - loss: 2.7548 - val_accuracy: 0.5981 - val_loss: 1.8611 - learning_rate: 1.2987e-04
Epoch 103/300
785/785 - 87s - 111ms/step - accuracy: 0.4173 - loss: 2.7739 - val_accuracy: 0.5804 - val_loss: 1.8768 - learning_rate: 1.2987e-04
Epoch 104/300
785/785 - 87s - 111ms/step - accuracy: 0.4158 - loss: 2.7569 - val_accuracy: 0.5965 - val_loss: 1.8895 - learning_rate: 1.2987e-04
Epoch 105/300
785/785 - 89s - 114ms/step - accuracy: 0.4181 - loss: 2.7295 - val_accuracy: 0.5852 - val_loss: 1.9010 - learning_rate: 1.2987e-04
Epoch 106/300
785/785 - 93s - 119ms/step - accuracy: 0.4174 - loss: 2.7713 - val_accuracy: 0.5826 - val_loss: 1.8887 - learning_rate: 1.2987e-04
Epoch 107/300
785/785 - 89s - 113ms/step - accuracy: 0.4176 - loss: 2.7396 - val_accuracy: 0.5868 - val_loss: 1.9001 - learning_rate: 1.2987e-04
Epoch 108/300
785/785 - 89s - 114ms/step - accuracy: 0.4279 - loss: 2.7472 - val_accuracy: 0.5881 - val_loss: 1.8808 - learning_rate: 1.2987e-04
Epoch 109/300
785/785 - 88s - 112ms/step - accuracy: 0.4177 - loss: 2.7373 - val_accuracy: 0.5920 - val_loss: 1.8639 - learning_rate: 1.2987e-04
Epoch 110/300
785/785 - 90s - 115ms/step - accuracy: 0.4157 - loss: 2.7288 - val_accuracy: 0.5947 - val_loss: 1.8581 - learning_rate: 1.2987e-04
Epoch 111/300
785/785 - 89s - 113ms/step - accuracy: 0.4281 - loss: 2.7349 - val_accuracy: 0.5933 - val_loss: 1.8812 - learning_rate: 1.2987e-04
Epoch 112/300
785/785 - 89s - 113ms/step - accuracy: 0.4271 - loss: 2.7420 - val_accuracy: 0.5871 - val_loss: 1.8563 - learning_rate: 1.2987e-04
Epoch 113/300
785/785 - 89s - 113ms/step - accuracy: 0.4200 - loss: 2.7523 - val_accuracy: 0.5928 - val_loss: 1.9019 - learning_rate: 1.2987e-04
Epoch 114/300
785/785 - 87s - 111ms/step - accuracy: 0.4228 - loss: 2.7169 - val_accuracy: 0.5901 - val_loss: 1.9131 - learning_rate: 1.2987e-04
Epoch 115/300
785/785 - 93s - 119ms/step - accuracy: 0.4174 - loss: 2.7444 - val_accuracy: 0.5916 - val_loss: 1.8732 - learning_rate: 1.2987e-04
Epoch 116/300
785/785 - 88s - 112ms/step - accuracy: 0.4255 - loss: 2.7547 - val_accuracy: 0.5955 - val_loss: 1.8530 - learning_rate: 1.2987e-04
Epoch 117/300
785/785 - 89s - 114ms/step - accuracy: 0.4244 - loss: 2.7399 - val_accuracy: 0.5895 - val_loss: 1.8716 - learning_rate: 1.2987e-04
Epoch 118/300
785/785 - 88s - 112ms/step - accuracy: 0.4181 - loss: 2.7316 - val_accuracy: 0.5979 - val_loss: 1.8719 - learning_rate: 1.2987e-04
Epoch 119/300
785/785 - 88s - 112ms/step - accuracy: 0.4136 - loss: 2.7471 - val_accuracy: 0.5987 - val_loss: 1.8408 - learning_rate: 1.2987e-04
Epoch 120/300
785/785 - 94s - 120ms/step - accuracy: 0.4270 - loss: 2.7135 - val_accuracy: 0.5887 - val_loss: 1.8772 - learning_rate: 1.2987e-04
Epoch 121/300
785/785 - 94s - 120ms/step - accuracy: 0.4281 - loss: 2.7120 - val_accuracy: 0.5877 - val_loss: 1.8367 - learning_rate: 1.2987e-04
Epoch 122/300
785/785 - 136s - 174ms/step - accuracy: 0.4263 - loss: 2.7206 - val_accuracy: 0.5967 - val_loss: 1.8551 - learning_rate: 1.2987e-04
Epoch 123/300
785/785 - 86s - 110ms/step - accuracy: 0.4278 - loss: 2.7456 - val_accuracy: 0.5919 - val_loss: 1.8442 - learning_rate: 1.2987e-04
Epoch 124/300
785/785 - 88s - 112ms/step - accuracy: 0.4244 - loss: 2.7310 - val_accuracy: 0.5889 - val_loss: 1.8193 - learning_rate: 1.2987e-04
Epoch 125/300
785/785 - 88s - 112ms/step - accuracy: 0.4290 - loss: 2.7344 - val_accuracy: 0.5885 - val_loss: 1.8416 - learning_rate: 1.2987e-04
Epoch 126/300
785/785 - 148s - 189ms/step - accuracy: 0.4177 - loss: 2.7301 - val_accuracy: 0.5909 - val_loss: 1.8471 - learning_rate: 1.2987e-04
Epoch 127/300
785/785 - 89s - 114ms/step - accuracy: 0.4268 - loss: 2.7059 - val_accuracy: 0.5968 - val_loss: 1.8583 - learning_rate: 1.2987e-04
Epoch 128/300
785/785 - 89s - 113ms/step - accuracy: 0.4263 - loss: 2.7074 - val_accuracy: 0.6002 - val_loss: 1.8673 - learning_rate: 1.2987e-04
Epoch 129/300
785/785 - 88s - 112ms/step - accuracy: 0.4208 - loss: 2.7439 - val_accuracy: 0.5997 - val_loss: 1.8463 - learning_rate: 1.2987e-04
Epoch 130/300
785/785 - 86s - 110ms/step - accuracy: 0.4321 - loss: 2.7067 - val_accuracy: 0.6045 - val_loss: 1.8744 - learning_rate: 1.2987e-04
Epoch 131/300
785/785 - 88s - 112ms/step - accuracy: 0.4300 - loss: 2.7112 - val_accuracy: 0.5912 - val_loss: 1.8774 - learning_rate: 1.2987e-04
Epoch 132/300

Epoch 132: ReduceLROnPlateau reducing learning rate to 6.493452383438125e-05.
785/785 - 88s - 112ms/step - accuracy: 0.4303 - loss: 2.6749 - val_accuracy: 0.6011 - val_loss: 1.8343 - learning_rate: 1.2987e-04
Epoch 133/300
785/785 - 88s - 113ms/step - accuracy: 0.4305 - loss: 2.7007 - val_accuracy: 0.6037 - val_loss: 1.8282 - learning_rate: 6.4935e-05
Epoch 134/300
785/785 - 90s - 115ms/step - accuracy: 0.4290 - loss: 2.6914 - val_accuracy: 0.6057 - val_loss: 1.8379 - learning_rate: 6.4935e-05
Epoch 135/300
785/785 - 89s - 114ms/step - accuracy: 0.4357 - loss: 2.6600 - val_accuracy: 0.6010 - val_loss: 1.8287 - learning_rate: 6.4935e-05
Epoch 136/300
785/785 - 89s - 114ms/step - accuracy: 0.4303 - loss: 2.6604 - val_accuracy: 0.6035 - val_loss: 1.8188 - learning_rate: 6.4935e-05
Epoch 137/300
785/785 - 90s - 114ms/step - accuracy: 0.4249 - loss: 2.6618 - val_accuracy: 0.6032 - val_loss: 1.8156 - learning_rate: 6.4935e-05
Epoch 138/300
785/785 - 142s - 181ms/step - accuracy: 0.4249 - loss: 2.6981 - val_accuracy: 0.6018 - val_loss: 1.8071 - learning_rate: 6.4935e-05
Epoch 139/300
785/785 - 90s - 115ms/step - accuracy: 0.4341 - loss: 2.6932 - val_accuracy: 0.6029 - val_loss: 1.8199 - learning_rate: 6.4935e-05
Epoch 140/300
785/785 - 88s - 112ms/step - accuracy: 0.4271 - loss: 2.6939 - val_accuracy: 0.6010 - val_loss: 1.8198 - learning_rate: 6.4935e-05
Epoch 141/300
785/785 - 142s - 181ms/step - accuracy: 0.4394 - loss: 2.6569 - val_accuracy: 0.6096 - val_loss: 1.8242 - learning_rate: 6.4935e-05
Epoch 142/300
785/785 - 89s - 113ms/step - accuracy: 0.4169 - loss: 2.7020 - val_accuracy: 0.6045 - val_loss: 1.8235 - learning_rate: 6.4935e-05
Epoch 143/300
785/785 - 87s - 111ms/step - accuracy: 0.4388 - loss: 2.6782 - val_accuracy: 0.6019 - val_loss: 1.8199 - learning_rate: 6.4935e-05
Epoch 144/300
785/785 - 85s - 108ms/step - accuracy: 0.4380 - loss: 2.6553 - val_accuracy: 0.6049 - val_loss: 1.8076 - learning_rate: 6.4935e-05
Epoch 145/300
785/785 - 84s - 108ms/step - accuracy: 0.4157 - loss: 2.7114 - val_accuracy: 0.6056 - val_loss: 1.8036 - learning_rate: 6.4935e-05
Epoch 146/300
785/785 - 84s - 108ms/step - accuracy: 0.4443 - loss: 2.6293 - val_accuracy: 0.5994 - val_loss: 1.8333 - learning_rate: 6.4935e-05
Epoch 147/300
785/785 - 148s - 189ms/step - accuracy: 0.4283 - loss: 2.6841 - val_accuracy: 0.6021 - val_loss: 1.8071 - learning_rate: 6.4935e-05
Epoch 148/300
785/785 - 83s - 106ms/step - accuracy: 0.4407 - loss: 2.6407 - val_accuracy: 0.6057 - val_loss: 1.8086 - learning_rate: 6.4935e-05
Epoch 149/300
785/785 - 81s - 104ms/step - accuracy: 0.4447 - loss: 2.6421 - val_accuracy: 0.6043 - val_loss: 1.8093 - learning_rate: 6.4935e-05
Epoch 150/300
785/785 - 84s - 107ms/step - accuracy: 0.4423 - loss: 2.6663 - val_accuracy: 0.6005 - val_loss: 1.7951 - learning_rate: 6.4935e-05
Epoch 151/300
785/785 - 84s - 107ms/step - accuracy: 0.4267 - loss: 2.6609 - val_accuracy: 0.6029 - val_loss: 1.8161 - learning_rate: 6.4935e-05
Epoch 152/300
785/785 - 83s - 106ms/step - accuracy: 0.4362 - loss: 2.6586 - val_accuracy: 0.6033 - val_loss: 1.7926 - learning_rate: 6.4935e-05
Epoch 153/300
785/785 - 84s - 107ms/step - accuracy: 0.4286 - loss: 2.6769 - val_accuracy: 0.6048 - val_loss: 1.7988 - learning_rate: 6.4935e-05
Epoch 154/300
785/785 - 83s - 106ms/step - accuracy: 0.4450 - loss: 2.6321 - val_accuracy: 0.6021 - val_loss: 1.8028 - learning_rate: 6.4935e-05
Epoch 155/300
785/785 - 83s - 106ms/step - accuracy: 0.4407 - loss: 2.6203 - val_accuracy: 0.6075 - val_loss: 1.7927 - learning_rate: 6.4935e-05
Epoch 156/300
785/785 - 83s - 106ms/step - accuracy: 0.4300 - loss: 2.6862 - val_accuracy: 0.6048 - val_loss: 1.8060 - learning_rate: 6.4935e-05
Epoch 157/300
785/785 - 82s - 105ms/step - accuracy: 0.4321 - loss: 2.6952 - val_accuracy: 0.6005 - val_loss: 1.8319 - learning_rate: 6.4935e-05
Epoch 158/300
785/785 - 84s - 107ms/step - accuracy: 0.4400 - loss: 2.6444 - val_accuracy: 0.6010 - val_loss: 1.8056 - learning_rate: 6.4935e-05
Epoch 159/300
785/785 - 84s - 107ms/step - accuracy: 0.4335 - loss: 2.6652 - val_accuracy: 0.5984 - val_loss: 1.8228 - learning_rate: 6.4935e-05
Epoch 160/300

Epoch 160: ReduceLROnPlateau reducing learning rate to 3.2467261917190626e-05.
785/785 - 83s - 106ms/step - accuracy: 0.4365 - loss: 2.6816 - val_accuracy: 0.6076 - val_loss: 1.8065 - learning_rate: 6.4935e-05
Epoch 161/300
785/785 - 84s - 107ms/step - accuracy: 0.4367 - loss: 2.6667 - val_accuracy: 0.6108 - val_loss: 1.7996 - learning_rate: 3.2467e-05
Epoch 162/300
785/785 - 83s - 106ms/step - accuracy: 0.4392 - loss: 2.6320 - val_accuracy: 0.6089 - val_loss: 1.7977 - learning_rate: 3.2467e-05
Epoch 163/300
785/785 - 83s - 106ms/step - accuracy: 0.4432 - loss: 2.6503 - val_accuracy: 0.6075 - val_loss: 1.7903 - learning_rate: 3.2467e-05
Epoch 164/300
785/785 - 142s - 181ms/step - accuracy: 0.4353 - loss: 2.6315 - val_accuracy: 0.6105 - val_loss: 1.7918 - learning_rate: 3.2467e-05
Epoch 165/300
785/785 - 85s - 108ms/step - accuracy: 0.4419 - loss: 2.6534 - val_accuracy: 0.6115 - val_loss: 1.7954 - learning_rate: 3.2467e-05
Epoch 166/300
785/785 - 83s - 106ms/step - accuracy: 0.4488 - loss: 2.6299 - val_accuracy: 0.6088 - val_loss: 1.7890 - learning_rate: 3.2467e-05
Epoch 167/300
785/785 - 90s - 114ms/step - accuracy: 0.4478 - loss: 2.6269 - val_accuracy: 0.6107 - val_loss: 1.7865 - learning_rate: 3.2467e-05
Epoch 168/300
785/785 - 84s - 107ms/step - accuracy: 0.4456 - loss: 2.6178 - val_accuracy: 0.6110 - val_loss: 1.7823 - learning_rate: 3.2467e-05
Epoch 169/300
785/785 - 83s - 106ms/step - accuracy: 0.4432 - loss: 2.6535 - val_accuracy: 0.6089 - val_loss: 1.7895 - learning_rate: 3.2467e-05
Epoch 170/300
785/785 - 83s - 106ms/step - accuracy: 0.4413 - loss: 2.6420 - val_accuracy: 0.6089 - val_loss: 1.7900 - learning_rate: 3.2467e-05
Epoch 171/300
785/785 - 91s - 116ms/step - accuracy: 0.4388 - loss: 2.6557 - val_accuracy: 0.6061 - val_loss: 1.7815 - learning_rate: 3.2467e-05
Epoch 172/300
785/785 - 84s - 107ms/step - accuracy: 0.4376 - loss: 2.6362 - val_accuracy: 0.6107 - val_loss: 1.7944 - learning_rate: 3.2467e-05
Epoch 173/300
785/785 - 85s - 108ms/step - accuracy: 0.4386 - loss: 2.6335 - val_accuracy: 0.6118 - val_loss: 1.7916 - learning_rate: 3.2467e-05
Epoch 174/300
785/785 - 84s - 107ms/step - accuracy: 0.4391 - loss: 2.6568 - val_accuracy: 0.6084 - val_loss: 1.7878 - learning_rate: 3.2467e-05
Epoch 175/300
785/785 - 90s - 114ms/step - accuracy: 0.4416 - loss: 2.6306 - val_accuracy: 0.6156 - val_loss: 1.7880 - learning_rate: 3.2467e-05
Epoch 176/300
785/785 - 84s - 107ms/step - accuracy: 0.4343 - loss: 2.6475 - val_accuracy: 0.6126 - val_loss: 1.7912 - learning_rate: 3.2467e-05
Epoch 177/300
785/785 - 84s - 106ms/step - accuracy: 0.4338 - loss: 2.6574 - val_accuracy: 0.6088 - val_loss: 1.7836 - learning_rate: 3.2467e-05
Epoch 178/300
785/785 - 85s - 108ms/step - accuracy: 0.4434 - loss: 2.6357 - val_accuracy: 0.6092 - val_loss: 1.7937 - learning_rate: 3.2467e-05
Epoch 179/300
785/785 - 142s - 182ms/step - accuracy: 0.4490 - loss: 2.5970 - val_accuracy: 0.6104 - val_loss: 1.7786 - learning_rate: 3.2467e-05
Epoch 180/300
785/785 - 85s - 109ms/step - accuracy: 0.4442 - loss: 2.6256 - val_accuracy: 0.6116 - val_loss: 1.7743 - learning_rate: 3.2467e-05
Epoch 181/300
785/785 - 84s - 107ms/step - accuracy: 0.4439 - loss: 2.6060 - val_accuracy: 0.6080 - val_loss: 1.7911 - learning_rate: 3.2467e-05
Epoch 182/300
785/785 - 83s - 106ms/step - accuracy: 0.4477 - loss: 2.6354 - val_accuracy: 0.6081 - val_loss: 1.7916 - learning_rate: 3.2467e-05
Epoch 183/300
785/785 - 83s - 106ms/step - accuracy: 0.4469 - loss: 2.6187 - val_accuracy: 0.6092 - val_loss: 1.7763 - learning_rate: 3.2467e-05
Epoch 184/300
785/785 - 84s - 107ms/step - accuracy: 0.4429 - loss: 2.6359 - val_accuracy: 0.6083 - val_loss: 1.7755 - learning_rate: 3.2467e-05
Epoch 185/300
785/785 - 85s - 108ms/step - accuracy: 0.4419 - loss: 2.6323 - val_accuracy: 0.6121 - val_loss: 1.7924 - learning_rate: 3.2467e-05
Epoch 186/300
785/785 - 83s - 106ms/step - accuracy: 0.4386 - loss: 2.6412 - val_accuracy: 0.6094 - val_loss: 1.7779 - learning_rate: 3.2467e-05
Epoch 187/300
785/785 - 84s - 108ms/step - accuracy: 0.4477 - loss: 2.6124 - val_accuracy: 0.6111 - val_loss: 1.7794 - learning_rate: 3.2467e-05
Epoch 188/300
785/785 - 85s - 108ms/step - accuracy: 0.4364 - loss: 2.6469 - val_accuracy: 0.6099 - val_loss: 1.7733 - learning_rate: 3.2467e-05
Epoch 189/300
785/785 - 84s - 107ms/step - accuracy: 0.4450 - loss: 2.6330 - val_accuracy: 0.6123 - val_loss: 1.7924 - learning_rate: 3.2467e-05
Epoch 190/300
785/785 - 83s - 106ms/step - accuracy: 0.4327 - loss: 2.6292 - val_accuracy: 0.6096 - val_loss: 1.7752 - learning_rate: 3.2467e-05
Epoch 191/300
785/785 - 85s - 108ms/step - accuracy: 0.4356 - loss: 2.6652 - val_accuracy: 0.6113 - val_loss: 1.7811 - learning_rate: 3.2467e-05
Epoch 192/300
785/785 - 83s - 106ms/step - accuracy: 0.4490 - loss: 2.5989 - val_accuracy: 0.6137 - val_loss: 1.7910 - learning_rate: 3.2467e-05
Epoch 193/300
785/785 - 84s - 107ms/step - accuracy: 0.4376 - loss: 2.6108 - val_accuracy: 0.6143 - val_loss: 1.7864 - learning_rate: 3.2467e-05
Epoch 194/300
785/785 - 85s - 108ms/step - accuracy: 0.4432 - loss: 2.6434 - val_accuracy: 0.6081 - val_loss: 1.7896 - learning_rate: 3.2467e-05
Epoch 195/300
785/785 - 83s - 106ms/step - accuracy: 0.4510 - loss: 2.6003 - val_accuracy: 0.6108 - val_loss: 1.7968 - learning_rate: 3.2467e-05
Epoch 196/300

Epoch 196: ReduceLROnPlateau reducing learning rate to 1.6233630958595313e-05.
785/785 - 83s - 106ms/step - accuracy: 0.4525 - loss: 2.5986 - val_accuracy: 0.6089 - val_loss: 1.7743 - learning_rate: 3.2467e-05
Epoch 197/300
785/785 - 83s - 105ms/step - accuracy: 0.4455 - loss: 2.6016 - val_accuracy: 0.6116 - val_loss: 1.7749 - learning_rate: 1.6234e-05
Epoch 198/300
785/785 - 90s - 115ms/step - accuracy: 0.4402 - loss: 2.6284 - val_accuracy: 0.6150 - val_loss: 1.7753 - learning_rate: 1.6234e-05
Epoch 199/300
785/785 - 85s - 109ms/step - accuracy: 0.4402 - loss: 2.6282 - val_accuracy: 0.6150 - val_loss: 1.7754 - learning_rate: 1.6234e-05
Epoch 200/300
785/785 - 91s - 116ms/step - accuracy: 0.4380 - loss: 2.5956 - val_accuracy: 0.6134 - val_loss: 1.7740 - learning_rate: 1.6234e-05
Epoch 201/300
785/785 - 85s - 108ms/step - accuracy: 0.4372 - loss: 2.6286 - val_accuracy: 0.6115 - val_loss: 1.7733 - learning_rate: 1.6234e-05
Epoch 202/300
785/785 - 84s - 107ms/step - accuracy: 0.4620 - loss: 2.5939 - val_accuracy: 0.6135 - val_loss: 1.7729 - learning_rate: 1.6234e-05
Epoch 203/300
785/785 - 90s - 115ms/step - accuracy: 0.4435 - loss: 2.6092 - val_accuracy: 0.6132 - val_loss: 1.7843 - learning_rate: 1.6234e-05
Epoch 204/300
785/785 - 84s - 107ms/step - accuracy: 0.4427 - loss: 2.6138 - val_accuracy: 0.6124 - val_loss: 1.7778 - learning_rate: 1.6234e-05
Epoch 205/300
785/785 - 83s - 105ms/step - accuracy: 0.4419 - loss: 2.6108 - val_accuracy: 0.6135 - val_loss: 1.7730 - learning_rate: 1.6234e-05
Epoch 206/300
785/785 - 83s - 106ms/step - accuracy: 0.4448 - loss: 2.6064 - val_accuracy: 0.6121 - val_loss: 1.7757 - learning_rate: 1.6234e-05
Epoch 207/300
785/785 - 85s - 108ms/step - accuracy: 0.4456 - loss: 2.6080 - val_accuracy: 0.6124 - val_loss: 1.7713 - learning_rate: 1.6234e-05
Epoch 208/300
785/785 - 84s - 107ms/step - accuracy: 0.4528 - loss: 2.6074 - val_accuracy: 0.6115 - val_loss: 1.7735 - learning_rate: 1.6234e-05
Epoch 209/300
785/785 - 84s - 107ms/step - accuracy: 0.4464 - loss: 2.5764 - val_accuracy: 0.6139 - val_loss: 1.7815 - learning_rate: 1.6234e-05
Epoch 210/300
785/785 - 83s - 106ms/step - accuracy: 0.4380 - loss: 2.6311 - val_accuracy: 0.6121 - val_loss: 1.7770 - learning_rate: 1.6234e-05
Epoch 211/300
785/785 - 83s - 105ms/step - accuracy: 0.4453 - loss: 2.6192 - val_accuracy: 0.6135 - val_loss: 1.7759 - learning_rate: 1.6234e-05
Epoch 212/300
785/785 - 89s - 114ms/step - accuracy: 0.4474 - loss: 2.6156 - val_accuracy: 0.6124 - val_loss: 1.7762 - learning_rate: 1.6234e-05
Epoch 213/300
785/785 - 84s - 107ms/step - accuracy: 0.4424 - loss: 2.6259 - val_accuracy: 0.6146 - val_loss: 1.7764 - learning_rate: 1.6234e-05
Epoch 214/300
785/785 - 84s - 107ms/step - accuracy: 0.4461 - loss: 2.6255 - val_accuracy: 0.6105 - val_loss: 1.7707 - learning_rate: 1.6234e-05
Epoch 215/300
785/785 - 85s - 109ms/step - accuracy: 0.4475 - loss: 2.5795 - val_accuracy: 0.6137 - val_loss: 1.7859 - learning_rate: 1.6234e-05
Epoch 216/300
785/785 - 84s - 107ms/step - accuracy: 0.4458 - loss: 2.6145 - val_accuracy: 0.6137 - val_loss: 1.7765 - learning_rate: 1.6234e-05
Epoch 217/300
785/785 - 84s - 107ms/step - accuracy: 0.4447 - loss: 2.6338 - val_accuracy: 0.6100 - val_loss: 1.7737 - learning_rate: 1.6234e-05
Epoch 218/300
785/785 - 84s - 107ms/step - accuracy: 0.4505 - loss: 2.5882 - val_accuracy: 0.6115 - val_loss: 1.7727 - learning_rate: 1.6234e-05
Epoch 219/300
785/785 - 83s - 106ms/step - accuracy: 0.4394 - loss: 2.6726 - val_accuracy: 0.6123 - val_loss: 1.7727 - learning_rate: 1.6234e-05
Epoch 220/300
785/785 - 91s - 116ms/step - accuracy: 0.4515 - loss: 2.5737 - val_accuracy: 0.6134 - val_loss: 1.7763 - learning_rate: 1.6234e-05
Epoch 221/300
785/785 - 84s - 106ms/step - accuracy: 0.4431 - loss: 2.6295 - val_accuracy: 0.6131 - val_loss: 1.7692 - learning_rate: 1.6234e-05
Epoch 222/300
785/785 - 84s - 107ms/step - accuracy: 0.4478 - loss: 2.5841 - val_accuracy: 0.6123 - val_loss: 1.7734 - learning_rate: 1.6234e-05
Epoch 223/300
785/785 - 85s - 109ms/step - accuracy: 0.4426 - loss: 2.6099 - val_accuracy: 0.6134 - val_loss: 1.7751 - learning_rate: 1.6234e-05
Epoch 224/300
785/785 - 84s - 107ms/step - accuracy: 0.4536 - loss: 2.5751 - val_accuracy: 0.6140 - val_loss: 1.7695 - learning_rate: 1.6234e-05
Epoch 225/300
785/785 - 85s - 108ms/step - accuracy: 0.4349 - loss: 2.6345 - val_accuracy: 0.6137 - val_loss: 1.7767 - learning_rate: 1.6234e-05
Epoch 226/300
785/785 - 90s - 114ms/step - accuracy: 0.4464 - loss: 2.6094 - val_accuracy: 0.6131 - val_loss: 1.7798 - learning_rate: 1.6234e-05
Epoch 227/300
785/785 - 83s - 105ms/step - accuracy: 0.4531 - loss: 2.5775 - val_accuracy: 0.6150 - val_loss: 1.7711 - learning_rate: 1.6234e-05
Epoch 228/300
785/785 - 83s - 106ms/step - accuracy: 0.4404 - loss: 2.6156 - val_accuracy: 0.6159 - val_loss: 1.7744 - learning_rate: 1.6234e-05
Epoch 229/300

Epoch 229: ReduceLROnPlateau reducing learning rate to 8.116815479297657e-06.
785/785 - 82s - 105ms/step - accuracy: 0.4435 - loss: 2.6036 - val_accuracy: 0.6107 - val_loss: 1.7693 - learning_rate: 1.6234e-05
Epoch 230/300
785/785 - 84s - 107ms/step - accuracy: 0.4512 - loss: 2.5983 - val_accuracy: 0.6073 - val_loss: 1.7728 - learning_rate: 8.1168e-06
Epoch 231/300
785/785 - 85s - 109ms/step - accuracy: 0.4507 - loss: 2.5901 - val_accuracy: 0.6127 - val_loss: 1.7739 - learning_rate: 8.1168e-06
Epoch 232/300
785/785 - 87s - 111ms/step - accuracy: 0.4563 - loss: 2.5960 - val_accuracy: 0.6123 - val_loss: 1.7708 - learning_rate: 8.1168e-06
Epoch 233/300
785/785 - 91s - 115ms/step - accuracy: 0.4496 - loss: 2.5881 - val_accuracy: 0.6110 - val_loss: 1.7706 - learning_rate: 8.1168e-06
Epoch 234/300
785/785 - 90s - 115ms/step - accuracy: 0.4455 - loss: 2.6076 - val_accuracy: 0.6131 - val_loss: 1.7670 - learning_rate: 8.1168e-06
Epoch 235/300
785/785 - 94s - 120ms/step - accuracy: 0.4542 - loss: 2.6060 - val_accuracy: 0.6110 - val_loss: 1.7680 - learning_rate: 8.1168e-06
Epoch 236/300
785/785 - 87s - 111ms/step - accuracy: 0.4410 - loss: 2.5810 - val_accuracy: 0.6119 - val_loss: 1.7635 - learning_rate: 8.1168e-06
Epoch 237/300
785/785 - 86s - 110ms/step - accuracy: 0.4423 - loss: 2.6050 - val_accuracy: 0.6111 - val_loss: 1.7705 - learning_rate: 8.1168e-06
Epoch 238/300
785/785 - 86s - 110ms/step - accuracy: 0.4505 - loss: 2.6014 - val_accuracy: 0.6118 - val_loss: 1.7696 - learning_rate: 8.1168e-06
Epoch 239/300
785/785 - 93s - 118ms/step - accuracy: 0.4480 - loss: 2.5853 - val_accuracy: 0.6134 - val_loss: 1.7753 - learning_rate: 8.1168e-06
Epoch 240/300
785/785 - 93s - 118ms/step - accuracy: 0.4478 - loss: 2.5623 - val_accuracy: 0.6127 - val_loss: 1.7704 - learning_rate: 8.1168e-06
Epoch 241/300
785/785 - 97s - 123ms/step - accuracy: 0.4426 - loss: 2.6169 - val_accuracy: 0.6110 - val_loss: 1.7676 - learning_rate: 8.1168e-06
Epoch 242/300
785/785 - 89s - 113ms/step - accuracy: 0.4364 - loss: 2.6275 - val_accuracy: 0.6108 - val_loss: 1.7725 - learning_rate: 8.1168e-06
Epoch 243/300
785/785 - 90s - 114ms/step - accuracy: 0.4455 - loss: 2.6030 - val_accuracy: 0.6121 - val_loss: 1.7721 - learning_rate: 8.1168e-06
Epoch 244/300

Epoch 244: ReduceLROnPlateau reducing learning rate to 4.058407739648828e-06.
785/785 - 89s - 114ms/step - accuracy: 0.4474 - loss: 2.6162 - val_accuracy: 0.6105 - val_loss: 1.7683 - learning_rate: 8.1168e-06
Epoch 245/300
785/785 - 90s - 115ms/step - accuracy: 0.4442 - loss: 2.6137 - val_accuracy: 0.6108 - val_loss: 1.7685 - learning_rate: 4.0584e-06
Epoch 246/300
785/785 - 89s - 114ms/step - accuracy: 0.4544 - loss: 2.5800 - val_accuracy: 0.6121 - val_loss: 1.7729 - learning_rate: 4.0584e-06
Epoch 247/300
785/785 - 88s - 113ms/step - accuracy: 0.4488 - loss: 2.6011 - val_accuracy: 0.6129 - val_loss: 1.7684 - learning_rate: 4.0584e-06
Epoch 248/300
785/785 - 91s - 116ms/step - accuracy: 0.4469 - loss: 2.6033 - val_accuracy: 0.6137 - val_loss: 1.7721 - learning_rate: 4.0584e-06
Epoch 249/300
785/785 - 89s - 113ms/step - accuracy: 0.4509 - loss: 2.5858 - val_accuracy: 0.6127 - val_loss: 1.7671 - learning_rate: 4.0584e-06
Epoch 250/300
785/785 - 89s - 114ms/step - accuracy: 0.4396 - loss: 2.6082 - val_accuracy: 0.6116 - val_loss: 1.7714 - learning_rate: 4.0584e-06
Epoch 251/300
785/785 - 95s - 121ms/step - accuracy: 0.4553 - loss: 2.5898 - val_accuracy: 0.6131 - val_loss: 1.7733 - learning_rate: 4.0584e-06
Epoch 252/300

Epoch 252: ReduceLROnPlateau reducing learning rate to 2.029203869824414e-06.
785/785 - 89s - 114ms/step - accuracy: 0.4442 - loss: 2.5689 - val_accuracy: 0.6121 - val_loss: 1.7693 - learning_rate: 4.0584e-06
Epoch 252: early stopping
Restoring model weights from the end of the best epoch: 236.
Fold 4_1 Evaluation results: [1.7644994258880615, 0.6119426488876343]
              precision    recall  f1-score   support

        1820       0.69      0.82      0.75       312
        1821       0.91      0.83      0.87       277
        1822       0.00      0.00      0.00         9
        1823       0.00      0.00      0.00         5
        1824       0.00      0.00      0.00         2
        1825       0.17      0.10      0.12        10
        1826       0.00      0.00      0.00        11
        1827       0.80      0.74      0.77       129
        1828       0.33      0.33      0.33         3
        1829       0.88      0.29      0.44        24
        1830       0.50      0.67      0.57       270
        1831       0.77      0.93      0.84       705
        1832       0.82      0.75      0.78       355
        1833       0.82      0.92      0.87        86
        1834       0.55      0.64      0.59       141
        1835       0.00      0.00      0.00        14
        1836       0.17      0.27      0.21        15
        1837       0.23      0.22      0.23        32
        1838       0.00      0.00      0.00        20
        1839       0.00      0.00      0.00         4
        1840       0.46      0.62      0.53       199
        1841       0.72      0.54      0.62       530
        1842       0.53      0.35      0.42        26
        1843       0.50      0.15      0.23        27
        1844       0.00      0.00      0.00         0
        1845       0.00      0.00      0.00         4
        1846       0.29      0.09      0.14        22
        1847       0.00      0.00      0.00         6
        1848       0.23      0.10      0.14        31
        1849       0.31      0.18      0.23        28
        1850       0.45      0.57      0.51       258
        1851       0.72      0.73      0.73       395
        1852       0.67      0.05      0.10        39
        1853       0.00      0.00      0.00        34
        1854       0.00      0.00      0.00        11
        1855       0.07      0.01      0.01       124
        1856       0.49      0.59      0.54        59
        1857       0.43      0.60      0.50       167
        1858       0.00      0.00      0.00        13
        1859       0.00      0.00      0.00         8
        1860       0.29      0.50      0.36       307
        1861       0.79      0.79      0.79       441
        1862       0.33      0.01      0.02        91
        1863       0.38      0.46      0.42        89
        1864       0.34      0.37      0.36        82
        1865       1.00      0.08      0.15        38
        1866       0.17      0.08      0.11        24
        1867       0.21      0.17      0.19        47
        1868       0.00      0.00      0.00        36
        1869       0.00      0.00      0.00        24
        1870       0.46      0.53      0.49       158
        1871       0.66      0.76      0.71       231
        1872       0.46      0.31      0.37        35
        1873       0.30      0.17      0.22        41
        1874       0.57      0.16      0.25        25
        1875       0.34      0.30      0.32        69
        1876       0.98      0.86      0.91        50
        1877       0.36      0.15      0.21        33
        1878       0.62      0.53      0.57        49
        1879       0.00      0.00      0.00         5

    accuracy                           0.61      6280
   macro avg       0.36      0.31      0.31      6280
weighted avg       0.60      0.61      0.59      6280

Matthews Correlation Coefficient: 0.592
Macro avg F1: 0.309
Weighted avg F1: 0.589
Micro avg F1: 0.612
Top-3 Accuracy: 0.852
Top-5 Accuracy: 0.906
Micro ROC AUC  = 0.99
Macro ROC AUC (present classes) = 0.97
Classification MAE (in years): 3.11

Fold 4_1 Misclassification Analysis:
Near misses (within 2 years): 560 out of 2437 misclassifications (22.98%)
Big misses (greater than 10 years): 1021
MAE with outliers: 3.11
MAE without outliers: 2.24 (improvement: 0.86)

10 Worst misclassifications:
Image: data/datasets/public/1870/1877_035met.jpg, True: 1877, Predicted: 1820, Error: 57
Image: data/datasets/public/1870/1876_70washington.jpg, True: 1876, Predicted: 1820, Error: 56
Image: data/datasets/public/1870/1870_79wikimedia2.jpg, True: 1870, Predicted: 1820, Error: 50
Image: data/datasets/public/1870/1870_75wikimedia2.jpg, True: 1870, Predicted: 1820, Error: 50
Image: data/datasets/private/1870/1871_404etsy.jpg, True: 1871, Predicted: 1821, Error: 50
Image: data/datasets/private/1870/1871_384etsy.jpg, True: 1871, Predicted: 1821, Error: 50
Image: data/datasets/private/1870/1871_415etsy.jpg, True: 1871, Predicted: 1821, Error: 50
Image: data/datasets/public/1860/1868_007met.jpg, True: 1868, Predicted: 1820, Error: 48
Image: data/datasets/public/1870/1879_39wikimedia2.jpg, True: 1879, Predicted: 1831, Error: 48
Image: data/datasets/public/1870/1876_53washington.jpg, True: 1876, Predicted: 1829, Error: 47

===== Fine Tuning 9 layers! =====
Epoch 1/300
785/785 - 112s - 142ms/step - accuracy: 0.1113 - loss: 4.4664 - val_accuracy: 0.1841 - val_loss: 4.1465 - learning_rate: 2.5974e-04
Epoch 2/300
785/785 - 95s - 121ms/step - accuracy: 0.1688 - loss: 4.1218 - val_accuracy: 0.2214 - val_loss: 3.7885 - learning_rate: 2.5974e-04
Epoch 3/300
785/785 - 89s - 113ms/step - accuracy: 0.2046 - loss: 3.9313 - val_accuracy: 0.2615 - val_loss: 3.6688 - learning_rate: 2.5974e-04
Epoch 4/300
785/785 - 89s - 114ms/step - accuracy: 0.2274 - loss: 3.7801 - val_accuracy: 0.2857 - val_loss: 3.2244 - learning_rate: 2.5974e-04
Epoch 5/300
785/785 - 89s - 113ms/step - accuracy: 0.2468 - loss: 3.6576 - val_accuracy: 0.3016 - val_loss: 3.2233 - learning_rate: 2.5974e-04
Epoch 6/300
785/785 - 88s - 112ms/step - accuracy: 0.2500 - loss: 3.5765 - val_accuracy: 0.3811 - val_loss: 3.0262 - learning_rate: 2.5974e-04
Epoch 7/300
785/785 - 89s - 114ms/step - accuracy: 0.2747 - loss: 3.4997 - val_accuracy: 0.3900 - val_loss: 2.9705 - learning_rate: 2.5974e-04
Epoch 8/300
785/785 - 90s - 114ms/step - accuracy: 0.2801 - loss: 3.4756 - val_accuracy: 0.4018 - val_loss: 2.8666 - learning_rate: 2.5974e-04
Epoch 9/300
785/785 - 89s - 114ms/step - accuracy: 0.2896 - loss: 3.4332 - val_accuracy: 0.3959 - val_loss: 2.8530 - learning_rate: 2.5974e-04
Epoch 10/300
785/785 - 89s - 113ms/step - accuracy: 0.2997 - loss: 3.3758 - val_accuracy: 0.4345 - val_loss: 2.7703 - learning_rate: 2.5974e-04
Epoch 11/300
785/785 - 87s - 111ms/step - accuracy: 0.3124 - loss: 3.3418 - val_accuracy: 0.4397 - val_loss: 2.6949 - learning_rate: 2.5974e-04
Epoch 12/300
785/785 - 88s - 112ms/step - accuracy: 0.3027 - loss: 3.3082 - val_accuracy: 0.4319 - val_loss: 2.7396 - learning_rate: 2.5974e-04
Epoch 13/300
785/785 - 88s - 112ms/step - accuracy: 0.3158 - loss: 3.2766 - val_accuracy: 0.4615 - val_loss: 2.5986 - learning_rate: 2.5974e-04
Epoch 14/300
785/785 - 89s - 114ms/step - accuracy: 0.3156 - loss: 3.2706 - val_accuracy: 0.4689 - val_loss: 2.5915 - learning_rate: 2.5974e-04
Epoch 15/300
785/785 - 89s - 114ms/step - accuracy: 0.3312 - loss: 3.2074 - val_accuracy: 0.4904 - val_loss: 2.5466 - learning_rate: 2.5974e-04
Epoch 16/300
785/785 - 89s - 113ms/step - accuracy: 0.3295 - loss: 3.2188 - val_accuracy: 0.4717 - val_loss: 2.5686 - learning_rate: 2.5974e-04
Epoch 17/300
785/785 - 90s - 114ms/step - accuracy: 0.3274 - loss: 3.2145 - val_accuracy: 0.4580 - val_loss: 2.5448 - learning_rate: 2.5974e-04
Epoch 18/300
785/785 - 91s - 116ms/step - accuracy: 0.3277 - loss: 3.1892 - val_accuracy: 0.4636 - val_loss: 2.4448 - learning_rate: 2.5974e-04
Epoch 19/300
785/785 - 88s - 113ms/step - accuracy: 0.3400 - loss: 3.1486 - val_accuracy: 0.4784 - val_loss: 2.5427 - learning_rate: 2.5974e-04
Epoch 20/300
785/785 - 88s - 113ms/step - accuracy: 0.3452 - loss: 3.1657 - val_accuracy: 0.4974 - val_loss: 2.4644 - learning_rate: 2.5974e-04
Epoch 21/300
785/785 - 89s - 114ms/step - accuracy: 0.3344 - loss: 3.1628 - val_accuracy: 0.4854 - val_loss: 2.4841 - learning_rate: 2.5974e-04
Epoch 22/300
785/785 - 89s - 114ms/step - accuracy: 0.3449 - loss: 3.1392 - val_accuracy: 0.5044 - val_loss: 2.4155 - learning_rate: 2.5974e-04
Epoch 23/300
785/785 - 90s - 115ms/step - accuracy: 0.3518 - loss: 3.0966 - val_accuracy: 0.5125 - val_loss: 2.3844 - learning_rate: 2.5974e-04
Epoch 24/300
785/785 - 140s - 179ms/step - accuracy: 0.3591 - loss: 3.0708 - val_accuracy: 0.5104 - val_loss: 2.4036 - learning_rate: 2.5974e-04
Epoch 25/300
785/785 - 90s - 115ms/step - accuracy: 0.3559 - loss: 3.1021 - val_accuracy: 0.5018 - val_loss: 2.3749 - learning_rate: 2.5974e-04
Epoch 26/300
785/785 - 89s - 114ms/step - accuracy: 0.3537 - loss: 3.0777 - val_accuracy: 0.4935 - val_loss: 2.3799 - learning_rate: 2.5974e-04
Epoch 27/300
785/785 - 90s - 114ms/step - accuracy: 0.3556 - loss: 3.0313 - val_accuracy: 0.5179 - val_loss: 2.3213 - learning_rate: 2.5974e-04
Epoch 28/300
785/785 - 90s - 114ms/step - accuracy: 0.3537 - loss: 3.0523 - val_accuracy: 0.5154 - val_loss: 2.3099 - learning_rate: 2.5974e-04
Epoch 29/300
785/785 - 89s - 113ms/step - accuracy: 0.3666 - loss: 3.0700 - val_accuracy: 0.5176 - val_loss: 2.3114 - learning_rate: 2.5974e-04
Epoch 30/300
785/785 - 89s - 113ms/step - accuracy: 0.3487 - loss: 3.0347 - val_accuracy: 0.5052 - val_loss: 2.3331 - learning_rate: 2.5974e-04
Epoch 31/300
785/785 - 89s - 114ms/step - accuracy: 0.3689 - loss: 2.9945 - val_accuracy: 0.5112 - val_loss: 2.3341 - learning_rate: 2.5974e-04
Epoch 32/300
785/785 - 87s - 111ms/step - accuracy: 0.3670 - loss: 3.0216 - val_accuracy: 0.5165 - val_loss: 2.3024 - learning_rate: 2.5974e-04
Epoch 33/300
785/785 - 87s - 111ms/step - accuracy: 0.3650 - loss: 3.0170 - val_accuracy: 0.4996 - val_loss: 2.2912 - learning_rate: 2.5974e-04
Epoch 34/300
785/785 - 87s - 110ms/step - accuracy: 0.3615 - loss: 3.0335 - val_accuracy: 0.4983 - val_loss: 2.2854 - learning_rate: 2.5974e-04
Epoch 35/300
785/785 - 89s - 113ms/step - accuracy: 0.3639 - loss: 3.0163 - val_accuracy: 0.5108 - val_loss: 2.3036 - learning_rate: 2.5974e-04
Epoch 36/300
785/785 - 89s - 113ms/step - accuracy: 0.3747 - loss: 2.9641 - val_accuracy: 0.5165 - val_loss: 2.3088 - learning_rate: 2.5974e-04
Epoch 37/300
785/785 - 141s - 179ms/step - accuracy: 0.3710 - loss: 3.0252 - val_accuracy: 0.5123 - val_loss: 2.3116 - learning_rate: 2.5974e-04
Epoch 38/300
785/785 - 87s - 111ms/step - accuracy: 0.3696 - loss: 2.9881 - val_accuracy: 0.5227 - val_loss: 2.2224 - learning_rate: 2.5974e-04
Epoch 39/300
785/785 - 86s - 109ms/step - accuracy: 0.3818 - loss: 2.9726 - val_accuracy: 0.5154 - val_loss: 2.2796 - learning_rate: 2.5974e-04
Epoch 40/300
785/785 - 88s - 112ms/step - accuracy: 0.3756 - loss: 2.9686 - val_accuracy: 0.5154 - val_loss: 2.2346 - learning_rate: 2.5974e-04
Epoch 41/300
785/785 - 89s - 113ms/step - accuracy: 0.3782 - loss: 2.9573 - val_accuracy: 0.5072 - val_loss: 2.2348 - learning_rate: 2.5974e-04
Epoch 42/300
785/785 - 89s - 114ms/step - accuracy: 0.3755 - loss: 2.9300 - val_accuracy: 0.5146 - val_loss: 2.2225 - learning_rate: 2.5974e-04
Epoch 43/300
785/785 - 89s - 114ms/step - accuracy: 0.3861 - loss: 2.9625 - val_accuracy: 0.5120 - val_loss: 2.2554 - learning_rate: 2.5974e-04
Epoch 44/300
785/785 - 89s - 113ms/step - accuracy: 0.3857 - loss: 2.9356 - val_accuracy: 0.5361 - val_loss: 2.2266 - learning_rate: 2.5974e-04
Epoch 45/300
785/785 - 89s - 113ms/step - accuracy: 0.3758 - loss: 2.9261 - val_accuracy: 0.5273 - val_loss: 2.2082 - learning_rate: 2.5974e-04
Epoch 46/300
785/785 - 89s - 113ms/step - accuracy: 0.3737 - loss: 2.9519 - val_accuracy: 0.5216 - val_loss: 2.2077 - learning_rate: 2.5974e-04
Epoch 47/300
785/785 - 89s - 113ms/step - accuracy: 0.3750 - loss: 2.9443 - val_accuracy: 0.5303 - val_loss: 2.1616 - learning_rate: 2.5974e-04
Epoch 48/300
785/785 - 88s - 113ms/step - accuracy: 0.3911 - loss: 2.9137 - val_accuracy: 0.5362 - val_loss: 2.2026 - learning_rate: 2.5974e-04
Epoch 49/300
785/785 - 88s - 112ms/step - accuracy: 0.3908 - loss: 2.9489 - val_accuracy: 0.5063 - val_loss: 2.2964 - learning_rate: 2.5974e-04
Epoch 50/300
785/785 - 89s - 113ms/step - accuracy: 0.3788 - loss: 2.9039 - val_accuracy: 0.5337 - val_loss: 2.1326 - learning_rate: 2.5974e-04
Epoch 51/300
785/785 - 89s - 113ms/step - accuracy: 0.3882 - loss: 2.9154 - val_accuracy: 0.5381 - val_loss: 2.2074 - learning_rate: 2.5974e-04
Epoch 52/300
785/785 - 89s - 113ms/step - accuracy: 0.3908 - loss: 2.9149 - val_accuracy: 0.5326 - val_loss: 2.1936 - learning_rate: 2.5974e-04
Epoch 53/300
785/785 - 89s - 113ms/step - accuracy: 0.3916 - loss: 2.9592 - val_accuracy: 0.5295 - val_loss: 2.1719 - learning_rate: 2.5974e-04
Epoch 54/300
785/785 - 88s - 113ms/step - accuracy: 0.3884 - loss: 2.9177 - val_accuracy: 0.5429 - val_loss: 2.1585 - learning_rate: 2.5974e-04
Epoch 55/300
785/785 - 89s - 113ms/step - accuracy: 0.3876 - loss: 2.8890 - val_accuracy: 0.5264 - val_loss: 2.2157 - learning_rate: 2.5974e-04
Epoch 56/300
785/785 - 89s - 113ms/step - accuracy: 0.3928 - loss: 2.9069 - val_accuracy: 0.5130 - val_loss: 2.2084 - learning_rate: 2.5974e-04
Epoch 57/300
785/785 - 89s - 113ms/step - accuracy: 0.3975 - loss: 2.8455 - val_accuracy: 0.5323 - val_loss: 2.1670 - learning_rate: 2.5974e-04
Epoch 58/300

Epoch 58: ReduceLROnPlateau reducing learning rate to 0.0001298690476687625.
785/785 - 89s - 114ms/step - accuracy: 0.3978 - loss: 2.8448 - val_accuracy: 0.5469 - val_loss: 2.1652 - learning_rate: 2.5974e-04
Epoch 59/300
785/785 - 87s - 111ms/step - accuracy: 0.4022 - loss: 2.8371 - val_accuracy: 0.5416 - val_loss: 2.1298 - learning_rate: 1.2987e-04
Epoch 60/300
785/785 - 87s - 111ms/step - accuracy: 0.4086 - loss: 2.8024 - val_accuracy: 0.5501 - val_loss: 2.0995 - learning_rate: 1.2987e-04
Epoch 61/300
785/785 - 87s - 111ms/step - accuracy: 0.4089 - loss: 2.7860 - val_accuracy: 0.5639 - val_loss: 2.0729 - learning_rate: 1.2987e-04
Epoch 62/300
785/785 - 89s - 113ms/step - accuracy: 0.4123 - loss: 2.8052 - val_accuracy: 0.5507 - val_loss: 2.0743 - learning_rate: 1.2987e-04
Epoch 63/300
785/785 - 88s - 113ms/step - accuracy: 0.4070 - loss: 2.8031 - val_accuracy: 0.5502 - val_loss: 2.0605 - learning_rate: 1.2987e-04
Epoch 64/300
785/785 - 89s - 113ms/step - accuracy: 0.4142 - loss: 2.8019 - val_accuracy: 0.5520 - val_loss: 2.0563 - learning_rate: 1.2987e-04
Epoch 65/300
785/785 - 87s - 111ms/step - accuracy: 0.4029 - loss: 2.7873 - val_accuracy: 0.5404 - val_loss: 2.0711 - learning_rate: 1.2987e-04
Epoch 66/300
785/785 - 88s - 112ms/step - accuracy: 0.4142 - loss: 2.7842 - val_accuracy: 0.5442 - val_loss: 2.0844 - learning_rate: 1.2987e-04
Epoch 67/300
785/785 - 86s - 109ms/step - accuracy: 0.4078 - loss: 2.7977 - val_accuracy: 0.5627 - val_loss: 2.0398 - learning_rate: 1.2987e-04
Epoch 68/300
785/785 - 88s - 112ms/step - accuracy: 0.4194 - loss: 2.7530 - val_accuracy: 0.5600 - val_loss: 2.0456 - learning_rate: 1.2987e-04
Epoch 69/300
785/785 - 95s - 121ms/step - accuracy: 0.4161 - loss: 2.7506 - val_accuracy: 0.5584 - val_loss: 2.0444 - learning_rate: 1.2987e-04
Epoch 70/300
785/785 - 89s - 114ms/step - accuracy: 0.4150 - loss: 2.7567 - val_accuracy: 0.5655 - val_loss: 2.0575 - learning_rate: 1.2987e-04
Epoch 71/300
785/785 - 94s - 119ms/step - accuracy: 0.4086 - loss: 2.7906 - val_accuracy: 0.5569 - val_loss: 2.0569 - learning_rate: 1.2987e-04
Epoch 72/300
785/785 - 89s - 114ms/step - accuracy: 0.4131 - loss: 2.7411 - val_accuracy: 0.5555 - val_loss: 2.0438 - learning_rate: 1.2987e-04
Epoch 73/300
785/785 - 89s - 113ms/step - accuracy: 0.4129 - loss: 2.7628 - val_accuracy: 0.5614 - val_loss: 2.0390 - learning_rate: 1.2987e-04
Epoch 74/300
785/785 - 89s - 113ms/step - accuracy: 0.4115 - loss: 2.7924 - val_accuracy: 0.5620 - val_loss: 2.0555 - learning_rate: 1.2987e-04
Epoch 75/300
785/785 - 91s - 116ms/step - accuracy: 0.4065 - loss: 2.7931 - val_accuracy: 0.5596 - val_loss: 2.0732 - learning_rate: 1.2987e-04
Epoch 76/300
785/785 - 90s - 114ms/step - accuracy: 0.4100 - loss: 2.7863 - val_accuracy: 0.5531 - val_loss: 2.0254 - learning_rate: 1.2987e-04
Epoch 77/300
785/785 - 90s - 114ms/step - accuracy: 0.4162 - loss: 2.7357 - val_accuracy: 0.5635 - val_loss: 2.0447 - learning_rate: 1.2987e-04
Epoch 78/300
785/785 - 89s - 113ms/step - accuracy: 0.4182 - loss: 2.7360 - val_accuracy: 0.5569 - val_loss: 2.0407 - learning_rate: 1.2987e-04
Epoch 79/300
785/785 - 89s - 114ms/step - accuracy: 0.4162 - loss: 2.7677 - val_accuracy: 0.5714 - val_loss: 2.0166 - learning_rate: 1.2987e-04
Epoch 80/300
785/785 - 88s - 112ms/step - accuracy: 0.4084 - loss: 2.7483 - val_accuracy: 0.5638 - val_loss: 2.0250 - learning_rate: 1.2987e-04
Epoch 81/300
785/785 - 89s - 114ms/step - accuracy: 0.4150 - loss: 2.7600 - val_accuracy: 0.5641 - val_loss: 2.0330 - learning_rate: 1.2987e-04
Epoch 82/300
785/785 - 88s - 112ms/step - accuracy: 0.4167 - loss: 2.7503 - val_accuracy: 0.5593 - val_loss: 2.0145 - learning_rate: 1.2987e-04
Epoch 83/300
785/785 - 88s - 113ms/step - accuracy: 0.4143 - loss: 2.7557 - val_accuracy: 0.5630 - val_loss: 2.0099 - learning_rate: 1.2987e-04
Epoch 84/300
785/785 - 95s - 121ms/step - accuracy: 0.4209 - loss: 2.7529 - val_accuracy: 0.5654 - val_loss: 2.0080 - learning_rate: 1.2987e-04
Epoch 85/300
785/785 - 91s - 116ms/step - accuracy: 0.4197 - loss: 2.7588 - val_accuracy: 0.5616 - val_loss: 2.0063 - learning_rate: 1.2987e-04
Epoch 86/300
785/785 - 144s - 183ms/step - accuracy: 0.4252 - loss: 2.7202 - val_accuracy: 0.5654 - val_loss: 2.0586 - learning_rate: 1.2987e-04
Epoch 87/300
785/785 - 91s - 116ms/step - accuracy: 0.4186 - loss: 2.7566 - val_accuracy: 0.5654 - val_loss: 2.0425 - learning_rate: 1.2987e-04
Epoch 88/300
785/785 - 91s - 116ms/step - accuracy: 0.4213 - loss: 2.7172 - val_accuracy: 0.5710 - val_loss: 2.0123 - learning_rate: 1.2987e-04
Epoch 89/300
785/785 - 91s - 115ms/step - accuracy: 0.4167 - loss: 2.7247 - val_accuracy: 0.5670 - val_loss: 2.0206 - learning_rate: 1.2987e-04
Epoch 90/300
785/785 - 142s - 181ms/step - accuracy: 0.4102 - loss: 2.7632 - val_accuracy: 0.5694 - val_loss: 2.0227 - learning_rate: 1.2987e-04
Epoch 91/300
785/785 - 92s - 117ms/step - accuracy: 0.4180 - loss: 2.7226 - val_accuracy: 0.5665 - val_loss: 2.0056 - learning_rate: 1.2987e-04
Epoch 92/300
785/785 - 91s - 116ms/step - accuracy: 0.4182 - loss: 2.7525 - val_accuracy: 0.5698 - val_loss: 2.0684 - learning_rate: 1.2987e-04
Epoch 93/300
785/785 - 87s - 111ms/step - accuracy: 0.4205 - loss: 2.7273 - val_accuracy: 0.5639 - val_loss: 2.0045 - learning_rate: 1.2987e-04
Epoch 94/300
785/785 - 87s - 111ms/step - accuracy: 0.4102 - loss: 2.7755 - val_accuracy: 0.5643 - val_loss: 2.0230 - learning_rate: 1.2987e-04
Epoch 95/300
785/785 - 87s - 111ms/step - accuracy: 0.4094 - loss: 2.7507 - val_accuracy: 0.5676 - val_loss: 1.9916 - learning_rate: 1.2987e-04
Epoch 96/300
785/785 - 89s - 113ms/step - accuracy: 0.4127 - loss: 2.7549 - val_accuracy: 0.5729 - val_loss: 2.0279 - learning_rate: 1.2987e-04
Epoch 97/300
785/785 - 89s - 113ms/step - accuracy: 0.4232 - loss: 2.7324 - val_accuracy: 0.5733 - val_loss: 2.0247 - learning_rate: 1.2987e-04
Epoch 98/300
785/785 - 89s - 114ms/step - accuracy: 0.4229 - loss: 2.7436 - val_accuracy: 0.5724 - val_loss: 2.0269 - learning_rate: 1.2987e-04
Epoch 99/300
785/785 - 89s - 114ms/step - accuracy: 0.4253 - loss: 2.7024 - val_accuracy: 0.5619 - val_loss: 1.9948 - learning_rate: 1.2987e-04
Epoch 100/300
785/785 - 88s - 112ms/step - accuracy: 0.4183 - loss: 2.6953 - val_accuracy: 0.5737 - val_loss: 1.9992 - learning_rate: 1.2987e-04
Epoch 101/300
785/785 - 90s - 114ms/step - accuracy: 0.4193 - loss: 2.6934 - val_accuracy: 0.5662 - val_loss: 1.9773 - learning_rate: 1.2987e-04
Epoch 102/300
785/785 - 88s - 112ms/step - accuracy: 0.4209 - loss: 2.7093 - val_accuracy: 0.5783 - val_loss: 2.0007 - learning_rate: 1.2987e-04
Epoch 103/300
785/785 - 89s - 113ms/step - accuracy: 0.4207 - loss: 2.7099 - val_accuracy: 0.5773 - val_loss: 1.9848 - learning_rate: 1.2987e-04
Epoch 104/300
785/785 - 88s - 112ms/step - accuracy: 0.4237 - loss: 2.7160 - val_accuracy: 0.5647 - val_loss: 2.0146 - learning_rate: 1.2987e-04
Epoch 105/300
785/785 - 88s - 112ms/step - accuracy: 0.4255 - loss: 2.7202 - val_accuracy: 0.5657 - val_loss: 2.0017 - learning_rate: 1.2987e-04
Epoch 106/300
785/785 - 89s - 113ms/step - accuracy: 0.4205 - loss: 2.7321 - val_accuracy: 0.5781 - val_loss: 1.9982 - learning_rate: 1.2987e-04
Epoch 107/300
785/785 - 88s - 112ms/step - accuracy: 0.4248 - loss: 2.7071 - val_accuracy: 0.5721 - val_loss: 1.9794 - learning_rate: 1.2987e-04
Epoch 108/300
785/785 - 89s - 113ms/step - accuracy: 0.4115 - loss: 2.7514 - val_accuracy: 0.5665 - val_loss: 2.0335 - learning_rate: 1.2987e-04
Epoch 109/300

Epoch 109: ReduceLROnPlateau reducing learning rate to 6.493452383438125e-05.
785/785 - 89s - 113ms/step - accuracy: 0.4293 - loss: 2.6958 - val_accuracy: 0.5756 - val_loss: 1.9883 - learning_rate: 1.2987e-04
Epoch 110/300
785/785 - 89s - 113ms/step - accuracy: 0.4361 - loss: 2.6703 - val_accuracy: 0.5775 - val_loss: 1.9796 - learning_rate: 6.4935e-05
Epoch 111/300
785/785 - 89s - 113ms/step - accuracy: 0.4361 - loss: 2.6867 - val_accuracy: 0.5794 - val_loss: 1.9620 - learning_rate: 6.4935e-05
Epoch 112/300
785/785 - 89s - 113ms/step - accuracy: 0.4384 - loss: 2.6640 - val_accuracy: 0.5811 - val_loss: 1.9622 - learning_rate: 6.4935e-05
Epoch 113/300
785/785 - 95s - 121ms/step - accuracy: 0.4272 - loss: 2.6922 - val_accuracy: 0.5807 - val_loss: 1.9595 - learning_rate: 6.4935e-05
Epoch 114/300
785/785 - 88s - 112ms/step - accuracy: 0.4247 - loss: 2.6727 - val_accuracy: 0.5839 - val_loss: 1.9520 - learning_rate: 6.4935e-05
Epoch 115/300
785/785 - 140s - 179ms/step - accuracy: 0.4336 - loss: 2.6863 - val_accuracy: 0.5816 - val_loss: 1.9611 - learning_rate: 6.4935e-05
Epoch 116/300
785/785 - 87s - 110ms/step - accuracy: 0.4360 - loss: 2.6773 - val_accuracy: 0.5843 - val_loss: 1.9669 - learning_rate: 6.4935e-05
Epoch 117/300
785/785 - 88s - 112ms/step - accuracy: 0.4258 - loss: 2.6774 - val_accuracy: 0.5810 - val_loss: 1.9583 - learning_rate: 6.4935e-05
Epoch 118/300
785/785 - 143s - 182ms/step - accuracy: 0.4309 - loss: 2.6794 - val_accuracy: 0.5725 - val_loss: 1.9576 - learning_rate: 6.4935e-05
Epoch 119/300
785/785 - 87s - 111ms/step - accuracy: 0.4336 - loss: 2.6588 - val_accuracy: 0.5853 - val_loss: 1.9711 - learning_rate: 6.4935e-05
Epoch 120/300
785/785 - 87s - 111ms/step - accuracy: 0.4240 - loss: 2.6810 - val_accuracy: 0.5797 - val_loss: 1.9556 - learning_rate: 6.4935e-05
Epoch 121/300
785/785 - 85s - 109ms/step - accuracy: 0.4354 - loss: 2.6572 - val_accuracy: 0.5846 - val_loss: 1.9544 - learning_rate: 6.4935e-05
Epoch 122/300

Epoch 122: ReduceLROnPlateau reducing learning rate to 3.2467261917190626e-05.
785/785 - 87s - 110ms/step - accuracy: 0.4237 - loss: 2.6587 - val_accuracy: 0.5775 - val_loss: 1.9656 - learning_rate: 6.4935e-05
Epoch 123/300
785/785 - 87s - 111ms/step - accuracy: 0.4432 - loss: 2.6297 - val_accuracy: 0.5861 - val_loss: 1.9321 - learning_rate: 3.2467e-05
Epoch 124/300
785/785 - 89s - 113ms/step - accuracy: 0.4400 - loss: 2.6614 - val_accuracy: 0.5848 - val_loss: 1.9312 - learning_rate: 3.2467e-05
Epoch 125/300
785/785 - 88s - 112ms/step - accuracy: 0.4490 - loss: 2.6373 - val_accuracy: 0.5896 - val_loss: 1.9387 - learning_rate: 3.2467e-05
Epoch 126/300
785/785 - 89s - 113ms/step - accuracy: 0.4374 - loss: 2.6241 - val_accuracy: 0.5864 - val_loss: 1.9341 - learning_rate: 3.2467e-05
Epoch 127/300
785/785 - 88s - 113ms/step - accuracy: 0.4385 - loss: 2.6272 - val_accuracy: 0.5904 - val_loss: 1.9421 - learning_rate: 3.2467e-05
Epoch 128/300
785/785 - 88s - 113ms/step - accuracy: 0.4349 - loss: 2.6494 - val_accuracy: 0.5839 - val_loss: 1.9407 - learning_rate: 3.2467e-05
Epoch 129/300
785/785 - 88s - 112ms/step - accuracy: 0.4385 - loss: 2.6292 - val_accuracy: 0.5877 - val_loss: 1.9420 - learning_rate: 3.2467e-05
Epoch 130/300
785/785 - 88s - 112ms/step - accuracy: 0.4379 - loss: 2.6211 - val_accuracy: 0.5850 - val_loss: 1.9450 - learning_rate: 3.2467e-05
Epoch 131/300
785/785 - 89s - 113ms/step - accuracy: 0.4336 - loss: 2.6535 - val_accuracy: 0.5853 - val_loss: 1.9364 - learning_rate: 3.2467e-05
Epoch 132/300
785/785 - 94s - 120ms/step - accuracy: 0.4306 - loss: 2.6200 - val_accuracy: 0.5867 - val_loss: 1.9302 - learning_rate: 3.2467e-05
Epoch 133/300
785/785 - 88s - 112ms/step - accuracy: 0.4371 - loss: 2.6387 - val_accuracy: 0.5827 - val_loss: 1.9374 - learning_rate: 3.2467e-05
Epoch 134/300
785/785 - 87s - 111ms/step - accuracy: 0.4363 - loss: 2.6383 - val_accuracy: 0.5818 - val_loss: 1.9457 - learning_rate: 3.2467e-05
Epoch 135/300
785/785 - 89s - 113ms/step - accuracy: 0.4363 - loss: 2.6318 - val_accuracy: 0.5872 - val_loss: 1.9335 - learning_rate: 3.2467e-05
Epoch 136/300
785/785 - 89s - 114ms/step - accuracy: 0.4408 - loss: 2.6314 - val_accuracy: 0.5776 - val_loss: 1.9368 - learning_rate: 3.2467e-05
Epoch 137/300
785/785 - 87s - 111ms/step - accuracy: 0.4430 - loss: 2.6485 - val_accuracy: 0.5928 - val_loss: 1.9378 - learning_rate: 3.2467e-05
Epoch 138/300
785/785 - 88s - 112ms/step - accuracy: 0.4403 - loss: 2.6604 - val_accuracy: 0.5939 - val_loss: 1.9260 - learning_rate: 3.2467e-05
Epoch 139/300
785/785 - 87s - 111ms/step - accuracy: 0.4396 - loss: 2.6331 - val_accuracy: 0.5901 - val_loss: 1.9276 - learning_rate: 3.2467e-05
Epoch 140/300
785/785 - 88s - 112ms/step - accuracy: 0.4311 - loss: 2.6746 - val_accuracy: 0.5846 - val_loss: 1.9376 - learning_rate: 3.2467e-05
Epoch 141/300
785/785 - 89s - 113ms/step - accuracy: 0.4377 - loss: 2.6461 - val_accuracy: 0.5885 - val_loss: 1.9404 - learning_rate: 3.2467e-05
Epoch 142/300
785/785 - 86s - 110ms/step - accuracy: 0.4339 - loss: 2.6214 - val_accuracy: 0.5883 - val_loss: 1.9369 - learning_rate: 3.2467e-05
Epoch 143/300
785/785 - 86s - 110ms/step - accuracy: 0.4444 - loss: 2.6213 - val_accuracy: 0.5905 - val_loss: 1.9248 - learning_rate: 3.2467e-05
Epoch 144/300
785/785 - 86s - 109ms/step - accuracy: 0.4298 - loss: 2.6509 - val_accuracy: 0.5867 - val_loss: 1.9295 - learning_rate: 3.2467e-05
Epoch 145/300
785/785 - 89s - 114ms/step - accuracy: 0.4368 - loss: 2.6297 - val_accuracy: 0.5866 - val_loss: 1.9361 - learning_rate: 3.2467e-05
Epoch 146/300
785/785 - 88s - 112ms/step - accuracy: 0.4298 - loss: 2.6553 - val_accuracy: 0.5818 - val_loss: 1.9471 - learning_rate: 3.2467e-05
Epoch 147/300
785/785 - 88s - 113ms/step - accuracy: 0.4379 - loss: 2.6276 - val_accuracy: 0.5869 - val_loss: 1.9369 - learning_rate: 3.2467e-05
Epoch 148/300
785/785 - 89s - 113ms/step - accuracy: 0.4497 - loss: 2.6273 - val_accuracy: 0.5886 - val_loss: 1.9332 - learning_rate: 3.2467e-05
Epoch 149/300
785/785 - 88s - 112ms/step - accuracy: 0.4451 - loss: 2.6531 - val_accuracy: 0.5842 - val_loss: 1.9352 - learning_rate: 3.2467e-05
Epoch 150/300
785/785 - 148s - 188ms/step - accuracy: 0.4369 - loss: 2.6262 - val_accuracy: 0.5904 - val_loss: 1.9358 - learning_rate: 3.2467e-05
Epoch 151/300

Epoch 151: ReduceLROnPlateau reducing learning rate to 1.6233630958595313e-05.
785/785 - 88s - 112ms/step - accuracy: 0.4443 - loss: 2.6149 - val_accuracy: 0.5845 - val_loss: 1.9359 - learning_rate: 3.2467e-05
Epoch 152/300
785/785 - 88s - 113ms/step - accuracy: 0.4396 - loss: 2.6270 - val_accuracy: 0.5802 - val_loss: 1.9305 - learning_rate: 1.6234e-05
Epoch 153/300
785/785 - 89s - 113ms/step - accuracy: 0.4439 - loss: 2.6245 - val_accuracy: 0.5866 - val_loss: 1.9254 - learning_rate: 1.6234e-05
Epoch 154/300
785/785 - 88s - 112ms/step - accuracy: 0.4439 - loss: 2.5848 - val_accuracy: 0.5875 - val_loss: 1.9271 - learning_rate: 1.6234e-05
Epoch 155/300
785/785 - 89s - 114ms/step - accuracy: 0.4403 - loss: 2.6419 - val_accuracy: 0.5864 - val_loss: 1.9223 - learning_rate: 1.6234e-05
Epoch 156/300
785/785 - 88s - 112ms/step - accuracy: 0.4447 - loss: 2.6274 - val_accuracy: 0.5912 - val_loss: 1.9204 - learning_rate: 1.6234e-05
Epoch 157/300
785/785 - 89s - 113ms/step - accuracy: 0.4330 - loss: 2.6570 - val_accuracy: 0.5882 - val_loss: 1.9154 - learning_rate: 1.6234e-05
Epoch 158/300
785/785 - 89s - 113ms/step - accuracy: 0.4408 - loss: 2.6001 - val_accuracy: 0.5902 - val_loss: 1.9283 - learning_rate: 1.6234e-05
Epoch 159/300
785/785 - 88s - 112ms/step - accuracy: 0.4403 - loss: 2.6168 - val_accuracy: 0.5862 - val_loss: 1.9254 - learning_rate: 1.6234e-05
Epoch 160/300
785/785 - 88s - 113ms/step - accuracy: 0.4471 - loss: 2.5992 - val_accuracy: 0.5866 - val_loss: 1.9240 - learning_rate: 1.6234e-05
Epoch 161/300
785/785 - 89s - 113ms/step - accuracy: 0.4451 - loss: 2.5988 - val_accuracy: 0.5883 - val_loss: 1.9251 - learning_rate: 1.6234e-05
Epoch 162/300
785/785 - 87s - 111ms/step - accuracy: 0.4443 - loss: 2.6156 - val_accuracy: 0.5888 - val_loss: 1.9248 - learning_rate: 1.6234e-05
Epoch 163/300
785/785 - 87s - 111ms/step - accuracy: 0.4403 - loss: 2.6199 - val_accuracy: 0.5893 - val_loss: 1.9161 - learning_rate: 1.6234e-05
Epoch 164/300
785/785 - 88s - 112ms/step - accuracy: 0.4514 - loss: 2.5957 - val_accuracy: 0.5917 - val_loss: 1.9127 - learning_rate: 1.6234e-05
Epoch 165/300
785/785 - 88s - 112ms/step - accuracy: 0.4396 - loss: 2.6168 - val_accuracy: 0.5883 - val_loss: 1.9316 - learning_rate: 1.6234e-05
Epoch 166/300
785/785 - 88s - 112ms/step - accuracy: 0.4349 - loss: 2.6647 - val_accuracy: 0.5862 - val_loss: 1.9310 - learning_rate: 1.6234e-05
Epoch 167/300
785/785 - 143s - 182ms/step - accuracy: 0.4449 - loss: 2.6258 - val_accuracy: 0.5856 - val_loss: 1.9193 - learning_rate: 1.6234e-05
Epoch 168/300
785/785 - 89s - 113ms/step - accuracy: 0.4462 - loss: 2.6007 - val_accuracy: 0.5862 - val_loss: 1.9152 - learning_rate: 1.6234e-05
Epoch 169/300
785/785 - 89s - 113ms/step - accuracy: 0.4463 - loss: 2.6045 - val_accuracy: 0.5864 - val_loss: 1.9088 - learning_rate: 1.6234e-05
Epoch 170/300
785/785 - 87s - 111ms/step - accuracy: 0.4424 - loss: 2.6071 - val_accuracy: 0.5902 - val_loss: 1.9118 - learning_rate: 1.6234e-05
Epoch 171/300
785/785 - 87s - 111ms/step - accuracy: 0.4320 - loss: 2.6328 - val_accuracy: 0.5869 - val_loss: 1.9216 - learning_rate: 1.6234e-05
Epoch 172/300
785/785 - 87s - 110ms/step - accuracy: 0.4454 - loss: 2.6088 - val_accuracy: 0.5902 - val_loss: 1.9205 - learning_rate: 1.6234e-05
Epoch 173/300
785/785 - 86s - 110ms/step - accuracy: 0.4462 - loss: 2.5962 - val_accuracy: 0.5899 - val_loss: 1.9195 - learning_rate: 1.6234e-05
Epoch 174/300
785/785 - 88s - 113ms/step - accuracy: 0.4428 - loss: 2.6279 - val_accuracy: 0.5861 - val_loss: 1.9133 - learning_rate: 1.6234e-05
Epoch 175/300
785/785 - 89s - 113ms/step - accuracy: 0.4447 - loss: 2.6064 - val_accuracy: 0.5866 - val_loss: 1.9192 - learning_rate: 1.6234e-05
Epoch 176/300
785/785 - 88s - 112ms/step - accuracy: 0.4468 - loss: 2.5996 - val_accuracy: 0.5902 - val_loss: 1.9104 - learning_rate: 1.6234e-05
Epoch 177/300

Epoch 177: ReduceLROnPlateau reducing learning rate to 8.116815479297657e-06.
785/785 - 87s - 111ms/step - accuracy: 0.4382 - loss: 2.6049 - val_accuracy: 0.5910 - val_loss: 1.9141 - learning_rate: 1.6234e-05
Epoch 178/300
785/785 - 86s - 109ms/step - accuracy: 0.4433 - loss: 2.6058 - val_accuracy: 0.5910 - val_loss: 1.9134 - learning_rate: 8.1168e-06
Epoch 179/300
785/785 - 88s - 112ms/step - accuracy: 0.4436 - loss: 2.6030 - val_accuracy: 0.5932 - val_loss: 1.9176 - learning_rate: 8.1168e-06
Epoch 180/300
785/785 - 89s - 113ms/step - accuracy: 0.4355 - loss: 2.6452 - val_accuracy: 0.5926 - val_loss: 1.9119 - learning_rate: 8.1168e-06
Epoch 181/300
785/785 - 88s - 113ms/step - accuracy: 0.4350 - loss: 2.6482 - val_accuracy: 0.5910 - val_loss: 1.9144 - learning_rate: 8.1168e-06
Epoch 182/300
785/785 - 87s - 111ms/step - accuracy: 0.4565 - loss: 2.5847 - val_accuracy: 0.5907 - val_loss: 1.9066 - learning_rate: 8.1168e-06
Epoch 183/300
785/785 - 88s - 112ms/step - accuracy: 0.4409 - loss: 2.6218 - val_accuracy: 0.5905 - val_loss: 1.9145 - learning_rate: 8.1168e-06
Epoch 184/300
785/785 - 88s - 113ms/step - accuracy: 0.4489 - loss: 2.5924 - val_accuracy: 0.5926 - val_loss: 1.9195 - learning_rate: 8.1168e-06
Epoch 185/300
785/785 - 89s - 113ms/step - accuracy: 0.4503 - loss: 2.5975 - val_accuracy: 0.5909 - val_loss: 1.9163 - learning_rate: 8.1168e-06
Epoch 186/300
785/785 - 95s - 121ms/step - accuracy: 0.4454 - loss: 2.5993 - val_accuracy: 0.5923 - val_loss: 1.9265 - learning_rate: 8.1168e-06
Epoch 187/300
785/785 - 89s - 113ms/step - accuracy: 0.4393 - loss: 2.6470 - val_accuracy: 0.5909 - val_loss: 1.9181 - learning_rate: 8.1168e-06
Epoch 188/300
785/785 - 88s - 113ms/step - accuracy: 0.4385 - loss: 2.6426 - val_accuracy: 0.5921 - val_loss: 1.9242 - learning_rate: 8.1168e-06
Epoch 189/300
785/785 - 88s - 113ms/step - accuracy: 0.4475 - loss: 2.6072 - val_accuracy: 0.5934 - val_loss: 1.9137 - learning_rate: 8.1168e-06
Epoch 190/300

Epoch 190: ReduceLROnPlateau reducing learning rate to 4.058407739648828e-06.
785/785 - 89s - 114ms/step - accuracy: 0.4505 - loss: 2.5778 - val_accuracy: 0.5909 - val_loss: 1.9075 - learning_rate: 8.1168e-06
Epoch 191/300
785/785 - 89s - 113ms/step - accuracy: 0.4363 - loss: 2.6164 - val_accuracy: 0.5929 - val_loss: 1.9135 - learning_rate: 4.0584e-06
Epoch 192/300
785/785 - 140s - 179ms/step - accuracy: 0.4462 - loss: 2.6071 - val_accuracy: 0.5909 - val_loss: 1.9107 - learning_rate: 4.0584e-06
Epoch 193/300
785/785 - 88s - 112ms/step - accuracy: 0.4419 - loss: 2.5933 - val_accuracy: 0.5909 - val_loss: 1.9127 - learning_rate: 4.0584e-06
Epoch 194/300
785/785 - 89s - 113ms/step - accuracy: 0.4433 - loss: 2.5975 - val_accuracy: 0.5894 - val_loss: 1.9128 - learning_rate: 4.0584e-06
Epoch 195/300
785/785 - 94s - 120ms/step - accuracy: 0.4414 - loss: 2.6525 - val_accuracy: 0.5940 - val_loss: 1.9123 - learning_rate: 4.0584e-06
Epoch 196/300
785/785 - 90s - 114ms/step - accuracy: 0.4460 - loss: 2.6121 - val_accuracy: 0.5915 - val_loss: 1.9136 - learning_rate: 4.0584e-06
Epoch 197/300
785/785 - 94s - 119ms/step - accuracy: 0.4363 - loss: 2.6324 - val_accuracy: 0.5942 - val_loss: 1.9115 - learning_rate: 4.0584e-06
Epoch 198/300

Epoch 198: ReduceLROnPlateau reducing learning rate to 2.029203869824414e-06.
785/785 - 87s - 111ms/step - accuracy: 0.4412 - loss: 2.6273 - val_accuracy: 0.5912 - val_loss: 1.9101 - learning_rate: 4.0584e-06
Epoch 198: early stopping
Restoring model weights from the end of the best epoch: 182.
Fold 4_2 Evaluation results: [1.905617356300354, 0.5906991362571716]
              precision    recall  f1-score   support

        1820       0.73      0.73      0.73       305
        1821       0.92      0.82      0.86       297
        1822       0.00      0.00      0.00         5
        1823       0.00      0.00      0.00         8
        1824       0.00      0.00      0.00         8
        1825       0.00      0.00      0.00        11
        1826       0.14      0.08      0.11        12
        1827       0.72      0.71      0.71       121
        1828       0.00      0.00      0.00        14
        1829       0.64      0.35      0.45        20
        1830       0.54      0.61      0.58       290
        1831       0.74      0.93      0.82       639
        1832       0.71      0.76      0.73       324
        1833       0.70      0.91      0.79       104
        1834       0.45      0.72      0.56       151
        1835       0.00      0.00      0.00         7
        1836       0.00      0.00      0.00        20
        1837       0.38      0.38      0.38        32
        1838       0.00      0.00      0.00        18
        1839       0.00      0.00      0.00         4
        1840       0.50      0.52      0.51       228
        1841       0.71      0.56      0.63       545
        1842       0.83      0.34      0.49        29
        1843       0.00      0.00      0.00        31
        1844       0.00      0.00      0.00         3
        1845       0.00      0.00      0.00         7
        1846       1.00      0.09      0.16        35
        1847       0.00      0.00      0.00        14
        1848       0.38      0.21      0.27        24
        1849       0.50      0.24      0.32        25
        1850       0.30      0.63      0.41       219
        1851       0.72      0.72      0.72       375
        1852       0.33      0.06      0.10        35
        1853       0.00      0.00      0.00        29
        1854       0.00      0.00      0.00        13
        1855       0.61      0.19      0.28       108
        1856       0.82      0.67      0.74        61
        1857       0.36      0.61      0.45       140
        1858       0.00      0.00      0.00        10
        1859       0.00      0.00      0.00        17
        1860       0.33      0.31      0.32       339
        1861       0.76      0.82      0.79       409
        1862       0.25      0.15      0.19        98
        1863       0.34      0.41      0.37        95
        1864       0.26      0.12      0.17        88
        1865       0.38      0.11      0.17        28
        1866       0.00      0.00      0.00        33
        1867       0.42      0.14      0.21        57
        1868       0.00      0.00      0.00        37
        1869       0.00      0.00      0.00        29
        1870       0.33      0.68      0.44       149
        1871       0.71      0.73      0.72       260
        1872       0.20      0.03      0.05        36
        1873       0.00      0.00      0.00        65
        1874       0.00      0.00      0.00        27
        1875       0.35      0.60      0.44        70
        1876       0.81      0.88      0.85        50
        1877       0.19      0.24      0.21        21
        1878       0.45      0.37      0.41        41
        1879       0.00      0.00      0.00         9

    accuracy                           0.59      6279
   macro avg       0.33      0.29      0.29      6279
weighted avg       0.57      0.59      0.56      6279

Matthews Correlation Coefficient: 0.571
Macro avg F1: 0.285
Weighted avg F1: 0.564
Micro avg F1: 0.591
Top-3 Accuracy: 0.833
Top-5 Accuracy: 0.896
Micro ROC AUC  = 0.98
Macro ROC AUC (present classes) = 0.97
Classification MAE (in years): 3.33

Fold 4_2 Misclassification Analysis:
Near misses (within 2 years): 578 out of 2570 misclassifications (22.49%)
Big misses (greater than 10 years): 1038
MAE with outliers: 3.33
MAE without outliers: 2.35 (improvement: 0.97)

10 Worst misclassifications:
Image: data/datasets/public/1870/1879_26wikimedia2.jpg, True: 1879, Predicted: 1820, Error: 59
Image: data/datasets/private/1820/1823_031_Zrzut ekranu 2022-07-26 203811.png, True: 1823, Predicted: 1876, Error: 53
Image: data/datasets/public/1820/1820_12wikimedia2.jpg, True: 1820, Predicted: 1871, Error: 51
Image: data/datasets/private/1820/1820_031_Zrzut ekranu 2022-07-26 195637.png, True: 1820, Predicted: 1871, Error: 51
Image: data/datasets/private/1820/1820_037_Zrzut ekranu 2022-07-26 210308.png, True: 1820, Predicted: 1871, Error: 51
Image: data/datasets/private/1820/1821_580etsy.jpg, True: 1821, Predicted: 1871, Error: 50
Image: data/datasets/private/1820/1821_486etsy.jpg, True: 1821, Predicted: 1871, Error: 50
Image: data/datasets/private/1870/1871_358etsy.jpg, True: 1871, Predicted: 1821, Error: 50
Image: data/datasets/public/1820/1820_021met.jpg, True: 1820, Predicted: 1870, Error: 50
Image: data/datasets/private/1820/1820_034_Zrzut ekranu 2022-07-26 203655.png, True: 1820, Predicted: 1870, Error: 50

===== 5x2 Cross-Validation Results =====
Base model average accuracy: 0.5921
Alternative model average accuracy: 0.5949
Mean difference: 0.0040

Specialized 5x2cv t-test (Dietterich 1998):
t-statistic: 0.3613
p-value: 0.7327
Statistically significant difference: No (alpha=0.05)

Standard paired t-test:
t-statistic: -0.7132
p-value: 0.4938
Statistically significant difference: No (alpha=0.05)

=== Total running time: 93 hours, 49 minutes, 19 seconds ===

