TensorFlow Version: 2.20.0-dev20250508
Num GPUs Available: 1
Physical devices cannot be modified after being initialized

=== Using model: ConvNeXtTiny. ===
RUN ID: 2025-05-22_16:52:18
Task: Classification

===== Fold 0 =====

===== Fine Tuning 7 layers! =====
Epoch 1/300
1413/1413 - 299s - 212ms/step - accuracy: 0.1282 - loss: 4.5161 - val_accuracy: 0.1823 - val_loss: 4.0474 - learning_rate: 1.6200e-04
Epoch 2/300
1413/1413 - 226s - 160ms/step - accuracy: 0.1872 - loss: 4.0381 - val_accuracy: 0.2277 - val_loss: 4.3913 - learning_rate: 1.6200e-04
Epoch 3/300
1413/1413 - 222s - 157ms/step - accuracy: 0.2245 - loss: 3.8313 - val_accuracy: 0.3010 - val_loss: 3.2706 - learning_rate: 1.6200e-04
Epoch 4/300
1413/1413 - 224s - 159ms/step - accuracy: 0.2431 - loss: 3.6801 - val_accuracy: 0.2022 - val_loss: 4.4623 - learning_rate: 1.6200e-04
Epoch 5/300
1413/1413 - 225s - 159ms/step - accuracy: 0.2616 - loss: 3.5873 - val_accuracy: 0.3583 - val_loss: 3.0564 - learning_rate: 1.6200e-04
Epoch 6/300
1413/1413 - 226s - 160ms/step - accuracy: 0.2736 - loss: 3.5206 - val_accuracy: 0.3997 - val_loss: 3.0042 - learning_rate: 1.6200e-04
Epoch 7/300
1413/1413 - 227s - 160ms/step - accuracy: 0.2799 - loss: 3.4774 - val_accuracy: 0.2731 - val_loss: 3.8012 - learning_rate: 1.6200e-04
Epoch 8/300
1413/1413 - 224s - 159ms/step - accuracy: 0.2842 - loss: 3.4466 - val_accuracy: 0.3416 - val_loss: 2.8085 - learning_rate: 1.6200e-04
Epoch 9/300
1413/1413 - 225s - 159ms/step - accuracy: 0.2889 - loss: 3.4111 - val_accuracy: 0.3169 - val_loss: 3.0921 - learning_rate: 1.6200e-04
Epoch 10/300
1413/1413 - 226s - 160ms/step - accuracy: 0.2974 - loss: 3.3509 - val_accuracy: 0.3336 - val_loss: 3.4327 - learning_rate: 1.6200e-04
Epoch 11/300
1413/1413 - 231s - 163ms/step - accuracy: 0.2980 - loss: 3.3632 - val_accuracy: 0.4053 - val_loss: 2.9217 - learning_rate: 1.6200e-04
Epoch 12/300
1413/1413 - 227s - 160ms/step - accuracy: 0.3073 - loss: 3.3141 - val_accuracy: 0.4084 - val_loss: 2.9144 - learning_rate: 1.6200e-04
Epoch 13/300
1413/1413 - 224s - 159ms/step - accuracy: 0.3079 - loss: 3.3044 - val_accuracy: 0.2962 - val_loss: 3.5214 - learning_rate: 1.6200e-04
Epoch 14/300
1413/1413 - 225s - 159ms/step - accuracy: 0.3158 - loss: 3.2545 - val_accuracy: 0.3527 - val_loss: 3.0403 - learning_rate: 1.6200e-04
Epoch 15/300
1413/1413 - 237s - 168ms/step - accuracy: 0.3239 - loss: 3.2415 - val_accuracy: 0.4658 - val_loss: 2.5105 - learning_rate: 1.6200e-04
Epoch 16/300
1413/1413 - 237s - 168ms/step - accuracy: 0.3194 - loss: 3.2161 - val_accuracy: 0.4538 - val_loss: 2.5166 - learning_rate: 1.6200e-04
Epoch 17/300
1413/1413 - 234s - 166ms/step - accuracy: 0.3312 - loss: 3.1636 - val_accuracy: 0.3583 - val_loss: 2.9105 - learning_rate: 1.6200e-04
Epoch 18/300
1413/1413 - 236s - 167ms/step - accuracy: 0.3309 - loss: 3.1851 - val_accuracy: 0.4188 - val_loss: 3.0105 - learning_rate: 1.6200e-04
Epoch 19/300
1413/1413 - 235s - 166ms/step - accuracy: 0.3420 - loss: 3.1365 - val_accuracy: 0.4196 - val_loss: 2.9089 - learning_rate: 1.6200e-04
Epoch 20/300
1413/1413 - 235s - 167ms/step - accuracy: 0.3367 - loss: 3.1456 - val_accuracy: 0.3973 - val_loss: 3.0492 - learning_rate: 1.6200e-04
Epoch 21/300
1413/1413 - 237s - 168ms/step - accuracy: 0.3410 - loss: 3.1258 - val_accuracy: 0.3933 - val_loss: 2.8210 - learning_rate: 1.6200e-04
Epoch 22/300
1413/1413 - 234s - 165ms/step - accuracy: 0.3434 - loss: 3.1250 - val_accuracy: 0.4252 - val_loss: 2.7958 - learning_rate: 1.6200e-04
Epoch 23/300
1413/1413 - 235s - 166ms/step - accuracy: 0.3430 - loss: 3.1219 - val_accuracy: 0.4952 - val_loss: 2.4455 - learning_rate: 1.6200e-04
Epoch 24/300
1413/1413 - 233s - 165ms/step - accuracy: 0.3490 - loss: 3.0951 - val_accuracy: 0.4618 - val_loss: 2.5263 - learning_rate: 1.6200e-04
Epoch 25/300
1413/1413 - 229s - 162ms/step - accuracy: 0.3439 - loss: 3.0820 - val_accuracy: 0.4323 - val_loss: 2.9965 - learning_rate: 1.6200e-04
Epoch 26/300
1413/1413 - 232s - 164ms/step - accuracy: 0.3419 - loss: 3.0928 - val_accuracy: 0.4889 - val_loss: 2.3390 - learning_rate: 1.6200e-04
Epoch 27/300
1413/1413 - 221s - 156ms/step - accuracy: 0.3521 - loss: 3.0660 - val_accuracy: 0.4904 - val_loss: 2.6799 - learning_rate: 1.6200e-04
Epoch 28/300
1413/1413 - 219s - 155ms/step - accuracy: 0.3563 - loss: 3.0436 - val_accuracy: 0.4896 - val_loss: 2.4158 - learning_rate: 1.6200e-04
Epoch 29/300
1413/1413 - 217s - 154ms/step - accuracy: 0.3553 - loss: 3.0469 - val_accuracy: 0.4379 - val_loss: 2.6868 - learning_rate: 1.6200e-04
Epoch 30/300
1413/1413 - 223s - 158ms/step - accuracy: 0.3550 - loss: 3.0206 - val_accuracy: 0.5318 - val_loss: 2.3489 - learning_rate: 1.6200e-04
Epoch 31/300
1413/1413 - 225s - 159ms/step - accuracy: 0.3671 - loss: 2.9997 - val_accuracy: 0.5255 - val_loss: 2.2072 - learning_rate: 1.6200e-04
Epoch 32/300
1413/1413 - 218s - 154ms/step - accuracy: 0.3672 - loss: 3.0026 - val_accuracy: 0.4984 - val_loss: 2.6002 - learning_rate: 1.6200e-04
Epoch 33/300
1413/1413 - 219s - 155ms/step - accuracy: 0.3674 - loss: 2.9858 - val_accuracy: 0.4705 - val_loss: 2.5089 - learning_rate: 1.6200e-04
Epoch 34/300
1413/1413 - 223s - 158ms/step - accuracy: 0.3657 - loss: 3.0076 - val_accuracy: 0.5366 - val_loss: 2.1178 - learning_rate: 1.6200e-04
Epoch 35/300
1413/1413 - 219s - 155ms/step - accuracy: 0.3665 - loss: 2.9887 - val_accuracy: 0.4912 - val_loss: 2.3491 - learning_rate: 1.6200e-04
Epoch 36/300
1413/1413 - 225s - 159ms/step - accuracy: 0.3735 - loss: 2.9891 - val_accuracy: 0.4976 - val_loss: 2.4757 - learning_rate: 1.6200e-04
Epoch 37/300
1413/1413 - 267s - 189ms/step - accuracy: 0.3727 - loss: 2.9680 - val_accuracy: 0.5318 - val_loss: 2.4458 - learning_rate: 1.6200e-04
Epoch 38/300
1413/1413 - 222s - 157ms/step - accuracy: 0.3693 - loss: 2.9965 - val_accuracy: 0.5318 - val_loss: 2.4988 - learning_rate: 1.6200e-04
Epoch 39/300
1413/1413 - 220s - 156ms/step - accuracy: 0.3680 - loss: 2.9861 - val_accuracy: 0.5382 - val_loss: 2.4931 - learning_rate: 1.6200e-04
Epoch 40/300
1413/1413 - 223s - 158ms/step - accuracy: 0.3750 - loss: 2.9637 - val_accuracy: 0.4642 - val_loss: 3.1268 - learning_rate: 1.6200e-04
Epoch 41/300
1413/1413 - 219s - 155ms/step - accuracy: 0.3724 - loss: 2.9733 - val_accuracy: 0.4005 - val_loss: 3.1628 - learning_rate: 1.6200e-04
Epoch 42/300

Epoch 42: ReduceLROnPlateau reducing learning rate to 8.099817205220461e-05.
1413/1413 - 223s - 158ms/step - accuracy: 0.3744 - loss: 2.9433 - val_accuracy: 0.5175 - val_loss: 2.2149 - learning_rate: 1.6200e-04
Epoch 43/300
1413/1413 - 225s - 159ms/step - accuracy: 0.3889 - loss: 2.8617 - val_accuracy: 0.5613 - val_loss: 2.0938 - learning_rate: 8.0998e-05
Epoch 44/300
1413/1413 - 222s - 157ms/step - accuracy: 0.3914 - loss: 2.8717 - val_accuracy: 0.5549 - val_loss: 2.2265 - learning_rate: 8.0998e-05
Epoch 45/300
1413/1413 - 219s - 155ms/step - accuracy: 0.3902 - loss: 2.8642 - val_accuracy: 0.5303 - val_loss: 2.2895 - learning_rate: 8.0998e-05
Epoch 46/300
1413/1413 - 231s - 163ms/step - accuracy: 0.3996 - loss: 2.8417 - val_accuracy: 0.5653 - val_loss: 2.1098 - learning_rate: 8.0998e-05
Epoch 47/300
1413/1413 - 231s - 164ms/step - accuracy: 0.3982 - loss: 2.8634 - val_accuracy: 0.5589 - val_loss: 2.1880 - learning_rate: 8.0998e-05
Epoch 48/300
1413/1413 - 232s - 164ms/step - accuracy: 0.3875 - loss: 2.8477 - val_accuracy: 0.5350 - val_loss: 2.1860 - learning_rate: 8.0998e-05
Epoch 49/300
1413/1413 - 227s - 161ms/step - accuracy: 0.3961 - loss: 2.8463 - val_accuracy: 0.5605 - val_loss: 1.9436 - learning_rate: 8.0998e-05
Epoch 50/300
1413/1413 - 233s - 165ms/step - accuracy: 0.3928 - loss: 2.8476 - val_accuracy: 0.5541 - val_loss: 1.9722 - learning_rate: 8.0998e-05
Epoch 51/300
1413/1413 - 234s - 166ms/step - accuracy: 0.3990 - loss: 2.8463 - val_accuracy: 0.5167 - val_loss: 2.4577 - learning_rate: 8.0998e-05
Epoch 52/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4019 - loss: 2.8165 - val_accuracy: 0.5072 - val_loss: 2.4353 - learning_rate: 8.0998e-05
Epoch 53/300
1413/1413 - 224s - 159ms/step - accuracy: 0.3928 - loss: 2.8564 - val_accuracy: 0.6027 - val_loss: 1.9061 - learning_rate: 8.0998e-05
Epoch 54/300
1413/1413 - 220s - 156ms/step - accuracy: 0.3967 - loss: 2.8332 - val_accuracy: 0.5581 - val_loss: 1.9639 - learning_rate: 8.0998e-05
Epoch 55/300
1413/1413 - 226s - 160ms/step - accuracy: 0.3963 - loss: 2.8419 - val_accuracy: 0.5231 - val_loss: 2.1533 - learning_rate: 8.0998e-05
Epoch 56/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4023 - loss: 2.8196 - val_accuracy: 0.5780 - val_loss: 2.1419 - learning_rate: 8.0998e-05
Epoch 57/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4010 - loss: 2.8217 - val_accuracy: 0.5326 - val_loss: 2.3027 - learning_rate: 8.0998e-05
Epoch 58/300
1413/1413 - 217s - 153ms/step - accuracy: 0.4030 - loss: 2.8239 - val_accuracy: 0.5908 - val_loss: 1.9158 - learning_rate: 8.0998e-05
Epoch 59/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4015 - loss: 2.8386 - val_accuracy: 0.5613 - val_loss: 1.9285 - learning_rate: 8.0998e-05
Epoch 60/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4011 - loss: 2.8160 - val_accuracy: 0.5390 - val_loss: 2.0052 - learning_rate: 8.0998e-05
Epoch 61/300

Epoch 61: ReduceLROnPlateau reducing learning rate to 4.0499086026102304e-05.
1413/1413 - 221s - 156ms/step - accuracy: 0.4066 - loss: 2.8210 - val_accuracy: 0.5279 - val_loss: 2.4325 - learning_rate: 8.0998e-05
Epoch 62/300
1413/1413 - 219s - 155ms/step - accuracy: 0.4113 - loss: 2.7562 - val_accuracy: 0.6210 - val_loss: 1.7713 - learning_rate: 4.0499e-05
Epoch 63/300
1413/1413 - 221s - 156ms/step - accuracy: 0.4210 - loss: 2.7432 - val_accuracy: 0.6115 - val_loss: 1.7919 - learning_rate: 4.0499e-05
Epoch 64/300
1413/1413 - 221s - 156ms/step - accuracy: 0.4141 - loss: 2.7605 - val_accuracy: 0.6035 - val_loss: 1.9169 - learning_rate: 4.0499e-05
Epoch 65/300
1413/1413 - 224s - 159ms/step - accuracy: 0.4102 - loss: 2.7582 - val_accuracy: 0.6154 - val_loss: 1.8290 - learning_rate: 4.0499e-05
Epoch 66/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4125 - loss: 2.7536 - val_accuracy: 0.6441 - val_loss: 1.7448 - learning_rate: 4.0499e-05
Epoch 67/300
1413/1413 - 221s - 156ms/step - accuracy: 0.4162 - loss: 2.7533 - val_accuracy: 0.6266 - val_loss: 1.9352 - learning_rate: 4.0499e-05
Epoch 68/300
1413/1413 - 228s - 162ms/step - accuracy: 0.4133 - loss: 2.7529 - val_accuracy: 0.5884 - val_loss: 1.9350 - learning_rate: 4.0499e-05
Epoch 69/300
1413/1413 - 228s - 161ms/step - accuracy: 0.4215 - loss: 2.7337 - val_accuracy: 0.6051 - val_loss: 1.8455 - learning_rate: 4.0499e-05
Epoch 70/300
1413/1413 - 232s - 164ms/step - accuracy: 0.4219 - loss: 2.7160 - val_accuracy: 0.6162 - val_loss: 1.7975 - learning_rate: 4.0499e-05
Epoch 71/300
1413/1413 - 232s - 164ms/step - accuracy: 0.4198 - loss: 2.7324 - val_accuracy: 0.6011 - val_loss: 2.0625 - learning_rate: 4.0499e-05
Epoch 72/300
1413/1413 - 233s - 165ms/step - accuracy: 0.4191 - loss: 2.7599 - val_accuracy: 0.6186 - val_loss: 1.7901 - learning_rate: 4.0499e-05
Epoch 73/300
1413/1413 - 232s - 164ms/step - accuracy: 0.4231 - loss: 2.7174 - val_accuracy: 0.6226 - val_loss: 1.8151 - learning_rate: 4.0499e-05
Epoch 74/300

Epoch 74: ReduceLROnPlateau reducing learning rate to 2.0249543013051152e-05.
1413/1413 - 227s - 161ms/step - accuracy: 0.4244 - loss: 2.7220 - val_accuracy: 0.5812 - val_loss: 2.1567 - learning_rate: 4.0499e-05
Epoch 75/300
1413/1413 - 220s - 156ms/step - accuracy: 0.4233 - loss: 2.7055 - val_accuracy: 0.6417 - val_loss: 1.6960 - learning_rate: 2.0250e-05
Epoch 76/300
1413/1413 - 221s - 156ms/step - accuracy: 0.4322 - loss: 2.6766 - val_accuracy: 0.6377 - val_loss: 1.7498 - learning_rate: 2.0250e-05
Epoch 77/300
1413/1413 - 220s - 156ms/step - accuracy: 0.4277 - loss: 2.6705 - val_accuracy: 0.6401 - val_loss: 1.7353 - learning_rate: 2.0250e-05
Epoch 78/300
1413/1413 - 221s - 156ms/step - accuracy: 0.4278 - loss: 2.6851 - val_accuracy: 0.6417 - val_loss: 1.7607 - learning_rate: 2.0250e-05
Epoch 79/300
1413/1413 - 220s - 155ms/step - accuracy: 0.4306 - loss: 2.6794 - val_accuracy: 0.6346 - val_loss: 1.7292 - learning_rate: 2.0250e-05
Epoch 80/300
1413/1413 - 224s - 158ms/step - accuracy: 0.4263 - loss: 2.6949 - val_accuracy: 0.6465 - val_loss: 1.6947 - learning_rate: 2.0250e-05
Epoch 81/300
1413/1413 - 217s - 154ms/step - accuracy: 0.4306 - loss: 2.6717 - val_accuracy: 0.6481 - val_loss: 1.6750 - learning_rate: 2.0250e-05
Epoch 82/300
1413/1413 - 220s - 156ms/step - accuracy: 0.4332 - loss: 2.6790 - val_accuracy: 0.6194 - val_loss: 1.7527 - learning_rate: 2.0250e-05
Epoch 83/300
1413/1413 - 221s - 157ms/step - accuracy: 0.4281 - loss: 2.6613 - val_accuracy: 0.5955 - val_loss: 1.9466 - learning_rate: 2.0250e-05
Epoch 84/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4293 - loss: 2.6573 - val_accuracy: 0.6545 - val_loss: 1.6722 - learning_rate: 2.0250e-05
Epoch 85/300
1413/1413 - 219s - 155ms/step - accuracy: 0.4325 - loss: 2.6919 - val_accuracy: 0.6361 - val_loss: 1.7236 - learning_rate: 2.0250e-05
Epoch 86/300
1413/1413 - 221s - 157ms/step - accuracy: 0.4323 - loss: 2.6643 - val_accuracy: 0.6393 - val_loss: 1.7412 - learning_rate: 2.0250e-05
Epoch 87/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4322 - loss: 2.6526 - val_accuracy: 0.6465 - val_loss: 1.6833 - learning_rate: 2.0250e-05
Epoch 88/300
1413/1413 - 227s - 160ms/step - accuracy: 0.4284 - loss: 2.6922 - val_accuracy: 0.6361 - val_loss: 1.8269 - learning_rate: 2.0250e-05
Epoch 89/300
1413/1413 - 216s - 153ms/step - accuracy: 0.4280 - loss: 2.6687 - val_accuracy: 0.6553 - val_loss: 1.6887 - learning_rate: 2.0250e-05
Epoch 90/300
1413/1413 - 219s - 155ms/step - accuracy: 0.4262 - loss: 2.6647 - val_accuracy: 0.6298 - val_loss: 1.6864 - learning_rate: 2.0250e-05
Epoch 91/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4302 - loss: 2.6795 - val_accuracy: 0.6449 - val_loss: 1.7243 - learning_rate: 2.0250e-05
Epoch 92/300

Epoch 92: ReduceLROnPlateau reducing learning rate to 1.0124771506525576e-05.
1413/1413 - 220s - 156ms/step - accuracy: 0.4280 - loss: 2.6582 - val_accuracy: 0.6409 - val_loss: 1.7247 - learning_rate: 2.0250e-05
Epoch 93/300
1413/1413 - 218s - 154ms/step - accuracy: 0.4324 - loss: 2.6471 - val_accuracy: 0.6457 - val_loss: 1.6512 - learning_rate: 1.0125e-05
Epoch 94/300
1413/1413 - 224s - 159ms/step - accuracy: 0.4358 - loss: 2.6384 - val_accuracy: 0.6481 - val_loss: 1.6707 - learning_rate: 1.0125e-05
Epoch 95/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4380 - loss: 2.6407 - val_accuracy: 0.6553 - val_loss: 1.6754 - learning_rate: 1.0125e-05
Epoch 96/300
1413/1413 - 220s - 156ms/step - accuracy: 0.4331 - loss: 2.6594 - val_accuracy: 0.6425 - val_loss: 1.7221 - learning_rate: 1.0125e-05
Epoch 97/300
1413/1413 - 221s - 156ms/step - accuracy: 0.4291 - loss: 2.6348 - val_accuracy: 0.6497 - val_loss: 1.6399 - learning_rate: 1.0125e-05
Epoch 98/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4403 - loss: 2.6065 - val_accuracy: 0.6473 - val_loss: 1.6588 - learning_rate: 1.0125e-05
Epoch 99/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4368 - loss: 2.6213 - val_accuracy: 0.6465 - val_loss: 1.6776 - learning_rate: 1.0125e-05
Epoch 100/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4340 - loss: 2.6433 - val_accuracy: 0.6385 - val_loss: 1.7249 - learning_rate: 1.0125e-05
Epoch 101/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4287 - loss: 2.6384 - val_accuracy: 0.6465 - val_loss: 1.7108 - learning_rate: 1.0125e-05
Epoch 102/300
1413/1413 - 221s - 156ms/step - accuracy: 0.4404 - loss: 2.6312 - val_accuracy: 0.6425 - val_loss: 1.6427 - learning_rate: 1.0125e-05
Epoch 103/300
1413/1413 - 220s - 156ms/step - accuracy: 0.4371 - loss: 2.6434 - val_accuracy: 0.6616 - val_loss: 1.6281 - learning_rate: 1.0125e-05
Epoch 104/300
1413/1413 - 219s - 155ms/step - accuracy: 0.4337 - loss: 2.6126 - val_accuracy: 0.6513 - val_loss: 1.6537 - learning_rate: 1.0125e-05
Epoch 105/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4426 - loss: 2.6147 - val_accuracy: 0.6529 - val_loss: 1.6500 - learning_rate: 1.0125e-05
Epoch 106/300
1413/1413 - 220s - 156ms/step - accuracy: 0.4370 - loss: 2.6295 - val_accuracy: 0.6441 - val_loss: 1.6626 - learning_rate: 1.0125e-05
Epoch 107/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4386 - loss: 2.6458 - val_accuracy: 0.6354 - val_loss: 1.7945 - learning_rate: 1.0125e-05
Epoch 108/300
1413/1413 - 221s - 157ms/step - accuracy: 0.4365 - loss: 2.6151 - val_accuracy: 0.6433 - val_loss: 1.7192 - learning_rate: 1.0125e-05
Epoch 109/300
1413/1413 - 219s - 155ms/step - accuracy: 0.4409 - loss: 2.6165 - val_accuracy: 0.6632 - val_loss: 1.6559 - learning_rate: 1.0125e-05
Epoch 110/300
1413/1413 - 221s - 157ms/step - accuracy: 0.4440 - loss: 2.6054 - val_accuracy: 0.6497 - val_loss: 1.6356 - learning_rate: 1.0125e-05
Epoch 111/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4417 - loss: 2.6418 - val_accuracy: 0.6664 - val_loss: 1.6054 - learning_rate: 1.0125e-05
Epoch 112/300
1413/1413 - 218s - 154ms/step - accuracy: 0.4367 - loss: 2.6345 - val_accuracy: 0.6529 - val_loss: 1.6434 - learning_rate: 1.0125e-05
Epoch 113/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4406 - loss: 2.6407 - val_accuracy: 0.6696 - val_loss: 1.6134 - learning_rate: 1.0125e-05
Epoch 114/300
1413/1413 - 220s - 156ms/step - accuracy: 0.4490 - loss: 2.6239 - val_accuracy: 0.6648 - val_loss: 1.6435 - learning_rate: 1.0125e-05
Epoch 115/300
1413/1413 - 220s - 156ms/step - accuracy: 0.4440 - loss: 2.6289 - val_accuracy: 0.6513 - val_loss: 1.6527 - learning_rate: 1.0125e-05
Epoch 116/300
1413/1413 - 221s - 156ms/step - accuracy: 0.4435 - loss: 2.5964 - val_accuracy: 0.6553 - val_loss: 1.6204 - learning_rate: 1.0125e-05
Epoch 117/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4459 - loss: 2.6141 - val_accuracy: 0.6616 - val_loss: 1.6280 - learning_rate: 1.0125e-05
Epoch 118/300
1413/1413 - 218s - 154ms/step - accuracy: 0.4371 - loss: 2.6236 - val_accuracy: 0.6441 - val_loss: 1.7236 - learning_rate: 1.0125e-05
Epoch 119/300
1413/1413 - 221s - 157ms/step - accuracy: 0.4409 - loss: 2.6304 - val_accuracy: 0.6632 - val_loss: 1.5892 - learning_rate: 1.0125e-05
Epoch 120/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4486 - loss: 2.5976 - val_accuracy: 0.6664 - val_loss: 1.6325 - learning_rate: 1.0125e-05
Epoch 121/300
1413/1413 - 218s - 154ms/step - accuracy: 0.4483 - loss: 2.5886 - val_accuracy: 0.6457 - val_loss: 1.6419 - learning_rate: 1.0125e-05
Epoch 122/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4417 - loss: 2.6138 - val_accuracy: 0.6545 - val_loss: 1.6420 - learning_rate: 1.0125e-05
Epoch 123/300
1413/1413 - 220s - 156ms/step - accuracy: 0.4386 - loss: 2.6055 - val_accuracy: 0.6473 - val_loss: 1.6653 - learning_rate: 1.0125e-05
Epoch 124/300
1413/1413 - 224s - 158ms/step - accuracy: 0.4381 - loss: 2.6114 - val_accuracy: 0.6489 - val_loss: 1.6639 - learning_rate: 1.0125e-05
Epoch 125/300
1413/1413 - 219s - 155ms/step - accuracy: 0.4461 - loss: 2.6014 - val_accuracy: 0.6608 - val_loss: 1.6287 - learning_rate: 1.0125e-05
Epoch 126/300
1413/1413 - 219s - 155ms/step - accuracy: 0.4459 - loss: 2.6190 - val_accuracy: 0.6537 - val_loss: 1.6381 - learning_rate: 1.0125e-05
Epoch 127/300

Epoch 127: ReduceLROnPlateau reducing learning rate to 5.062385753262788e-06.
1413/1413 - 218s - 154ms/step - accuracy: 0.4440 - loss: 2.5948 - val_accuracy: 0.6616 - val_loss: 1.6282 - learning_rate: 1.0125e-05
Epoch 128/300
1413/1413 - 219s - 155ms/step - accuracy: 0.4441 - loss: 2.6380 - val_accuracy: 0.6672 - val_loss: 1.6130 - learning_rate: 5.0624e-06
Epoch 129/300
1413/1413 - 215s - 152ms/step - accuracy: 0.4458 - loss: 2.5935 - val_accuracy: 0.6576 - val_loss: 1.6283 - learning_rate: 5.0624e-06
Epoch 130/300
1413/1413 - 223s - 157ms/step - accuracy: 0.4446 - loss: 2.6074 - val_accuracy: 0.6568 - val_loss: 1.6294 - learning_rate: 5.0624e-06
Epoch 131/300
1413/1413 - 220s - 156ms/step - accuracy: 0.4459 - loss: 2.6016 - val_accuracy: 0.6561 - val_loss: 1.5803 - learning_rate: 5.0624e-06
Epoch 132/300
1413/1413 - 220s - 156ms/step - accuracy: 0.4431 - loss: 2.6057 - val_accuracy: 0.6624 - val_loss: 1.6195 - learning_rate: 5.0624e-06
Epoch 133/300
1413/1413 - 219s - 155ms/step - accuracy: 0.4441 - loss: 2.6179 - val_accuracy: 0.6473 - val_loss: 1.6797 - learning_rate: 5.0624e-06
Epoch 134/300
1413/1413 - 219s - 155ms/step - accuracy: 0.4475 - loss: 2.5930 - val_accuracy: 0.6545 - val_loss: 1.6078 - learning_rate: 5.0624e-06
Epoch 135/300
1413/1413 - 219s - 155ms/step - accuracy: 0.4453 - loss: 2.5920 - val_accuracy: 0.6369 - val_loss: 1.6674 - learning_rate: 5.0624e-06
Epoch 136/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4377 - loss: 2.6022 - val_accuracy: 0.6521 - val_loss: 1.6030 - learning_rate: 5.0624e-06
Epoch 137/300
1413/1413 - 220s - 156ms/step - accuracy: 0.4394 - loss: 2.6221 - val_accuracy: 0.6568 - val_loss: 1.6089 - learning_rate: 5.0624e-06
Epoch 138/300
1413/1413 - 218s - 154ms/step - accuracy: 0.4447 - loss: 2.5905 - val_accuracy: 0.6568 - val_loss: 1.6252 - learning_rate: 5.0624e-06
Epoch 139/300

Epoch 139: ReduceLROnPlateau reducing learning rate to 2.531192876631394e-06.
1413/1413 - 221s - 156ms/step - accuracy: 0.4419 - loss: 2.5857 - val_accuracy: 0.6481 - val_loss: 1.6441 - learning_rate: 5.0624e-06
Epoch 140/300
1413/1413 - 221s - 156ms/step - accuracy: 0.4463 - loss: 2.5774 - val_accuracy: 0.6576 - val_loss: 1.6138 - learning_rate: 2.5312e-06
Epoch 141/300
1413/1413 - 217s - 154ms/step - accuracy: 0.4490 - loss: 2.5793 - val_accuracy: 0.6521 - val_loss: 1.6446 - learning_rate: 2.5312e-06
Epoch 142/300
1413/1413 - 219s - 155ms/step - accuracy: 0.4471 - loss: 2.5961 - val_accuracy: 0.6545 - val_loss: 1.6355 - learning_rate: 2.5312e-06
Epoch 143/300
1413/1413 - 220s - 156ms/step - accuracy: 0.4371 - loss: 2.6127 - val_accuracy: 0.6497 - val_loss: 1.6111 - learning_rate: 2.5312e-06
Epoch 144/300
1413/1413 - 225s - 160ms/step - accuracy: 0.4468 - loss: 2.6029 - val_accuracy: 0.6584 - val_loss: 1.6227 - learning_rate: 2.5312e-06
Epoch 145/300
1413/1413 - 219s - 155ms/step - accuracy: 0.4416 - loss: 2.6081 - val_accuracy: 0.6561 - val_loss: 1.6062 - learning_rate: 2.5312e-06
Epoch 146/300
1413/1413 - 221s - 156ms/step - accuracy: 0.4436 - loss: 2.6082 - val_accuracy: 0.6553 - val_loss: 1.6230 - learning_rate: 2.5312e-06
Epoch 147/300

Epoch 147: ReduceLROnPlateau reducing learning rate to 1.265596438315697e-06.
1413/1413 - 218s - 154ms/step - accuracy: 0.4493 - loss: 2.5659 - val_accuracy: 0.6545 - val_loss: 1.6126 - learning_rate: 2.5312e-06
Epoch 147: early stopping
Restoring model weights from the end of the best epoch: 131.
Fold 0 Evaluation results: [1.5819470882415771, 0.656050980091095]
              precision    recall  f1-score   support

        1820       0.83      0.81      0.82        62
        1821       0.89      0.89      0.89        57
        1822       0.00      0.00      0.00         1
        1823       0.50      1.00      0.67         1
        1824       0.00      0.00      0.00         1
        1825       0.00      0.00      0.00         3
        1826       0.00      0.00      0.00         2
        1827       0.85      0.92      0.88        25
        1828       0.00      0.00      0.00         1
        1829       0.67      0.80      0.73         5
        1830       0.81      0.54      0.65        56
        1831       0.88      0.90      0.89       134
        1832       0.63      0.84      0.72        67
        1833       0.94      0.89      0.92        19
        1834       0.54      0.72      0.62        29
        1835       0.00      0.00      0.00         2
        1836       0.25      0.25      0.25         4
        1837       0.38      0.83      0.53         6
        1838       1.00      0.33      0.50         3
        1839       0.00      0.00      0.00         1
        1840       0.67      0.72      0.70        43
        1841       0.80      0.69      0.74       108
        1842       0.62      0.83      0.71         6
        1843       0.50      0.17      0.25         6
        1844       0.00      0.00      0.00         1
        1845       0.00      0.00      0.00         1
        1846       0.33      0.50      0.40         6
        1847       0.50      0.50      0.50         2
        1848       0.00      0.00      0.00         5
        1849       0.21      0.50      0.30         6
        1850       0.49      0.56      0.52        48
        1851       0.74      0.81      0.77        77
        1852       0.00      0.00      0.00         7
        1853       0.00      0.00      0.00         7
        1854       0.00      0.00      0.00         3
        1855       0.48      0.43      0.45        23
        1856       0.64      0.58      0.61        12
        1857       0.43      0.67      0.52        30
        1858       0.00      0.00      0.00         2
        1859       0.00      0.00      0.00         2
        1860       0.31      0.35      0.33        65
        1861       0.80      0.78      0.79        85
        1862       0.30      0.32      0.31        19
        1863       0.67      0.53      0.59        19
        1864       0.64      0.53      0.58        17
        1865       0.33      0.57      0.42         7
        1866       0.17      0.20      0.18         5
        1867       0.33      0.45      0.38        11
        1868       0.00      0.00      0.00         7
        1869       0.00      0.00      0.00         5
        1870       0.46      0.39      0.42        31
        1871       0.74      0.76      0.75        49
        1872       0.75      0.43      0.55         7
        1873       0.00      0.00      0.00        10
        1874       0.00      0.00      0.00         5
        1875       0.55      0.43      0.48        14
        1876       0.57      0.80      0.67        10
        1877       0.44      0.80      0.57         5
        1878       0.50      0.44      0.47         9
        1879       0.00      0.00      0.00         2

    accuracy                           0.66      1256
   macro avg       0.39      0.41      0.38      1256
weighted avg       0.65      0.66      0.64      1256

Matthews Correlation Coefficient: 0.639
Macro avg F1: 0.384
Weighted avg F1: 0.644
Micro avg F1: 0.656
Top-3 Accuracy: 0.858
Top-5 Accuracy: 0.907
Micro ROC AUC  = 0.99
Macro ROC AUC (present classes) = 0.98
Classification MAE (in years): 2.90

Fold 0 Misclassification Analysis:
Near misses (within 2 years): 129 out of 432 misclassifications (29.86%)
Big misses (greater than 10 years): 187
MAE with outliers: 2.90
MAE without outliers: 1.91 (improvement: 0.98)

10 Worst misclassifications:
Image: data/datasets/public/1820/1820_036met.jpg, True: 1820, Predicted: 1873, Error: 53
Image: data/datasets/public/1820/1826_44washington.jpg, True: 1826, Predicted: 1876, Error: 50
Image: data/datasets/public/1870/1878_030met.jpg, True: 1878, Predicted: 1832, Error: 46
Image: data/datasets/public/1870/1876_455vna.jpg, True: 1876, Predicted: 1832, Error: 44
Image: data/datasets/public/1870/1872_1405vna.jpg, True: 1872, Predicted: 1830, Error: 42
Image: data/datasets/public/1870/1873_014met.jpg, True: 1873, Predicted: 1832, Error: 41
Image: data/datasets/public/1820/1820_026met.jpg, True: 1820, Predicted: 1861, Error: 41
Image: data/datasets/private/1860/1860_123et.jpg, True: 1860, Predicted: 1820, Error: 40
Image: data/datasets/public/1820/1825_819vna.jpg, True: 1825, Predicted: 1865, Error: 40
Image: data/datasets/public/1820/1820_046met.jpg, True: 1820, Predicted: 1860, Error: 40

===== Fold 1 =====

===== Fine Tuning 7 layers! =====
Epoch 1/300
1413/1413 - 241s - 171ms/step - accuracy: 0.1365 - loss: 4.4762 - val_accuracy: 0.1139 - val_loss: 5.2501 - learning_rate: 1.6200e-04
Epoch 2/300
1413/1413 - 219s - 155ms/step - accuracy: 0.1985 - loss: 3.9404 - val_accuracy: 0.2779 - val_loss: 3.9719 - learning_rate: 1.6200e-04
Epoch 3/300
1413/1413 - 220s - 156ms/step - accuracy: 0.2260 - loss: 3.7369 - val_accuracy: 0.1322 - val_loss: 5.5888 - learning_rate: 1.6200e-04
Epoch 4/300
1413/1413 - 219s - 155ms/step - accuracy: 0.2467 - loss: 3.6669 - val_accuracy: 0.2030 - val_loss: 4.6294 - learning_rate: 1.6200e-04
Epoch 5/300
1413/1413 - 218s - 154ms/step - accuracy: 0.2629 - loss: 3.6048 - val_accuracy: 0.1298 - val_loss: 6.2778 - learning_rate: 1.6200e-04
Epoch 6/300
1413/1413 - 221s - 157ms/step - accuracy: 0.2688 - loss: 3.5210 - val_accuracy: 0.2954 - val_loss: 3.7654 - learning_rate: 1.6200e-04
Epoch 7/300
1413/1413 - 218s - 155ms/step - accuracy: 0.2827 - loss: 3.4842 - val_accuracy: 0.3185 - val_loss: 3.7354 - learning_rate: 1.6200e-04
Epoch 8/300
1413/1413 - 221s - 157ms/step - accuracy: 0.2913 - loss: 3.4369 - val_accuracy: 0.2444 - val_loss: 4.1379 - learning_rate: 1.6200e-04
Epoch 9/300
1413/1413 - 218s - 154ms/step - accuracy: 0.2886 - loss: 3.4437 - val_accuracy: 0.3368 - val_loss: 3.0238 - learning_rate: 1.6200e-04
Epoch 10/300
1413/1413 - 223s - 158ms/step - accuracy: 0.2997 - loss: 3.3620 - val_accuracy: 0.4013 - val_loss: 2.6682 - learning_rate: 1.6200e-04
Epoch 11/300
1413/1413 - 219s - 155ms/step - accuracy: 0.3030 - loss: 3.3443 - val_accuracy: 0.3320 - val_loss: 3.4192 - learning_rate: 1.6200e-04
Epoch 12/300
1413/1413 - 226s - 160ms/step - accuracy: 0.3082 - loss: 3.3450 - val_accuracy: 0.4172 - val_loss: 2.6494 - learning_rate: 1.6200e-04
Epoch 13/300
1413/1413 - 217s - 154ms/step - accuracy: 0.3221 - loss: 3.2760 - val_accuracy: 0.3041 - val_loss: 4.0011 - learning_rate: 1.6200e-04
Epoch 14/300
1413/1413 - 220s - 156ms/step - accuracy: 0.3201 - loss: 3.2599 - val_accuracy: 0.4355 - val_loss: 2.5504 - learning_rate: 1.6200e-04
Epoch 15/300
1413/1413 - 225s - 159ms/step - accuracy: 0.3229 - loss: 3.2291 - val_accuracy: 0.4865 - val_loss: 2.5820 - learning_rate: 1.6200e-04
Epoch 16/300
1413/1413 - 220s - 156ms/step - accuracy: 0.3258 - loss: 3.2265 - val_accuracy: 0.3272 - val_loss: 3.5442 - learning_rate: 1.6200e-04
Epoch 17/300
1413/1413 - 221s - 157ms/step - accuracy: 0.3181 - loss: 3.2321 - val_accuracy: 0.4315 - val_loss: 2.7001 - learning_rate: 1.6200e-04
Epoch 18/300
1413/1413 - 224s - 158ms/step - accuracy: 0.3280 - loss: 3.1867 - val_accuracy: 0.4411 - val_loss: 2.7797 - learning_rate: 1.6200e-04
Epoch 19/300
1413/1413 - 222s - 157ms/step - accuracy: 0.3289 - loss: 3.1659 - val_accuracy: 0.4347 - val_loss: 2.8814 - learning_rate: 1.6200e-04
Epoch 20/300
1413/1413 - 222s - 157ms/step - accuracy: 0.3405 - loss: 3.1470 - val_accuracy: 0.4371 - val_loss: 2.6038 - learning_rate: 1.6200e-04
Epoch 21/300
1413/1413 - 220s - 156ms/step - accuracy: 0.3376 - loss: 3.1684 - val_accuracy: 0.4172 - val_loss: 2.5641 - learning_rate: 1.6200e-04
Epoch 22/300

Epoch 22: ReduceLROnPlateau reducing learning rate to 8.099817205220461e-05.
1413/1413 - 218s - 154ms/step - accuracy: 0.3333 - loss: 3.1707 - val_accuracy: 0.3718 - val_loss: 3.5337 - learning_rate: 1.6200e-04
Epoch 23/300
1413/1413 - 222s - 157ms/step - accuracy: 0.3538 - loss: 3.0733 - val_accuracy: 0.5422 - val_loss: 2.2318 - learning_rate: 8.0998e-05
Epoch 24/300
1413/1413 - 218s - 154ms/step - accuracy: 0.3507 - loss: 3.0463 - val_accuracy: 0.4833 - val_loss: 2.1903 - learning_rate: 8.0998e-05
Epoch 25/300
1413/1413 - 220s - 156ms/step - accuracy: 0.3631 - loss: 3.0259 - val_accuracy: 0.4459 - val_loss: 2.7136 - learning_rate: 8.0998e-05
Epoch 26/300
1413/1413 - 219s - 155ms/step - accuracy: 0.3608 - loss: 3.0291 - val_accuracy: 0.5167 - val_loss: 2.2607 - learning_rate: 8.0998e-05
Epoch 27/300
1413/1413 - 222s - 157ms/step - accuracy: 0.3653 - loss: 3.0136 - val_accuracy: 0.4689 - val_loss: 2.3733 - learning_rate: 8.0998e-05
Epoch 28/300
1413/1413 - 220s - 156ms/step - accuracy: 0.3636 - loss: 2.9926 - val_accuracy: 0.4841 - val_loss: 2.1935 - learning_rate: 8.0998e-05
Epoch 29/300
1413/1413 - 216s - 153ms/step - accuracy: 0.3653 - loss: 2.9769 - val_accuracy: 0.5119 - val_loss: 2.2627 - learning_rate: 8.0998e-05
Epoch 30/300
1413/1413 - 220s - 156ms/step - accuracy: 0.3775 - loss: 2.9737 - val_accuracy: 0.4833 - val_loss: 2.3854 - learning_rate: 8.0998e-05
Epoch 31/300
1413/1413 - 221s - 157ms/step - accuracy: 0.3685 - loss: 2.9760 - val_accuracy: 0.4132 - val_loss: 3.0542 - learning_rate: 8.0998e-05
Epoch 32/300

Epoch 32: ReduceLROnPlateau reducing learning rate to 4.0499086026102304e-05.
1413/1413 - 217s - 153ms/step - accuracy: 0.3685 - loss: 2.9744 - val_accuracy: 0.4578 - val_loss: 2.8362 - learning_rate: 8.0998e-05
Epoch 33/300
1413/1413 - 220s - 156ms/step - accuracy: 0.3841 - loss: 2.9238 - val_accuracy: 0.5693 - val_loss: 2.0305 - learning_rate: 4.0499e-05
Epoch 34/300
1413/1413 - 222s - 157ms/step - accuracy: 0.3815 - loss: 2.9229 - val_accuracy: 0.5581 - val_loss: 2.0200 - learning_rate: 4.0499e-05
Epoch 35/300
1413/1413 - 222s - 157ms/step - accuracy: 0.3839 - loss: 2.8945 - val_accuracy: 0.5685 - val_loss: 2.1592 - learning_rate: 4.0499e-05
Epoch 36/300
1413/1413 - 222s - 157ms/step - accuracy: 0.3816 - loss: 2.9226 - val_accuracy: 0.5772 - val_loss: 1.9447 - learning_rate: 4.0499e-05
Epoch 37/300
1413/1413 - 256s - 181ms/step - accuracy: 0.3826 - loss: 2.9146 - val_accuracy: 0.5844 - val_loss: 1.9583 - learning_rate: 4.0499e-05
Epoch 38/300
1413/1413 - 227s - 161ms/step - accuracy: 0.3828 - loss: 2.8855 - val_accuracy: 0.5661 - val_loss: 2.0255 - learning_rate: 4.0499e-05
Epoch 39/300
1413/1413 - 220s - 156ms/step - accuracy: 0.3933 - loss: 2.8618 - val_accuracy: 0.5613 - val_loss: 1.9426 - learning_rate: 4.0499e-05
Epoch 40/300
1413/1413 - 218s - 154ms/step - accuracy: 0.3852 - loss: 2.9159 - val_accuracy: 0.6027 - val_loss: 1.9691 - learning_rate: 4.0499e-05
Epoch 41/300
1413/1413 - 218s - 154ms/step - accuracy: 0.3910 - loss: 2.8744 - val_accuracy: 0.5677 - val_loss: 1.9949 - learning_rate: 4.0499e-05
Epoch 42/300
1413/1413 - 219s - 155ms/step - accuracy: 0.3883 - loss: 2.8742 - val_accuracy: 0.5581 - val_loss: 2.1739 - learning_rate: 4.0499e-05
Epoch 43/300
1413/1413 - 218s - 155ms/step - accuracy: 0.3911 - loss: 2.8685 - val_accuracy: 0.5677 - val_loss: 2.0809 - learning_rate: 4.0499e-05
Epoch 44/300
1413/1413 - 216s - 153ms/step - accuracy: 0.3834 - loss: 2.9007 - val_accuracy: 0.5597 - val_loss: 2.1456 - learning_rate: 4.0499e-05
Epoch 45/300
1413/1413 - 219s - 155ms/step - accuracy: 0.3937 - loss: 2.8712 - val_accuracy: 0.5406 - val_loss: 2.0553 - learning_rate: 4.0499e-05
Epoch 46/300
1413/1413 - 217s - 154ms/step - accuracy: 0.3888 - loss: 2.8767 - val_accuracy: 0.5677 - val_loss: 1.9287 - learning_rate: 4.0499e-05
Epoch 47/300
1413/1413 - 220s - 156ms/step - accuracy: 0.3920 - loss: 2.8691 - val_accuracy: 0.5446 - val_loss: 2.0521 - learning_rate: 4.0499e-05
Epoch 48/300
1413/1413 - 221s - 156ms/step - accuracy: 0.3964 - loss: 2.8666 - val_accuracy: 0.5796 - val_loss: 1.9979 - learning_rate: 4.0499e-05
Epoch 49/300
1413/1413 - 218s - 155ms/step - accuracy: 0.3993 - loss: 2.8249 - val_accuracy: 0.4881 - val_loss: 2.6199 - learning_rate: 4.0499e-05
Epoch 50/300
1413/1413 - 221s - 156ms/step - accuracy: 0.3957 - loss: 2.8548 - val_accuracy: 0.5597 - val_loss: 2.0748 - learning_rate: 4.0499e-05
Epoch 51/300
1413/1413 - 222s - 157ms/step - accuracy: 0.3960 - loss: 2.8502 - val_accuracy: 0.5860 - val_loss: 1.9147 - learning_rate: 4.0499e-05
Epoch 52/300
1413/1413 - 219s - 155ms/step - accuracy: 0.3925 - loss: 2.8770 - val_accuracy: 0.5621 - val_loss: 2.0714 - learning_rate: 4.0499e-05
Epoch 53/300
1413/1413 - 221s - 156ms/step - accuracy: 0.3925 - loss: 2.8489 - val_accuracy: 0.6202 - val_loss: 1.8601 - learning_rate: 4.0499e-05
Epoch 54/300
1413/1413 - 219s - 155ms/step - accuracy: 0.3953 - loss: 2.8374 - val_accuracy: 0.5024 - val_loss: 2.2677 - learning_rate: 4.0499e-05
Epoch 55/300
1413/1413 - 220s - 156ms/step - accuracy: 0.4002 - loss: 2.8446 - val_accuracy: 0.5764 - val_loss: 2.0882 - learning_rate: 4.0499e-05
Epoch 56/300
1413/1413 - 220s - 155ms/step - accuracy: 0.4064 - loss: 2.8565 - val_accuracy: 0.5924 - val_loss: 1.8549 - learning_rate: 4.0499e-05
Epoch 57/300
1413/1413 - 221s - 156ms/step - accuracy: 0.3953 - loss: 2.8410 - val_accuracy: 0.5884 - val_loss: 1.8989 - learning_rate: 4.0499e-05
Epoch 58/300
1413/1413 - 219s - 155ms/step - accuracy: 0.3940 - loss: 2.8709 - val_accuracy: 0.5844 - val_loss: 1.9637 - learning_rate: 4.0499e-05
Epoch 59/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4027 - loss: 2.8283 - val_accuracy: 0.5979 - val_loss: 1.9181 - learning_rate: 4.0499e-05
Epoch 60/300
1413/1413 - 228s - 161ms/step - accuracy: 0.4002 - loss: 2.8240 - val_accuracy: 0.5987 - val_loss: 1.8146 - learning_rate: 4.0499e-05
Epoch 61/300
1413/1413 - 232s - 165ms/step - accuracy: 0.4092 - loss: 2.7963 - val_accuracy: 0.5939 - val_loss: 1.9275 - learning_rate: 4.0499e-05
Epoch 62/300
1413/1413 - 230s - 163ms/step - accuracy: 0.4027 - loss: 2.8218 - val_accuracy: 0.5764 - val_loss: 2.0166 - learning_rate: 4.0499e-05
Epoch 63/300
1413/1413 - 232s - 164ms/step - accuracy: 0.3991 - loss: 2.8383 - val_accuracy: 0.6123 - val_loss: 1.7649 - learning_rate: 4.0499e-05
Epoch 64/300
1413/1413 - 231s - 163ms/step - accuracy: 0.4039 - loss: 2.8238 - val_accuracy: 0.5884 - val_loss: 2.0917 - learning_rate: 4.0499e-05
Epoch 65/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4041 - loss: 2.7970 - val_accuracy: 0.6115 - val_loss: 1.8276 - learning_rate: 4.0499e-05
Epoch 66/300
1413/1413 - 231s - 163ms/step - accuracy: 0.4070 - loss: 2.8074 - val_accuracy: 0.5932 - val_loss: 1.8894 - learning_rate: 4.0499e-05
Epoch 67/300
1413/1413 - 228s - 161ms/step - accuracy: 0.4088 - loss: 2.7911 - val_accuracy: 0.5860 - val_loss: 1.8829 - learning_rate: 4.0499e-05
Epoch 68/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4098 - loss: 2.7988 - val_accuracy: 0.5924 - val_loss: 1.9997 - learning_rate: 4.0499e-05
Epoch 69/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4027 - loss: 2.8144 - val_accuracy: 0.6075 - val_loss: 2.0193 - learning_rate: 4.0499e-05
Epoch 70/300
1413/1413 - 231s - 164ms/step - accuracy: 0.4030 - loss: 2.8169 - val_accuracy: 0.5947 - val_loss: 1.8161 - learning_rate: 4.0499e-05
Epoch 71/300

Epoch 71: ReduceLROnPlateau reducing learning rate to 2.0249543013051152e-05.
1413/1413 - 231s - 163ms/step - accuracy: 0.4049 - loss: 2.7918 - val_accuracy: 0.4928 - val_loss: 2.5405 - learning_rate: 4.0499e-05
Epoch 72/300
1413/1413 - 231s - 164ms/step - accuracy: 0.4143 - loss: 2.7658 - val_accuracy: 0.6330 - val_loss: 1.7733 - learning_rate: 2.0250e-05
Epoch 73/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4129 - loss: 2.7552 - val_accuracy: 0.6306 - val_loss: 1.6812 - learning_rate: 2.0250e-05
Epoch 74/300
1413/1413 - 231s - 163ms/step - accuracy: 0.4085 - loss: 2.7685 - val_accuracy: 0.6115 - val_loss: 1.7819 - learning_rate: 2.0250e-05
Epoch 75/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4166 - loss: 2.7614 - val_accuracy: 0.6274 - val_loss: 1.7575 - learning_rate: 2.0250e-05
Epoch 76/300
1413/1413 - 231s - 163ms/step - accuracy: 0.4176 - loss: 2.7445 - val_accuracy: 0.5963 - val_loss: 1.8229 - learning_rate: 2.0250e-05
Epoch 77/300
1413/1413 - 232s - 164ms/step - accuracy: 0.4154 - loss: 2.7503 - val_accuracy: 0.6298 - val_loss: 1.7945 - learning_rate: 2.0250e-05
Epoch 78/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4184 - loss: 2.7667 - val_accuracy: 0.6210 - val_loss: 1.8188 - learning_rate: 2.0250e-05
Epoch 79/300
1413/1413 - 235s - 166ms/step - accuracy: 0.4153 - loss: 2.7405 - val_accuracy: 0.6401 - val_loss: 1.7054 - learning_rate: 2.0250e-05
Epoch 80/300
1413/1413 - 228s - 162ms/step - accuracy: 0.4185 - loss: 2.7336 - val_accuracy: 0.6178 - val_loss: 1.7732 - learning_rate: 2.0250e-05
Epoch 81/300

Epoch 81: ReduceLROnPlateau reducing learning rate to 1.0124771506525576e-05.
1413/1413 - 238s - 168ms/step - accuracy: 0.4241 - loss: 2.7352 - val_accuracy: 0.6139 - val_loss: 1.8507 - learning_rate: 2.0250e-05
Epoch 82/300
1413/1413 - 236s - 167ms/step - accuracy: 0.4118 - loss: 2.7401 - val_accuracy: 0.6210 - val_loss: 1.7996 - learning_rate: 1.0125e-05
Epoch 83/300
1413/1413 - 239s - 169ms/step - accuracy: 0.4157 - loss: 2.7374 - val_accuracy: 0.6393 - val_loss: 1.6824 - learning_rate: 1.0125e-05
Epoch 84/300
1413/1413 - 235s - 166ms/step - accuracy: 0.4188 - loss: 2.7411 - val_accuracy: 0.6361 - val_loss: 1.6584 - learning_rate: 1.0125e-05
Epoch 85/300
1413/1413 - 230s - 163ms/step - accuracy: 0.4191 - loss: 2.7388 - val_accuracy: 0.6385 - val_loss: 1.6688 - learning_rate: 1.0125e-05
Epoch 86/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4139 - loss: 2.7466 - val_accuracy: 0.6361 - val_loss: 1.7230 - learning_rate: 1.0125e-05
Epoch 87/300
1413/1413 - 221s - 156ms/step - accuracy: 0.4261 - loss: 2.7206 - val_accuracy: 0.6322 - val_loss: 1.7084 - learning_rate: 1.0125e-05
Epoch 88/300
1413/1413 - 224s - 158ms/step - accuracy: 0.4123 - loss: 2.7211 - val_accuracy: 0.6242 - val_loss: 1.7205 - learning_rate: 1.0125e-05
Epoch 89/300
1413/1413 - 224s - 158ms/step - accuracy: 0.4217 - loss: 2.7048 - val_accuracy: 0.6409 - val_loss: 1.7088 - learning_rate: 1.0125e-05
Epoch 90/300
1413/1413 - 224s - 159ms/step - accuracy: 0.4205 - loss: 2.7265 - val_accuracy: 0.6425 - val_loss: 1.6797 - learning_rate: 1.0125e-05
Epoch 91/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4172 - loss: 2.7115 - val_accuracy: 0.6481 - val_loss: 1.6674 - learning_rate: 1.0125e-05
Epoch 92/300

Epoch 92: ReduceLROnPlateau reducing learning rate to 5.062385753262788e-06.
1413/1413 - 229s - 162ms/step - accuracy: 0.4200 - loss: 2.7420 - val_accuracy: 0.6417 - val_loss: 1.7330 - learning_rate: 1.0125e-05
Epoch 93/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4262 - loss: 2.6944 - val_accuracy: 0.6433 - val_loss: 1.6759 - learning_rate: 5.0624e-06
Epoch 94/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4242 - loss: 2.7168 - val_accuracy: 0.6465 - val_loss: 1.6394 - learning_rate: 5.0624e-06
Epoch 95/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4249 - loss: 2.7181 - val_accuracy: 0.6505 - val_loss: 1.6418 - learning_rate: 5.0624e-06
Epoch 96/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4199 - loss: 2.7280 - val_accuracy: 0.6481 - val_loss: 1.6597 - learning_rate: 5.0624e-06
Epoch 97/300
1413/1413 - 221s - 156ms/step - accuracy: 0.4191 - loss: 2.7211 - val_accuracy: 0.6465 - val_loss: 1.6471 - learning_rate: 5.0624e-06
Epoch 98/300
1413/1413 - 220s - 156ms/step - accuracy: 0.4307 - loss: 2.6806 - val_accuracy: 0.6465 - val_loss: 1.6483 - learning_rate: 5.0624e-06
Epoch 99/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4282 - loss: 2.6801 - val_accuracy: 0.6513 - val_loss: 1.6494 - learning_rate: 5.0624e-06
Epoch 100/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4167 - loss: 2.6932 - val_accuracy: 0.6481 - val_loss: 1.6572 - learning_rate: 5.0624e-06
Epoch 101/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4298 - loss: 2.6914 - val_accuracy: 0.6473 - val_loss: 1.6588 - learning_rate: 5.0624e-06
Epoch 102/300
1413/1413 - 224s - 159ms/step - accuracy: 0.4212 - loss: 2.7179 - val_accuracy: 0.6457 - val_loss: 1.6327 - learning_rate: 5.0624e-06
Epoch 103/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4261 - loss: 2.6818 - val_accuracy: 0.6489 - val_loss: 1.6577 - learning_rate: 5.0624e-06
Epoch 104/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4166 - loss: 2.7341 - val_accuracy: 0.6513 - val_loss: 1.6485 - learning_rate: 5.0624e-06
Epoch 105/300
1413/1413 - 221s - 157ms/step - accuracy: 0.4254 - loss: 2.7093 - val_accuracy: 0.6457 - val_loss: 1.6214 - learning_rate: 5.0624e-06
Epoch 106/300
1413/1413 - 218s - 155ms/step - accuracy: 0.4273 - loss: 2.6920 - val_accuracy: 0.6489 - val_loss: 1.6269 - learning_rate: 5.0624e-06
Epoch 107/300
1413/1413 - 224s - 159ms/step - accuracy: 0.4227 - loss: 2.7076 - val_accuracy: 0.6521 - val_loss: 1.6518 - learning_rate: 5.0624e-06
Epoch 108/300
1413/1413 - 227s - 161ms/step - accuracy: 0.4295 - loss: 2.7091 - val_accuracy: 0.6481 - val_loss: 1.6226 - learning_rate: 5.0624e-06
Epoch 109/300
1413/1413 - 224s - 159ms/step - accuracy: 0.4209 - loss: 2.7017 - val_accuracy: 0.6465 - val_loss: 1.6587 - learning_rate: 5.0624e-06
Epoch 110/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4148 - loss: 2.7403 - val_accuracy: 0.6505 - val_loss: 1.6531 - learning_rate: 5.0624e-06
Epoch 111/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4328 - loss: 2.6747 - val_accuracy: 0.6497 - val_loss: 1.6364 - learning_rate: 5.0624e-06
Epoch 112/300
1413/1413 - 238s - 169ms/step - accuracy: 0.4281 - loss: 2.6800 - val_accuracy: 0.6473 - val_loss: 1.6584 - learning_rate: 5.0624e-06
Epoch 113/300

Epoch 113: ReduceLROnPlateau reducing learning rate to 2.531192876631394e-06.
1413/1413 - 236s - 167ms/step - accuracy: 0.4266 - loss: 2.6920 - val_accuracy: 0.6561 - val_loss: 1.6556 - learning_rate: 5.0624e-06
Epoch 114/300
1413/1413 - 233s - 165ms/step - accuracy: 0.4287 - loss: 2.6831 - val_accuracy: 0.6553 - val_loss: 1.6298 - learning_rate: 2.5312e-06
Epoch 115/300
1413/1413 - 239s - 169ms/step - accuracy: 0.4299 - loss: 2.6798 - val_accuracy: 0.6537 - val_loss: 1.6400 - learning_rate: 2.5312e-06
Epoch 116/300
1413/1413 - 236s - 167ms/step - accuracy: 0.4205 - loss: 2.7199 - val_accuracy: 0.6529 - val_loss: 1.6374 - learning_rate: 2.5312e-06
Epoch 117/300
1413/1413 - 239s - 169ms/step - accuracy: 0.4217 - loss: 2.6992 - val_accuracy: 0.6497 - val_loss: 1.6310 - learning_rate: 2.5312e-06
Epoch 118/300
1413/1413 - 233s - 165ms/step - accuracy: 0.4354 - loss: 2.6918 - val_accuracy: 0.6393 - val_loss: 1.6715 - learning_rate: 2.5312e-06
Epoch 119/300
1413/1413 - 234s - 166ms/step - accuracy: 0.4306 - loss: 2.6770 - val_accuracy: 0.6568 - val_loss: 1.6199 - learning_rate: 2.5312e-06
Epoch 120/300
1413/1413 - 235s - 166ms/step - accuracy: 0.4347 - loss: 2.6706 - val_accuracy: 0.6489 - val_loss: 1.6406 - learning_rate: 2.5312e-06
Epoch 121/300
1413/1413 - 233s - 165ms/step - accuracy: 0.4280 - loss: 2.7008 - val_accuracy: 0.6473 - val_loss: 1.6262 - learning_rate: 2.5312e-06
Epoch 122/300
1413/1413 - 237s - 168ms/step - accuracy: 0.4272 - loss: 2.6790 - val_accuracy: 0.6433 - val_loss: 1.6489 - learning_rate: 2.5312e-06
Epoch 123/300
1413/1413 - 236s - 167ms/step - accuracy: 0.4330 - loss: 2.6868 - val_accuracy: 0.6465 - val_loss: 1.6650 - learning_rate: 2.5312e-06
Epoch 124/300
1413/1413 - 240s - 170ms/step - accuracy: 0.4323 - loss: 2.6724 - val_accuracy: 0.6473 - val_loss: 1.6393 - learning_rate: 2.5312e-06
Epoch 125/300
1413/1413 - 238s - 169ms/step - accuracy: 0.4259 - loss: 2.6909 - val_accuracy: 0.6513 - val_loss: 1.6526 - learning_rate: 2.5312e-06
Epoch 126/300
1413/1413 - 235s - 166ms/step - accuracy: 0.4324 - loss: 2.6773 - val_accuracy: 0.6497 - val_loss: 1.6330 - learning_rate: 2.5312e-06
Epoch 127/300

Epoch 127: ReduceLROnPlateau reducing learning rate to 1.265596438315697e-06.
1413/1413 - 238s - 168ms/step - accuracy: 0.4289 - loss: 2.6653 - val_accuracy: 0.6473 - val_loss: 1.6660 - learning_rate: 2.5312e-06
Epoch 128/300
1413/1413 - 235s - 166ms/step - accuracy: 0.4282 - loss: 2.6763 - val_accuracy: 0.6481 - val_loss: 1.6234 - learning_rate: 1.2656e-06
Epoch 129/300
1413/1413 - 235s - 166ms/step - accuracy: 0.4279 - loss: 2.6883 - val_accuracy: 0.6537 - val_loss: 1.6236 - learning_rate: 1.2656e-06
Epoch 130/300
1413/1413 - 237s - 167ms/step - accuracy: 0.4325 - loss: 2.6828 - val_accuracy: 0.6537 - val_loss: 1.6329 - learning_rate: 1.2656e-06
Epoch 131/300
1413/1413 - 236s - 167ms/step - accuracy: 0.4281 - loss: 2.6857 - val_accuracy: 0.6497 - val_loss: 1.6393 - learning_rate: 1.2656e-06
Epoch 132/300
1413/1413 - 234s - 166ms/step - accuracy: 0.4335 - loss: 2.6759 - val_accuracy: 0.6521 - val_loss: 1.6373 - learning_rate: 1.2656e-06
Epoch 133/300
1413/1413 - 239s - 169ms/step - accuracy: 0.4262 - loss: 2.6877 - val_accuracy: 0.6529 - val_loss: 1.6371 - learning_rate: 1.2656e-06
Epoch 134/300
1413/1413 - 237s - 167ms/step - accuracy: 0.4294 - loss: 2.6673 - val_accuracy: 0.6561 - val_loss: 1.6384 - learning_rate: 1.2656e-06
Epoch 135/300

Epoch 135: ReduceLROnPlateau reducing learning rate to 1e-06.
1413/1413 - 236s - 167ms/step - accuracy: 0.4362 - loss: 2.6599 - val_accuracy: 0.6537 - val_loss: 1.6431 - learning_rate: 1.2656e-06
Epoch 135: early stopping
Restoring model weights from the end of the best epoch: 119.
Fold 1 Evaluation results: [1.613343358039856, 0.6568471193313599]
              precision    recall  f1-score   support

        1820       0.81      0.77      0.79        62
        1821       0.84      0.82      0.83        57
        1822       0.00      0.00      0.00         1
        1823       1.00      1.00      1.00         1
        1824       0.00      0.00      0.00         1
        1825       0.00      0.00      0.00         2
        1826       0.00      0.00      0.00         2
        1827       0.82      0.92      0.87        25
        1828       0.00      0.00      0.00         1
        1829       0.44      0.80      0.57         5
        1830       0.76      0.62      0.69        56
        1831       0.74      0.89      0.81       134
        1832       0.75      0.87      0.80        68
        1833       0.90      0.95      0.92        19
        1834       0.51      0.72      0.60        29
        1835       0.00      0.00      0.00         3
        1836       0.25      0.25      0.25         4
        1837       0.16      0.43      0.23         7
        1838       1.00      0.33      0.50         3
        1839       0.00      0.00      0.00         0
        1840       0.59      0.53      0.56        43
        1841       0.75      0.56      0.64       108
        1842       0.50      0.80      0.62         5
        1843       0.33      0.17      0.22         6
        1844       0.00      0.00      0.00         1
        1845       0.00      0.00      0.00         2
        1846       0.80      0.67      0.73         6
        1847       0.00      0.00      0.00         2
        1848       0.50      0.17      0.25         6
        1849       1.00      0.33      0.50         6
        1850       0.52      0.62      0.57        48
        1851       0.81      0.75      0.78        77
        1852       0.25      0.14      0.18         7
        1853       0.00      0.00      0.00         6
        1854       0.00      0.00      0.00         3
        1855       0.42      0.33      0.37        24
        1856       0.69      0.75      0.72        12
        1857       0.50      0.67      0.57        30
        1858       0.00      0.00      0.00         2
        1859       0.00      0.00      0.00         2
        1860       0.45      0.47      0.46        64
        1861       0.84      0.86      0.85        85
        1862       0.42      0.44      0.43        18
        1863       0.46      0.63      0.53        19
        1864       0.50      0.41      0.45        17
        1865       0.35      1.00      0.52         6
        1866       0.00      0.00      0.00         5
        1867       0.33      0.55      0.41        11
        1868       0.00      0.00      0.00         7
        1869       0.00      0.00      0.00         5
        1870       0.50      0.58      0.54        31
        1871       0.75      0.80      0.77        49
        1872       0.60      0.38      0.46         8
        1873       0.67      0.20      0.31        10
        1874       0.50      0.40      0.44         5
        1875       0.38      0.43      0.40        14
        1876       0.86      0.60      0.71        10
        1877       0.40      0.40      0.40         5
        1878       0.50      0.44      0.47         9
        1879       0.00      0.00      0.00         2

    accuracy                           0.66      1256
   macro avg       0.42      0.41      0.40      1256
weighted avg       0.65      0.66      0.64      1256

Matthews Correlation Coefficient: 0.640
Macro avg F1: 0.395
Weighted avg F1: 0.644
Micro avg F1: 0.657
Top-3 Accuracy: 0.868
Top-5 Accuracy: 0.912
Micro ROC AUC  = 0.99
Macro ROC AUC (present classes) = 0.97
Classification MAE (in years): 3.14

Fold 1 Misclassification Analysis:
Near misses (within 2 years): 99 out of 431 misclassifications (22.97%)
Big misses (greater than 10 years): 204
MAE with outliers: 3.14
MAE without outliers: 2.05 (improvement: 1.10)

10 Worst misclassifications:
Image: data/datasets/public/1870/1879_180wikimedia2.jpg, True: 1879, Predicted: 1820, Error: 59
Image: data/datasets/public/1870/1879_39wikimedia2.jpg, True: 1879, Predicted: 1820, Error: 59
Image: data/datasets/public/1870/1877_033met.jpg, True: 1877, Predicted: 1820, Error: 57
Image: data/datasets/public/1820/1821_52vna.jpg, True: 1821, Predicted: 1876, Error: 55
Image: data/datasets/public/1870/1875_38washington.jpg, True: 1875, Predicted: 1821, Error: 54
Image: data/datasets/public/1820/1820_035met.jpg, True: 1820, Predicted: 1867, Error: 47
Image: data/datasets/public/1870/1878_468vna.jpg, True: 1878, Predicted: 1832, Error: 46
Image: data/datasets/public/1870/1876_386vna.jpg, True: 1876, Predicted: 1831, Error: 45
Image: data/datasets/public/1870/1878_490vna.jpg, True: 1878, Predicted: 1834, Error: 44
Image: data/datasets/public/1820/1820_013_001met.jpg, True: 1820, Predicted: 1863, Error: 43

===== Fold 2 =====

===== Fine Tuning 7 layers! =====
Epoch 1/300
1413/1413 - 261s - 185ms/step - accuracy: 0.1347 - loss: 4.4370 - val_accuracy: 0.2094 - val_loss: 3.7016 - learning_rate: 1.6200e-04
Epoch 2/300
1413/1413 - 234s - 165ms/step - accuracy: 0.1963 - loss: 3.9691 - val_accuracy: 0.1529 - val_loss: 5.9143 - learning_rate: 1.6200e-04
Epoch 3/300
1413/1413 - 238s - 168ms/step - accuracy: 0.2253 - loss: 3.8266 - val_accuracy: 0.2739 - val_loss: 3.5164 - learning_rate: 1.6200e-04
Epoch 4/300
1413/1413 - 239s - 169ms/step - accuracy: 0.2465 - loss: 3.6757 - val_accuracy: 0.2826 - val_loss: 3.3005 - learning_rate: 1.6200e-04
Epoch 5/300
1413/1413 - 239s - 169ms/step - accuracy: 0.2619 - loss: 3.5828 - val_accuracy: 0.3057 - val_loss: 3.8273 - learning_rate: 1.6200e-04
Epoch 6/300
1413/1413 - 237s - 168ms/step - accuracy: 0.2694 - loss: 3.5329 - val_accuracy: 0.1584 - val_loss: 3.9819 - learning_rate: 1.6200e-04
Epoch 7/300
1413/1413 - 238s - 169ms/step - accuracy: 0.2799 - loss: 3.4789 - val_accuracy: 0.3368 - val_loss: 3.0390 - learning_rate: 1.6200e-04
Epoch 8/300
1413/1413 - 237s - 167ms/step - accuracy: 0.2882 - loss: 3.4361 - val_accuracy: 0.4100 - val_loss: 2.7350 - learning_rate: 1.6200e-04
Epoch 9/300
1413/1413 - 240s - 170ms/step - accuracy: 0.2979 - loss: 3.4087 - val_accuracy: 0.3129 - val_loss: 3.9345 - learning_rate: 1.6200e-04
Epoch 10/300
1413/1413 - 234s - 166ms/step - accuracy: 0.3005 - loss: 3.3621 - val_accuracy: 0.2532 - val_loss: 3.5531 - learning_rate: 1.6200e-04
Epoch 11/300
1413/1413 - 239s - 169ms/step - accuracy: 0.3038 - loss: 3.3350 - val_accuracy: 0.4817 - val_loss: 2.7437 - learning_rate: 1.6200e-04
Epoch 12/300
1413/1413 - 233s - 165ms/step - accuracy: 0.3113 - loss: 3.2921 - val_accuracy: 0.2938 - val_loss: 3.7507 - learning_rate: 1.6200e-04
Epoch 13/300
1413/1413 - 234s - 165ms/step - accuracy: 0.3135 - loss: 3.2957 - val_accuracy: 0.2604 - val_loss: 3.3097 - learning_rate: 1.6200e-04
Epoch 14/300
1413/1413 - 241s - 170ms/step - accuracy: 0.3181 - loss: 3.2694 - val_accuracy: 0.3543 - val_loss: 3.5385 - learning_rate: 1.6200e-04
Epoch 15/300
1413/1413 - 239s - 169ms/step - accuracy: 0.3219 - loss: 3.2626 - val_accuracy: 0.4323 - val_loss: 2.9565 - learning_rate: 1.6200e-04
Epoch 16/300

Epoch 16: ReduceLROnPlateau reducing learning rate to 8.099817205220461e-05.
1413/1413 - 235s - 166ms/step - accuracy: 0.3274 - loss: 3.2341 - val_accuracy: 0.2723 - val_loss: 4.0123 - learning_rate: 1.6200e-04
Epoch 17/300
1413/1413 - 239s - 169ms/step - accuracy: 0.3393 - loss: 3.1326 - val_accuracy: 0.4522 - val_loss: 2.4565 - learning_rate: 8.0998e-05
Epoch 18/300
1413/1413 - 235s - 166ms/step - accuracy: 0.3454 - loss: 3.1169 - val_accuracy: 0.4968 - val_loss: 2.3347 - learning_rate: 8.0998e-05
Epoch 19/300
1413/1413 - 234s - 165ms/step - accuracy: 0.3477 - loss: 3.1111 - val_accuracy: 0.4634 - val_loss: 2.6964 - learning_rate: 8.0998e-05
Epoch 20/300
1413/1413 - 236s - 167ms/step - accuracy: 0.3506 - loss: 3.0898 - val_accuracy: 0.4968 - val_loss: 2.4248 - learning_rate: 8.0998e-05
Epoch 21/300
1413/1413 - 235s - 166ms/step - accuracy: 0.3519 - loss: 3.0862 - val_accuracy: 0.4737 - val_loss: 2.7338 - learning_rate: 8.0998e-05
Epoch 22/300
1413/1413 - 239s - 169ms/step - accuracy: 0.3561 - loss: 3.0513 - val_accuracy: 0.5064 - val_loss: 2.4139 - learning_rate: 8.0998e-05
Epoch 23/300
1413/1413 - 233s - 165ms/step - accuracy: 0.3541 - loss: 3.0538 - val_accuracy: 0.4984 - val_loss: 2.3085 - learning_rate: 8.0998e-05
Epoch 24/300
1413/1413 - 239s - 169ms/step - accuracy: 0.3639 - loss: 3.0465 - val_accuracy: 0.5080 - val_loss: 2.2965 - learning_rate: 8.0998e-05
Epoch 25/300
1413/1413 - 233s - 165ms/step - accuracy: 0.3655 - loss: 3.0291 - val_accuracy: 0.4689 - val_loss: 2.3131 - learning_rate: 8.0998e-05
Epoch 26/300
1413/1413 - 239s - 169ms/step - accuracy: 0.3635 - loss: 3.0271 - val_accuracy: 0.4713 - val_loss: 2.4653 - learning_rate: 8.0998e-05
Epoch 27/300
1413/1413 - 235s - 166ms/step - accuracy: 0.3539 - loss: 3.0395 - val_accuracy: 0.5111 - val_loss: 2.2393 - learning_rate: 8.0998e-05
Epoch 28/300
1413/1413 - 236s - 167ms/step - accuracy: 0.3673 - loss: 3.0236 - val_accuracy: 0.4737 - val_loss: 2.3206 - learning_rate: 8.0998e-05
Epoch 29/300
1413/1413 - 238s - 169ms/step - accuracy: 0.3628 - loss: 3.0031 - val_accuracy: 0.4674 - val_loss: 2.3435 - learning_rate: 8.0998e-05
Epoch 30/300
1413/1413 - 239s - 169ms/step - accuracy: 0.3747 - loss: 2.9882 - val_accuracy: 0.5183 - val_loss: 2.2418 - learning_rate: 8.0998e-05
Epoch 31/300
1413/1413 - 237s - 168ms/step - accuracy: 0.3627 - loss: 3.0000 - val_accuracy: 0.4801 - val_loss: 2.5005 - learning_rate: 8.0998e-05
Epoch 32/300
1413/1413 - 235s - 167ms/step - accuracy: 0.3736 - loss: 2.9962 - val_accuracy: 0.4498 - val_loss: 2.8052 - learning_rate: 8.0998e-05
Epoch 33/300
1413/1413 - 238s - 169ms/step - accuracy: 0.3709 - loss: 2.9880 - val_accuracy: 0.5247 - val_loss: 2.3057 - learning_rate: 8.0998e-05
Epoch 34/300
1413/1413 - 235s - 166ms/step - accuracy: 0.3766 - loss: 2.9915 - val_accuracy: 0.5008 - val_loss: 2.3386 - learning_rate: 8.0998e-05
Epoch 35/300
1413/1413 - 241s - 171ms/step - accuracy: 0.3741 - loss: 2.9724 - val_accuracy: 0.5311 - val_loss: 2.1825 - learning_rate: 8.0998e-05
Epoch 36/300
1413/1413 - 235s - 167ms/step - accuracy: 0.3745 - loss: 2.9689 - val_accuracy: 0.5462 - val_loss: 2.1440 - learning_rate: 8.0998e-05
Epoch 37/300
1413/1413 - 234s - 165ms/step - accuracy: 0.3748 - loss: 2.9580 - val_accuracy: 0.5541 - val_loss: 1.9970 - learning_rate: 8.0998e-05
Epoch 38/300
1413/1413 - 238s - 169ms/step - accuracy: 0.3752 - loss: 2.9549 - val_accuracy: 0.4196 - val_loss: 2.8781 - learning_rate: 8.0998e-05
Epoch 39/300
1413/1413 - 236s - 167ms/step - accuracy: 0.3731 - loss: 2.9662 - val_accuracy: 0.4873 - val_loss: 2.3457 - learning_rate: 8.0998e-05
Epoch 40/300
1413/1413 - 235s - 167ms/step - accuracy: 0.3834 - loss: 2.9360 - val_accuracy: 0.5127 - val_loss: 2.5607 - learning_rate: 8.0998e-05
Epoch 41/300
1413/1413 - 236s - 167ms/step - accuracy: 0.3785 - loss: 2.9329 - val_accuracy: 0.5064 - val_loss: 2.2856 - learning_rate: 8.0998e-05
Epoch 42/300
1413/1413 - 237s - 168ms/step - accuracy: 0.3758 - loss: 2.9526 - val_accuracy: 0.5565 - val_loss: 2.1256 - learning_rate: 8.0998e-05
Epoch 43/300
1413/1413 - 235s - 166ms/step - accuracy: 0.3792 - loss: 2.9222 - val_accuracy: 0.5645 - val_loss: 2.0871 - learning_rate: 8.0998e-05
Epoch 44/300
1413/1413 - 224s - 159ms/step - accuracy: 0.3798 - loss: 2.9421 - val_accuracy: 0.5557 - val_loss: 1.9935 - learning_rate: 8.0998e-05
Epoch 45/300
1413/1413 - 222s - 157ms/step - accuracy: 0.3818 - loss: 2.8991 - val_accuracy: 0.4857 - val_loss: 2.2884 - learning_rate: 8.0998e-05
Epoch 46/300
1413/1413 - 220s - 156ms/step - accuracy: 0.3849 - loss: 2.8759 - val_accuracy: 0.4960 - val_loss: 2.8028 - learning_rate: 8.0998e-05
Epoch 47/300
1413/1413 - 219s - 155ms/step - accuracy: 0.3875 - loss: 2.9027 - val_accuracy: 0.5772 - val_loss: 2.0830 - learning_rate: 8.0998e-05
Epoch 48/300
1413/1413 - 223s - 157ms/step - accuracy: 0.3815 - loss: 2.8890 - val_accuracy: 0.4697 - val_loss: 2.6085 - learning_rate: 8.0998e-05
Epoch 49/300
1413/1413 - 221s - 157ms/step - accuracy: 0.3765 - loss: 2.9026 - val_accuracy: 0.5342 - val_loss: 2.1494 - learning_rate: 8.0998e-05
Epoch 50/300
1413/1413 - 224s - 158ms/step - accuracy: 0.3818 - loss: 2.8733 - val_accuracy: 0.5008 - val_loss: 2.3103 - learning_rate: 8.0998e-05
Epoch 51/300
1413/1413 - 222s - 157ms/step - accuracy: 0.3910 - loss: 2.8821 - val_accuracy: 0.5111 - val_loss: 2.3592 - learning_rate: 8.0998e-05
Epoch 52/300

Epoch 52: ReduceLROnPlateau reducing learning rate to 4.0499086026102304e-05.
1413/1413 - 225s - 159ms/step - accuracy: 0.3949 - loss: 2.8755 - val_accuracy: 0.5199 - val_loss: 2.1120 - learning_rate: 8.0998e-05
Epoch 53/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4038 - loss: 2.8136 - val_accuracy: 0.6202 - val_loss: 1.7800 - learning_rate: 4.0499e-05
Epoch 54/300
1413/1413 - 225s - 159ms/step - accuracy: 0.3982 - loss: 2.8153 - val_accuracy: 0.5900 - val_loss: 1.9318 - learning_rate: 4.0499e-05
Epoch 55/300
1413/1413 - 221s - 157ms/step - accuracy: 0.4058 - loss: 2.8036 - val_accuracy: 0.6035 - val_loss: 1.8721 - learning_rate: 4.0499e-05
Epoch 56/300
1413/1413 - 220s - 155ms/step - accuracy: 0.4018 - loss: 2.8077 - val_accuracy: 0.6067 - val_loss: 1.8499 - learning_rate: 4.0499e-05
Epoch 57/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4046 - loss: 2.7971 - val_accuracy: 0.6091 - val_loss: 1.8765 - learning_rate: 4.0499e-05
Epoch 58/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4144 - loss: 2.7868 - val_accuracy: 0.5971 - val_loss: 2.0488 - learning_rate: 4.0499e-05
Epoch 59/300
1413/1413 - 221s - 156ms/step - accuracy: 0.4099 - loss: 2.7794 - val_accuracy: 0.5796 - val_loss: 1.9525 - learning_rate: 4.0499e-05
Epoch 60/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4021 - loss: 2.8032 - val_accuracy: 0.5939 - val_loss: 2.0039 - learning_rate: 4.0499e-05
Epoch 61/300

Epoch 61: ReduceLROnPlateau reducing learning rate to 2.0249543013051152e-05.
1413/1413 - 220s - 156ms/step - accuracy: 0.4083 - loss: 2.7769 - val_accuracy: 0.5900 - val_loss: 1.9781 - learning_rate: 4.0499e-05
Epoch 62/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4113 - loss: 2.7431 - val_accuracy: 0.6377 - val_loss: 1.8184 - learning_rate: 2.0250e-05
Epoch 63/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4118 - loss: 2.7614 - val_accuracy: 0.6035 - val_loss: 1.9214 - learning_rate: 2.0250e-05
Epoch 64/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4133 - loss: 2.7797 - val_accuracy: 0.6282 - val_loss: 1.8193 - learning_rate: 2.0250e-05
Epoch 65/300
1413/1413 - 218s - 155ms/step - accuracy: 0.4177 - loss: 2.7320 - val_accuracy: 0.6354 - val_loss: 1.7440 - learning_rate: 2.0250e-05
Epoch 66/300
1413/1413 - 227s - 161ms/step - accuracy: 0.4134 - loss: 2.7694 - val_accuracy: 0.5748 - val_loss: 1.9412 - learning_rate: 2.0250e-05
Epoch 67/300
1413/1413 - 219s - 155ms/step - accuracy: 0.4218 - loss: 2.7440 - val_accuracy: 0.6258 - val_loss: 1.7210 - learning_rate: 2.0250e-05
Epoch 68/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4107 - loss: 2.7549 - val_accuracy: 0.6298 - val_loss: 1.7509 - learning_rate: 2.0250e-05
Epoch 69/300
1413/1413 - 221s - 157ms/step - accuracy: 0.4186 - loss: 2.7152 - val_accuracy: 0.6274 - val_loss: 1.7538 - learning_rate: 2.0250e-05
Epoch 70/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4138 - loss: 2.7647 - val_accuracy: 0.6051 - val_loss: 1.8043 - learning_rate: 2.0250e-05
Epoch 71/300
1413/1413 - 217s - 154ms/step - accuracy: 0.4134 - loss: 2.7500 - val_accuracy: 0.6115 - val_loss: 1.8235 - learning_rate: 2.0250e-05
Epoch 72/300
1413/1413 - 230s - 163ms/step - accuracy: 0.4211 - loss: 2.7352 - val_accuracy: 0.6266 - val_loss: 1.7520 - learning_rate: 2.0250e-05
Epoch 73/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4203 - loss: 2.7129 - val_accuracy: 0.6059 - val_loss: 1.8091 - learning_rate: 2.0250e-05
Epoch 74/300
1413/1413 - 220s - 156ms/step - accuracy: 0.4191 - loss: 2.7342 - val_accuracy: 0.6083 - val_loss: 1.8227 - learning_rate: 2.0250e-05
Epoch 75/300

Epoch 75: ReduceLROnPlateau reducing learning rate to 1.0124771506525576e-05.
1413/1413 - 222s - 157ms/step - accuracy: 0.4165 - loss: 2.7402 - val_accuracy: 0.6290 - val_loss: 1.8034 - learning_rate: 2.0250e-05
Epoch 76/300
1413/1413 - 221s - 156ms/step - accuracy: 0.4263 - loss: 2.6986 - val_accuracy: 0.6361 - val_loss: 1.6803 - learning_rate: 1.0125e-05
Epoch 77/300
1413/1413 - 221s - 156ms/step - accuracy: 0.4226 - loss: 2.6972 - val_accuracy: 0.6346 - val_loss: 1.7161 - learning_rate: 1.0125e-05
Epoch 78/300
1413/1413 - 220s - 156ms/step - accuracy: 0.4233 - loss: 2.7040 - val_accuracy: 0.6314 - val_loss: 1.7405 - learning_rate: 1.0125e-05
Epoch 79/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4194 - loss: 2.6921 - val_accuracy: 0.6266 - val_loss: 1.7260 - learning_rate: 1.0125e-05
Epoch 80/300
1413/1413 - 221s - 156ms/step - accuracy: 0.4292 - loss: 2.6696 - val_accuracy: 0.6385 - val_loss: 1.7493 - learning_rate: 1.0125e-05
Epoch 81/300
1413/1413 - 221s - 156ms/step - accuracy: 0.4244 - loss: 2.6760 - val_accuracy: 0.6282 - val_loss: 1.7910 - learning_rate: 1.0125e-05
Epoch 82/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4289 - loss: 2.6965 - val_accuracy: 0.6393 - val_loss: 1.7220 - learning_rate: 1.0125e-05
Epoch 83/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4241 - loss: 2.7072 - val_accuracy: 0.6306 - val_loss: 1.7279 - learning_rate: 1.0125e-05
Epoch 84/300

Epoch 84: ReduceLROnPlateau reducing learning rate to 5.062385753262788e-06.
1413/1413 - 228s - 162ms/step - accuracy: 0.4241 - loss: 2.7061 - val_accuracy: 0.6377 - val_loss: 1.7709 - learning_rate: 1.0125e-05
Epoch 85/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4235 - loss: 2.6872 - val_accuracy: 0.6457 - val_loss: 1.7137 - learning_rate: 5.0624e-06
Epoch 86/300
1413/1413 - 228s - 162ms/step - accuracy: 0.4248 - loss: 2.7102 - val_accuracy: 0.6433 - val_loss: 1.6861 - learning_rate: 5.0624e-06
Epoch 87/300
1413/1413 - 225s - 160ms/step - accuracy: 0.4230 - loss: 2.7102 - val_accuracy: 0.6417 - val_loss: 1.6832 - learning_rate: 5.0624e-06
Epoch 88/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4252 - loss: 2.6956 - val_accuracy: 0.6513 - val_loss: 1.6943 - learning_rate: 5.0624e-06
Epoch 89/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4286 - loss: 2.6762 - val_accuracy: 0.6409 - val_loss: 1.7127 - learning_rate: 5.0624e-06
Epoch 90/300
1413/1413 - 224s - 159ms/step - accuracy: 0.4309 - loss: 2.7002 - val_accuracy: 0.6521 - val_loss: 1.6584 - learning_rate: 5.0624e-06
Epoch 91/300
1413/1413 - 219s - 155ms/step - accuracy: 0.4267 - loss: 2.7070 - val_accuracy: 0.6505 - val_loss: 1.6842 - learning_rate: 5.0624e-06
Epoch 92/300
1413/1413 - 224s - 159ms/step - accuracy: 0.4337 - loss: 2.6710 - val_accuracy: 0.6417 - val_loss: 1.6899 - learning_rate: 5.0624e-06
Epoch 93/300
1413/1413 - 220s - 156ms/step - accuracy: 0.4266 - loss: 2.7124 - val_accuracy: 0.6409 - val_loss: 1.7126 - learning_rate: 5.0624e-06
Epoch 94/300
1413/1413 - 224s - 159ms/step - accuracy: 0.4319 - loss: 2.6918 - val_accuracy: 0.6369 - val_loss: 1.6988 - learning_rate: 5.0624e-06
Epoch 95/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4302 - loss: 2.6807 - val_accuracy: 0.6417 - val_loss: 1.6794 - learning_rate: 5.0624e-06
Epoch 96/300
1413/1413 - 227s - 160ms/step - accuracy: 0.4316 - loss: 2.6788 - val_accuracy: 0.6497 - val_loss: 1.6862 - learning_rate: 5.0624e-06
Epoch 97/300
1413/1413 - 220s - 156ms/step - accuracy: 0.4249 - loss: 2.6812 - val_accuracy: 0.6322 - val_loss: 1.7076 - learning_rate: 5.0624e-06
Epoch 98/300

Epoch 98: ReduceLROnPlateau reducing learning rate to 2.531192876631394e-06.
1413/1413 - 223s - 157ms/step - accuracy: 0.4319 - loss: 2.6675 - val_accuracy: 0.6298 - val_loss: 1.6806 - learning_rate: 5.0624e-06
Epoch 99/300
1413/1413 - 221s - 157ms/step - accuracy: 0.4251 - loss: 2.6973 - val_accuracy: 0.6401 - val_loss: 1.6679 - learning_rate: 2.5312e-06
Epoch 100/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4339 - loss: 2.6749 - val_accuracy: 0.6497 - val_loss: 1.6728 - learning_rate: 2.5312e-06
Epoch 101/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4218 - loss: 2.7123 - val_accuracy: 0.6449 - val_loss: 1.6864 - learning_rate: 2.5312e-06
Epoch 102/300
1413/1413 - 220s - 156ms/step - accuracy: 0.4300 - loss: 2.6789 - val_accuracy: 0.6465 - val_loss: 1.6664 - learning_rate: 2.5312e-06
Epoch 103/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4368 - loss: 2.6827 - val_accuracy: 0.6497 - val_loss: 1.6578 - learning_rate: 2.5312e-06
Epoch 104/300
1413/1413 - 219s - 155ms/step - accuracy: 0.4354 - loss: 2.6420 - val_accuracy: 0.6457 - val_loss: 1.6803 - learning_rate: 2.5312e-06
Epoch 105/300
1413/1413 - 221s - 156ms/step - accuracy: 0.4303 - loss: 2.6717 - val_accuracy: 0.6473 - val_loss: 1.6818 - learning_rate: 2.5312e-06
Epoch 106/300
1413/1413 - 221s - 157ms/step - accuracy: 0.4302 - loss: 2.6471 - val_accuracy: 0.6497 - val_loss: 1.6680 - learning_rate: 2.5312e-06
Epoch 107/300
1413/1413 - 220s - 156ms/step - accuracy: 0.4293 - loss: 2.6668 - val_accuracy: 0.6497 - val_loss: 1.6645 - learning_rate: 2.5312e-06
Epoch 108/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4370 - loss: 2.6275 - val_accuracy: 0.6473 - val_loss: 1.6653 - learning_rate: 2.5312e-06
Epoch 109/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4367 - loss: 2.6512 - val_accuracy: 0.6465 - val_loss: 1.6851 - learning_rate: 2.5312e-06
Epoch 110/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4306 - loss: 2.6956 - val_accuracy: 0.6457 - val_loss: 1.6714 - learning_rate: 2.5312e-06
Epoch 111/300

Epoch 111: ReduceLROnPlateau reducing learning rate to 1.265596438315697e-06.
1413/1413 - 222s - 157ms/step - accuracy: 0.4258 - loss: 2.7037 - val_accuracy: 0.6449 - val_loss: 1.6885 - learning_rate: 2.5312e-06
Epoch 112/300
1413/1413 - 228s - 161ms/step - accuracy: 0.4351 - loss: 2.6827 - val_accuracy: 0.6521 - val_loss: 1.6825 - learning_rate: 1.2656e-06
Epoch 113/300
1413/1413 - 221s - 157ms/step - accuracy: 0.4350 - loss: 2.6455 - val_accuracy: 0.6489 - val_loss: 1.6708 - learning_rate: 1.2656e-06
Epoch 114/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4332 - loss: 2.6804 - val_accuracy: 0.6521 - val_loss: 1.6628 - learning_rate: 1.2656e-06
Epoch 115/300
1413/1413 - 224s - 158ms/step - accuracy: 0.4326 - loss: 2.6645 - val_accuracy: 0.6497 - val_loss: 1.6642 - learning_rate: 1.2656e-06
Epoch 116/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4264 - loss: 2.6726 - val_accuracy: 0.6505 - val_loss: 1.6629 - learning_rate: 1.2656e-06
Epoch 117/300
1413/1413 - 221s - 156ms/step - accuracy: 0.4278 - loss: 2.6673 - val_accuracy: 0.6449 - val_loss: 1.6555 - learning_rate: 1.2656e-06
Epoch 118/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4305 - loss: 2.6857 - val_accuracy: 0.6497 - val_loss: 1.6664 - learning_rate: 1.2656e-06
Epoch 119/300
1413/1413 - 220s - 156ms/step - accuracy: 0.4309 - loss: 2.6737 - val_accuracy: 0.6409 - val_loss: 1.6726 - learning_rate: 1.2656e-06
Epoch 120/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4294 - loss: 2.6579 - val_accuracy: 0.6481 - val_loss: 1.6706 - learning_rate: 1.2656e-06
Epoch 121/300
1413/1413 - 221s - 156ms/step - accuracy: 0.4263 - loss: 2.6757 - val_accuracy: 0.6457 - val_loss: 1.6612 - learning_rate: 1.2656e-06
Epoch 122/300
1413/1413 - 224s - 158ms/step - accuracy: 0.4355 - loss: 2.6841 - val_accuracy: 0.6441 - val_loss: 1.6578 - learning_rate: 1.2656e-06
Epoch 123/300
1413/1413 - 221s - 157ms/step - accuracy: 0.4356 - loss: 2.6629 - val_accuracy: 0.6481 - val_loss: 1.6703 - learning_rate: 1.2656e-06
Epoch 124/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4264 - loss: 2.6857 - val_accuracy: 0.6497 - val_loss: 1.6589 - learning_rate: 1.2656e-06
Epoch 125/300

Epoch 125: ReduceLROnPlateau reducing learning rate to 1e-06.
1413/1413 - 220s - 155ms/step - accuracy: 0.4332 - loss: 2.6611 - val_accuracy: 0.6441 - val_loss: 1.6661 - learning_rate: 1.2656e-06
Epoch 126/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4320 - loss: 2.6742 - val_accuracy: 0.6497 - val_loss: 1.6698 - learning_rate: 1.0000e-06
Epoch 127/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4267 - loss: 2.6807 - val_accuracy: 0.6489 - val_loss: 1.6630 - learning_rate: 1.0000e-06
Epoch 128/300
1413/1413 - 224s - 158ms/step - accuracy: 0.4308 - loss: 2.6548 - val_accuracy: 0.6473 - val_loss: 1.6617 - learning_rate: 1.0000e-06
Epoch 129/300
1413/1413 - 221s - 157ms/step - accuracy: 0.4265 - loss: 2.6746 - val_accuracy: 0.6521 - val_loss: 1.6677 - learning_rate: 1.0000e-06
Epoch 130/300
1413/1413 - 225s - 160ms/step - accuracy: 0.4373 - loss: 2.6653 - val_accuracy: 0.6489 - val_loss: 1.6746 - learning_rate: 1.0000e-06
Epoch 131/300
1413/1413 - 218s - 154ms/step - accuracy: 0.4317 - loss: 2.6619 - val_accuracy: 0.6529 - val_loss: 1.6658 - learning_rate: 1.0000e-06
Epoch 132/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4368 - loss: 2.6304 - val_accuracy: 0.6521 - val_loss: 1.6590 - learning_rate: 1.0000e-06
Epoch 133/300
1413/1413 - 219s - 155ms/step - accuracy: 0.4338 - loss: 2.6708 - val_accuracy: 0.6489 - val_loss: 1.6714 - learning_rate: 1.0000e-06
Epoch 133: early stopping
Restoring model weights from the end of the best epoch: 117.
Fold 2 Evaluation results: [1.6547132730484009, 0.6449044346809387]
              precision    recall  f1-score   support

        1820       0.82      0.85      0.83        62
        1821       0.85      0.81      0.83        57
        1822       0.00      0.00      0.00         1
        1823       0.00      0.00      0.00         2
        1824       0.00      0.00      0.00         1
        1825       0.00      0.00      0.00         2
        1826       0.00      0.00      0.00         3
        1827       0.86      0.76      0.81        25
        1828       0.00      0.00      0.00         1
        1829       0.56      1.00      0.71         5
        1830       0.69      0.52      0.59        56
        1831       0.82      0.87      0.85       134
        1832       0.71      0.85      0.77        68
        1833       0.94      0.84      0.89        19
        1834       0.60      0.83      0.70        29
        1835       0.00      0.00      0.00         2
        1836       0.00      0.00      0.00         3
        1837       0.25      0.14      0.18         7
        1838       0.50      0.25      0.33         4
        1839       0.00      0.00      0.00         0
        1840       0.61      0.63      0.62        43
        1841       0.76      0.69      0.72       108
        1842       0.67      0.40      0.50         5
        1843       1.00      0.17      0.29         6
        1844       0.00      0.00      0.00         1
        1845       0.00      0.00      0.00         1
        1846       0.44      0.67      0.53         6
        1847       0.00      0.00      0.00         2
        1848       0.33      0.17      0.22         6
        1849       0.38      0.60      0.46         5
        1850       0.49      0.62      0.55        48
        1851       0.78      0.68      0.72        77
        1852       0.00      0.00      0.00         7
        1853       0.00      0.00      0.00         6
        1854       0.00      0.00      0.00         2
        1855       0.62      0.42      0.50        24
        1856       0.47      0.58      0.52        12
        1857       0.54      0.65      0.59        31
        1858       0.00      0.00      0.00         2
        1859       0.00      0.00      0.00         3
        1860       0.31      0.31      0.31        64
        1861       0.78      0.82      0.80        85
        1862       0.43      0.53      0.48        19
        1863       0.50      0.50      0.50        18
        1864       0.36      0.29      0.32        17
        1865       0.60      1.00      0.75         6
        1866       0.00      0.00      0.00         5
        1867       0.31      0.45      0.37        11
        1868       0.00      0.00      0.00         8
        1869       0.00      0.00      0.00         5
        1870       0.41      0.63      0.50        30
        1871       0.75      0.88      0.81        49
        1872       0.60      0.43      0.50         7
        1873       0.14      0.10      0.12        10
        1874       0.00      0.00      0.00         5
        1875       0.29      0.36      0.32        14
        1876       0.80      0.80      0.80        10
        1877       0.40      0.33      0.36         6
        1878       0.44      0.44      0.44         9
        1879       0.00      0.00      0.00         2

    accuracy                           0.64      1256
   macro avg       0.36      0.36      0.35      1256
weighted avg       0.63      0.64      0.63      1256

Matthews Correlation Coefficient: 0.627
Macro avg F1: 0.352
Weighted avg F1: 0.632
Micro avg F1: 0.645
Top-3 Accuracy: 0.864
Top-5 Accuracy: 0.905
Micro ROC AUC  = 0.99
Macro ROC AUC (present classes) = 0.98
Classification MAE (in years): 2.98

Fold 2 Misclassification Analysis:
Near misses (within 2 years): 124 out of 446 misclassifications (27.80%)
Big misses (greater than 10 years): 202
MAE with outliers: 2.98
MAE without outliers: 1.95 (improvement: 1.03)

10 Worst misclassifications:
Image: data/datasets/public/1820/1820_020met.jpg, True: 1820, Predicted: 1876, Error: 56
Image: data/datasets/private/1820/1825_040_Zrzut ekranu 2022-07-26 211114.png, True: 1825, Predicted: 1878, Error: 53
Image: data/datasets/private/1830/1830_74etsy.jpg, True: 1830, Predicted: 1875, Error: 45
Image: data/datasets/public/1870/1876_1953vna.jpg, True: 1876, Predicted: 1832, Error: 44
Image: data/datasets/public/1830/1832_1087vna.jpg, True: 1832, Predicted: 1876, Error: 44
Image: data/datasets/public/1820/1823_53vna.jpg, True: 1823, Predicted: 1865, Error: 42
Image: data/datasets/public/1860/1862_1622vna.jpg, True: 1862, Predicted: 1820, Error: 42
Image: data/datasets/public/1860/1862_22washington.jpg, True: 1862, Predicted: 1820, Error: 42
Image: data/datasets/private/1820/1820_039_Zrzut ekranu 2022-07-26 211152.png, True: 1820, Predicted: 1860, Error: 40
Image: data/datasets/public/1820/1820_019met.jpg, True: 1820, Predicted: 1860, Error: 40

===== Fold 3 =====

===== Fine Tuning 7 layers! =====
Epoch 1/300
1413/1413 - 244s - 173ms/step - accuracy: 0.1230 - loss: 4.6381 - val_accuracy: 0.1640 - val_loss: 4.9664 - learning_rate: 1.6200e-04
Epoch 2/300
1413/1413 - 223s - 158ms/step - accuracy: 0.1953 - loss: 3.9992 - val_accuracy: 0.2174 - val_loss: 4.6928 - learning_rate: 1.6200e-04
Epoch 3/300
1413/1413 - 219s - 155ms/step - accuracy: 0.2245 - loss: 3.8045 - val_accuracy: 0.2930 - val_loss: 4.1604 - learning_rate: 1.6200e-04
Epoch 4/300
1413/1413 - 223s - 158ms/step - accuracy: 0.2435 - loss: 3.6759 - val_accuracy: 0.1998 - val_loss: 4.8704 - learning_rate: 1.6200e-04
Epoch 5/300
1413/1413 - 222s - 157ms/step - accuracy: 0.2555 - loss: 3.6229 - val_accuracy: 0.2564 - val_loss: 3.8672 - learning_rate: 1.6200e-04
Epoch 6/300
1413/1413 - 221s - 157ms/step - accuracy: 0.2651 - loss: 3.5587 - val_accuracy: 0.1935 - val_loss: 4.4987 - learning_rate: 1.6200e-04
Epoch 7/300
1413/1413 - 225s - 159ms/step - accuracy: 0.2683 - loss: 3.5324 - val_accuracy: 0.3511 - val_loss: 3.1419 - learning_rate: 1.6200e-04
Epoch 8/300
1413/1413 - 222s - 157ms/step - accuracy: 0.2835 - loss: 3.4483 - val_accuracy: 0.4188 - val_loss: 2.8571 - learning_rate: 1.6200e-04
Epoch 9/300
1413/1413 - 224s - 159ms/step - accuracy: 0.2930 - loss: 3.3990 - val_accuracy: 0.3957 - val_loss: 2.8743 - learning_rate: 1.6200e-04
Epoch 10/300
1413/1413 - 220s - 156ms/step - accuracy: 0.2949 - loss: 3.3803 - val_accuracy: 0.3989 - val_loss: 2.9260 - learning_rate: 1.6200e-04
Epoch 11/300
1413/1413 - 225s - 159ms/step - accuracy: 0.3028 - loss: 3.3573 - val_accuracy: 0.4682 - val_loss: 2.7362 - learning_rate: 1.6200e-04
Epoch 12/300
1413/1413 - 223s - 158ms/step - accuracy: 0.3040 - loss: 3.3278 - val_accuracy: 0.2046 - val_loss: 4.4086 - learning_rate: 1.6200e-04
Epoch 13/300
1413/1413 - 266s - 188ms/step - accuracy: 0.3109 - loss: 3.2997 - val_accuracy: 0.4713 - val_loss: 2.4662 - learning_rate: 1.6200e-04
Epoch 14/300
1413/1413 - 226s - 160ms/step - accuracy: 0.3189 - loss: 3.2503 - val_accuracy: 0.3822 - val_loss: 3.3028 - learning_rate: 1.6200e-04
Epoch 15/300
1413/1413 - 224s - 159ms/step - accuracy: 0.3196 - loss: 3.2626 - val_accuracy: 0.4697 - val_loss: 2.3699 - learning_rate: 1.6200e-04
Epoch 16/300
1413/1413 - 226s - 160ms/step - accuracy: 0.3249 - loss: 3.2577 - val_accuracy: 0.4490 - val_loss: 2.7950 - learning_rate: 1.6200e-04
Epoch 17/300
1413/1413 - 225s - 159ms/step - accuracy: 0.3254 - loss: 3.2393 - val_accuracy: 0.3662 - val_loss: 2.9945 - learning_rate: 1.6200e-04
Epoch 18/300
1413/1413 - 222s - 157ms/step - accuracy: 0.3232 - loss: 3.2028 - val_accuracy: 0.4530 - val_loss: 2.6589 - learning_rate: 1.6200e-04
Epoch 19/300
1413/1413 - 223s - 158ms/step - accuracy: 0.3335 - loss: 3.1744 - val_accuracy: 0.3392 - val_loss: 2.9248 - learning_rate: 1.6200e-04
Epoch 20/300
1413/1413 - 224s - 159ms/step - accuracy: 0.3342 - loss: 3.1482 - val_accuracy: 0.4260 - val_loss: 2.4984 - learning_rate: 1.6200e-04
Epoch 21/300
1413/1413 - 229s - 162ms/step - accuracy: 0.3391 - loss: 3.1535 - val_accuracy: 0.5151 - val_loss: 2.2106 - learning_rate: 1.6200e-04
Epoch 22/300
1413/1413 - 220s - 156ms/step - accuracy: 0.3401 - loss: 3.1308 - val_accuracy: 0.5048 - val_loss: 2.3058 - learning_rate: 1.6200e-04
Epoch 23/300
1413/1413 - 225s - 159ms/step - accuracy: 0.3435 - loss: 3.1260 - val_accuracy: 0.4825 - val_loss: 2.5698 - learning_rate: 1.6200e-04
Epoch 24/300
1413/1413 - 224s - 158ms/step - accuracy: 0.3427 - loss: 3.1357 - val_accuracy: 0.4522 - val_loss: 2.6701 - learning_rate: 1.6200e-04
Epoch 25/300
1413/1413 - 224s - 159ms/step - accuracy: 0.3449 - loss: 3.0969 - val_accuracy: 0.4156 - val_loss: 2.7249 - learning_rate: 1.6200e-04
Epoch 26/300
1413/1413 - 237s - 167ms/step - accuracy: 0.3448 - loss: 3.0885 - val_accuracy: 0.4140 - val_loss: 2.6926 - learning_rate: 1.6200e-04
Epoch 27/300
1413/1413 - 239s - 169ms/step - accuracy: 0.3502 - loss: 3.0750 - val_accuracy: 0.4498 - val_loss: 2.6273 - learning_rate: 1.6200e-04
Epoch 28/300
1413/1413 - 235s - 166ms/step - accuracy: 0.3524 - loss: 3.0732 - val_accuracy: 0.4124 - val_loss: 2.7907 - learning_rate: 1.6200e-04
Epoch 29/300

Epoch 29: ReduceLROnPlateau reducing learning rate to 8.099817205220461e-05.
1413/1413 - 240s - 170ms/step - accuracy: 0.3550 - loss: 3.0467 - val_accuracy: 0.3432 - val_loss: 3.4609 - learning_rate: 1.6200e-04
Epoch 30/300
1413/1413 - 231s - 164ms/step - accuracy: 0.3725 - loss: 2.9699 - val_accuracy: 0.5175 - val_loss: 2.1991 - learning_rate: 8.0998e-05
Epoch 31/300
1413/1413 - 238s - 169ms/step - accuracy: 0.3710 - loss: 2.9674 - val_accuracy: 0.5446 - val_loss: 2.3296 - learning_rate: 8.0998e-05
Epoch 32/300
1413/1413 - 240s - 170ms/step - accuracy: 0.3754 - loss: 2.9517 - val_accuracy: 0.5183 - val_loss: 2.1905 - learning_rate: 8.0998e-05
Epoch 33/300
1413/1413 - 240s - 170ms/step - accuracy: 0.3803 - loss: 2.9299 - val_accuracy: 0.5119 - val_loss: 2.2952 - learning_rate: 8.0998e-05
Epoch 34/300
1413/1413 - 239s - 169ms/step - accuracy: 0.3789 - loss: 2.9439 - val_accuracy: 0.5096 - val_loss: 2.7054 - learning_rate: 8.0998e-05
Epoch 35/300
1413/1413 - 234s - 166ms/step - accuracy: 0.3780 - loss: 2.9382 - val_accuracy: 0.5518 - val_loss: 2.1870 - learning_rate: 8.0998e-05
Epoch 36/300
1413/1413 - 239s - 169ms/step - accuracy: 0.3741 - loss: 2.9288 - val_accuracy: 0.4674 - val_loss: 2.2865 - learning_rate: 8.0998e-05
Epoch 37/300
1413/1413 - 235s - 167ms/step - accuracy: 0.3819 - loss: 2.9422 - val_accuracy: 0.4443 - val_loss: 2.9029 - learning_rate: 8.0998e-05
Epoch 38/300
1413/1413 - 240s - 170ms/step - accuracy: 0.3834 - loss: 2.9114 - val_accuracy: 0.5932 - val_loss: 1.8921 - learning_rate: 8.0998e-05
Epoch 39/300
1413/1413 - 235s - 166ms/step - accuracy: 0.3800 - loss: 2.9100 - val_accuracy: 0.5438 - val_loss: 2.0378 - learning_rate: 8.0998e-05
Epoch 40/300
1413/1413 - 241s - 170ms/step - accuracy: 0.3875 - loss: 2.8673 - val_accuracy: 0.5661 - val_loss: 2.1377 - learning_rate: 8.0998e-05
Epoch 41/300
1413/1413 - 235s - 166ms/step - accuracy: 0.3924 - loss: 2.8899 - val_accuracy: 0.4873 - val_loss: 2.3679 - learning_rate: 8.0998e-05
Epoch 42/300
1413/1413 - 239s - 169ms/step - accuracy: 0.3918 - loss: 2.8775 - val_accuracy: 0.6043 - val_loss: 1.9235 - learning_rate: 8.0998e-05
Epoch 43/300
1413/1413 - 234s - 166ms/step - accuracy: 0.3877 - loss: 2.8924 - val_accuracy: 0.5908 - val_loss: 1.8711 - learning_rate: 8.0998e-05
Epoch 44/300
1413/1413 - 234s - 166ms/step - accuracy: 0.3882 - loss: 2.8921 - val_accuracy: 0.5740 - val_loss: 2.0549 - learning_rate: 8.0998e-05
Epoch 45/300
1413/1413 - 240s - 170ms/step - accuracy: 0.3877 - loss: 2.8926 - val_accuracy: 0.5685 - val_loss: 1.8147 - learning_rate: 8.0998e-05
Epoch 46/300
1413/1413 - 235s - 167ms/step - accuracy: 0.3858 - loss: 2.8746 - val_accuracy: 0.5231 - val_loss: 2.3102 - learning_rate: 8.0998e-05
Epoch 47/300
1413/1413 - 231s - 164ms/step - accuracy: 0.3994 - loss: 2.8473 - val_accuracy: 0.5701 - val_loss: 2.0069 - learning_rate: 8.0998e-05
Epoch 48/300
1413/1413 - 234s - 166ms/step - accuracy: 0.3924 - loss: 2.8672 - val_accuracy: 0.5223 - val_loss: 2.3421 - learning_rate: 8.0998e-05
Epoch 49/300
1413/1413 - 239s - 169ms/step - accuracy: 0.3969 - loss: 2.8482 - val_accuracy: 0.4833 - val_loss: 2.3660 - learning_rate: 8.0998e-05
Epoch 50/300
1413/1413 - 239s - 169ms/step - accuracy: 0.3972 - loss: 2.8661 - val_accuracy: 0.5502 - val_loss: 2.0688 - learning_rate: 8.0998e-05
Epoch 51/300
1413/1413 - 235s - 166ms/step - accuracy: 0.3881 - loss: 2.8578 - val_accuracy: 0.5430 - val_loss: 2.0567 - learning_rate: 8.0998e-05
Epoch 52/300
1413/1413 - 235s - 166ms/step - accuracy: 0.3949 - loss: 2.8288 - val_accuracy: 0.5732 - val_loss: 1.9250 - learning_rate: 8.0998e-05
Epoch 53/300
1413/1413 - 235s - 167ms/step - accuracy: 0.3993 - loss: 2.8402 - val_accuracy: 0.6035 - val_loss: 1.8139 - learning_rate: 8.0998e-05
Epoch 54/300
1413/1413 - 238s - 168ms/step - accuracy: 0.4033 - loss: 2.8058 - val_accuracy: 0.5764 - val_loss: 1.9897 - learning_rate: 8.0998e-05
Epoch 55/300
1413/1413 - 236s - 167ms/step - accuracy: 0.3988 - loss: 2.8377 - val_accuracy: 0.5326 - val_loss: 2.3747 - learning_rate: 8.0998e-05
Epoch 56/300
1413/1413 - 238s - 168ms/step - accuracy: 0.3916 - loss: 2.8424 - val_accuracy: 0.5175 - val_loss: 2.4565 - learning_rate: 8.0998e-05
Epoch 57/300
1413/1413 - 234s - 166ms/step - accuracy: 0.3946 - loss: 2.8532 - val_accuracy: 0.6162 - val_loss: 1.7905 - learning_rate: 8.0998e-05
Epoch 58/300
1413/1413 - 235s - 166ms/step - accuracy: 0.4018 - loss: 2.8108 - val_accuracy: 0.6218 - val_loss: 1.7205 - learning_rate: 8.0998e-05
Epoch 59/300
1413/1413 - 238s - 169ms/step - accuracy: 0.4015 - loss: 2.8251 - val_accuracy: 0.5693 - val_loss: 1.8856 - learning_rate: 8.0998e-05
Epoch 60/300
1413/1413 - 235s - 166ms/step - accuracy: 0.3987 - loss: 2.8346 - val_accuracy: 0.5947 - val_loss: 1.9561 - learning_rate: 8.0998e-05
Epoch 61/300
1413/1413 - 240s - 170ms/step - accuracy: 0.4017 - loss: 2.8092 - val_accuracy: 0.5844 - val_loss: 1.9560 - learning_rate: 8.0998e-05
Epoch 62/300
1413/1413 - 235s - 166ms/step - accuracy: 0.3996 - loss: 2.8187 - val_accuracy: 0.5271 - val_loss: 2.2710 - learning_rate: 8.0998e-05
Epoch 63/300
1413/1413 - 237s - 167ms/step - accuracy: 0.4023 - loss: 2.7883 - val_accuracy: 0.4562 - val_loss: 2.6098 - learning_rate: 8.0998e-05
Epoch 64/300
1413/1413 - 240s - 170ms/step - accuracy: 0.4053 - loss: 2.7891 - val_accuracy: 0.5677 - val_loss: 2.0717 - learning_rate: 8.0998e-05
Epoch 65/300
1413/1413 - 235s - 166ms/step - accuracy: 0.4127 - loss: 2.7702 - val_accuracy: 0.5494 - val_loss: 2.2329 - learning_rate: 8.0998e-05
Epoch 66/300

Epoch 66: ReduceLROnPlateau reducing learning rate to 4.0499086026102304e-05.
1413/1413 - 240s - 170ms/step - accuracy: 0.4037 - loss: 2.8185 - val_accuracy: 0.5884 - val_loss: 1.9637 - learning_rate: 8.0998e-05
Epoch 67/300
1413/1413 - 232s - 164ms/step - accuracy: 0.4159 - loss: 2.7644 - val_accuracy: 0.6441 - val_loss: 1.7335 - learning_rate: 4.0499e-05
Epoch 68/300
1413/1413 - 237s - 168ms/step - accuracy: 0.4137 - loss: 2.7472 - val_accuracy: 0.6481 - val_loss: 1.6522 - learning_rate: 4.0499e-05
Epoch 69/300
1413/1413 - 236s - 167ms/step - accuracy: 0.4140 - loss: 2.7464 - val_accuracy: 0.6146 - val_loss: 1.7318 - learning_rate: 4.0499e-05
Epoch 70/300
1413/1413 - 237s - 168ms/step - accuracy: 0.4136 - loss: 2.7292 - val_accuracy: 0.6401 - val_loss: 1.6077 - learning_rate: 4.0499e-05
Epoch 71/300
1413/1413 - 235s - 166ms/step - accuracy: 0.4107 - loss: 2.7559 - val_accuracy: 0.6226 - val_loss: 1.8318 - learning_rate: 4.0499e-05
Epoch 72/300
1413/1413 - 236s - 167ms/step - accuracy: 0.4187 - loss: 2.7259 - val_accuracy: 0.6521 - val_loss: 1.6127 - learning_rate: 4.0499e-05
Epoch 73/300
1413/1413 - 235s - 166ms/step - accuracy: 0.4235 - loss: 2.7031 - val_accuracy: 0.5900 - val_loss: 1.9894 - learning_rate: 4.0499e-05
Epoch 74/300
1413/1413 - 235s - 166ms/step - accuracy: 0.4216 - loss: 2.7340 - val_accuracy: 0.6146 - val_loss: 1.7333 - learning_rate: 4.0499e-05
Epoch 75/300
1413/1413 - 240s - 170ms/step - accuracy: 0.4173 - loss: 2.7479 - val_accuracy: 0.6409 - val_loss: 1.6599 - learning_rate: 4.0499e-05
Epoch 76/300
1413/1413 - 237s - 168ms/step - accuracy: 0.4175 - loss: 2.7187 - val_accuracy: 0.6107 - val_loss: 1.7533 - learning_rate: 4.0499e-05
Epoch 77/300
1413/1413 - 235s - 167ms/step - accuracy: 0.4251 - loss: 2.6984 - val_accuracy: 0.6139 - val_loss: 1.8761 - learning_rate: 4.0499e-05
Epoch 78/300

Epoch 78: ReduceLROnPlateau reducing learning rate to 2.0249543013051152e-05.
1413/1413 - 237s - 168ms/step - accuracy: 0.4231 - loss: 2.7314 - val_accuracy: 0.6330 - val_loss: 1.7146 - learning_rate: 4.0499e-05
Epoch 79/300
1413/1413 - 239s - 169ms/step - accuracy: 0.4269 - loss: 2.6848 - val_accuracy: 0.6425 - val_loss: 1.6440 - learning_rate: 2.0250e-05
Epoch 80/300
1413/1413 - 235s - 167ms/step - accuracy: 0.4282 - loss: 2.6765 - val_accuracy: 0.6497 - val_loss: 1.6097 - learning_rate: 2.0250e-05
Epoch 81/300
1413/1413 - 237s - 168ms/step - accuracy: 0.4252 - loss: 2.6805 - val_accuracy: 0.6624 - val_loss: 1.5949 - learning_rate: 2.0250e-05
Epoch 82/300
1413/1413 - 235s - 167ms/step - accuracy: 0.4362 - loss: 2.6705 - val_accuracy: 0.6330 - val_loss: 1.6622 - learning_rate: 2.0250e-05
Epoch 83/300
1413/1413 - 236s - 167ms/step - accuracy: 0.4254 - loss: 2.6933 - val_accuracy: 0.6393 - val_loss: 1.6330 - learning_rate: 2.0250e-05
Epoch 84/300
1413/1413 - 240s - 170ms/step - accuracy: 0.4299 - loss: 2.6600 - val_accuracy: 0.6489 - val_loss: 1.5796 - learning_rate: 2.0250e-05
Epoch 85/300
1413/1413 - 235s - 166ms/step - accuracy: 0.4271 - loss: 2.6635 - val_accuracy: 0.6505 - val_loss: 1.6664 - learning_rate: 2.0250e-05
Epoch 86/300
1413/1413 - 238s - 169ms/step - accuracy: 0.4248 - loss: 2.6689 - val_accuracy: 0.6624 - val_loss: 1.5167 - learning_rate: 2.0250e-05
Epoch 87/300
1413/1413 - 232s - 164ms/step - accuracy: 0.4233 - loss: 2.6898 - val_accuracy: 0.6401 - val_loss: 1.6095 - learning_rate: 2.0250e-05
Epoch 88/300
1413/1413 - 238s - 168ms/step - accuracy: 0.4351 - loss: 2.6450 - val_accuracy: 0.6457 - val_loss: 1.5828 - learning_rate: 2.0250e-05
Epoch 89/300
1413/1413 - 236s - 167ms/step - accuracy: 0.4336 - loss: 2.6584 - val_accuracy: 0.6465 - val_loss: 1.5524 - learning_rate: 2.0250e-05
Epoch 90/300
1413/1413 - 237s - 167ms/step - accuracy: 0.4331 - loss: 2.6578 - val_accuracy: 0.6521 - val_loss: 1.5665 - learning_rate: 2.0250e-05
Epoch 91/300
1413/1413 - 236s - 167ms/step - accuracy: 0.4287 - loss: 2.6462 - val_accuracy: 0.6505 - val_loss: 1.5784 - learning_rate: 2.0250e-05
Epoch 92/300
1413/1413 - 232s - 164ms/step - accuracy: 0.4286 - loss: 2.6572 - val_accuracy: 0.6258 - val_loss: 1.7497 - learning_rate: 2.0250e-05
Epoch 93/300
1413/1413 - 244s - 173ms/step - accuracy: 0.4292 - loss: 2.6674 - val_accuracy: 0.6592 - val_loss: 1.5364 - learning_rate: 2.0250e-05
Epoch 94/300

Epoch 94: ReduceLROnPlateau reducing learning rate to 1.0124771506525576e-05.
1413/1413 - 243s - 172ms/step - accuracy: 0.4335 - loss: 2.6635 - val_accuracy: 0.6576 - val_loss: 1.5805 - learning_rate: 2.0250e-05
Epoch 95/300
1413/1413 - 239s - 169ms/step - accuracy: 0.4344 - loss: 2.6526 - val_accuracy: 0.6656 - val_loss: 1.5549 - learning_rate: 1.0125e-05
Epoch 96/300
1413/1413 - 244s - 173ms/step - accuracy: 0.4411 - loss: 2.6278 - val_accuracy: 0.6720 - val_loss: 1.4977 - learning_rate: 1.0125e-05
Epoch 97/300
1413/1413 - 234s - 166ms/step - accuracy: 0.4332 - loss: 2.6483 - val_accuracy: 0.6672 - val_loss: 1.5296 - learning_rate: 1.0125e-05
Epoch 98/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4364 - loss: 2.6387 - val_accuracy: 0.6624 - val_loss: 1.5090 - learning_rate: 1.0125e-05
Epoch 99/300
1413/1413 - 230s - 162ms/step - accuracy: 0.4387 - loss: 2.6417 - val_accuracy: 0.6688 - val_loss: 1.4779 - learning_rate: 1.0125e-05
Epoch 100/300
1413/1413 - 228s - 161ms/step - accuracy: 0.4414 - loss: 2.6243 - val_accuracy: 0.6624 - val_loss: 1.5418 - learning_rate: 1.0125e-05
Epoch 101/300
1413/1413 - 228s - 161ms/step - accuracy: 0.4385 - loss: 2.6385 - val_accuracy: 0.6696 - val_loss: 1.4804 - learning_rate: 1.0125e-05
Epoch 102/300
1413/1413 - 224s - 159ms/step - accuracy: 0.4402 - loss: 2.6291 - val_accuracy: 0.6712 - val_loss: 1.4915 - learning_rate: 1.0125e-05
Epoch 103/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4411 - loss: 2.6422 - val_accuracy: 0.6656 - val_loss: 1.5189 - learning_rate: 1.0125e-05
Epoch 104/300
1413/1413 - 228s - 161ms/step - accuracy: 0.4423 - loss: 2.6146 - val_accuracy: 0.6632 - val_loss: 1.5502 - learning_rate: 1.0125e-05
Epoch 105/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4382 - loss: 2.6312 - val_accuracy: 0.6672 - val_loss: 1.5513 - learning_rate: 1.0125e-05
Epoch 106/300
1413/1413 - 228s - 161ms/step - accuracy: 0.4394 - loss: 2.6214 - val_accuracy: 0.6704 - val_loss: 1.4824 - learning_rate: 1.0125e-05
Epoch 107/300

Epoch 107: ReduceLROnPlateau reducing learning rate to 5.062385753262788e-06.
1413/1413 - 225s - 160ms/step - accuracy: 0.4394 - loss: 2.6297 - val_accuracy: 0.6712 - val_loss: 1.5047 - learning_rate: 1.0125e-05
Epoch 108/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4468 - loss: 2.5757 - val_accuracy: 0.6720 - val_loss: 1.4932 - learning_rate: 5.0624e-06
Epoch 109/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4329 - loss: 2.6262 - val_accuracy: 0.6736 - val_loss: 1.4870 - learning_rate: 5.0624e-06
Epoch 110/300
1413/1413 - 230s - 163ms/step - accuracy: 0.4408 - loss: 2.6154 - val_accuracy: 0.6839 - val_loss: 1.4711 - learning_rate: 5.0624e-06
Epoch 111/300
1413/1413 - 230s - 163ms/step - accuracy: 0.4413 - loss: 2.6112 - val_accuracy: 0.6839 - val_loss: 1.4646 - learning_rate: 5.0624e-06
Epoch 112/300
1413/1413 - 227s - 161ms/step - accuracy: 0.4398 - loss: 2.6103 - val_accuracy: 0.6799 - val_loss: 1.4634 - learning_rate: 5.0624e-06
Epoch 113/300
1413/1413 - 230s - 163ms/step - accuracy: 0.4476 - loss: 2.5913 - val_accuracy: 0.6712 - val_loss: 1.4959 - learning_rate: 5.0624e-06
Epoch 114/300
1413/1413 - 227s - 161ms/step - accuracy: 0.4453 - loss: 2.5793 - val_accuracy: 0.6768 - val_loss: 1.4791 - learning_rate: 5.0624e-06
Epoch 115/300
1413/1413 - 230s - 163ms/step - accuracy: 0.4536 - loss: 2.5781 - val_accuracy: 0.6783 - val_loss: 1.4759 - learning_rate: 5.0624e-06
Epoch 116/300
1413/1413 - 230s - 163ms/step - accuracy: 0.4466 - loss: 2.6028 - val_accuracy: 0.6720 - val_loss: 1.4758 - learning_rate: 5.0624e-06
Epoch 117/300
1413/1413 - 230s - 163ms/step - accuracy: 0.4412 - loss: 2.5893 - val_accuracy: 0.6712 - val_loss: 1.4944 - learning_rate: 5.0624e-06
Epoch 118/300
1413/1413 - 227s - 161ms/step - accuracy: 0.4446 - loss: 2.6094 - val_accuracy: 0.6712 - val_loss: 1.4885 - learning_rate: 5.0624e-06
Epoch 119/300
1413/1413 - 228s - 161ms/step - accuracy: 0.4406 - loss: 2.6157 - val_accuracy: 0.6791 - val_loss: 1.4924 - learning_rate: 5.0624e-06
Epoch 120/300

Epoch 120: ReduceLROnPlateau reducing learning rate to 2.531192876631394e-06.
1413/1413 - 227s - 161ms/step - accuracy: 0.4417 - loss: 2.6249 - val_accuracy: 0.6720 - val_loss: 1.5008 - learning_rate: 5.0624e-06
Epoch 121/300
1413/1413 - 227s - 160ms/step - accuracy: 0.4391 - loss: 2.6251 - val_accuracy: 0.6823 - val_loss: 1.4708 - learning_rate: 2.5312e-06
Epoch 122/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4467 - loss: 2.5734 - val_accuracy: 0.6760 - val_loss: 1.4588 - learning_rate: 2.5312e-06
Epoch 123/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4379 - loss: 2.6052 - val_accuracy: 0.6807 - val_loss: 1.4642 - learning_rate: 2.5312e-06
Epoch 124/300
1413/1413 - 227s - 160ms/step - accuracy: 0.4463 - loss: 2.5927 - val_accuracy: 0.6736 - val_loss: 1.4807 - learning_rate: 2.5312e-06
Epoch 125/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4414 - loss: 2.5963 - val_accuracy: 0.6720 - val_loss: 1.4856 - learning_rate: 2.5312e-06
Epoch 126/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4428 - loss: 2.6170 - val_accuracy: 0.6823 - val_loss: 1.4698 - learning_rate: 2.5312e-06
Epoch 127/300
1413/1413 - 227s - 160ms/step - accuracy: 0.4488 - loss: 2.6050 - val_accuracy: 0.6783 - val_loss: 1.4652 - learning_rate: 2.5312e-06
Epoch 128/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4480 - loss: 2.6039 - val_accuracy: 0.6736 - val_loss: 1.4556 - learning_rate: 2.5312e-06
Epoch 129/300
1413/1413 - 228s - 161ms/step - accuracy: 0.4493 - loss: 2.6050 - val_accuracy: 0.6768 - val_loss: 1.4858 - learning_rate: 2.5312e-06
Epoch 130/300
1413/1413 - 225s - 160ms/step - accuracy: 0.4391 - loss: 2.6149 - val_accuracy: 0.6775 - val_loss: 1.4736 - learning_rate: 2.5312e-06
Epoch 131/300
1413/1413 - 221s - 157ms/step - accuracy: 0.4495 - loss: 2.5993 - val_accuracy: 0.6791 - val_loss: 1.4708 - learning_rate: 2.5312e-06
Epoch 132/300
1413/1413 - 231s - 163ms/step - accuracy: 0.4495 - loss: 2.5903 - val_accuracy: 0.6768 - val_loss: 1.5040 - learning_rate: 2.5312e-06
Epoch 133/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4491 - loss: 2.5838 - val_accuracy: 0.6752 - val_loss: 1.4784 - learning_rate: 2.5312e-06
Epoch 134/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4394 - loss: 2.6390 - val_accuracy: 0.6768 - val_loss: 1.4639 - learning_rate: 2.5312e-06
Epoch 135/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4438 - loss: 2.6170 - val_accuracy: 0.6799 - val_loss: 1.4590 - learning_rate: 2.5312e-06
Epoch 136/300

Epoch 136: ReduceLROnPlateau reducing learning rate to 1.265596438315697e-06.
1413/1413 - 224s - 159ms/step - accuracy: 0.4521 - loss: 2.5716 - val_accuracy: 0.6775 - val_loss: 1.4674 - learning_rate: 2.5312e-06
Epoch 137/300
1413/1413 - 227s - 161ms/step - accuracy: 0.4428 - loss: 2.5928 - val_accuracy: 0.6768 - val_loss: 1.4614 - learning_rate: 1.2656e-06
Epoch 138/300
1413/1413 - 228s - 161ms/step - accuracy: 0.4366 - loss: 2.6257 - val_accuracy: 0.6783 - val_loss: 1.4630 - learning_rate: 1.2656e-06
Epoch 139/300
1413/1413 - 228s - 161ms/step - accuracy: 0.4434 - loss: 2.6050 - val_accuracy: 0.6791 - val_loss: 1.4732 - learning_rate: 1.2656e-06
Epoch 140/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4493 - loss: 2.6038 - val_accuracy: 0.6783 - val_loss: 1.4809 - learning_rate: 1.2656e-06
Epoch 141/300
1413/1413 - 227s - 161ms/step - accuracy: 0.4519 - loss: 2.5778 - val_accuracy: 0.6752 - val_loss: 1.4693 - learning_rate: 1.2656e-06
Epoch 142/300
1413/1413 - 227s - 161ms/step - accuracy: 0.4450 - loss: 2.5809 - val_accuracy: 0.6768 - val_loss: 1.4687 - learning_rate: 1.2656e-06
Epoch 143/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4475 - loss: 2.5821 - val_accuracy: 0.6807 - val_loss: 1.4532 - learning_rate: 1.2656e-06
Epoch 144/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4456 - loss: 2.6134 - val_accuracy: 0.6799 - val_loss: 1.4629 - learning_rate: 1.2656e-06
Epoch 145/300
1413/1413 - 224s - 159ms/step - accuracy: 0.4502 - loss: 2.5770 - val_accuracy: 0.6855 - val_loss: 1.4614 - learning_rate: 1.2656e-06
Epoch 146/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4448 - loss: 2.5936 - val_accuracy: 0.6831 - val_loss: 1.4609 - learning_rate: 1.2656e-06
Epoch 147/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4478 - loss: 2.5821 - val_accuracy: 0.6760 - val_loss: 1.4640 - learning_rate: 1.2656e-06
Epoch 148/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4497 - loss: 2.6043 - val_accuracy: 0.6783 - val_loss: 1.4558 - learning_rate: 1.2656e-06
Epoch 149/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4486 - loss: 2.5956 - val_accuracy: 0.6791 - val_loss: 1.4636 - learning_rate: 1.2656e-06
Epoch 150/300
1413/1413 - 221s - 157ms/step - accuracy: 0.4406 - loss: 2.6083 - val_accuracy: 0.6815 - val_loss: 1.4490 - learning_rate: 1.2656e-06
Epoch 151/300
1413/1413 - 228s - 161ms/step - accuracy: 0.4481 - loss: 2.5828 - val_accuracy: 0.6775 - val_loss: 1.4679 - learning_rate: 1.2656e-06
Epoch 152/300
1413/1413 - 227s - 160ms/step - accuracy: 0.4486 - loss: 2.5837 - val_accuracy: 0.6807 - val_loss: 1.4672 - learning_rate: 1.2656e-06
Epoch 153/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4441 - loss: 2.5896 - val_accuracy: 0.6768 - val_loss: 1.4736 - learning_rate: 1.2656e-06
Epoch 154/300
1413/1413 - 231s - 164ms/step - accuracy: 0.4562 - loss: 2.5844 - val_accuracy: 0.6815 - val_loss: 1.4452 - learning_rate: 1.2656e-06
Epoch 155/300
1413/1413 - 224s - 159ms/step - accuracy: 0.4443 - loss: 2.5973 - val_accuracy: 0.6807 - val_loss: 1.4551 - learning_rate: 1.2656e-06
Epoch 156/300
1413/1413 - 231s - 163ms/step - accuracy: 0.4461 - loss: 2.5842 - val_accuracy: 0.6823 - val_loss: 1.4551 - learning_rate: 1.2656e-06
Epoch 157/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4454 - loss: 2.5972 - val_accuracy: 0.6823 - val_loss: 1.4580 - learning_rate: 1.2656e-06
Epoch 158/300
1413/1413 - 231s - 163ms/step - accuracy: 0.4503 - loss: 2.5747 - val_accuracy: 0.6791 - val_loss: 1.4526 - learning_rate: 1.2656e-06
Epoch 159/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4476 - loss: 2.5943 - val_accuracy: 0.6799 - val_loss: 1.4597 - learning_rate: 1.2656e-06
Epoch 160/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4495 - loss: 2.5626 - val_accuracy: 0.6791 - val_loss: 1.4551 - learning_rate: 1.2656e-06
Epoch 161/300
1413/1413 - 228s - 161ms/step - accuracy: 0.4452 - loss: 2.5835 - val_accuracy: 0.6815 - val_loss: 1.4585 - learning_rate: 1.2656e-06
Epoch 162/300

Epoch 162: ReduceLROnPlateau reducing learning rate to 1e-06.
1413/1413 - 229s - 162ms/step - accuracy: 0.4432 - loss: 2.5984 - val_accuracy: 0.6839 - val_loss: 1.4552 - learning_rate: 1.2656e-06
Epoch 163/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4414 - loss: 2.6174 - val_accuracy: 0.6855 - val_loss: 1.4538 - learning_rate: 1.0000e-06
Epoch 164/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4424 - loss: 2.5877 - val_accuracy: 0.6799 - val_loss: 1.4527 - learning_rate: 1.0000e-06
Epoch 165/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4492 - loss: 2.5958 - val_accuracy: 0.6768 - val_loss: 1.4705 - learning_rate: 1.0000e-06
Epoch 166/300
1413/1413 - 224s - 159ms/step - accuracy: 0.4442 - loss: 2.5846 - val_accuracy: 0.6775 - val_loss: 1.4572 - learning_rate: 1.0000e-06
Epoch 167/300
1413/1413 - 230s - 163ms/step - accuracy: 0.4495 - loss: 2.5749 - val_accuracy: 0.6783 - val_loss: 1.4512 - learning_rate: 1.0000e-06
Epoch 168/300
1413/1413 - 228s - 161ms/step - accuracy: 0.4490 - loss: 2.5829 - val_accuracy: 0.6799 - val_loss: 1.4583 - learning_rate: 1.0000e-06
Epoch 169/300
1413/1413 - 227s - 160ms/step - accuracy: 0.4449 - loss: 2.5970 - val_accuracy: 0.6839 - val_loss: 1.4645 - learning_rate: 1.0000e-06
Epoch 170/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4493 - loss: 2.5802 - val_accuracy: 0.6831 - val_loss: 1.4534 - learning_rate: 1.0000e-06
Epoch 170: early stopping
Restoring model weights from the end of the best epoch: 154.
Fold 3 Evaluation results: [1.454471230506897, 0.6815286874771118]
              precision    recall  f1-score   support

        1820       0.85      0.84      0.85        62
        1821       0.88      0.88      0.88        57
        1822       0.00      0.00      0.00         1
        1823       0.00      0.00      0.00         2
        1824       0.00      0.00      0.00         1
        1825       0.00      0.00      0.00         2
        1826       0.00      0.00      0.00         3
        1827       0.95      0.76      0.84        25
        1828       0.00      0.00      0.00         2
        1829       0.50      0.80      0.62         5
        1830       0.72      0.61      0.66        56
        1831       0.80      0.87      0.83       134
        1832       0.70      0.90      0.79        68
        1833       0.89      0.89      0.89        19
        1834       0.74      0.83      0.78        30
        1835       0.00      0.00      0.00         2
        1836       0.33      0.33      0.33         3
        1837       0.10      0.14      0.12         7
        1838       0.00      0.00      0.00         4
        1839       0.00      0.00      0.00         1
        1840       0.76      0.72      0.74        43
        1841       0.80      0.67      0.73       108
        1842       0.33      0.40      0.36         5
        1843       1.00      0.17      0.29         6
        1844       0.00      0.00      0.00         0
        1845       0.00      0.00      0.00         1
        1846       0.40      0.80      0.53         5
        1847       0.50      0.50      0.50         2
        1848       0.50      0.33      0.40         6
        1849       0.40      0.40      0.40         5
        1850       0.55      0.66      0.60        47
        1851       0.77      0.87      0.82        77
        1852       0.00      0.00      0.00         7
        1853       1.00      0.17      0.29         6
        1854       0.17      0.50      0.25         2
        1855       0.47      0.39      0.43        23
        1856       0.40      0.33      0.36        12
        1857       0.50      0.68      0.58        31
        1858       0.00      0.00      0.00         2
        1859       0.00      0.00      0.00         3
        1860       0.44      0.36      0.40        64
        1861       0.89      0.88      0.89        85
        1862       0.40      0.53      0.45        19
        1863       0.45      0.56      0.50        18
        1864       0.65      0.65      0.65        17
        1865       0.33      0.50      0.40         6
        1866       0.00      0.00      0.00         6
        1867       0.29      0.70      0.41        10
        1868       0.00      0.00      0.00         8
        1869       0.00      0.00      0.00         5
        1870       0.47      0.57      0.52        30
        1871       0.77      0.82      0.80        50
        1872       0.20      0.29      0.24         7
        1873       0.22      0.18      0.20        11
        1874       0.50      0.20      0.29         5
        1875       0.58      0.50      0.54        14
        1876       0.89      0.80      0.84        10
        1877       0.57      0.67      0.62         6
        1878       0.71      0.56      0.62         9
        1879       0.00      0.00      0.00         1

    accuracy                           0.68      1256
   macro avg       0.41      0.40      0.39      1256
weighted avg       0.67      0.68      0.67      1256

Matthews Correlation Coefficient: 0.666
Macro avg F1: 0.387
Weighted avg F1: 0.669
Micro avg F1: 0.682
Top-3 Accuracy: 0.876
Top-5 Accuracy: 0.920
Micro ROC AUC  = 0.99
Macro ROC AUC (present classes) = 0.98
Classification MAE (in years): 2.50

Fold 3 Misclassification Analysis:
Near misses (within 2 years): 117 out of 400 misclassifications (29.25%)
Big misses (greater than 10 years): 158
MAE with outliers: 2.50
MAE without outliers: 1.63 (improvement: 0.86)

10 Worst misclassifications:
Image: data/datasets/public/1820/1828_3011vna.jpg, True: 1828, Predicted: 1876, Error: 48
Image: data/datasets/public/1820/1820_033met.jpg, True: 1820, Predicted: 1867, Error: 47
Image: data/datasets/public/1820/1820_037met.jpg, True: 1820, Predicted: 1867, Error: 47
Image: data/datasets/public/1860/1865_30washington.jpg, True: 1865, Predicted: 1821, Error: 44
Image: data/datasets/private/1820/1820_62etsy.jpg, True: 1820, Predicted: 1863, Error: 43
Image: data/datasets/private/1860/1861_859etsy.jpg, True: 1861, Predicted: 1821, Error: 40
Image: data/datasets/public/1870/1873_017met.jpg, True: 1873, Predicted: 1840, Error: 33
Image: data/datasets/public/1860/1863_1385vna.jpg, True: 1863, Predicted: 1830, Error: 33
Image: data/datasets/public/1860/1865_693vna.jpg, True: 1865, Predicted: 1832, Error: 33
Image: data/datasets/public/1830/1830_70vna.jpg, True: 1830, Predicted: 1861, Error: 31

===== Fold 4 =====

===== Fine Tuning 7 layers! =====
Epoch 1/300
1413/1413 - 252s - 178ms/step - accuracy: 0.1351 - loss: 4.4174 - val_accuracy: 0.1489 - val_loss: 4.4113 - learning_rate: 1.6200e-04
Epoch 2/300
1413/1413 - 228s - 161ms/step - accuracy: 0.1874 - loss: 3.9930 - val_accuracy: 0.2707 - val_loss: 3.7718 - learning_rate: 1.6200e-04
Epoch 3/300
1413/1413 - 226s - 160ms/step - accuracy: 0.2225 - loss: 3.8354 - val_accuracy: 0.3256 - val_loss: 3.5498 - learning_rate: 1.6200e-04
Epoch 4/300
1413/1413 - 230s - 163ms/step - accuracy: 0.2424 - loss: 3.6875 - val_accuracy: 0.2428 - val_loss: 5.0761 - learning_rate: 1.6200e-04
Epoch 5/300
1413/1413 - 229s - 162ms/step - accuracy: 0.2553 - loss: 3.6066 - val_accuracy: 0.2516 - val_loss: 3.3893 - learning_rate: 1.6200e-04
Epoch 6/300
1413/1413 - 228s - 161ms/step - accuracy: 0.2712 - loss: 3.5339 - val_accuracy: 0.3073 - val_loss: 3.5740 - learning_rate: 1.6200e-04
Epoch 7/300
1413/1413 - 228s - 162ms/step - accuracy: 0.2768 - loss: 3.5007 - val_accuracy: 0.3893 - val_loss: 3.0529 - learning_rate: 1.6200e-04
Epoch 8/300
1413/1413 - 229s - 162ms/step - accuracy: 0.2896 - loss: 3.4256 - val_accuracy: 0.4156 - val_loss: 2.7462 - learning_rate: 1.6200e-04
Epoch 9/300
1413/1413 - 227s - 161ms/step - accuracy: 0.2896 - loss: 3.4250 - val_accuracy: 0.2874 - val_loss: 5.3568 - learning_rate: 1.6200e-04
Epoch 10/300
1413/1413 - 230s - 162ms/step - accuracy: 0.3028 - loss: 3.3755 - val_accuracy: 0.3201 - val_loss: 3.5252 - learning_rate: 1.6200e-04
Epoch 11/300
1413/1413 - 229s - 162ms/step - accuracy: 0.3057 - loss: 3.3331 - val_accuracy: 0.3360 - val_loss: 3.7867 - learning_rate: 1.6200e-04
Epoch 12/300
1413/1413 - 233s - 165ms/step - accuracy: 0.3074 - loss: 3.3356 - val_accuracy: 0.3941 - val_loss: 3.5843 - learning_rate: 1.6200e-04
Epoch 13/300
1413/1413 - 231s - 163ms/step - accuracy: 0.3116 - loss: 3.2905 - val_accuracy: 0.3854 - val_loss: 3.0309 - learning_rate: 1.6200e-04
Epoch 14/300
1413/1413 - 229s - 162ms/step - accuracy: 0.3165 - loss: 3.2712 - val_accuracy: 0.3949 - val_loss: 3.4792 - learning_rate: 1.6200e-04
Epoch 15/300
1413/1413 - 229s - 162ms/step - accuracy: 0.3219 - loss: 3.2279 - val_accuracy: 0.3105 - val_loss: 3.4702 - learning_rate: 1.6200e-04
Epoch 16/300
1413/1413 - 229s - 162ms/step - accuracy: 0.3269 - loss: 3.2172 - val_accuracy: 0.4785 - val_loss: 2.3718 - learning_rate: 1.6200e-04
Epoch 17/300
1413/1413 - 228s - 161ms/step - accuracy: 0.3255 - loss: 3.1941 - val_accuracy: 0.4164 - val_loss: 2.9010 - learning_rate: 1.6200e-04
Epoch 18/300
1413/1413 - 224s - 158ms/step - accuracy: 0.3254 - loss: 3.1807 - val_accuracy: 0.4841 - val_loss: 2.3032 - learning_rate: 1.6200e-04
Epoch 19/300
1413/1413 - 228s - 161ms/step - accuracy: 0.3336 - loss: 3.1551 - val_accuracy: 0.3185 - val_loss: 4.0225 - learning_rate: 1.6200e-04
Epoch 20/300
1413/1413 - 221s - 157ms/step - accuracy: 0.3403 - loss: 3.1379 - val_accuracy: 0.3551 - val_loss: 3.6831 - learning_rate: 1.6200e-04
Epoch 21/300
1413/1413 - 223s - 158ms/step - accuracy: 0.3406 - loss: 3.1260 - val_accuracy: 0.4307 - val_loss: 2.8221 - learning_rate: 1.6200e-04
Epoch 22/300
1413/1413 - 222s - 157ms/step - accuracy: 0.3447 - loss: 3.1447 - val_accuracy: 0.3025 - val_loss: 4.0928 - learning_rate: 1.6200e-04
Epoch 23/300
1413/1413 - 227s - 160ms/step - accuracy: 0.3398 - loss: 3.1057 - val_accuracy: 0.3965 - val_loss: 2.7107 - learning_rate: 1.6200e-04
Epoch 24/300
1413/1413 - 224s - 159ms/step - accuracy: 0.3463 - loss: 3.1014 - val_accuracy: 0.5597 - val_loss: 2.2561 - learning_rate: 1.6200e-04
Epoch 25/300
1413/1413 - 225s - 159ms/step - accuracy: 0.3453 - loss: 3.0603 - val_accuracy: 0.4140 - val_loss: 3.7515 - learning_rate: 1.6200e-04
Epoch 26/300
1413/1413 - 222s - 157ms/step - accuracy: 0.3530 - loss: 3.0831 - val_accuracy: 0.4650 - val_loss: 2.5393 - learning_rate: 1.6200e-04
Epoch 27/300
1413/1413 - 226s - 160ms/step - accuracy: 0.3554 - loss: 3.0367 - val_accuracy: 0.4682 - val_loss: 2.8510 - learning_rate: 1.6200e-04
Epoch 28/300
1413/1413 - 220s - 156ms/step - accuracy: 0.3562 - loss: 3.0498 - val_accuracy: 0.4833 - val_loss: 2.4135 - learning_rate: 1.6200e-04
Epoch 29/300
1413/1413 - 228s - 161ms/step - accuracy: 0.3602 - loss: 3.0183 - val_accuracy: 0.4737 - val_loss: 2.5443 - learning_rate: 1.6200e-04
Epoch 30/300
1413/1413 - 223s - 158ms/step - accuracy: 0.3606 - loss: 3.0434 - val_accuracy: 0.4936 - val_loss: 2.2771 - learning_rate: 1.6200e-04
Epoch 31/300
1413/1413 - 229s - 162ms/step - accuracy: 0.3560 - loss: 3.0189 - val_accuracy: 0.4865 - val_loss: 2.4452 - learning_rate: 1.6200e-04
Epoch 32/300

Epoch 32: ReduceLROnPlateau reducing learning rate to 8.099817205220461e-05.
1413/1413 - 226s - 160ms/step - accuracy: 0.3677 - loss: 3.0036 - val_accuracy: 0.4331 - val_loss: 2.4713 - learning_rate: 1.6200e-04
Epoch 33/300
1413/1413 - 228s - 162ms/step - accuracy: 0.3763 - loss: 2.9190 - val_accuracy: 0.5597 - val_loss: 2.0138 - learning_rate: 8.0998e-05
Epoch 34/300
1413/1413 - 227s - 161ms/step - accuracy: 0.3806 - loss: 2.9258 - val_accuracy: 0.5398 - val_loss: 2.2642 - learning_rate: 8.0998e-05
Epoch 35/300
1413/1413 - 229s - 162ms/step - accuracy: 0.3818 - loss: 2.8931 - val_accuracy: 0.4912 - val_loss: 2.5608 - learning_rate: 8.0998e-05
Epoch 36/300
1413/1413 - 229s - 162ms/step - accuracy: 0.3786 - loss: 2.8947 - val_accuracy: 0.5748 - val_loss: 2.2119 - learning_rate: 8.0998e-05
Epoch 37/300
1413/1413 - 261s - 185ms/step - accuracy: 0.3930 - loss: 2.8618 - val_accuracy: 0.5486 - val_loss: 2.4043 - learning_rate: 8.0998e-05
Epoch 38/300
1413/1413 - 227s - 161ms/step - accuracy: 0.3803 - loss: 2.8890 - val_accuracy: 0.4578 - val_loss: 2.4975 - learning_rate: 8.0998e-05
Epoch 39/300
1413/1413 - 224s - 158ms/step - accuracy: 0.3840 - loss: 2.9033 - val_accuracy: 0.5756 - val_loss: 1.9704 - learning_rate: 8.0998e-05
Epoch 40/300
1413/1413 - 228s - 161ms/step - accuracy: 0.3956 - loss: 2.8648 - val_accuracy: 0.5358 - val_loss: 2.0974 - learning_rate: 8.0998e-05
Epoch 41/300
1413/1413 - 227s - 161ms/step - accuracy: 0.3864 - loss: 2.8869 - val_accuracy: 0.5478 - val_loss: 1.9407 - learning_rate: 8.0998e-05
Epoch 42/300
1413/1413 - 226s - 160ms/step - accuracy: 0.3927 - loss: 2.8513 - val_accuracy: 0.6011 - val_loss: 1.9927 - learning_rate: 8.0998e-05
Epoch 43/300
1413/1413 - 228s - 162ms/step - accuracy: 0.3875 - loss: 2.8704 - val_accuracy: 0.5382 - val_loss: 2.1470 - learning_rate: 8.0998e-05
Epoch 44/300
1413/1413 - 228s - 162ms/step - accuracy: 0.4002 - loss: 2.8417 - val_accuracy: 0.5462 - val_loss: 1.9817 - learning_rate: 8.0998e-05
Epoch 45/300
1413/1413 - 228s - 161ms/step - accuracy: 0.3899 - loss: 2.8681 - val_accuracy: 0.5533 - val_loss: 2.1329 - learning_rate: 8.0998e-05
Epoch 46/300
1413/1413 - 224s - 158ms/step - accuracy: 0.3920 - loss: 2.8546 - val_accuracy: 0.5541 - val_loss: 2.2041 - learning_rate: 8.0998e-05
Epoch 47/300
1413/1413 - 229s - 162ms/step - accuracy: 0.3946 - loss: 2.8537 - val_accuracy: 0.5653 - val_loss: 1.9978 - learning_rate: 8.0998e-05
Epoch 48/300
1413/1413 - 224s - 158ms/step - accuracy: 0.3959 - loss: 2.8326 - val_accuracy: 0.5963 - val_loss: 1.9498 - learning_rate: 8.0998e-05
Epoch 49/300

Epoch 49: ReduceLROnPlateau reducing learning rate to 4.0499086026102304e-05.
1413/1413 - 227s - 161ms/step - accuracy: 0.3956 - loss: 2.8471 - val_accuracy: 0.5748 - val_loss: 2.0422 - learning_rate: 8.0998e-05
Epoch 50/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4108 - loss: 2.7742 - val_accuracy: 0.6234 - val_loss: 1.8257 - learning_rate: 4.0499e-05
Epoch 51/300
1413/1413 - 224s - 159ms/step - accuracy: 0.4074 - loss: 2.7733 - val_accuracy: 0.6298 - val_loss: 1.8266 - learning_rate: 4.0499e-05
Epoch 52/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4117 - loss: 2.7616 - val_accuracy: 0.6154 - val_loss: 1.8493 - learning_rate: 4.0499e-05
Epoch 53/300
1413/1413 - 224s - 159ms/step - accuracy: 0.4116 - loss: 2.7688 - val_accuracy: 0.5955 - val_loss: 2.0645 - learning_rate: 4.0499e-05
Epoch 54/300
1413/1413 - 268s - 189ms/step - accuracy: 0.4087 - loss: 2.7327 - val_accuracy: 0.6075 - val_loss: 1.8115 - learning_rate: 4.0499e-05
Epoch 55/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4179 - loss: 2.7447 - val_accuracy: 0.5796 - val_loss: 2.1798 - learning_rate: 4.0499e-05
Epoch 56/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4103 - loss: 2.7600 - val_accuracy: 0.5597 - val_loss: 2.2823 - learning_rate: 4.0499e-05
Epoch 57/300
1413/1413 - 233s - 165ms/step - accuracy: 0.4114 - loss: 2.7677 - val_accuracy: 0.6210 - val_loss: 1.8812 - learning_rate: 4.0499e-05
Epoch 58/300
1413/1413 - 228s - 162ms/step - accuracy: 0.4140 - loss: 2.7445 - val_accuracy: 0.6218 - val_loss: 1.7491 - learning_rate: 4.0499e-05
Epoch 59/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4112 - loss: 2.7521 - val_accuracy: 0.5876 - val_loss: 2.0006 - learning_rate: 4.0499e-05
Epoch 60/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4137 - loss: 2.7488 - val_accuracy: 0.5597 - val_loss: 2.0373 - learning_rate: 4.0499e-05
Epoch 61/300
1413/1413 - 230s - 163ms/step - accuracy: 0.4112 - loss: 2.7699 - val_accuracy: 0.6075 - val_loss: 1.8888 - learning_rate: 4.0499e-05
Epoch 62/300
1413/1413 - 230s - 163ms/step - accuracy: 0.4156 - loss: 2.7498 - val_accuracy: 0.6194 - val_loss: 1.7979 - learning_rate: 4.0499e-05
Epoch 63/300
1413/1413 - 227s - 161ms/step - accuracy: 0.4182 - loss: 2.7282 - val_accuracy: 0.6075 - val_loss: 1.8259 - learning_rate: 4.0499e-05
Epoch 64/300
1413/1413 - 230s - 163ms/step - accuracy: 0.4224 - loss: 2.7436 - val_accuracy: 0.5828 - val_loss: 1.8885 - learning_rate: 4.0499e-05
Epoch 65/300
1413/1413 - 227s - 161ms/step - accuracy: 0.4206 - loss: 2.7450 - val_accuracy: 0.6258 - val_loss: 1.7502 - learning_rate: 4.0499e-05
Epoch 66/300

Epoch 66: ReduceLROnPlateau reducing learning rate to 2.0249543013051152e-05.
1413/1413 - 228s - 162ms/step - accuracy: 0.4156 - loss: 2.7444 - val_accuracy: 0.6131 - val_loss: 1.8120 - learning_rate: 4.0499e-05
Epoch 67/300
1413/1413 - 260s - 184ms/step - accuracy: 0.4239 - loss: 2.6847 - val_accuracy: 0.6393 - val_loss: 1.7134 - learning_rate: 2.0250e-05
Epoch 68/300
1413/1413 - 231s - 164ms/step - accuracy: 0.4176 - loss: 2.6910 - val_accuracy: 0.5717 - val_loss: 2.1524 - learning_rate: 2.0250e-05
Epoch 69/300
1413/1413 - 228s - 161ms/step - accuracy: 0.4294 - loss: 2.7058 - val_accuracy: 0.6210 - val_loss: 1.7365 - learning_rate: 2.0250e-05
Epoch 70/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4297 - loss: 2.6989 - val_accuracy: 0.6226 - val_loss: 1.8219 - learning_rate: 2.0250e-05
Epoch 71/300
1413/1413 - 224s - 159ms/step - accuracy: 0.4191 - loss: 2.7235 - val_accuracy: 0.6457 - val_loss: 1.7371 - learning_rate: 2.0250e-05
Epoch 72/300
1413/1413 - 227s - 160ms/step - accuracy: 0.4275 - loss: 2.6887 - val_accuracy: 0.6162 - val_loss: 1.7498 - learning_rate: 2.0250e-05
Epoch 73/300
1413/1413 - 221s - 157ms/step - accuracy: 0.4258 - loss: 2.7321 - val_accuracy: 0.6354 - val_loss: 1.7222 - learning_rate: 2.0250e-05
Epoch 74/300
1413/1413 - 224s - 159ms/step - accuracy: 0.4252 - loss: 2.6752 - val_accuracy: 0.6298 - val_loss: 1.7246 - learning_rate: 2.0250e-05
Epoch 75/300
1413/1413 - 220s - 156ms/step - accuracy: 0.4204 - loss: 2.6985 - val_accuracy: 0.6266 - val_loss: 1.7059 - learning_rate: 2.0250e-05
Epoch 76/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4255 - loss: 2.6784 - val_accuracy: 0.6202 - val_loss: 1.8226 - learning_rate: 2.0250e-05
Epoch 77/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4237 - loss: 2.7075 - val_accuracy: 0.6186 - val_loss: 1.7429 - learning_rate: 2.0250e-05
Epoch 78/300
1413/1413 - 221s - 157ms/step - accuracy: 0.4271 - loss: 2.6919 - val_accuracy: 0.6393 - val_loss: 1.6532 - learning_rate: 2.0250e-05
Epoch 79/300
1413/1413 - 228s - 161ms/step - accuracy: 0.4300 - loss: 2.6534 - val_accuracy: 0.6027 - val_loss: 1.8819 - learning_rate: 2.0250e-05
Epoch 80/300
1413/1413 - 234s - 166ms/step - accuracy: 0.4325 - loss: 2.6861 - val_accuracy: 0.6338 - val_loss: 1.7524 - learning_rate: 2.0250e-05
Epoch 81/300
1413/1413 - 238s - 168ms/step - accuracy: 0.4266 - loss: 2.6672 - val_accuracy: 0.6139 - val_loss: 1.8580 - learning_rate: 2.0250e-05
Epoch 82/300
1413/1413 - 234s - 166ms/step - accuracy: 0.4330 - loss: 2.6890 - val_accuracy: 0.6481 - val_loss: 1.6516 - learning_rate: 2.0250e-05
Epoch 83/300
1413/1413 - 240s - 170ms/step - accuracy: 0.4238 - loss: 2.7077 - val_accuracy: 0.6361 - val_loss: 1.7357 - learning_rate: 2.0250e-05
Epoch 84/300
1413/1413 - 234s - 165ms/step - accuracy: 0.4184 - loss: 2.7189 - val_accuracy: 0.6338 - val_loss: 1.7205 - learning_rate: 2.0250e-05
Epoch 85/300
1413/1413 - 227s - 161ms/step - accuracy: 0.4262 - loss: 2.7032 - val_accuracy: 0.6369 - val_loss: 1.7834 - learning_rate: 2.0250e-05
Epoch 86/300
1413/1413 - 227s - 160ms/step - accuracy: 0.4253 - loss: 2.6802 - val_accuracy: 0.6322 - val_loss: 1.7221 - learning_rate: 2.0250e-05
Epoch 87/300
1413/1413 - 227s - 160ms/step - accuracy: 0.4266 - loss: 2.6977 - val_accuracy: 0.6433 - val_loss: 1.6684 - learning_rate: 2.0250e-05
Epoch 88/300
1413/1413 - 231s - 164ms/step - accuracy: 0.4201 - loss: 2.7081 - val_accuracy: 0.6290 - val_loss: 1.7861 - learning_rate: 2.0250e-05
Epoch 89/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4292 - loss: 2.6657 - val_accuracy: 0.6338 - val_loss: 1.8042 - learning_rate: 2.0250e-05
Epoch 90/300

Epoch 90: ReduceLROnPlateau reducing learning rate to 1.0124771506525576e-05.
1413/1413 - 228s - 161ms/step - accuracy: 0.4316 - loss: 2.6591 - val_accuracy: 0.6393 - val_loss: 1.6746 - learning_rate: 2.0250e-05
Epoch 91/300
1413/1413 - 224s - 159ms/step - accuracy: 0.4347 - loss: 2.6612 - val_accuracy: 0.6521 - val_loss: 1.6213 - learning_rate: 1.0125e-05
Epoch 92/300
1413/1413 - 228s - 161ms/step - accuracy: 0.4285 - loss: 2.6839 - val_accuracy: 0.6521 - val_loss: 1.6430 - learning_rate: 1.0125e-05
Epoch 93/300
1413/1413 - 235s - 167ms/step - accuracy: 0.4312 - loss: 2.6586 - val_accuracy: 0.6354 - val_loss: 1.6737 - learning_rate: 1.0125e-05
Epoch 94/300
1413/1413 - 235s - 166ms/step - accuracy: 0.4313 - loss: 2.6714 - val_accuracy: 0.6457 - val_loss: 1.7089 - learning_rate: 1.0125e-05
Epoch 95/300
1413/1413 - 237s - 167ms/step - accuracy: 0.4313 - loss: 2.6518 - val_accuracy: 0.6377 - val_loss: 1.6782 - learning_rate: 1.0125e-05
Epoch 96/300
1413/1413 - 237s - 168ms/step - accuracy: 0.4344 - loss: 2.6534 - val_accuracy: 0.6489 - val_loss: 1.6841 - learning_rate: 1.0125e-05
Epoch 97/300
1413/1413 - 234s - 166ms/step - accuracy: 0.4354 - loss: 2.6383 - val_accuracy: 0.6298 - val_loss: 1.6673 - learning_rate: 1.0125e-05
Epoch 98/300
1413/1413 - 239s - 169ms/step - accuracy: 0.4404 - loss: 2.6482 - val_accuracy: 0.6505 - val_loss: 1.6372 - learning_rate: 1.0125e-05
Epoch 99/300

Epoch 99: ReduceLROnPlateau reducing learning rate to 5.062385753262788e-06.
1413/1413 - 235s - 167ms/step - accuracy: 0.4394 - loss: 2.6340 - val_accuracy: 0.6258 - val_loss: 1.7868 - learning_rate: 1.0125e-05
Epoch 100/300
1413/1413 - 240s - 170ms/step - accuracy: 0.4381 - loss: 2.6194 - val_accuracy: 0.6433 - val_loss: 1.6329 - learning_rate: 5.0624e-06
Epoch 101/300
1413/1413 - 237s - 168ms/step - accuracy: 0.4362 - loss: 2.6409 - val_accuracy: 0.6489 - val_loss: 1.6394 - learning_rate: 5.0624e-06
Epoch 102/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4313 - loss: 2.6317 - val_accuracy: 0.6561 - val_loss: 1.6614 - learning_rate: 5.0624e-06
Epoch 103/300
1413/1413 - 228s - 162ms/step - accuracy: 0.4381 - loss: 2.6554 - val_accuracy: 0.6473 - val_loss: 1.6409 - learning_rate: 5.0624e-06
Epoch 104/300
1413/1413 - 224s - 158ms/step - accuracy: 0.4381 - loss: 2.6293 - val_accuracy: 0.6497 - val_loss: 1.6356 - learning_rate: 5.0624e-06
Epoch 105/300
1413/1413 - 276s - 196ms/step - accuracy: 0.4342 - loss: 2.6594 - val_accuracy: 0.6608 - val_loss: 1.6063 - learning_rate: 5.0624e-06
Epoch 106/300
1413/1413 - 231s - 164ms/step - accuracy: 0.4416 - loss: 2.6275 - val_accuracy: 0.6537 - val_loss: 1.6344 - learning_rate: 5.0624e-06
Epoch 107/300
1413/1413 - 240s - 170ms/step - accuracy: 0.4405 - loss: 2.5986 - val_accuracy: 0.6465 - val_loss: 1.6646 - learning_rate: 5.0624e-06
Epoch 108/300
1413/1413 - 236s - 167ms/step - accuracy: 0.4401 - loss: 2.6452 - val_accuracy: 0.6481 - val_loss: 1.6400 - learning_rate: 5.0624e-06
Epoch 109/300
1413/1413 - 236s - 167ms/step - accuracy: 0.4360 - loss: 2.6355 - val_accuracy: 0.6592 - val_loss: 1.6402 - learning_rate: 5.0624e-06
Epoch 110/300
1413/1413 - 237s - 167ms/step - accuracy: 0.4442 - loss: 2.6066 - val_accuracy: 0.6441 - val_loss: 1.6546 - learning_rate: 5.0624e-06
Epoch 111/300
1413/1413 - 239s - 169ms/step - accuracy: 0.4393 - loss: 2.6393 - val_accuracy: 0.6441 - val_loss: 1.6613 - learning_rate: 5.0624e-06
Epoch 112/300
1413/1413 - 240s - 170ms/step - accuracy: 0.4573 - loss: 2.6137 - val_accuracy: 0.6497 - val_loss: 1.6402 - learning_rate: 5.0624e-06
Epoch 113/300
1413/1413 - 240s - 170ms/step - accuracy: 0.4341 - loss: 2.6424 - val_accuracy: 0.6505 - val_loss: 1.5876 - learning_rate: 5.0624e-06
Epoch 114/300
1413/1413 - 236s - 167ms/step - accuracy: 0.4414 - loss: 2.6232 - val_accuracy: 0.6473 - val_loss: 1.6500 - learning_rate: 5.0624e-06
Epoch 115/300
1413/1413 - 235s - 166ms/step - accuracy: 0.4394 - loss: 2.6333 - val_accuracy: 0.6481 - val_loss: 1.6127 - learning_rate: 5.0624e-06
Epoch 116/300
1413/1413 - 240s - 170ms/step - accuracy: 0.4411 - loss: 2.6184 - val_accuracy: 0.6465 - val_loss: 1.6207 - learning_rate: 5.0624e-06
Epoch 117/300
1413/1413 - 234s - 166ms/step - accuracy: 0.4399 - loss: 2.6211 - val_accuracy: 0.6489 - val_loss: 1.6350 - learning_rate: 5.0624e-06
Epoch 118/300
1413/1413 - 240s - 170ms/step - accuracy: 0.4319 - loss: 2.6435 - val_accuracy: 0.6553 - val_loss: 1.6241 - learning_rate: 5.0624e-06
Epoch 119/300
1413/1413 - 235s - 167ms/step - accuracy: 0.4375 - loss: 2.6314 - val_accuracy: 0.6561 - val_loss: 1.6499 - learning_rate: 5.0624e-06
Epoch 120/300
1413/1413 - 228s - 161ms/step - accuracy: 0.4353 - loss: 2.6286 - val_accuracy: 0.6481 - val_loss: 1.5946 - learning_rate: 5.0624e-06
Epoch 121/300

Epoch 121: ReduceLROnPlateau reducing learning rate to 2.531192876631394e-06.
1413/1413 - 223s - 158ms/step - accuracy: 0.4432 - loss: 2.6198 - val_accuracy: 0.6529 - val_loss: 1.6189 - learning_rate: 5.0624e-06
Epoch 122/300
1413/1413 - 228s - 161ms/step - accuracy: 0.4447 - loss: 2.6067 - val_accuracy: 0.6537 - val_loss: 1.6153 - learning_rate: 2.5312e-06
Epoch 123/300
1413/1413 - 227s - 161ms/step - accuracy: 0.4403 - loss: 2.6191 - val_accuracy: 0.6529 - val_loss: 1.6129 - learning_rate: 2.5312e-06
Epoch 124/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4383 - loss: 2.6226 - val_accuracy: 0.6537 - val_loss: 1.6380 - learning_rate: 2.5312e-06
Epoch 125/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4369 - loss: 2.5988 - val_accuracy: 0.6521 - val_loss: 1.6170 - learning_rate: 2.5312e-06
Epoch 126/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4405 - loss: 2.6269 - val_accuracy: 0.6545 - val_loss: 1.6243 - learning_rate: 2.5312e-06
Epoch 127/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4394 - loss: 2.6183 - val_accuracy: 0.6489 - val_loss: 1.6221 - learning_rate: 2.5312e-06
Epoch 128/300
1413/1413 - 230s - 163ms/step - accuracy: 0.4382 - loss: 2.6398 - val_accuracy: 0.6561 - val_loss: 1.6283 - learning_rate: 2.5312e-06
Epoch 129/300

Epoch 129: ReduceLROnPlateau reducing learning rate to 1.265596438315697e-06.
1413/1413 - 224s - 158ms/step - accuracy: 0.4429 - loss: 2.5962 - val_accuracy: 0.6505 - val_loss: 1.6274 - learning_rate: 2.5312e-06
Epoch 129: early stopping
Restoring model weights from the end of the best epoch: 113.
Fold 4 Evaluation results: [1.595448613166809, 0.6504777073860168]
              precision    recall  f1-score   support

        1820       0.73      0.87      0.79        62
        1821       0.93      0.90      0.91        58
        1822       0.00      0.00      0.00         1
        1823       0.00      0.00      0.00         2
        1824       0.00      0.00      0.00         1
        1825       0.00      0.00      0.00         2
        1826       0.00      0.00      0.00         3
        1827       0.87      0.80      0.83        25
        1828       0.00      0.00      0.00         2
        1829       0.57      1.00      0.73         4
        1830       0.65      0.77      0.70        56
        1831       0.80      0.92      0.86       134
        1832       0.71      0.82      0.76        68
        1833       0.82      0.95      0.88        19
        1834       0.63      0.63      0.63        30
        1835       0.00      0.00      0.00         2
        1836       0.17      0.33      0.22         3
        1837       0.38      0.43      0.40         7
        1838       0.00      0.00      0.00         4
        1839       0.00      0.00      0.00         1
        1840       0.55      0.67      0.60        43
        1841       0.77      0.58      0.66       108
        1842       1.00      0.80      0.89         5
        1843       0.33      0.17      0.22         6
        1844       0.00      0.00      0.00         0
        1845       0.00      0.00      0.00         1
        1846       0.57      0.80      0.67         5
        1847       0.00      0.00      0.00         2
        1848       0.00      0.00      0.00         6
        1849       0.14      0.20      0.17         5
        1850       0.38      0.51      0.44        47
        1851       0.77      0.75      0.76        77
        1852       0.00      0.00      0.00         7
        1853       0.25      0.17      0.20         6
        1854       0.25      0.50      0.33         2
        1855       0.50      0.43      0.47        23
        1856       0.45      0.42      0.43        12
        1857       0.61      0.71      0.66        31
        1858       0.00      0.00      0.00         2
        1859       0.00      0.00      0.00         3
        1860       0.35      0.34      0.35        64
        1861       0.80      0.78      0.79        85
        1862       0.40      0.21      0.28        19
        1863       0.65      0.83      0.73        18
        1864       0.36      0.29      0.32        17
        1865       0.40      0.67      0.50         6
        1866       0.33      0.17      0.22         6
        1867       0.29      0.20      0.24        10
        1868       0.00      0.00      0.00         8
        1869       0.00      0.00      0.00         5
        1870       0.51      0.67      0.58        30
        1871       0.73      0.88      0.80        49
        1872       1.00      0.14      0.25         7
        1873       0.00      0.00      0.00        11
        1874       0.00      0.00      0.00         6
        1875       0.26      0.36      0.30        14
        1876       0.80      0.80      0.80        10
        1877       0.14      0.33      0.20         6
        1878       0.75      0.33      0.46         9
        1879       0.00      0.00      0.00         1

    accuracy                           0.65      1256
   macro avg       0.36      0.37      0.35      1256
weighted avg       0.63      0.65      0.63      1256

Matthews Correlation Coefficient: 0.633
Macro avg F1: 0.351
Weighted avg F1: 0.630
Micro avg F1: 0.650
Top-3 Accuracy: 0.851
Top-5 Accuracy: 0.906
Micro ROC AUC  = 0.99
Macro ROC AUC (present classes) = 0.98
Classification MAE (in years): 3.21

Fold 4 Misclassification Analysis:
Near misses (within 2 years): 100 out of 439 misclassifications (22.78%)
Big misses (greater than 10 years): 209
MAE with outliers: 3.21
MAE without outliers: 2.01 (improvement: 1.20)

10 Worst misclassifications:
Image: data/datasets/public/1870/1877_035met.jpg, True: 1877, Predicted: 1820, Error: 57
Image: data/datasets/public/1870/1876_382vna.jpg, True: 1876, Predicted: 1820, Error: 56
Image: data/datasets/public/1870/1870_79wikimedia2.jpg, True: 1870, Predicted: 1820, Error: 50
Image: data/datasets/public/1820/1820_029met.jpg, True: 1820, Predicted: 1870, Error: 50
Image: data/datasets/public/1820/1826_58washington.jpg, True: 1826, Predicted: 1876, Error: 50
Image: data/datasets/public/1860/1868_049met.jpg, True: 1868, Predicted: 1820, Error: 48
Image: data/datasets/public/1870/1877_004met.jpg, True: 1877, Predicted: 1830, Error: 47
Image: data/datasets/private/1860/1861_857etsy.jpg, True: 1861, Predicted: 1820, Error: 41
Image: data/datasets/public/1870/1873_1812vna.jpg, True: 1873, Predicted: 1832, Error: 41
Image: data/datasets/public/1860/1860_11wikimedia2.jpg, True: 1860, Predicted: 1820, Error: 40

===== Fold 5 =====

===== Fine Tuning 7 layers! =====
Epoch 1/300
1413/1413 - 251s - 177ms/step - accuracy: 0.1327 - loss: 4.3874 - val_accuracy: 0.1561 - val_loss: 3.9041 - learning_rate: 1.6200e-04
Epoch 2/300
1413/1413 - 223s - 158ms/step - accuracy: 0.2047 - loss: 3.9540 - val_accuracy: 0.3097 - val_loss: 3.7382 - learning_rate: 1.6200e-04
Epoch 3/300
1413/1413 - 224s - 159ms/step - accuracy: 0.2334 - loss: 3.7805 - val_accuracy: 0.3153 - val_loss: 3.2766 - learning_rate: 1.6200e-04
Epoch 4/300
1413/1413 - 224s - 159ms/step - accuracy: 0.2498 - loss: 3.6860 - val_accuracy: 0.3280 - val_loss: 3.4123 - learning_rate: 1.6200e-04
Epoch 5/300
1413/1413 - 223s - 158ms/step - accuracy: 0.2593 - loss: 3.5783 - val_accuracy: 0.3790 - val_loss: 3.1657 - learning_rate: 1.6200e-04
Epoch 6/300
1413/1413 - 227s - 160ms/step - accuracy: 0.2651 - loss: 3.5485 - val_accuracy: 0.2922 - val_loss: 3.6637 - learning_rate: 1.6200e-04
Epoch 7/300
1413/1413 - 224s - 158ms/step - accuracy: 0.2794 - loss: 3.4801 - val_accuracy: 0.2818 - val_loss: 3.9097 - learning_rate: 1.6200e-04
Epoch 8/300
1413/1413 - 222s - 157ms/step - accuracy: 0.2881 - loss: 3.4260 - val_accuracy: 0.3487 - val_loss: 3.0898 - learning_rate: 1.6200e-04
Epoch 9/300
1413/1413 - 230s - 163ms/step - accuracy: 0.2896 - loss: 3.3950 - val_accuracy: 0.4021 - val_loss: 2.9489 - learning_rate: 1.6200e-04
Epoch 10/300
1413/1413 - 225s - 159ms/step - accuracy: 0.3046 - loss: 3.3850 - val_accuracy: 0.4164 - val_loss: 2.8237 - learning_rate: 1.6200e-04
Epoch 11/300
1413/1413 - 224s - 159ms/step - accuracy: 0.3153 - loss: 3.3337 - val_accuracy: 0.4658 - val_loss: 2.7786 - learning_rate: 1.6200e-04
Epoch 12/300
1413/1413 - 226s - 160ms/step - accuracy: 0.3105 - loss: 3.3101 - val_accuracy: 0.4260 - val_loss: 2.4997 - learning_rate: 1.6200e-04
Epoch 13/300
1413/1413 - 226s - 160ms/step - accuracy: 0.3126 - loss: 3.2931 - val_accuracy: 0.3607 - val_loss: 2.8039 - learning_rate: 1.6200e-04
Epoch 14/300
1413/1413 - 226s - 160ms/step - accuracy: 0.3194 - loss: 3.2453 - val_accuracy: 0.2651 - val_loss: 3.8868 - learning_rate: 1.6200e-04
Epoch 15/300
1413/1413 - 225s - 159ms/step - accuracy: 0.3249 - loss: 3.2486 - val_accuracy: 0.4602 - val_loss: 2.8070 - learning_rate: 1.6200e-04
Epoch 16/300
1413/1413 - 227s - 161ms/step - accuracy: 0.3298 - loss: 3.2134 - val_accuracy: 0.4061 - val_loss: 3.1568 - learning_rate: 1.6200e-04
Epoch 17/300
1413/1413 - 226s - 160ms/step - accuracy: 0.3326 - loss: 3.2099 - val_accuracy: 0.4546 - val_loss: 2.5649 - learning_rate: 1.6200e-04
Epoch 18/300
1413/1413 - 225s - 159ms/step - accuracy: 0.3337 - loss: 3.1919 - val_accuracy: 0.3455 - val_loss: 3.4187 - learning_rate: 1.6200e-04
Epoch 19/300
1413/1413 - 226s - 160ms/step - accuracy: 0.3318 - loss: 3.1789 - val_accuracy: 0.4180 - val_loss: 3.0141 - learning_rate: 1.6200e-04
Epoch 20/300

Epoch 20: ReduceLROnPlateau reducing learning rate to 8.099817205220461e-05.
1413/1413 - 224s - 159ms/step - accuracy: 0.3410 - loss: 3.1605 - val_accuracy: 0.1521 - val_loss: 4.6245 - learning_rate: 1.6200e-04
Epoch 21/300
1413/1413 - 267s - 189ms/step - accuracy: 0.3544 - loss: 3.0922 - val_accuracy: 0.5430 - val_loss: 2.1838 - learning_rate: 8.0998e-05
Epoch 22/300
1413/1413 - 230s - 163ms/step - accuracy: 0.3516 - loss: 3.0862 - val_accuracy: 0.5271 - val_loss: 2.3944 - learning_rate: 8.0998e-05
Epoch 23/300
1413/1413 - 229s - 162ms/step - accuracy: 0.3536 - loss: 3.0467 - val_accuracy: 0.5350 - val_loss: 2.3875 - learning_rate: 8.0998e-05
Epoch 24/300
1413/1413 - 230s - 163ms/step - accuracy: 0.3611 - loss: 3.0488 - val_accuracy: 0.5438 - val_loss: 2.1169 - learning_rate: 8.0998e-05
Epoch 25/300
1413/1413 - 229s - 162ms/step - accuracy: 0.3621 - loss: 3.0260 - val_accuracy: 0.4952 - val_loss: 2.3164 - learning_rate: 8.0998e-05
Epoch 26/300
1413/1413 - 230s - 163ms/step - accuracy: 0.3567 - loss: 3.0584 - val_accuracy: 0.3798 - val_loss: 2.9121 - learning_rate: 8.0998e-05
Epoch 27/300
1413/1413 - 228s - 162ms/step - accuracy: 0.3644 - loss: 3.0365 - val_accuracy: 0.3965 - val_loss: 3.5429 - learning_rate: 8.0998e-05
Epoch 28/300
1413/1413 - 229s - 162ms/step - accuracy: 0.3590 - loss: 3.0493 - val_accuracy: 0.5159 - val_loss: 2.4473 - learning_rate: 8.0998e-05
Epoch 29/300
1413/1413 - 228s - 162ms/step - accuracy: 0.3705 - loss: 3.0388 - val_accuracy: 0.5701 - val_loss: 2.0720 - learning_rate: 8.0998e-05
Epoch 30/300
1413/1413 - 231s - 163ms/step - accuracy: 0.3730 - loss: 2.9906 - val_accuracy: 0.4379 - val_loss: 3.2435 - learning_rate: 8.0998e-05
Epoch 31/300
1413/1413 - 233s - 165ms/step - accuracy: 0.3688 - loss: 3.0176 - val_accuracy: 0.5127 - val_loss: 2.2337 - learning_rate: 8.0998e-05
Epoch 32/300
1413/1413 - 232s - 164ms/step - accuracy: 0.3680 - loss: 3.0098 - val_accuracy: 0.5223 - val_loss: 2.3568 - learning_rate: 8.0998e-05
Epoch 33/300
1413/1413 - 230s - 163ms/step - accuracy: 0.3718 - loss: 2.9628 - val_accuracy: 0.4889 - val_loss: 2.8251 - learning_rate: 8.0998e-05
Epoch 34/300
1413/1413 - 230s - 163ms/step - accuracy: 0.3654 - loss: 2.9937 - val_accuracy: 0.5422 - val_loss: 2.2133 - learning_rate: 8.0998e-05
Epoch 35/300
1413/1413 - 232s - 164ms/step - accuracy: 0.3773 - loss: 2.9494 - val_accuracy: 0.3830 - val_loss: 3.0231 - learning_rate: 8.0998e-05
Epoch 36/300
1413/1413 - 229s - 162ms/step - accuracy: 0.3795 - loss: 2.9470 - val_accuracy: 0.4761 - val_loss: 2.3244 - learning_rate: 8.0998e-05
Epoch 37/300
1413/1413 - 233s - 165ms/step - accuracy: 0.3766 - loss: 2.9560 - val_accuracy: 0.5884 - val_loss: 1.9681 - learning_rate: 8.0998e-05
Epoch 38/300
1413/1413 - 230s - 163ms/step - accuracy: 0.3759 - loss: 2.9414 - val_accuracy: 0.5653 - val_loss: 2.0484 - learning_rate: 8.0998e-05
Epoch 39/300
1413/1413 - 230s - 163ms/step - accuracy: 0.3764 - loss: 2.9380 - val_accuracy: 0.5573 - val_loss: 2.1269 - learning_rate: 8.0998e-05
Epoch 40/300
1413/1413 - 223s - 157ms/step - accuracy: 0.3810 - loss: 2.9364 - val_accuracy: 0.6003 - val_loss: 1.9223 - learning_rate: 8.0998e-05
Epoch 41/300
1413/1413 - 225s - 160ms/step - accuracy: 0.3780 - loss: 2.9425 - val_accuracy: 0.5605 - val_loss: 2.1973 - learning_rate: 8.0998e-05
Epoch 42/300
1413/1413 - 228s - 162ms/step - accuracy: 0.3874 - loss: 2.8921 - val_accuracy: 0.5525 - val_loss: 2.1080 - learning_rate: 8.0998e-05
Epoch 43/300
1413/1413 - 230s - 163ms/step - accuracy: 0.3840 - loss: 2.9022 - val_accuracy: 0.5454 - val_loss: 2.1548 - learning_rate: 8.0998e-05
Epoch 44/300
1413/1413 - 233s - 165ms/step - accuracy: 0.3897 - loss: 2.9118 - val_accuracy: 0.4825 - val_loss: 2.4942 - learning_rate: 8.0998e-05
Epoch 45/300
1413/1413 - 226s - 160ms/step - accuracy: 0.3804 - loss: 2.9130 - val_accuracy: 0.5207 - val_loss: 2.1332 - learning_rate: 8.0998e-05
Epoch 46/300
1413/1413 - 233s - 165ms/step - accuracy: 0.3877 - loss: 2.9319 - val_accuracy: 0.5852 - val_loss: 2.0029 - learning_rate: 8.0998e-05
Epoch 47/300
1413/1413 - 231s - 164ms/step - accuracy: 0.3826 - loss: 2.9035 - val_accuracy: 0.4753 - val_loss: 2.6465 - learning_rate: 8.0998e-05
Epoch 48/300

Epoch 48: ReduceLROnPlateau reducing learning rate to 4.0499086026102304e-05.
1413/1413 - 234s - 165ms/step - accuracy: 0.3895 - loss: 2.8994 - val_accuracy: 0.3782 - val_loss: 3.6999 - learning_rate: 8.0998e-05
Epoch 49/300
1413/1413 - 229s - 162ms/step - accuracy: 0.3952 - loss: 2.8506 - val_accuracy: 0.5040 - val_loss: 2.5619 - learning_rate: 4.0499e-05
Epoch 50/300
1413/1413 - 232s - 164ms/step - accuracy: 0.3956 - loss: 2.8165 - val_accuracy: 0.5932 - val_loss: 1.9268 - learning_rate: 4.0499e-05
Epoch 51/300
1413/1413 - 230s - 163ms/step - accuracy: 0.4023 - loss: 2.8262 - val_accuracy: 0.5573 - val_loss: 1.9448 - learning_rate: 4.0499e-05
Epoch 52/300
1413/1413 - 235s - 166ms/step - accuracy: 0.3954 - loss: 2.8211 - val_accuracy: 0.5884 - val_loss: 1.9466 - learning_rate: 4.0499e-05
Epoch 53/300
1413/1413 - 230s - 163ms/step - accuracy: 0.3993 - loss: 2.8300 - val_accuracy: 0.5653 - val_loss: 1.9820 - learning_rate: 4.0499e-05
Epoch 54/300
1413/1413 - 231s - 164ms/step - accuracy: 0.4018 - loss: 2.8220 - val_accuracy: 0.6154 - val_loss: 1.8391 - learning_rate: 4.0499e-05
Epoch 55/300
1413/1413 - 234s - 166ms/step - accuracy: 0.4040 - loss: 2.8131 - val_accuracy: 0.5788 - val_loss: 1.9888 - learning_rate: 4.0499e-05
Epoch 56/300
1413/1413 - 238s - 169ms/step - accuracy: 0.3996 - loss: 2.8352 - val_accuracy: 0.5892 - val_loss: 1.9661 - learning_rate: 4.0499e-05
Epoch 57/300
1413/1413 - 234s - 166ms/step - accuracy: 0.4090 - loss: 2.8053 - val_accuracy: 0.5955 - val_loss: 1.9176 - learning_rate: 4.0499e-05
Epoch 58/300
1413/1413 - 238s - 168ms/step - accuracy: 0.4079 - loss: 2.7961 - val_accuracy: 0.5772 - val_loss: 2.0442 - learning_rate: 4.0499e-05
Epoch 59/300
1413/1413 - 232s - 164ms/step - accuracy: 0.4007 - loss: 2.8209 - val_accuracy: 0.5764 - val_loss: 1.8894 - learning_rate: 4.0499e-05
Epoch 60/300
1413/1413 - 235s - 167ms/step - accuracy: 0.4061 - loss: 2.8201 - val_accuracy: 0.6186 - val_loss: 1.7668 - learning_rate: 4.0499e-05
Epoch 61/300
1413/1413 - 256s - 182ms/step - accuracy: 0.4080 - loss: 2.8173 - val_accuracy: 0.4817 - val_loss: 2.5785 - learning_rate: 4.0499e-05
Epoch 62/300
1413/1413 - 231s - 164ms/step - accuracy: 0.4106 - loss: 2.7968 - val_accuracy: 0.5939 - val_loss: 1.9622 - learning_rate: 4.0499e-05
Epoch 63/300
1413/1413 - 232s - 164ms/step - accuracy: 0.4061 - loss: 2.8120 - val_accuracy: 0.5709 - val_loss: 2.1021 - learning_rate: 4.0499e-05
Epoch 64/300
1413/1413 - 232s - 164ms/step - accuracy: 0.4102 - loss: 2.7920 - val_accuracy: 0.5788 - val_loss: 2.0739 - learning_rate: 4.0499e-05
Epoch 65/300
1413/1413 - 233s - 165ms/step - accuracy: 0.4105 - loss: 2.7908 - val_accuracy: 0.6043 - val_loss: 1.8853 - learning_rate: 4.0499e-05
Epoch 66/300
1413/1413 - 235s - 167ms/step - accuracy: 0.4085 - loss: 2.7691 - val_accuracy: 0.5605 - val_loss: 2.0121 - learning_rate: 4.0499e-05
Epoch 67/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4062 - loss: 2.7866 - val_accuracy: 0.6075 - val_loss: 1.7939 - learning_rate: 4.0499e-05
Epoch 68/300

Epoch 68: ReduceLROnPlateau reducing learning rate to 2.0249543013051152e-05.
1413/1413 - 235s - 167ms/step - accuracy: 0.4073 - loss: 2.7990 - val_accuracy: 0.5725 - val_loss: 2.1190 - learning_rate: 4.0499e-05
Epoch 69/300
1413/1413 - 231s - 163ms/step - accuracy: 0.4241 - loss: 2.7277 - val_accuracy: 0.6298 - val_loss: 1.7181 - learning_rate: 2.0250e-05
Epoch 70/300
1413/1413 - 231s - 164ms/step - accuracy: 0.4198 - loss: 2.7467 - val_accuracy: 0.6091 - val_loss: 1.7793 - learning_rate: 2.0250e-05
Epoch 71/300
1413/1413 - 232s - 164ms/step - accuracy: 0.4131 - loss: 2.7572 - val_accuracy: 0.6234 - val_loss: 1.7599 - learning_rate: 2.0250e-05
Epoch 72/300
1413/1413 - 232s - 164ms/step - accuracy: 0.4177 - loss: 2.7261 - val_accuracy: 0.6099 - val_loss: 1.8067 - learning_rate: 2.0250e-05
Epoch 73/300
1413/1413 - 263s - 186ms/step - accuracy: 0.4214 - loss: 2.7388 - val_accuracy: 0.6083 - val_loss: 1.7431 - learning_rate: 2.0250e-05
Epoch 74/300
1413/1413 - 230s - 163ms/step - accuracy: 0.4200 - loss: 2.7412 - val_accuracy: 0.6178 - val_loss: 1.7572 - learning_rate: 2.0250e-05
Epoch 75/300
1413/1413 - 263s - 186ms/step - accuracy: 0.4147 - loss: 2.7460 - val_accuracy: 0.6162 - val_loss: 1.7617 - learning_rate: 2.0250e-05
Epoch 76/300
1413/1413 - 233s - 165ms/step - accuracy: 0.4263 - loss: 2.7238 - val_accuracy: 0.6154 - val_loss: 1.7420 - learning_rate: 2.0250e-05
Epoch 77/300

Epoch 77: ReduceLROnPlateau reducing learning rate to 1.0124771506525576e-05.
1413/1413 - 231s - 163ms/step - accuracy: 0.4175 - loss: 2.7136 - val_accuracy: 0.6242 - val_loss: 1.7693 - learning_rate: 2.0250e-05
Epoch 78/300
1413/1413 - 234s - 166ms/step - accuracy: 0.4265 - loss: 2.7141 - val_accuracy: 0.6298 - val_loss: 1.7611 - learning_rate: 1.0125e-05
Epoch 79/300
1413/1413 - 230s - 163ms/step - accuracy: 0.4217 - loss: 2.6979 - val_accuracy: 0.6338 - val_loss: 1.7570 - learning_rate: 1.0125e-05
Epoch 80/300
1413/1413 - 235s - 167ms/step - accuracy: 0.4235 - loss: 2.7018 - val_accuracy: 0.6354 - val_loss: 1.7659 - learning_rate: 1.0125e-05
Epoch 81/300
1413/1413 - 233s - 165ms/step - accuracy: 0.4198 - loss: 2.7299 - val_accuracy: 0.6282 - val_loss: 1.7325 - learning_rate: 1.0125e-05
Epoch 82/300
1413/1413 - 231s - 164ms/step - accuracy: 0.4202 - loss: 2.7124 - val_accuracy: 0.6298 - val_loss: 1.7419 - learning_rate: 1.0125e-05
Epoch 83/300
1413/1413 - 234s - 165ms/step - accuracy: 0.4291 - loss: 2.7036 - val_accuracy: 0.6146 - val_loss: 1.7975 - learning_rate: 1.0125e-05
Epoch 84/300
1413/1413 - 231s - 163ms/step - accuracy: 0.4204 - loss: 2.7110 - val_accuracy: 0.6186 - val_loss: 1.8252 - learning_rate: 1.0125e-05
Epoch 85/300
1413/1413 - 233s - 165ms/step - accuracy: 0.4233 - loss: 2.7084 - val_accuracy: 0.6338 - val_loss: 1.7177 - learning_rate: 1.0125e-05
Epoch 86/300
1413/1413 - 228s - 161ms/step - accuracy: 0.4240 - loss: 2.6881 - val_accuracy: 0.6306 - val_loss: 1.7909 - learning_rate: 1.0125e-05
Epoch 87/300
1413/1413 - 231s - 163ms/step - accuracy: 0.4211 - loss: 2.7006 - val_accuracy: 0.6298 - val_loss: 1.7445 - learning_rate: 1.0125e-05
Epoch 88/300
1413/1413 - 232s - 164ms/step - accuracy: 0.4344 - loss: 2.6780 - val_accuracy: 0.6290 - val_loss: 1.7449 - learning_rate: 1.0125e-05
Epoch 89/300
1413/1413 - 233s - 165ms/step - accuracy: 0.4249 - loss: 2.6948 - val_accuracy: 0.6266 - val_loss: 1.7423 - learning_rate: 1.0125e-05
Epoch 90/300
1413/1413 - 228s - 162ms/step - accuracy: 0.4274 - loss: 2.6901 - val_accuracy: 0.6385 - val_loss: 1.6748 - learning_rate: 1.0125e-05
Epoch 91/300
1413/1413 - 231s - 164ms/step - accuracy: 0.4352 - loss: 2.6748 - val_accuracy: 0.6330 - val_loss: 1.7234 - learning_rate: 1.0125e-05
Epoch 92/300
1413/1413 - 234s - 166ms/step - accuracy: 0.4235 - loss: 2.6941 - val_accuracy: 0.6250 - val_loss: 1.7288 - learning_rate: 1.0125e-05
Epoch 93/300
1413/1413 - 234s - 165ms/step - accuracy: 0.4255 - loss: 2.6924 - val_accuracy: 0.6202 - val_loss: 1.7091 - learning_rate: 1.0125e-05
Epoch 94/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4272 - loss: 2.6935 - val_accuracy: 0.6131 - val_loss: 1.7512 - learning_rate: 1.0125e-05
Epoch 95/300
1413/1413 - 233s - 165ms/step - accuracy: 0.4243 - loss: 2.6863 - val_accuracy: 0.6330 - val_loss: 1.7372 - learning_rate: 1.0125e-05
Epoch 96/300
1413/1413 - 230s - 163ms/step - accuracy: 0.4297 - loss: 2.6850 - val_accuracy: 0.6298 - val_loss: 1.7586 - learning_rate: 1.0125e-05
Epoch 97/300
1413/1413 - 233s - 165ms/step - accuracy: 0.4231 - loss: 2.6867 - val_accuracy: 0.6361 - val_loss: 1.6695 - learning_rate: 1.0125e-05
Epoch 98/300
1413/1413 - 230s - 162ms/step - accuracy: 0.4261 - loss: 2.7040 - val_accuracy: 0.6401 - val_loss: 1.7017 - learning_rate: 1.0125e-05
Epoch 99/300
1413/1413 - 232s - 164ms/step - accuracy: 0.4282 - loss: 2.7235 - val_accuracy: 0.6361 - val_loss: 1.6795 - learning_rate: 1.0125e-05
Epoch 100/300
1413/1413 - 230s - 163ms/step - accuracy: 0.4249 - loss: 2.6888 - val_accuracy: 0.6178 - val_loss: 1.7436 - learning_rate: 1.0125e-05
Epoch 101/300
1413/1413 - 233s - 165ms/step - accuracy: 0.4306 - loss: 2.6796 - val_accuracy: 0.6457 - val_loss: 1.7123 - learning_rate: 1.0125e-05
Epoch 102/300
