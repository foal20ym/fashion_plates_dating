TensorFlow Version: 2.20.0-dev20250508
Num GPUs Available: 1
Physical devices cannot be modified after being initialized

=== Using model: ConvNeXtTiny. ===
RUN ID: 2025-05-22_16:52:18
Task: Classification

===== Fold 0 =====

===== Fine Tuning 7 layers! =====
Epoch 1/300
1413/1413 - 299s - 212ms/step - accuracy: 0.1282 - loss: 4.5161 - val_accuracy: 0.1823 - val_loss: 4.0474 - learning_rate: 1.6200e-04
Epoch 2/300
1413/1413 - 226s - 160ms/step - accuracy: 0.1872 - loss: 4.0381 - val_accuracy: 0.2277 - val_loss: 4.3913 - learning_rate: 1.6200e-04
Epoch 3/300
1413/1413 - 222s - 157ms/step - accuracy: 0.2245 - loss: 3.8313 - val_accuracy: 0.3010 - val_loss: 3.2706 - learning_rate: 1.6200e-04
Epoch 4/300
1413/1413 - 224s - 159ms/step - accuracy: 0.2431 - loss: 3.6801 - val_accuracy: 0.2022 - val_loss: 4.4623 - learning_rate: 1.6200e-04
Epoch 5/300
1413/1413 - 225s - 159ms/step - accuracy: 0.2616 - loss: 3.5873 - val_accuracy: 0.3583 - val_loss: 3.0564 - learning_rate: 1.6200e-04
Epoch 6/300
1413/1413 - 226s - 160ms/step - accuracy: 0.2736 - loss: 3.5206 - val_accuracy: 0.3997 - val_loss: 3.0042 - learning_rate: 1.6200e-04
Epoch 7/300
1413/1413 - 227s - 160ms/step - accuracy: 0.2799 - loss: 3.4774 - val_accuracy: 0.2731 - val_loss: 3.8012 - learning_rate: 1.6200e-04
Epoch 8/300
1413/1413 - 224s - 159ms/step - accuracy: 0.2842 - loss: 3.4466 - val_accuracy: 0.3416 - val_loss: 2.8085 - learning_rate: 1.6200e-04
Epoch 9/300
1413/1413 - 225s - 159ms/step - accuracy: 0.2889 - loss: 3.4111 - val_accuracy: 0.3169 - val_loss: 3.0921 - learning_rate: 1.6200e-04
Epoch 10/300
1413/1413 - 226s - 160ms/step - accuracy: 0.2974 - loss: 3.3509 - val_accuracy: 0.3336 - val_loss: 3.4327 - learning_rate: 1.6200e-04
Epoch 11/300
1413/1413 - 231s - 163ms/step - accuracy: 0.2980 - loss: 3.3632 - val_accuracy: 0.4053 - val_loss: 2.9217 - learning_rate: 1.6200e-04
Epoch 12/300
1413/1413 - 227s - 160ms/step - accuracy: 0.3073 - loss: 3.3141 - val_accuracy: 0.4084 - val_loss: 2.9144 - learning_rate: 1.6200e-04
Epoch 13/300
1413/1413 - 224s - 159ms/step - accuracy: 0.3079 - loss: 3.3044 - val_accuracy: 0.2962 - val_loss: 3.5214 - learning_rate: 1.6200e-04
Epoch 14/300
1413/1413 - 225s - 159ms/step - accuracy: 0.3158 - loss: 3.2545 - val_accuracy: 0.3527 - val_loss: 3.0403 - learning_rate: 1.6200e-04
Epoch 15/300
1413/1413 - 237s - 168ms/step - accuracy: 0.3239 - loss: 3.2415 - val_accuracy: 0.4658 - val_loss: 2.5105 - learning_rate: 1.6200e-04
Epoch 16/300
1413/1413 - 237s - 168ms/step - accuracy: 0.3194 - loss: 3.2161 - val_accuracy: 0.4538 - val_loss: 2.5166 - learning_rate: 1.6200e-04
Epoch 17/300
1413/1413 - 234s - 166ms/step - accuracy: 0.3312 - loss: 3.1636 - val_accuracy: 0.3583 - val_loss: 2.9105 - learning_rate: 1.6200e-04
Epoch 18/300
1413/1413 - 236s - 167ms/step - accuracy: 0.3309 - loss: 3.1851 - val_accuracy: 0.4188 - val_loss: 3.0105 - learning_rate: 1.6200e-04
Epoch 19/300
1413/1413 - 235s - 166ms/step - accuracy: 0.3420 - loss: 3.1365 - val_accuracy: 0.4196 - val_loss: 2.9089 - learning_rate: 1.6200e-04
Epoch 20/300
1413/1413 - 235s - 167ms/step - accuracy: 0.3367 - loss: 3.1456 - val_accuracy: 0.3973 - val_loss: 3.0492 - learning_rate: 1.6200e-04
Epoch 21/300
1413/1413 - 237s - 168ms/step - accuracy: 0.3410 - loss: 3.1258 - val_accuracy: 0.3933 - val_loss: 2.8210 - learning_rate: 1.6200e-04
Epoch 22/300
1413/1413 - 234s - 165ms/step - accuracy: 0.3434 - loss: 3.1250 - val_accuracy: 0.4252 - val_loss: 2.7958 - learning_rate: 1.6200e-04
Epoch 23/300
1413/1413 - 235s - 166ms/step - accuracy: 0.3430 - loss: 3.1219 - val_accuracy: 0.4952 - val_loss: 2.4455 - learning_rate: 1.6200e-04
Epoch 24/300
1413/1413 - 233s - 165ms/step - accuracy: 0.3490 - loss: 3.0951 - val_accuracy: 0.4618 - val_loss: 2.5263 - learning_rate: 1.6200e-04
Epoch 25/300
1413/1413 - 229s - 162ms/step - accuracy: 0.3439 - loss: 3.0820 - val_accuracy: 0.4323 - val_loss: 2.9965 - learning_rate: 1.6200e-04
Epoch 26/300
1413/1413 - 232s - 164ms/step - accuracy: 0.3419 - loss: 3.0928 - val_accuracy: 0.4889 - val_loss: 2.3390 - learning_rate: 1.6200e-04
Epoch 27/300
1413/1413 - 221s - 156ms/step - accuracy: 0.3521 - loss: 3.0660 - val_accuracy: 0.4904 - val_loss: 2.6799 - learning_rate: 1.6200e-04
Epoch 28/300
1413/1413 - 219s - 155ms/step - accuracy: 0.3563 - loss: 3.0436 - val_accuracy: 0.4896 - val_loss: 2.4158 - learning_rate: 1.6200e-04
Epoch 29/300
1413/1413 - 217s - 154ms/step - accuracy: 0.3553 - loss: 3.0469 - val_accuracy: 0.4379 - val_loss: 2.6868 - learning_rate: 1.6200e-04
Epoch 30/300
1413/1413 - 223s - 158ms/step - accuracy: 0.3550 - loss: 3.0206 - val_accuracy: 0.5318 - val_loss: 2.3489 - learning_rate: 1.6200e-04
Epoch 31/300
1413/1413 - 225s - 159ms/step - accuracy: 0.3671 - loss: 2.9997 - val_accuracy: 0.5255 - val_loss: 2.2072 - learning_rate: 1.6200e-04
Epoch 32/300
1413/1413 - 218s - 154ms/step - accuracy: 0.3672 - loss: 3.0026 - val_accuracy: 0.4984 - val_loss: 2.6002 - learning_rate: 1.6200e-04
Epoch 33/300
1413/1413 - 219s - 155ms/step - accuracy: 0.3674 - loss: 2.9858 - val_accuracy: 0.4705 - val_loss: 2.5089 - learning_rate: 1.6200e-04
Epoch 34/300
1413/1413 - 223s - 158ms/step - accuracy: 0.3657 - loss: 3.0076 - val_accuracy: 0.5366 - val_loss: 2.1178 - learning_rate: 1.6200e-04
Epoch 35/300
1413/1413 - 219s - 155ms/step - accuracy: 0.3665 - loss: 2.9887 - val_accuracy: 0.4912 - val_loss: 2.3491 - learning_rate: 1.6200e-04
Epoch 36/300
1413/1413 - 225s - 159ms/step - accuracy: 0.3735 - loss: 2.9891 - val_accuracy: 0.4976 - val_loss: 2.4757 - learning_rate: 1.6200e-04
Epoch 37/300
1413/1413 - 267s - 189ms/step - accuracy: 0.3727 - loss: 2.9680 - val_accuracy: 0.5318 - val_loss: 2.4458 - learning_rate: 1.6200e-04
Epoch 38/300
1413/1413 - 222s - 157ms/step - accuracy: 0.3693 - loss: 2.9965 - val_accuracy: 0.5318 - val_loss: 2.4988 - learning_rate: 1.6200e-04
Epoch 39/300
1413/1413 - 220s - 156ms/step - accuracy: 0.3680 - loss: 2.9861 - val_accuracy: 0.5382 - val_loss: 2.4931 - learning_rate: 1.6200e-04
Epoch 40/300
1413/1413 - 223s - 158ms/step - accuracy: 0.3750 - loss: 2.9637 - val_accuracy: 0.4642 - val_loss: 3.1268 - learning_rate: 1.6200e-04
Epoch 41/300
1413/1413 - 219s - 155ms/step - accuracy: 0.3724 - loss: 2.9733 - val_accuracy: 0.4005 - val_loss: 3.1628 - learning_rate: 1.6200e-04
Epoch 42/300

Epoch 42: ReduceLROnPlateau reducing learning rate to 8.099817205220461e-05.
1413/1413 - 223s - 158ms/step - accuracy: 0.3744 - loss: 2.9433 - val_accuracy: 0.5175 - val_loss: 2.2149 - learning_rate: 1.6200e-04
Epoch 43/300
1413/1413 - 225s - 159ms/step - accuracy: 0.3889 - loss: 2.8617 - val_accuracy: 0.5613 - val_loss: 2.0938 - learning_rate: 8.0998e-05
Epoch 44/300
1413/1413 - 222s - 157ms/step - accuracy: 0.3914 - loss: 2.8717 - val_accuracy: 0.5549 - val_loss: 2.2265 - learning_rate: 8.0998e-05
Epoch 45/300
1413/1413 - 219s - 155ms/step - accuracy: 0.3902 - loss: 2.8642 - val_accuracy: 0.5303 - val_loss: 2.2895 - learning_rate: 8.0998e-05
Epoch 46/300
1413/1413 - 231s - 163ms/step - accuracy: 0.3996 - loss: 2.8417 - val_accuracy: 0.5653 - val_loss: 2.1098 - learning_rate: 8.0998e-05
Epoch 47/300
1413/1413 - 231s - 164ms/step - accuracy: 0.3982 - loss: 2.8634 - val_accuracy: 0.5589 - val_loss: 2.1880 - learning_rate: 8.0998e-05
Epoch 48/300
1413/1413 - 232s - 164ms/step - accuracy: 0.3875 - loss: 2.8477 - val_accuracy: 0.5350 - val_loss: 2.1860 - learning_rate: 8.0998e-05
Epoch 49/300
1413/1413 - 227s - 161ms/step - accuracy: 0.3961 - loss: 2.8463 - val_accuracy: 0.5605 - val_loss: 1.9436 - learning_rate: 8.0998e-05
Epoch 50/300
1413/1413 - 233s - 165ms/step - accuracy: 0.3928 - loss: 2.8476 - val_accuracy: 0.5541 - val_loss: 1.9722 - learning_rate: 8.0998e-05
Epoch 51/300
1413/1413 - 234s - 166ms/step - accuracy: 0.3990 - loss: 2.8463 - val_accuracy: 0.5167 - val_loss: 2.4577 - learning_rate: 8.0998e-05
Epoch 52/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4019 - loss: 2.8165 - val_accuracy: 0.5072 - val_loss: 2.4353 - learning_rate: 8.0998e-05
Epoch 53/300
1413/1413 - 224s - 159ms/step - accuracy: 0.3928 - loss: 2.8564 - val_accuracy: 0.6027 - val_loss: 1.9061 - learning_rate: 8.0998e-05
Epoch 54/300
1413/1413 - 220s - 156ms/step - accuracy: 0.3967 - loss: 2.8332 - val_accuracy: 0.5581 - val_loss: 1.9639 - learning_rate: 8.0998e-05
Epoch 55/300
1413/1413 - 226s - 160ms/step - accuracy: 0.3963 - loss: 2.8419 - val_accuracy: 0.5231 - val_loss: 2.1533 - learning_rate: 8.0998e-05
Epoch 56/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4023 - loss: 2.8196 - val_accuracy: 0.5780 - val_loss: 2.1419 - learning_rate: 8.0998e-05
Epoch 57/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4010 - loss: 2.8217 - val_accuracy: 0.5326 - val_loss: 2.3027 - learning_rate: 8.0998e-05
Epoch 58/300
1413/1413 - 217s - 153ms/step - accuracy: 0.4030 - loss: 2.8239 - val_accuracy: 0.5908 - val_loss: 1.9158 - learning_rate: 8.0998e-05
Epoch 59/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4015 - loss: 2.8386 - val_accuracy: 0.5613 - val_loss: 1.9285 - learning_rate: 8.0998e-05
Epoch 60/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4011 - loss: 2.8160 - val_accuracy: 0.5390 - val_loss: 2.0052 - learning_rate: 8.0998e-05
Epoch 61/300

Epoch 61: ReduceLROnPlateau reducing learning rate to 4.0499086026102304e-05.
1413/1413 - 221s - 156ms/step - accuracy: 0.4066 - loss: 2.8210 - val_accuracy: 0.5279 - val_loss: 2.4325 - learning_rate: 8.0998e-05
Epoch 62/300
1413/1413 - 219s - 155ms/step - accuracy: 0.4113 - loss: 2.7562 - val_accuracy: 0.6210 - val_loss: 1.7713 - learning_rate: 4.0499e-05
Epoch 63/300
1413/1413 - 221s - 156ms/step - accuracy: 0.4210 - loss: 2.7432 - val_accuracy: 0.6115 - val_loss: 1.7919 - learning_rate: 4.0499e-05
Epoch 64/300
1413/1413 - 221s - 156ms/step - accuracy: 0.4141 - loss: 2.7605 - val_accuracy: 0.6035 - val_loss: 1.9169 - learning_rate: 4.0499e-05
Epoch 65/300
1413/1413 - 224s - 159ms/step - accuracy: 0.4102 - loss: 2.7582 - val_accuracy: 0.6154 - val_loss: 1.8290 - learning_rate: 4.0499e-05
Epoch 66/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4125 - loss: 2.7536 - val_accuracy: 0.6441 - val_loss: 1.7448 - learning_rate: 4.0499e-05
Epoch 67/300
1413/1413 - 221s - 156ms/step - accuracy: 0.4162 - loss: 2.7533 - val_accuracy: 0.6266 - val_loss: 1.9352 - learning_rate: 4.0499e-05
Epoch 68/300
1413/1413 - 228s - 162ms/step - accuracy: 0.4133 - loss: 2.7529 - val_accuracy: 0.5884 - val_loss: 1.9350 - learning_rate: 4.0499e-05
Epoch 69/300
1413/1413 - 228s - 161ms/step - accuracy: 0.4215 - loss: 2.7337 - val_accuracy: 0.6051 - val_loss: 1.8455 - learning_rate: 4.0499e-05
Epoch 70/300
1413/1413 - 232s - 164ms/step - accuracy: 0.4219 - loss: 2.7160 - val_accuracy: 0.6162 - val_loss: 1.7975 - learning_rate: 4.0499e-05
Epoch 71/300
1413/1413 - 232s - 164ms/step - accuracy: 0.4198 - loss: 2.7324 - val_accuracy: 0.6011 - val_loss: 2.0625 - learning_rate: 4.0499e-05
Epoch 72/300
1413/1413 - 233s - 165ms/step - accuracy: 0.4191 - loss: 2.7599 - val_accuracy: 0.6186 - val_loss: 1.7901 - learning_rate: 4.0499e-05
Epoch 73/300
1413/1413 - 232s - 164ms/step - accuracy: 0.4231 - loss: 2.7174 - val_accuracy: 0.6226 - val_loss: 1.8151 - learning_rate: 4.0499e-05
Epoch 74/300

Epoch 74: ReduceLROnPlateau reducing learning rate to 2.0249543013051152e-05.
1413/1413 - 227s - 161ms/step - accuracy: 0.4244 - loss: 2.7220 - val_accuracy: 0.5812 - val_loss: 2.1567 - learning_rate: 4.0499e-05
Epoch 75/300
1413/1413 - 220s - 156ms/step - accuracy: 0.4233 - loss: 2.7055 - val_accuracy: 0.6417 - val_loss: 1.6960 - learning_rate: 2.0250e-05
Epoch 76/300
1413/1413 - 221s - 156ms/step - accuracy: 0.4322 - loss: 2.6766 - val_accuracy: 0.6377 - val_loss: 1.7498 - learning_rate: 2.0250e-05
Epoch 77/300
1413/1413 - 220s - 156ms/step - accuracy: 0.4277 - loss: 2.6705 - val_accuracy: 0.6401 - val_loss: 1.7353 - learning_rate: 2.0250e-05
Epoch 78/300
1413/1413 - 221s - 156ms/step - accuracy: 0.4278 - loss: 2.6851 - val_accuracy: 0.6417 - val_loss: 1.7607 - learning_rate: 2.0250e-05
Epoch 79/300
1413/1413 - 220s - 155ms/step - accuracy: 0.4306 - loss: 2.6794 - val_accuracy: 0.6346 - val_loss: 1.7292 - learning_rate: 2.0250e-05
Epoch 80/300
1413/1413 - 224s - 158ms/step - accuracy: 0.4263 - loss: 2.6949 - val_accuracy: 0.6465 - val_loss: 1.6947 - learning_rate: 2.0250e-05
Epoch 81/300
1413/1413 - 217s - 154ms/step - accuracy: 0.4306 - loss: 2.6717 - val_accuracy: 0.6481 - val_loss: 1.6750 - learning_rate: 2.0250e-05
Epoch 82/300
1413/1413 - 220s - 156ms/step - accuracy: 0.4332 - loss: 2.6790 - val_accuracy: 0.6194 - val_loss: 1.7527 - learning_rate: 2.0250e-05
Epoch 83/300
1413/1413 - 221s - 157ms/step - accuracy: 0.4281 - loss: 2.6613 - val_accuracy: 0.5955 - val_loss: 1.9466 - learning_rate: 2.0250e-05
Epoch 84/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4293 - loss: 2.6573 - val_accuracy: 0.6545 - val_loss: 1.6722 - learning_rate: 2.0250e-05
Epoch 85/300
1413/1413 - 219s - 155ms/step - accuracy: 0.4325 - loss: 2.6919 - val_accuracy: 0.6361 - val_loss: 1.7236 - learning_rate: 2.0250e-05
Epoch 86/300
1413/1413 - 221s - 157ms/step - accuracy: 0.4323 - loss: 2.6643 - val_accuracy: 0.6393 - val_loss: 1.7412 - learning_rate: 2.0250e-05
Epoch 87/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4322 - loss: 2.6526 - val_accuracy: 0.6465 - val_loss: 1.6833 - learning_rate: 2.0250e-05
Epoch 88/300
1413/1413 - 227s - 160ms/step - accuracy: 0.4284 - loss: 2.6922 - val_accuracy: 0.6361 - val_loss: 1.8269 - learning_rate: 2.0250e-05
Epoch 89/300
1413/1413 - 216s - 153ms/step - accuracy: 0.4280 - loss: 2.6687 - val_accuracy: 0.6553 - val_loss: 1.6887 - learning_rate: 2.0250e-05
Epoch 90/300
1413/1413 - 219s - 155ms/step - accuracy: 0.4262 - loss: 2.6647 - val_accuracy: 0.6298 - val_loss: 1.6864 - learning_rate: 2.0250e-05
Epoch 91/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4302 - loss: 2.6795 - val_accuracy: 0.6449 - val_loss: 1.7243 - learning_rate: 2.0250e-05
Epoch 92/300

Epoch 92: ReduceLROnPlateau reducing learning rate to 1.0124771506525576e-05.
1413/1413 - 220s - 156ms/step - accuracy: 0.4280 - loss: 2.6582 - val_accuracy: 0.6409 - val_loss: 1.7247 - learning_rate: 2.0250e-05
Epoch 93/300
1413/1413 - 218s - 154ms/step - accuracy: 0.4324 - loss: 2.6471 - val_accuracy: 0.6457 - val_loss: 1.6512 - learning_rate: 1.0125e-05
Epoch 94/300
1413/1413 - 224s - 159ms/step - accuracy: 0.4358 - loss: 2.6384 - val_accuracy: 0.6481 - val_loss: 1.6707 - learning_rate: 1.0125e-05
Epoch 95/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4380 - loss: 2.6407 - val_accuracy: 0.6553 - val_loss: 1.6754 - learning_rate: 1.0125e-05
Epoch 96/300
1413/1413 - 220s - 156ms/step - accuracy: 0.4331 - loss: 2.6594 - val_accuracy: 0.6425 - val_loss: 1.7221 - learning_rate: 1.0125e-05
Epoch 97/300
1413/1413 - 221s - 156ms/step - accuracy: 0.4291 - loss: 2.6348 - val_accuracy: 0.6497 - val_loss: 1.6399 - learning_rate: 1.0125e-05
Epoch 98/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4403 - loss: 2.6065 - val_accuracy: 0.6473 - val_loss: 1.6588 - learning_rate: 1.0125e-05
Epoch 99/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4368 - loss: 2.6213 - val_accuracy: 0.6465 - val_loss: 1.6776 - learning_rate: 1.0125e-05
Epoch 100/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4340 - loss: 2.6433 - val_accuracy: 0.6385 - val_loss: 1.7249 - learning_rate: 1.0125e-05
Epoch 101/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4287 - loss: 2.6384 - val_accuracy: 0.6465 - val_loss: 1.7108 - learning_rate: 1.0125e-05
Epoch 102/300
1413/1413 - 221s - 156ms/step - accuracy: 0.4404 - loss: 2.6312 - val_accuracy: 0.6425 - val_loss: 1.6427 - learning_rate: 1.0125e-05
Epoch 103/300
1413/1413 - 220s - 156ms/step - accuracy: 0.4371 - loss: 2.6434 - val_accuracy: 0.6616 - val_loss: 1.6281 - learning_rate: 1.0125e-05
Epoch 104/300
1413/1413 - 219s - 155ms/step - accuracy: 0.4337 - loss: 2.6126 - val_accuracy: 0.6513 - val_loss: 1.6537 - learning_rate: 1.0125e-05
Epoch 105/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4426 - loss: 2.6147 - val_accuracy: 0.6529 - val_loss: 1.6500 - learning_rate: 1.0125e-05
Epoch 106/300
1413/1413 - 220s - 156ms/step - accuracy: 0.4370 - loss: 2.6295 - val_accuracy: 0.6441 - val_loss: 1.6626 - learning_rate: 1.0125e-05
Epoch 107/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4386 - loss: 2.6458 - val_accuracy: 0.6354 - val_loss: 1.7945 - learning_rate: 1.0125e-05
Epoch 108/300
1413/1413 - 221s - 157ms/step - accuracy: 0.4365 - loss: 2.6151 - val_accuracy: 0.6433 - val_loss: 1.7192 - learning_rate: 1.0125e-05
Epoch 109/300
1413/1413 - 219s - 155ms/step - accuracy: 0.4409 - loss: 2.6165 - val_accuracy: 0.6632 - val_loss: 1.6559 - learning_rate: 1.0125e-05
Epoch 110/300
1413/1413 - 221s - 157ms/step - accuracy: 0.4440 - loss: 2.6054 - val_accuracy: 0.6497 - val_loss: 1.6356 - learning_rate: 1.0125e-05
Epoch 111/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4417 - loss: 2.6418 - val_accuracy: 0.6664 - val_loss: 1.6054 - learning_rate: 1.0125e-05
Epoch 112/300
1413/1413 - 218s - 154ms/step - accuracy: 0.4367 - loss: 2.6345 - val_accuracy: 0.6529 - val_loss: 1.6434 - learning_rate: 1.0125e-05
Epoch 113/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4406 - loss: 2.6407 - val_accuracy: 0.6696 - val_loss: 1.6134 - learning_rate: 1.0125e-05
Epoch 114/300
1413/1413 - 220s - 156ms/step - accuracy: 0.4490 - loss: 2.6239 - val_accuracy: 0.6648 - val_loss: 1.6435 - learning_rate: 1.0125e-05
Epoch 115/300
1413/1413 - 220s - 156ms/step - accuracy: 0.4440 - loss: 2.6289 - val_accuracy: 0.6513 - val_loss: 1.6527 - learning_rate: 1.0125e-05
Epoch 116/300
1413/1413 - 221s - 156ms/step - accuracy: 0.4435 - loss: 2.5964 - val_accuracy: 0.6553 - val_loss: 1.6204 - learning_rate: 1.0125e-05
Epoch 117/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4459 - loss: 2.6141 - val_accuracy: 0.6616 - val_loss: 1.6280 - learning_rate: 1.0125e-05
Epoch 118/300
1413/1413 - 218s - 154ms/step - accuracy: 0.4371 - loss: 2.6236 - val_accuracy: 0.6441 - val_loss: 1.7236 - learning_rate: 1.0125e-05
Epoch 119/300
1413/1413 - 221s - 157ms/step - accuracy: 0.4409 - loss: 2.6304 - val_accuracy: 0.6632 - val_loss: 1.5892 - learning_rate: 1.0125e-05
Epoch 120/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4486 - loss: 2.5976 - val_accuracy: 0.6664 - val_loss: 1.6325 - learning_rate: 1.0125e-05
Epoch 121/300
1413/1413 - 218s - 154ms/step - accuracy: 0.4483 - loss: 2.5886 - val_accuracy: 0.6457 - val_loss: 1.6419 - learning_rate: 1.0125e-05
Epoch 122/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4417 - loss: 2.6138 - val_accuracy: 0.6545 - val_loss: 1.6420 - learning_rate: 1.0125e-05
Epoch 123/300
1413/1413 - 220s - 156ms/step - accuracy: 0.4386 - loss: 2.6055 - val_accuracy: 0.6473 - val_loss: 1.6653 - learning_rate: 1.0125e-05
Epoch 124/300
1413/1413 - 224s - 158ms/step - accuracy: 0.4381 - loss: 2.6114 - val_accuracy: 0.6489 - val_loss: 1.6639 - learning_rate: 1.0125e-05
Epoch 125/300
1413/1413 - 219s - 155ms/step - accuracy: 0.4461 - loss: 2.6014 - val_accuracy: 0.6608 - val_loss: 1.6287 - learning_rate: 1.0125e-05
Epoch 126/300
1413/1413 - 219s - 155ms/step - accuracy: 0.4459 - loss: 2.6190 - val_accuracy: 0.6537 - val_loss: 1.6381 - learning_rate: 1.0125e-05
Epoch 127/300

Epoch 127: ReduceLROnPlateau reducing learning rate to 5.062385753262788e-06.
1413/1413 - 218s - 154ms/step - accuracy: 0.4440 - loss: 2.5948 - val_accuracy: 0.6616 - val_loss: 1.6282 - learning_rate: 1.0125e-05
Epoch 128/300
1413/1413 - 219s - 155ms/step - accuracy: 0.4441 - loss: 2.6380 - val_accuracy: 0.6672 - val_loss: 1.6130 - learning_rate: 5.0624e-06
Epoch 129/300
1413/1413 - 215s - 152ms/step - accuracy: 0.4458 - loss: 2.5935 - val_accuracy: 0.6576 - val_loss: 1.6283 - learning_rate: 5.0624e-06
Epoch 130/300
1413/1413 - 223s - 157ms/step - accuracy: 0.4446 - loss: 2.6074 - val_accuracy: 0.6568 - val_loss: 1.6294 - learning_rate: 5.0624e-06
Epoch 131/300
1413/1413 - 220s - 156ms/step - accuracy: 0.4459 - loss: 2.6016 - val_accuracy: 0.6561 - val_loss: 1.5803 - learning_rate: 5.0624e-06
Epoch 132/300
1413/1413 - 220s - 156ms/step - accuracy: 0.4431 - loss: 2.6057 - val_accuracy: 0.6624 - val_loss: 1.6195 - learning_rate: 5.0624e-06
Epoch 133/300
1413/1413 - 219s - 155ms/step - accuracy: 0.4441 - loss: 2.6179 - val_accuracy: 0.6473 - val_loss: 1.6797 - learning_rate: 5.0624e-06
Epoch 134/300
1413/1413 - 219s - 155ms/step - accuracy: 0.4475 - loss: 2.5930 - val_accuracy: 0.6545 - val_loss: 1.6078 - learning_rate: 5.0624e-06
Epoch 135/300
1413/1413 - 219s - 155ms/step - accuracy: 0.4453 - loss: 2.5920 - val_accuracy: 0.6369 - val_loss: 1.6674 - learning_rate: 5.0624e-06
Epoch 136/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4377 - loss: 2.6022 - val_accuracy: 0.6521 - val_loss: 1.6030 - learning_rate: 5.0624e-06
Epoch 137/300
1413/1413 - 220s - 156ms/step - accuracy: 0.4394 - loss: 2.6221 - val_accuracy: 0.6568 - val_loss: 1.6089 - learning_rate: 5.0624e-06
Epoch 138/300
1413/1413 - 218s - 154ms/step - accuracy: 0.4447 - loss: 2.5905 - val_accuracy: 0.6568 - val_loss: 1.6252 - learning_rate: 5.0624e-06
Epoch 139/300

Epoch 139: ReduceLROnPlateau reducing learning rate to 2.531192876631394e-06.
1413/1413 - 221s - 156ms/step - accuracy: 0.4419 - loss: 2.5857 - val_accuracy: 0.6481 - val_loss: 1.6441 - learning_rate: 5.0624e-06
Epoch 140/300
1413/1413 - 221s - 156ms/step - accuracy: 0.4463 - loss: 2.5774 - val_accuracy: 0.6576 - val_loss: 1.6138 - learning_rate: 2.5312e-06
Epoch 141/300
1413/1413 - 217s - 154ms/step - accuracy: 0.4490 - loss: 2.5793 - val_accuracy: 0.6521 - val_loss: 1.6446 - learning_rate: 2.5312e-06
Epoch 142/300
1413/1413 - 219s - 155ms/step - accuracy: 0.4471 - loss: 2.5961 - val_accuracy: 0.6545 - val_loss: 1.6355 - learning_rate: 2.5312e-06
Epoch 143/300
1413/1413 - 220s - 156ms/step - accuracy: 0.4371 - loss: 2.6127 - val_accuracy: 0.6497 - val_loss: 1.6111 - learning_rate: 2.5312e-06
Epoch 144/300
1413/1413 - 225s - 160ms/step - accuracy: 0.4468 - loss: 2.6029 - val_accuracy: 0.6584 - val_loss: 1.6227 - learning_rate: 2.5312e-06
Epoch 145/300
1413/1413 - 219s - 155ms/step - accuracy: 0.4416 - loss: 2.6081 - val_accuracy: 0.6561 - val_loss: 1.6062 - learning_rate: 2.5312e-06
Epoch 146/300
1413/1413 - 221s - 156ms/step - accuracy: 0.4436 - loss: 2.6082 - val_accuracy: 0.6553 - val_loss: 1.6230 - learning_rate: 2.5312e-06
Epoch 147/300

Epoch 147: ReduceLROnPlateau reducing learning rate to 1.265596438315697e-06.
1413/1413 - 218s - 154ms/step - accuracy: 0.4493 - loss: 2.5659 - val_accuracy: 0.6545 - val_loss: 1.6126 - learning_rate: 2.5312e-06
Epoch 147: early stopping
Restoring model weights from the end of the best epoch: 131.
Fold 0 Evaluation results: [1.5819470882415771, 0.656050980091095]
              precision    recall  f1-score   support

        1820       0.83      0.81      0.82        62
        1821       0.89      0.89      0.89        57
        1822       0.00      0.00      0.00         1
        1823       0.50      1.00      0.67         1
        1824       0.00      0.00      0.00         1
        1825       0.00      0.00      0.00         3
        1826       0.00      0.00      0.00         2
        1827       0.85      0.92      0.88        25
        1828       0.00      0.00      0.00         1
        1829       0.67      0.80      0.73         5
        1830       0.81      0.54      0.65        56
        1831       0.88      0.90      0.89       134
        1832       0.63      0.84      0.72        67
        1833       0.94      0.89      0.92        19
        1834       0.54      0.72      0.62        29
        1835       0.00      0.00      0.00         2
        1836       0.25      0.25      0.25         4
        1837       0.38      0.83      0.53         6
        1838       1.00      0.33      0.50         3
        1839       0.00      0.00      0.00         1
        1840       0.67      0.72      0.70        43
        1841       0.80      0.69      0.74       108
        1842       0.62      0.83      0.71         6
        1843       0.50      0.17      0.25         6
        1844       0.00      0.00      0.00         1
        1845       0.00      0.00      0.00         1
        1846       0.33      0.50      0.40         6
        1847       0.50      0.50      0.50         2
        1848       0.00      0.00      0.00         5
        1849       0.21      0.50      0.30         6
        1850       0.49      0.56      0.52        48
        1851       0.74      0.81      0.77        77
        1852       0.00      0.00      0.00         7
        1853       0.00      0.00      0.00         7
        1854       0.00      0.00      0.00         3
        1855       0.48      0.43      0.45        23
        1856       0.64      0.58      0.61        12
        1857       0.43      0.67      0.52        30
        1858       0.00      0.00      0.00         2
        1859       0.00      0.00      0.00         2
        1860       0.31      0.35      0.33        65
        1861       0.80      0.78      0.79        85
        1862       0.30      0.32      0.31        19
        1863       0.67      0.53      0.59        19
        1864       0.64      0.53      0.58        17
        1865       0.33      0.57      0.42         7
        1866       0.17      0.20      0.18         5
        1867       0.33      0.45      0.38        11
        1868       0.00      0.00      0.00         7
        1869       0.00      0.00      0.00         5
        1870       0.46      0.39      0.42        31
        1871       0.74      0.76      0.75        49
        1872       0.75      0.43      0.55         7
        1873       0.00      0.00      0.00        10
        1874       0.00      0.00      0.00         5
        1875       0.55      0.43      0.48        14
        1876       0.57      0.80      0.67        10
        1877       0.44      0.80      0.57         5
        1878       0.50      0.44      0.47         9
        1879       0.00      0.00      0.00         2

    accuracy                           0.66      1256
   macro avg       0.39      0.41      0.38      1256
weighted avg       0.65      0.66      0.64      1256

Matthews Correlation Coefficient: 0.639
Macro avg F1: 0.384
Weighted avg F1: 0.644
Micro avg F1: 0.656
Top-3 Accuracy: 0.858
Top-5 Accuracy: 0.907
Micro ROC AUC  = 0.99
Macro ROC AUC (present classes) = 0.98
Classification MAE (in years): 2.90

Fold 0 Misclassification Analysis:
Near misses (within 2 years): 129 out of 432 misclassifications (29.86%)
Big misses (greater than 10 years): 187
MAE with outliers: 2.90
MAE without outliers: 1.91 (improvement: 0.98)

10 Worst misclassifications:
Image: data/datasets/public/1820/1820_036met.jpg, True: 1820, Predicted: 1873, Error: 53
Image: data/datasets/public/1820/1826_44washington.jpg, True: 1826, Predicted: 1876, Error: 50
Image: data/datasets/public/1870/1878_030met.jpg, True: 1878, Predicted: 1832, Error: 46
Image: data/datasets/public/1870/1876_455vna.jpg, True: 1876, Predicted: 1832, Error: 44
Image: data/datasets/public/1870/1872_1405vna.jpg, True: 1872, Predicted: 1830, Error: 42
Image: data/datasets/public/1870/1873_014met.jpg, True: 1873, Predicted: 1832, Error: 41
Image: data/datasets/public/1820/1820_026met.jpg, True: 1820, Predicted: 1861, Error: 41
Image: data/datasets/private/1860/1860_123et.jpg, True: 1860, Predicted: 1820, Error: 40
Image: data/datasets/public/1820/1825_819vna.jpg, True: 1825, Predicted: 1865, Error: 40
Image: data/datasets/public/1820/1820_046met.jpg, True: 1820, Predicted: 1860, Error: 40

===== Fold 1 =====

===== Fine Tuning 7 layers! =====
Epoch 1/300
1413/1413 - 241s - 171ms/step - accuracy: 0.1365 - loss: 4.4762 - val_accuracy: 0.1139 - val_loss: 5.2501 - learning_rate: 1.6200e-04
Epoch 2/300
1413/1413 - 219s - 155ms/step - accuracy: 0.1985 - loss: 3.9404 - val_accuracy: 0.2779 - val_loss: 3.9719 - learning_rate: 1.6200e-04
Epoch 3/300
1413/1413 - 220s - 156ms/step - accuracy: 0.2260 - loss: 3.7369 - val_accuracy: 0.1322 - val_loss: 5.5888 - learning_rate: 1.6200e-04
Epoch 4/300
1413/1413 - 219s - 155ms/step - accuracy: 0.2467 - loss: 3.6669 - val_accuracy: 0.2030 - val_loss: 4.6294 - learning_rate: 1.6200e-04
Epoch 5/300
1413/1413 - 218s - 154ms/step - accuracy: 0.2629 - loss: 3.6048 - val_accuracy: 0.1298 - val_loss: 6.2778 - learning_rate: 1.6200e-04
Epoch 6/300
1413/1413 - 221s - 157ms/step - accuracy: 0.2688 - loss: 3.5210 - val_accuracy: 0.2954 - val_loss: 3.7654 - learning_rate: 1.6200e-04
Epoch 7/300
1413/1413 - 218s - 155ms/step - accuracy: 0.2827 - loss: 3.4842 - val_accuracy: 0.3185 - val_loss: 3.7354 - learning_rate: 1.6200e-04
Epoch 8/300
1413/1413 - 221s - 157ms/step - accuracy: 0.2913 - loss: 3.4369 - val_accuracy: 0.2444 - val_loss: 4.1379 - learning_rate: 1.6200e-04
Epoch 9/300
1413/1413 - 218s - 154ms/step - accuracy: 0.2886 - loss: 3.4437 - val_accuracy: 0.3368 - val_loss: 3.0238 - learning_rate: 1.6200e-04
Epoch 10/300
1413/1413 - 223s - 158ms/step - accuracy: 0.2997 - loss: 3.3620 - val_accuracy: 0.4013 - val_loss: 2.6682 - learning_rate: 1.6200e-04
Epoch 11/300
1413/1413 - 219s - 155ms/step - accuracy: 0.3030 - loss: 3.3443 - val_accuracy: 0.3320 - val_loss: 3.4192 - learning_rate: 1.6200e-04
Epoch 12/300
1413/1413 - 226s - 160ms/step - accuracy: 0.3082 - loss: 3.3450 - val_accuracy: 0.4172 - val_loss: 2.6494 - learning_rate: 1.6200e-04
Epoch 13/300
1413/1413 - 217s - 154ms/step - accuracy: 0.3221 - loss: 3.2760 - val_accuracy: 0.3041 - val_loss: 4.0011 - learning_rate: 1.6200e-04
Epoch 14/300
1413/1413 - 220s - 156ms/step - accuracy: 0.3201 - loss: 3.2599 - val_accuracy: 0.4355 - val_loss: 2.5504 - learning_rate: 1.6200e-04
Epoch 15/300
1413/1413 - 225s - 159ms/step - accuracy: 0.3229 - loss: 3.2291 - val_accuracy: 0.4865 - val_loss: 2.5820 - learning_rate: 1.6200e-04
Epoch 16/300
1413/1413 - 220s - 156ms/step - accuracy: 0.3258 - loss: 3.2265 - val_accuracy: 0.3272 - val_loss: 3.5442 - learning_rate: 1.6200e-04
Epoch 17/300
1413/1413 - 221s - 157ms/step - accuracy: 0.3181 - loss: 3.2321 - val_accuracy: 0.4315 - val_loss: 2.7001 - learning_rate: 1.6200e-04
Epoch 18/300
1413/1413 - 224s - 158ms/step - accuracy: 0.3280 - loss: 3.1867 - val_accuracy: 0.4411 - val_loss: 2.7797 - learning_rate: 1.6200e-04
Epoch 19/300
1413/1413 - 222s - 157ms/step - accuracy: 0.3289 - loss: 3.1659 - val_accuracy: 0.4347 - val_loss: 2.8814 - learning_rate: 1.6200e-04
Epoch 20/300
1413/1413 - 222s - 157ms/step - accuracy: 0.3405 - loss: 3.1470 - val_accuracy: 0.4371 - val_loss: 2.6038 - learning_rate: 1.6200e-04
Epoch 21/300
1413/1413 - 220s - 156ms/step - accuracy: 0.3376 - loss: 3.1684 - val_accuracy: 0.4172 - val_loss: 2.5641 - learning_rate: 1.6200e-04
Epoch 22/300

Epoch 22: ReduceLROnPlateau reducing learning rate to 8.099817205220461e-05.
1413/1413 - 218s - 154ms/step - accuracy: 0.3333 - loss: 3.1707 - val_accuracy: 0.3718 - val_loss: 3.5337 - learning_rate: 1.6200e-04
Epoch 23/300
1413/1413 - 222s - 157ms/step - accuracy: 0.3538 - loss: 3.0733 - val_accuracy: 0.5422 - val_loss: 2.2318 - learning_rate: 8.0998e-05
Epoch 24/300
1413/1413 - 218s - 154ms/step - accuracy: 0.3507 - loss: 3.0463 - val_accuracy: 0.4833 - val_loss: 2.1903 - learning_rate: 8.0998e-05
Epoch 25/300
1413/1413 - 220s - 156ms/step - accuracy: 0.3631 - loss: 3.0259 - val_accuracy: 0.4459 - val_loss: 2.7136 - learning_rate: 8.0998e-05
Epoch 26/300
1413/1413 - 219s - 155ms/step - accuracy: 0.3608 - loss: 3.0291 - val_accuracy: 0.5167 - val_loss: 2.2607 - learning_rate: 8.0998e-05
Epoch 27/300
1413/1413 - 222s - 157ms/step - accuracy: 0.3653 - loss: 3.0136 - val_accuracy: 0.4689 - val_loss: 2.3733 - learning_rate: 8.0998e-05
Epoch 28/300
1413/1413 - 220s - 156ms/step - accuracy: 0.3636 - loss: 2.9926 - val_accuracy: 0.4841 - val_loss: 2.1935 - learning_rate: 8.0998e-05
Epoch 29/300
1413/1413 - 216s - 153ms/step - accuracy: 0.3653 - loss: 2.9769 - val_accuracy: 0.5119 - val_loss: 2.2627 - learning_rate: 8.0998e-05
Epoch 30/300
1413/1413 - 220s - 156ms/step - accuracy: 0.3775 - loss: 2.9737 - val_accuracy: 0.4833 - val_loss: 2.3854 - learning_rate: 8.0998e-05
Epoch 31/300
1413/1413 - 221s - 157ms/step - accuracy: 0.3685 - loss: 2.9760 - val_accuracy: 0.4132 - val_loss: 3.0542 - learning_rate: 8.0998e-05
Epoch 32/300

Epoch 32: ReduceLROnPlateau reducing learning rate to 4.0499086026102304e-05.
1413/1413 - 217s - 153ms/step - accuracy: 0.3685 - loss: 2.9744 - val_accuracy: 0.4578 - val_loss: 2.8362 - learning_rate: 8.0998e-05
Epoch 33/300
1413/1413 - 220s - 156ms/step - accuracy: 0.3841 - loss: 2.9238 - val_accuracy: 0.5693 - val_loss: 2.0305 - learning_rate: 4.0499e-05
Epoch 34/300
1413/1413 - 222s - 157ms/step - accuracy: 0.3815 - loss: 2.9229 - val_accuracy: 0.5581 - val_loss: 2.0200 - learning_rate: 4.0499e-05
Epoch 35/300
1413/1413 - 222s - 157ms/step - accuracy: 0.3839 - loss: 2.8945 - val_accuracy: 0.5685 - val_loss: 2.1592 - learning_rate: 4.0499e-05
Epoch 36/300
1413/1413 - 222s - 157ms/step - accuracy: 0.3816 - loss: 2.9226 - val_accuracy: 0.5772 - val_loss: 1.9447 - learning_rate: 4.0499e-05
Epoch 37/300
1413/1413 - 256s - 181ms/step - accuracy: 0.3826 - loss: 2.9146 - val_accuracy: 0.5844 - val_loss: 1.9583 - learning_rate: 4.0499e-05
Epoch 38/300
1413/1413 - 227s - 161ms/step - accuracy: 0.3828 - loss: 2.8855 - val_accuracy: 0.5661 - val_loss: 2.0255 - learning_rate: 4.0499e-05
Epoch 39/300
1413/1413 - 220s - 156ms/step - accuracy: 0.3933 - loss: 2.8618 - val_accuracy: 0.5613 - val_loss: 1.9426 - learning_rate: 4.0499e-05
Epoch 40/300
1413/1413 - 218s - 154ms/step - accuracy: 0.3852 - loss: 2.9159 - val_accuracy: 0.6027 - val_loss: 1.9691 - learning_rate: 4.0499e-05
Epoch 41/300
1413/1413 - 218s - 154ms/step - accuracy: 0.3910 - loss: 2.8744 - val_accuracy: 0.5677 - val_loss: 1.9949 - learning_rate: 4.0499e-05
Epoch 42/300
1413/1413 - 219s - 155ms/step - accuracy: 0.3883 - loss: 2.8742 - val_accuracy: 0.5581 - val_loss: 2.1739 - learning_rate: 4.0499e-05
Epoch 43/300
1413/1413 - 218s - 155ms/step - accuracy: 0.3911 - loss: 2.8685 - val_accuracy: 0.5677 - val_loss: 2.0809 - learning_rate: 4.0499e-05
Epoch 44/300
1413/1413 - 216s - 153ms/step - accuracy: 0.3834 - loss: 2.9007 - val_accuracy: 0.5597 - val_loss: 2.1456 - learning_rate: 4.0499e-05
Epoch 45/300
1413/1413 - 219s - 155ms/step - accuracy: 0.3937 - loss: 2.8712 - val_accuracy: 0.5406 - val_loss: 2.0553 - learning_rate: 4.0499e-05
Epoch 46/300
1413/1413 - 217s - 154ms/step - accuracy: 0.3888 - loss: 2.8767 - val_accuracy: 0.5677 - val_loss: 1.9287 - learning_rate: 4.0499e-05
Epoch 47/300
1413/1413 - 220s - 156ms/step - accuracy: 0.3920 - loss: 2.8691 - val_accuracy: 0.5446 - val_loss: 2.0521 - learning_rate: 4.0499e-05
Epoch 48/300
1413/1413 - 221s - 156ms/step - accuracy: 0.3964 - loss: 2.8666 - val_accuracy: 0.5796 - val_loss: 1.9979 - learning_rate: 4.0499e-05
Epoch 49/300
1413/1413 - 218s - 155ms/step - accuracy: 0.3993 - loss: 2.8249 - val_accuracy: 0.4881 - val_loss: 2.6199 - learning_rate: 4.0499e-05
Epoch 50/300
1413/1413 - 221s - 156ms/step - accuracy: 0.3957 - loss: 2.8548 - val_accuracy: 0.5597 - val_loss: 2.0748 - learning_rate: 4.0499e-05
Epoch 51/300
1413/1413 - 222s - 157ms/step - accuracy: 0.3960 - loss: 2.8502 - val_accuracy: 0.5860 - val_loss: 1.9147 - learning_rate: 4.0499e-05
Epoch 52/300
1413/1413 - 219s - 155ms/step - accuracy: 0.3925 - loss: 2.8770 - val_accuracy: 0.5621 - val_loss: 2.0714 - learning_rate: 4.0499e-05
Epoch 53/300
1413/1413 - 221s - 156ms/step - accuracy: 0.3925 - loss: 2.8489 - val_accuracy: 0.6202 - val_loss: 1.8601 - learning_rate: 4.0499e-05
Epoch 54/300
1413/1413 - 219s - 155ms/step - accuracy: 0.3953 - loss: 2.8374 - val_accuracy: 0.5024 - val_loss: 2.2677 - learning_rate: 4.0499e-05
Epoch 55/300
1413/1413 - 220s - 156ms/step - accuracy: 0.4002 - loss: 2.8446 - val_accuracy: 0.5764 - val_loss: 2.0882 - learning_rate: 4.0499e-05
Epoch 56/300
1413/1413 - 220s - 155ms/step - accuracy: 0.4064 - loss: 2.8565 - val_accuracy: 0.5924 - val_loss: 1.8549 - learning_rate: 4.0499e-05
Epoch 57/300
1413/1413 - 221s - 156ms/step - accuracy: 0.3953 - loss: 2.8410 - val_accuracy: 0.5884 - val_loss: 1.8989 - learning_rate: 4.0499e-05
Epoch 58/300
1413/1413 - 219s - 155ms/step - accuracy: 0.3940 - loss: 2.8709 - val_accuracy: 0.5844 - val_loss: 1.9637 - learning_rate: 4.0499e-05
Epoch 59/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4027 - loss: 2.8283 - val_accuracy: 0.5979 - val_loss: 1.9181 - learning_rate: 4.0499e-05
Epoch 60/300
1413/1413 - 228s - 161ms/step - accuracy: 0.4002 - loss: 2.8240 - val_accuracy: 0.5987 - val_loss: 1.8146 - learning_rate: 4.0499e-05
Epoch 61/300
1413/1413 - 232s - 165ms/step - accuracy: 0.4092 - loss: 2.7963 - val_accuracy: 0.5939 - val_loss: 1.9275 - learning_rate: 4.0499e-05
Epoch 62/300
1413/1413 - 230s - 163ms/step - accuracy: 0.4027 - loss: 2.8218 - val_accuracy: 0.5764 - val_loss: 2.0166 - learning_rate: 4.0499e-05
Epoch 63/300
1413/1413 - 232s - 164ms/step - accuracy: 0.3991 - loss: 2.8383 - val_accuracy: 0.6123 - val_loss: 1.7649 - learning_rate: 4.0499e-05
Epoch 64/300
1413/1413 - 231s - 163ms/step - accuracy: 0.4039 - loss: 2.8238 - val_accuracy: 0.5884 - val_loss: 2.0917 - learning_rate: 4.0499e-05
Epoch 65/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4041 - loss: 2.7970 - val_accuracy: 0.6115 - val_loss: 1.8276 - learning_rate: 4.0499e-05
Epoch 66/300
1413/1413 - 231s - 163ms/step - accuracy: 0.4070 - loss: 2.8074 - val_accuracy: 0.5932 - val_loss: 1.8894 - learning_rate: 4.0499e-05
Epoch 67/300
1413/1413 - 228s - 161ms/step - accuracy: 0.4088 - loss: 2.7911 - val_accuracy: 0.5860 - val_loss: 1.8829 - learning_rate: 4.0499e-05
Epoch 68/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4098 - loss: 2.7988 - val_accuracy: 0.5924 - val_loss: 1.9997 - learning_rate: 4.0499e-05
Epoch 69/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4027 - loss: 2.8144 - val_accuracy: 0.6075 - val_loss: 2.0193 - learning_rate: 4.0499e-05
Epoch 70/300
1413/1413 - 231s - 164ms/step - accuracy: 0.4030 - loss: 2.8169 - val_accuracy: 0.5947 - val_loss: 1.8161 - learning_rate: 4.0499e-05
Epoch 71/300

Epoch 71: ReduceLROnPlateau reducing learning rate to 2.0249543013051152e-05.
1413/1413 - 231s - 163ms/step - accuracy: 0.4049 - loss: 2.7918 - val_accuracy: 0.4928 - val_loss: 2.5405 - learning_rate: 4.0499e-05
Epoch 72/300
1413/1413 - 231s - 164ms/step - accuracy: 0.4143 - loss: 2.7658 - val_accuracy: 0.6330 - val_loss: 1.7733 - learning_rate: 2.0250e-05
Epoch 73/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4129 - loss: 2.7552 - val_accuracy: 0.6306 - val_loss: 1.6812 - learning_rate: 2.0250e-05
Epoch 74/300
1413/1413 - 231s - 163ms/step - accuracy: 0.4085 - loss: 2.7685 - val_accuracy: 0.6115 - val_loss: 1.7819 - learning_rate: 2.0250e-05
Epoch 75/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4166 - loss: 2.7614 - val_accuracy: 0.6274 - val_loss: 1.7575 - learning_rate: 2.0250e-05
Epoch 76/300
1413/1413 - 231s - 163ms/step - accuracy: 0.4176 - loss: 2.7445 - val_accuracy: 0.5963 - val_loss: 1.8229 - learning_rate: 2.0250e-05
Epoch 77/300
1413/1413 - 232s - 164ms/step - accuracy: 0.4154 - loss: 2.7503 - val_accuracy: 0.6298 - val_loss: 1.7945 - learning_rate: 2.0250e-05
Epoch 78/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4184 - loss: 2.7667 - val_accuracy: 0.6210 - val_loss: 1.8188 - learning_rate: 2.0250e-05
Epoch 79/300
1413/1413 - 235s - 166ms/step - accuracy: 0.4153 - loss: 2.7405 - val_accuracy: 0.6401 - val_loss: 1.7054 - learning_rate: 2.0250e-05
Epoch 80/300
1413/1413 - 228s - 162ms/step - accuracy: 0.4185 - loss: 2.7336 - val_accuracy: 0.6178 - val_loss: 1.7732 - learning_rate: 2.0250e-05
Epoch 81/300

Epoch 81: ReduceLROnPlateau reducing learning rate to 1.0124771506525576e-05.
1413/1413 - 238s - 168ms/step - accuracy: 0.4241 - loss: 2.7352 - val_accuracy: 0.6139 - val_loss: 1.8507 - learning_rate: 2.0250e-05
Epoch 82/300
1413/1413 - 236s - 167ms/step - accuracy: 0.4118 - loss: 2.7401 - val_accuracy: 0.6210 - val_loss: 1.7996 - learning_rate: 1.0125e-05
Epoch 83/300
1413/1413 - 239s - 169ms/step - accuracy: 0.4157 - loss: 2.7374 - val_accuracy: 0.6393 - val_loss: 1.6824 - learning_rate: 1.0125e-05
Epoch 84/300
1413/1413 - 235s - 166ms/step - accuracy: 0.4188 - loss: 2.7411 - val_accuracy: 0.6361 - val_loss: 1.6584 - learning_rate: 1.0125e-05
Epoch 85/300
1413/1413 - 230s - 163ms/step - accuracy: 0.4191 - loss: 2.7388 - val_accuracy: 0.6385 - val_loss: 1.6688 - learning_rate: 1.0125e-05
Epoch 86/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4139 - loss: 2.7466 - val_accuracy: 0.6361 - val_loss: 1.7230 - learning_rate: 1.0125e-05
Epoch 87/300
1413/1413 - 221s - 156ms/step - accuracy: 0.4261 - loss: 2.7206 - val_accuracy: 0.6322 - val_loss: 1.7084 - learning_rate: 1.0125e-05
Epoch 88/300
1413/1413 - 224s - 158ms/step - accuracy: 0.4123 - loss: 2.7211 - val_accuracy: 0.6242 - val_loss: 1.7205 - learning_rate: 1.0125e-05
Epoch 89/300
1413/1413 - 224s - 158ms/step - accuracy: 0.4217 - loss: 2.7048 - val_accuracy: 0.6409 - val_loss: 1.7088 - learning_rate: 1.0125e-05
Epoch 90/300
1413/1413 - 224s - 159ms/step - accuracy: 0.4205 - loss: 2.7265 - val_accuracy: 0.6425 - val_loss: 1.6797 - learning_rate: 1.0125e-05
Epoch 91/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4172 - loss: 2.7115 - val_accuracy: 0.6481 - val_loss: 1.6674 - learning_rate: 1.0125e-05
Epoch 92/300

Epoch 92: ReduceLROnPlateau reducing learning rate to 5.062385753262788e-06.
1413/1413 - 229s - 162ms/step - accuracy: 0.4200 - loss: 2.7420 - val_accuracy: 0.6417 - val_loss: 1.7330 - learning_rate: 1.0125e-05
Epoch 93/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4262 - loss: 2.6944 - val_accuracy: 0.6433 - val_loss: 1.6759 - learning_rate: 5.0624e-06
Epoch 94/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4242 - loss: 2.7168 - val_accuracy: 0.6465 - val_loss: 1.6394 - learning_rate: 5.0624e-06
Epoch 95/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4249 - loss: 2.7181 - val_accuracy: 0.6505 - val_loss: 1.6418 - learning_rate: 5.0624e-06
Epoch 96/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4199 - loss: 2.7280 - val_accuracy: 0.6481 - val_loss: 1.6597 - learning_rate: 5.0624e-06
Epoch 97/300
1413/1413 - 221s - 156ms/step - accuracy: 0.4191 - loss: 2.7211 - val_accuracy: 0.6465 - val_loss: 1.6471 - learning_rate: 5.0624e-06
Epoch 98/300
1413/1413 - 220s - 156ms/step - accuracy: 0.4307 - loss: 2.6806 - val_accuracy: 0.6465 - val_loss: 1.6483 - learning_rate: 5.0624e-06
Epoch 99/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4282 - loss: 2.6801 - val_accuracy: 0.6513 - val_loss: 1.6494 - learning_rate: 5.0624e-06
Epoch 100/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4167 - loss: 2.6932 - val_accuracy: 0.6481 - val_loss: 1.6572 - learning_rate: 5.0624e-06
Epoch 101/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4298 - loss: 2.6914 - val_accuracy: 0.6473 - val_loss: 1.6588 - learning_rate: 5.0624e-06
Epoch 102/300
1413/1413 - 224s - 159ms/step - accuracy: 0.4212 - loss: 2.7179 - val_accuracy: 0.6457 - val_loss: 1.6327 - learning_rate: 5.0624e-06
Epoch 103/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4261 - loss: 2.6818 - val_accuracy: 0.6489 - val_loss: 1.6577 - learning_rate: 5.0624e-06
Epoch 104/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4166 - loss: 2.7341 - val_accuracy: 0.6513 - val_loss: 1.6485 - learning_rate: 5.0624e-06
Epoch 105/300
1413/1413 - 221s - 157ms/step - accuracy: 0.4254 - loss: 2.7093 - val_accuracy: 0.6457 - val_loss: 1.6214 - learning_rate: 5.0624e-06
Epoch 106/300
1413/1413 - 218s - 155ms/step - accuracy: 0.4273 - loss: 2.6920 - val_accuracy: 0.6489 - val_loss: 1.6269 - learning_rate: 5.0624e-06
Epoch 107/300
1413/1413 - 224s - 159ms/step - accuracy: 0.4227 - loss: 2.7076 - val_accuracy: 0.6521 - val_loss: 1.6518 - learning_rate: 5.0624e-06
Epoch 108/300
1413/1413 - 227s - 161ms/step - accuracy: 0.4295 - loss: 2.7091 - val_accuracy: 0.6481 - val_loss: 1.6226 - learning_rate: 5.0624e-06
Epoch 109/300
1413/1413 - 224s - 159ms/step - accuracy: 0.4209 - loss: 2.7017 - val_accuracy: 0.6465 - val_loss: 1.6587 - learning_rate: 5.0624e-06
Epoch 110/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4148 - loss: 2.7403 - val_accuracy: 0.6505 - val_loss: 1.6531 - learning_rate: 5.0624e-06
Epoch 111/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4328 - loss: 2.6747 - val_accuracy: 0.6497 - val_loss: 1.6364 - learning_rate: 5.0624e-06
Epoch 112/300
1413/1413 - 238s - 169ms/step - accuracy: 0.4281 - loss: 2.6800 - val_accuracy: 0.6473 - val_loss: 1.6584 - learning_rate: 5.0624e-06
Epoch 113/300

Epoch 113: ReduceLROnPlateau reducing learning rate to 2.531192876631394e-06.
1413/1413 - 236s - 167ms/step - accuracy: 0.4266 - loss: 2.6920 - val_accuracy: 0.6561 - val_loss: 1.6556 - learning_rate: 5.0624e-06
Epoch 114/300
1413/1413 - 233s - 165ms/step - accuracy: 0.4287 - loss: 2.6831 - val_accuracy: 0.6553 - val_loss: 1.6298 - learning_rate: 2.5312e-06
Epoch 115/300
1413/1413 - 239s - 169ms/step - accuracy: 0.4299 - loss: 2.6798 - val_accuracy: 0.6537 - val_loss: 1.6400 - learning_rate: 2.5312e-06
Epoch 116/300
1413/1413 - 236s - 167ms/step - accuracy: 0.4205 - loss: 2.7199 - val_accuracy: 0.6529 - val_loss: 1.6374 - learning_rate: 2.5312e-06
Epoch 117/300
1413/1413 - 239s - 169ms/step - accuracy: 0.4217 - loss: 2.6992 - val_accuracy: 0.6497 - val_loss: 1.6310 - learning_rate: 2.5312e-06
Epoch 118/300
1413/1413 - 233s - 165ms/step - accuracy: 0.4354 - loss: 2.6918 - val_accuracy: 0.6393 - val_loss: 1.6715 - learning_rate: 2.5312e-06
Epoch 119/300
1413/1413 - 234s - 166ms/step - accuracy: 0.4306 - loss: 2.6770 - val_accuracy: 0.6568 - val_loss: 1.6199 - learning_rate: 2.5312e-06
Epoch 120/300
1413/1413 - 235s - 166ms/step - accuracy: 0.4347 - loss: 2.6706 - val_accuracy: 0.6489 - val_loss: 1.6406 - learning_rate: 2.5312e-06
Epoch 121/300
1413/1413 - 233s - 165ms/step - accuracy: 0.4280 - loss: 2.7008 - val_accuracy: 0.6473 - val_loss: 1.6262 - learning_rate: 2.5312e-06
Epoch 122/300
1413/1413 - 237s - 168ms/step - accuracy: 0.4272 - loss: 2.6790 - val_accuracy: 0.6433 - val_loss: 1.6489 - learning_rate: 2.5312e-06
Epoch 123/300
1413/1413 - 236s - 167ms/step - accuracy: 0.4330 - loss: 2.6868 - val_accuracy: 0.6465 - val_loss: 1.6650 - learning_rate: 2.5312e-06
Epoch 124/300
1413/1413 - 240s - 170ms/step - accuracy: 0.4323 - loss: 2.6724 - val_accuracy: 0.6473 - val_loss: 1.6393 - learning_rate: 2.5312e-06
Epoch 125/300
1413/1413 - 238s - 169ms/step - accuracy: 0.4259 - loss: 2.6909 - val_accuracy: 0.6513 - val_loss: 1.6526 - learning_rate: 2.5312e-06
Epoch 126/300
1413/1413 - 235s - 166ms/step - accuracy: 0.4324 - loss: 2.6773 - val_accuracy: 0.6497 - val_loss: 1.6330 - learning_rate: 2.5312e-06
Epoch 127/300

Epoch 127: ReduceLROnPlateau reducing learning rate to 1.265596438315697e-06.
1413/1413 - 238s - 168ms/step - accuracy: 0.4289 - loss: 2.6653 - val_accuracy: 0.6473 - val_loss: 1.6660 - learning_rate: 2.5312e-06
Epoch 128/300
1413/1413 - 235s - 166ms/step - accuracy: 0.4282 - loss: 2.6763 - val_accuracy: 0.6481 - val_loss: 1.6234 - learning_rate: 1.2656e-06
Epoch 129/300
1413/1413 - 235s - 166ms/step - accuracy: 0.4279 - loss: 2.6883 - val_accuracy: 0.6537 - val_loss: 1.6236 - learning_rate: 1.2656e-06
Epoch 130/300
1413/1413 - 237s - 167ms/step - accuracy: 0.4325 - loss: 2.6828 - val_accuracy: 0.6537 - val_loss: 1.6329 - learning_rate: 1.2656e-06
Epoch 131/300
1413/1413 - 236s - 167ms/step - accuracy: 0.4281 - loss: 2.6857 - val_accuracy: 0.6497 - val_loss: 1.6393 - learning_rate: 1.2656e-06
Epoch 132/300
1413/1413 - 234s - 166ms/step - accuracy: 0.4335 - loss: 2.6759 - val_accuracy: 0.6521 - val_loss: 1.6373 - learning_rate: 1.2656e-06
Epoch 133/300
1413/1413 - 239s - 169ms/step - accuracy: 0.4262 - loss: 2.6877 - val_accuracy: 0.6529 - val_loss: 1.6371 - learning_rate: 1.2656e-06
Epoch 134/300
1413/1413 - 237s - 167ms/step - accuracy: 0.4294 - loss: 2.6673 - val_accuracy: 0.6561 - val_loss: 1.6384 - learning_rate: 1.2656e-06
Epoch 135/300

Epoch 135: ReduceLROnPlateau reducing learning rate to 1e-06.
1413/1413 - 236s - 167ms/step - accuracy: 0.4362 - loss: 2.6599 - val_accuracy: 0.6537 - val_loss: 1.6431 - learning_rate: 1.2656e-06
Epoch 135: early stopping
Restoring model weights from the end of the best epoch: 119.
Fold 1 Evaluation results: [1.613343358039856, 0.6568471193313599]
              precision    recall  f1-score   support

        1820       0.81      0.77      0.79        62
        1821       0.84      0.82      0.83        57
        1822       0.00      0.00      0.00         1
        1823       1.00      1.00      1.00         1
        1824       0.00      0.00      0.00         1
        1825       0.00      0.00      0.00         2
        1826       0.00      0.00      0.00         2
        1827       0.82      0.92      0.87        25
        1828       0.00      0.00      0.00         1
        1829       0.44      0.80      0.57         5
        1830       0.76      0.62      0.69        56
        1831       0.74      0.89      0.81       134
        1832       0.75      0.87      0.80        68
        1833       0.90      0.95      0.92        19
        1834       0.51      0.72      0.60        29
        1835       0.00      0.00      0.00         3
        1836       0.25      0.25      0.25         4
        1837       0.16      0.43      0.23         7
        1838       1.00      0.33      0.50         3
        1839       0.00      0.00      0.00         0
        1840       0.59      0.53      0.56        43
        1841       0.75      0.56      0.64       108
        1842       0.50      0.80      0.62         5
        1843       0.33      0.17      0.22         6
        1844       0.00      0.00      0.00         1
        1845       0.00      0.00      0.00         2
        1846       0.80      0.67      0.73         6
        1847       0.00      0.00      0.00         2
        1848       0.50      0.17      0.25         6
        1849       1.00      0.33      0.50         6
        1850       0.52      0.62      0.57        48
        1851       0.81      0.75      0.78        77
        1852       0.25      0.14      0.18         7
        1853       0.00      0.00      0.00         6
        1854       0.00      0.00      0.00         3
        1855       0.42      0.33      0.37        24
        1856       0.69      0.75      0.72        12
        1857       0.50      0.67      0.57        30
        1858       0.00      0.00      0.00         2
        1859       0.00      0.00      0.00         2
        1860       0.45      0.47      0.46        64
        1861       0.84      0.86      0.85        85
        1862       0.42      0.44      0.43        18
        1863       0.46      0.63      0.53        19
        1864       0.50      0.41      0.45        17
        1865       0.35      1.00      0.52         6
        1866       0.00      0.00      0.00         5
        1867       0.33      0.55      0.41        11
        1868       0.00      0.00      0.00         7
        1869       0.00      0.00      0.00         5
        1870       0.50      0.58      0.54        31
        1871       0.75      0.80      0.77        49
        1872       0.60      0.38      0.46         8
        1873       0.67      0.20      0.31        10
        1874       0.50      0.40      0.44         5
        1875       0.38      0.43      0.40        14
        1876       0.86      0.60      0.71        10
        1877       0.40      0.40      0.40         5
        1878       0.50      0.44      0.47         9
        1879       0.00      0.00      0.00         2

    accuracy                           0.66      1256
   macro avg       0.42      0.41      0.40      1256
weighted avg       0.65      0.66      0.64      1256

Matthews Correlation Coefficient: 0.640
Macro avg F1: 0.395
Weighted avg F1: 0.644
Micro avg F1: 0.657
Top-3 Accuracy: 0.868
Top-5 Accuracy: 0.912
Micro ROC AUC  = 0.99
Macro ROC AUC (present classes) = 0.97
Classification MAE (in years): 3.14

Fold 1 Misclassification Analysis:
Near misses (within 2 years): 99 out of 431 misclassifications (22.97%)
Big misses (greater than 10 years): 204
MAE with outliers: 3.14
MAE without outliers: 2.05 (improvement: 1.10)

10 Worst misclassifications:
Image: data/datasets/public/1870/1879_180wikimedia2.jpg, True: 1879, Predicted: 1820, Error: 59
Image: data/datasets/public/1870/1879_39wikimedia2.jpg, True: 1879, Predicted: 1820, Error: 59
Image: data/datasets/public/1870/1877_033met.jpg, True: 1877, Predicted: 1820, Error: 57
Image: data/datasets/public/1820/1821_52vna.jpg, True: 1821, Predicted: 1876, Error: 55
Image: data/datasets/public/1870/1875_38washington.jpg, True: 1875, Predicted: 1821, Error: 54
Image: data/datasets/public/1820/1820_035met.jpg, True: 1820, Predicted: 1867, Error: 47
Image: data/datasets/public/1870/1878_468vna.jpg, True: 1878, Predicted: 1832, Error: 46
Image: data/datasets/public/1870/1876_386vna.jpg, True: 1876, Predicted: 1831, Error: 45
Image: data/datasets/public/1870/1878_490vna.jpg, True: 1878, Predicted: 1834, Error: 44
Image: data/datasets/public/1820/1820_013_001met.jpg, True: 1820, Predicted: 1863, Error: 43

===== Fold 2 =====

===== Fine Tuning 7 layers! =====
Epoch 1/300
1413/1413 - 261s - 185ms/step - accuracy: 0.1347 - loss: 4.4370 - val_accuracy: 0.2094 - val_loss: 3.7016 - learning_rate: 1.6200e-04
Epoch 2/300
1413/1413 - 234s - 165ms/step - accuracy: 0.1963 - loss: 3.9691 - val_accuracy: 0.1529 - val_loss: 5.9143 - learning_rate: 1.6200e-04
Epoch 3/300
1413/1413 - 238s - 168ms/step - accuracy: 0.2253 - loss: 3.8266 - val_accuracy: 0.2739 - val_loss: 3.5164 - learning_rate: 1.6200e-04
Epoch 4/300
1413/1413 - 239s - 169ms/step - accuracy: 0.2465 - loss: 3.6757 - val_accuracy: 0.2826 - val_loss: 3.3005 - learning_rate: 1.6200e-04
Epoch 5/300
1413/1413 - 239s - 169ms/step - accuracy: 0.2619 - loss: 3.5828 - val_accuracy: 0.3057 - val_loss: 3.8273 - learning_rate: 1.6200e-04
Epoch 6/300
1413/1413 - 237s - 168ms/step - accuracy: 0.2694 - loss: 3.5329 - val_accuracy: 0.1584 - val_loss: 3.9819 - learning_rate: 1.6200e-04
Epoch 7/300
1413/1413 - 238s - 169ms/step - accuracy: 0.2799 - loss: 3.4789 - val_accuracy: 0.3368 - val_loss: 3.0390 - learning_rate: 1.6200e-04
Epoch 8/300
1413/1413 - 237s - 167ms/step - accuracy: 0.2882 - loss: 3.4361 - val_accuracy: 0.4100 - val_loss: 2.7350 - learning_rate: 1.6200e-04
Epoch 9/300
1413/1413 - 240s - 170ms/step - accuracy: 0.2979 - loss: 3.4087 - val_accuracy: 0.3129 - val_loss: 3.9345 - learning_rate: 1.6200e-04
Epoch 10/300
1413/1413 - 234s - 166ms/step - accuracy: 0.3005 - loss: 3.3621 - val_accuracy: 0.2532 - val_loss: 3.5531 - learning_rate: 1.6200e-04
Epoch 11/300
1413/1413 - 239s - 169ms/step - accuracy: 0.3038 - loss: 3.3350 - val_accuracy: 0.4817 - val_loss: 2.7437 - learning_rate: 1.6200e-04
Epoch 12/300
1413/1413 - 233s - 165ms/step - accuracy: 0.3113 - loss: 3.2921 - val_accuracy: 0.2938 - val_loss: 3.7507 - learning_rate: 1.6200e-04
Epoch 13/300
1413/1413 - 234s - 165ms/step - accuracy: 0.3135 - loss: 3.2957 - val_accuracy: 0.2604 - val_loss: 3.3097 - learning_rate: 1.6200e-04
Epoch 14/300
1413/1413 - 241s - 170ms/step - accuracy: 0.3181 - loss: 3.2694 - val_accuracy: 0.3543 - val_loss: 3.5385 - learning_rate: 1.6200e-04
Epoch 15/300
1413/1413 - 239s - 169ms/step - accuracy: 0.3219 - loss: 3.2626 - val_accuracy: 0.4323 - val_loss: 2.9565 - learning_rate: 1.6200e-04
Epoch 16/300

Epoch 16: ReduceLROnPlateau reducing learning rate to 8.099817205220461e-05.
1413/1413 - 235s - 166ms/step - accuracy: 0.3274 - loss: 3.2341 - val_accuracy: 0.2723 - val_loss: 4.0123 - learning_rate: 1.6200e-04
Epoch 17/300
1413/1413 - 239s - 169ms/step - accuracy: 0.3393 - loss: 3.1326 - val_accuracy: 0.4522 - val_loss: 2.4565 - learning_rate: 8.0998e-05
Epoch 18/300
1413/1413 - 235s - 166ms/step - accuracy: 0.3454 - loss: 3.1169 - val_accuracy: 0.4968 - val_loss: 2.3347 - learning_rate: 8.0998e-05
Epoch 19/300
1413/1413 - 234s - 165ms/step - accuracy: 0.3477 - loss: 3.1111 - val_accuracy: 0.4634 - val_loss: 2.6964 - learning_rate: 8.0998e-05
Epoch 20/300
1413/1413 - 236s - 167ms/step - accuracy: 0.3506 - loss: 3.0898 - val_accuracy: 0.4968 - val_loss: 2.4248 - learning_rate: 8.0998e-05
Epoch 21/300
1413/1413 - 235s - 166ms/step - accuracy: 0.3519 - loss: 3.0862 - val_accuracy: 0.4737 - val_loss: 2.7338 - learning_rate: 8.0998e-05
Epoch 22/300
1413/1413 - 239s - 169ms/step - accuracy: 0.3561 - loss: 3.0513 - val_accuracy: 0.5064 - val_loss: 2.4139 - learning_rate: 8.0998e-05
Epoch 23/300
1413/1413 - 233s - 165ms/step - accuracy: 0.3541 - loss: 3.0538 - val_accuracy: 0.4984 - val_loss: 2.3085 - learning_rate: 8.0998e-05
Epoch 24/300
1413/1413 - 239s - 169ms/step - accuracy: 0.3639 - loss: 3.0465 - val_accuracy: 0.5080 - val_loss: 2.2965 - learning_rate: 8.0998e-05
Epoch 25/300
1413/1413 - 233s - 165ms/step - accuracy: 0.3655 - loss: 3.0291 - val_accuracy: 0.4689 - val_loss: 2.3131 - learning_rate: 8.0998e-05
Epoch 26/300
1413/1413 - 239s - 169ms/step - accuracy: 0.3635 - loss: 3.0271 - val_accuracy: 0.4713 - val_loss: 2.4653 - learning_rate: 8.0998e-05
Epoch 27/300
1413/1413 - 235s - 166ms/step - accuracy: 0.3539 - loss: 3.0395 - val_accuracy: 0.5111 - val_loss: 2.2393 - learning_rate: 8.0998e-05
Epoch 28/300
1413/1413 - 236s - 167ms/step - accuracy: 0.3673 - loss: 3.0236 - val_accuracy: 0.4737 - val_loss: 2.3206 - learning_rate: 8.0998e-05
Epoch 29/300
1413/1413 - 238s - 169ms/step - accuracy: 0.3628 - loss: 3.0031 - val_accuracy: 0.4674 - val_loss: 2.3435 - learning_rate: 8.0998e-05
Epoch 30/300
1413/1413 - 239s - 169ms/step - accuracy: 0.3747 - loss: 2.9882 - val_accuracy: 0.5183 - val_loss: 2.2418 - learning_rate: 8.0998e-05
Epoch 31/300
1413/1413 - 237s - 168ms/step - accuracy: 0.3627 - loss: 3.0000 - val_accuracy: 0.4801 - val_loss: 2.5005 - learning_rate: 8.0998e-05
Epoch 32/300
1413/1413 - 235s - 167ms/step - accuracy: 0.3736 - loss: 2.9962 - val_accuracy: 0.4498 - val_loss: 2.8052 - learning_rate: 8.0998e-05
Epoch 33/300
1413/1413 - 238s - 169ms/step - accuracy: 0.3709 - loss: 2.9880 - val_accuracy: 0.5247 - val_loss: 2.3057 - learning_rate: 8.0998e-05
Epoch 34/300
1413/1413 - 235s - 166ms/step - accuracy: 0.3766 - loss: 2.9915 - val_accuracy: 0.5008 - val_loss: 2.3386 - learning_rate: 8.0998e-05
Epoch 35/300
1413/1413 - 241s - 171ms/step - accuracy: 0.3741 - loss: 2.9724 - val_accuracy: 0.5311 - val_loss: 2.1825 - learning_rate: 8.0998e-05
Epoch 36/300
1413/1413 - 235s - 167ms/step - accuracy: 0.3745 - loss: 2.9689 - val_accuracy: 0.5462 - val_loss: 2.1440 - learning_rate: 8.0998e-05
Epoch 37/300
1413/1413 - 234s - 165ms/step - accuracy: 0.3748 - loss: 2.9580 - val_accuracy: 0.5541 - val_loss: 1.9970 - learning_rate: 8.0998e-05
Epoch 38/300
1413/1413 - 238s - 169ms/step - accuracy: 0.3752 - loss: 2.9549 - val_accuracy: 0.4196 - val_loss: 2.8781 - learning_rate: 8.0998e-05
Epoch 39/300
1413/1413 - 236s - 167ms/step - accuracy: 0.3731 - loss: 2.9662 - val_accuracy: 0.4873 - val_loss: 2.3457 - learning_rate: 8.0998e-05
Epoch 40/300
1413/1413 - 235s - 167ms/step - accuracy: 0.3834 - loss: 2.9360 - val_accuracy: 0.5127 - val_loss: 2.5607 - learning_rate: 8.0998e-05
Epoch 41/300
1413/1413 - 236s - 167ms/step - accuracy: 0.3785 - loss: 2.9329 - val_accuracy: 0.5064 - val_loss: 2.2856 - learning_rate: 8.0998e-05
Epoch 42/300
1413/1413 - 237s - 168ms/step - accuracy: 0.3758 - loss: 2.9526 - val_accuracy: 0.5565 - val_loss: 2.1256 - learning_rate: 8.0998e-05
Epoch 43/300
1413/1413 - 235s - 166ms/step - accuracy: 0.3792 - loss: 2.9222 - val_accuracy: 0.5645 - val_loss: 2.0871 - learning_rate: 8.0998e-05
Epoch 44/300
1413/1413 - 224s - 159ms/step - accuracy: 0.3798 - loss: 2.9421 - val_accuracy: 0.5557 - val_loss: 1.9935 - learning_rate: 8.0998e-05
Epoch 45/300
1413/1413 - 222s - 157ms/step - accuracy: 0.3818 - loss: 2.8991 - val_accuracy: 0.4857 - val_loss: 2.2884 - learning_rate: 8.0998e-05
Epoch 46/300
1413/1413 - 220s - 156ms/step - accuracy: 0.3849 - loss: 2.8759 - val_accuracy: 0.4960 - val_loss: 2.8028 - learning_rate: 8.0998e-05
Epoch 47/300
1413/1413 - 219s - 155ms/step - accuracy: 0.3875 - loss: 2.9027 - val_accuracy: 0.5772 - val_loss: 2.0830 - learning_rate: 8.0998e-05
Epoch 48/300
1413/1413 - 223s - 157ms/step - accuracy: 0.3815 - loss: 2.8890 - val_accuracy: 0.4697 - val_loss: 2.6085 - learning_rate: 8.0998e-05
Epoch 49/300
1413/1413 - 221s - 157ms/step - accuracy: 0.3765 - loss: 2.9026 - val_accuracy: 0.5342 - val_loss: 2.1494 - learning_rate: 8.0998e-05
Epoch 50/300
1413/1413 - 224s - 158ms/step - accuracy: 0.3818 - loss: 2.8733 - val_accuracy: 0.5008 - val_loss: 2.3103 - learning_rate: 8.0998e-05
Epoch 51/300
1413/1413 - 222s - 157ms/step - accuracy: 0.3910 - loss: 2.8821 - val_accuracy: 0.5111 - val_loss: 2.3592 - learning_rate: 8.0998e-05
Epoch 52/300

Epoch 52: ReduceLROnPlateau reducing learning rate to 4.0499086026102304e-05.
1413/1413 - 225s - 159ms/step - accuracy: 0.3949 - loss: 2.8755 - val_accuracy: 0.5199 - val_loss: 2.1120 - learning_rate: 8.0998e-05
Epoch 53/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4038 - loss: 2.8136 - val_accuracy: 0.6202 - val_loss: 1.7800 - learning_rate: 4.0499e-05
Epoch 54/300
1413/1413 - 225s - 159ms/step - accuracy: 0.3982 - loss: 2.8153 - val_accuracy: 0.5900 - val_loss: 1.9318 - learning_rate: 4.0499e-05
Epoch 55/300
1413/1413 - 221s - 157ms/step - accuracy: 0.4058 - loss: 2.8036 - val_accuracy: 0.6035 - val_loss: 1.8721 - learning_rate: 4.0499e-05
Epoch 56/300
1413/1413 - 220s - 155ms/step - accuracy: 0.4018 - loss: 2.8077 - val_accuracy: 0.6067 - val_loss: 1.8499 - learning_rate: 4.0499e-05
Epoch 57/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4046 - loss: 2.7971 - val_accuracy: 0.6091 - val_loss: 1.8765 - learning_rate: 4.0499e-05
Epoch 58/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4144 - loss: 2.7868 - val_accuracy: 0.5971 - val_loss: 2.0488 - learning_rate: 4.0499e-05
Epoch 59/300
1413/1413 - 221s - 156ms/step - accuracy: 0.4099 - loss: 2.7794 - val_accuracy: 0.5796 - val_loss: 1.9525 - learning_rate: 4.0499e-05
Epoch 60/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4021 - loss: 2.8032 - val_accuracy: 0.5939 - val_loss: 2.0039 - learning_rate: 4.0499e-05
Epoch 61/300

Epoch 61: ReduceLROnPlateau reducing learning rate to 2.0249543013051152e-05.
1413/1413 - 220s - 156ms/step - accuracy: 0.4083 - loss: 2.7769 - val_accuracy: 0.5900 - val_loss: 1.9781 - learning_rate: 4.0499e-05
Epoch 62/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4113 - loss: 2.7431 - val_accuracy: 0.6377 - val_loss: 1.8184 - learning_rate: 2.0250e-05
Epoch 63/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4118 - loss: 2.7614 - val_accuracy: 0.6035 - val_loss: 1.9214 - learning_rate: 2.0250e-05
Epoch 64/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4133 - loss: 2.7797 - val_accuracy: 0.6282 - val_loss: 1.8193 - learning_rate: 2.0250e-05
Epoch 65/300
1413/1413 - 218s - 155ms/step - accuracy: 0.4177 - loss: 2.7320 - val_accuracy: 0.6354 - val_loss: 1.7440 - learning_rate: 2.0250e-05
Epoch 66/300
1413/1413 - 227s - 161ms/step - accuracy: 0.4134 - loss: 2.7694 - val_accuracy: 0.5748 - val_loss: 1.9412 - learning_rate: 2.0250e-05
Epoch 67/300
1413/1413 - 219s - 155ms/step - accuracy: 0.4218 - loss: 2.7440 - val_accuracy: 0.6258 - val_loss: 1.7210 - learning_rate: 2.0250e-05
Epoch 68/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4107 - loss: 2.7549 - val_accuracy: 0.6298 - val_loss: 1.7509 - learning_rate: 2.0250e-05
Epoch 69/300
1413/1413 - 221s - 157ms/step - accuracy: 0.4186 - loss: 2.7152 - val_accuracy: 0.6274 - val_loss: 1.7538 - learning_rate: 2.0250e-05
Epoch 70/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4138 - loss: 2.7647 - val_accuracy: 0.6051 - val_loss: 1.8043 - learning_rate: 2.0250e-05
Epoch 71/300
1413/1413 - 217s - 154ms/step - accuracy: 0.4134 - loss: 2.7500 - val_accuracy: 0.6115 - val_loss: 1.8235 - learning_rate: 2.0250e-05
Epoch 72/300
1413/1413 - 230s - 163ms/step - accuracy: 0.4211 - loss: 2.7352 - val_accuracy: 0.6266 - val_loss: 1.7520 - learning_rate: 2.0250e-05
Epoch 73/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4203 - loss: 2.7129 - val_accuracy: 0.6059 - val_loss: 1.8091 - learning_rate: 2.0250e-05
Epoch 74/300
1413/1413 - 220s - 156ms/step - accuracy: 0.4191 - loss: 2.7342 - val_accuracy: 0.6083 - val_loss: 1.8227 - learning_rate: 2.0250e-05
Epoch 75/300

Epoch 75: ReduceLROnPlateau reducing learning rate to 1.0124771506525576e-05.
1413/1413 - 222s - 157ms/step - accuracy: 0.4165 - loss: 2.7402 - val_accuracy: 0.6290 - val_loss: 1.8034 - learning_rate: 2.0250e-05
Epoch 76/300
1413/1413 - 221s - 156ms/step - accuracy: 0.4263 - loss: 2.6986 - val_accuracy: 0.6361 - val_loss: 1.6803 - learning_rate: 1.0125e-05
Epoch 77/300
1413/1413 - 221s - 156ms/step - accuracy: 0.4226 - loss: 2.6972 - val_accuracy: 0.6346 - val_loss: 1.7161 - learning_rate: 1.0125e-05
Epoch 78/300
1413/1413 - 220s - 156ms/step - accuracy: 0.4233 - loss: 2.7040 - val_accuracy: 0.6314 - val_loss: 1.7405 - learning_rate: 1.0125e-05
Epoch 79/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4194 - loss: 2.6921 - val_accuracy: 0.6266 - val_loss: 1.7260 - learning_rate: 1.0125e-05
Epoch 80/300
1413/1413 - 221s - 156ms/step - accuracy: 0.4292 - loss: 2.6696 - val_accuracy: 0.6385 - val_loss: 1.7493 - learning_rate: 1.0125e-05
Epoch 81/300
1413/1413 - 221s - 156ms/step - accuracy: 0.4244 - loss: 2.6760 - val_accuracy: 0.6282 - val_loss: 1.7910 - learning_rate: 1.0125e-05
Epoch 82/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4289 - loss: 2.6965 - val_accuracy: 0.6393 - val_loss: 1.7220 - learning_rate: 1.0125e-05
Epoch 83/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4241 - loss: 2.7072 - val_accuracy: 0.6306 - val_loss: 1.7279 - learning_rate: 1.0125e-05
Epoch 84/300

Epoch 84: ReduceLROnPlateau reducing learning rate to 5.062385753262788e-06.
1413/1413 - 228s - 162ms/step - accuracy: 0.4241 - loss: 2.7061 - val_accuracy: 0.6377 - val_loss: 1.7709 - learning_rate: 1.0125e-05
Epoch 85/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4235 - loss: 2.6872 - val_accuracy: 0.6457 - val_loss: 1.7137 - learning_rate: 5.0624e-06
Epoch 86/300
1413/1413 - 228s - 162ms/step - accuracy: 0.4248 - loss: 2.7102 - val_accuracy: 0.6433 - val_loss: 1.6861 - learning_rate: 5.0624e-06
Epoch 87/300
1413/1413 - 225s - 160ms/step - accuracy: 0.4230 - loss: 2.7102 - val_accuracy: 0.6417 - val_loss: 1.6832 - learning_rate: 5.0624e-06
Epoch 88/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4252 - loss: 2.6956 - val_accuracy: 0.6513 - val_loss: 1.6943 - learning_rate: 5.0624e-06
Epoch 89/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4286 - loss: 2.6762 - val_accuracy: 0.6409 - val_loss: 1.7127 - learning_rate: 5.0624e-06
Epoch 90/300
1413/1413 - 224s - 159ms/step - accuracy: 0.4309 - loss: 2.7002 - val_accuracy: 0.6521 - val_loss: 1.6584 - learning_rate: 5.0624e-06
Epoch 91/300
1413/1413 - 219s - 155ms/step - accuracy: 0.4267 - loss: 2.7070 - val_accuracy: 0.6505 - val_loss: 1.6842 - learning_rate: 5.0624e-06
Epoch 92/300
1413/1413 - 224s - 159ms/step - accuracy: 0.4337 - loss: 2.6710 - val_accuracy: 0.6417 - val_loss: 1.6899 - learning_rate: 5.0624e-06
Epoch 93/300
1413/1413 - 220s - 156ms/step - accuracy: 0.4266 - loss: 2.7124 - val_accuracy: 0.6409 - val_loss: 1.7126 - learning_rate: 5.0624e-06
Epoch 94/300
1413/1413 - 224s - 159ms/step - accuracy: 0.4319 - loss: 2.6918 - val_accuracy: 0.6369 - val_loss: 1.6988 - learning_rate: 5.0624e-06
Epoch 95/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4302 - loss: 2.6807 - val_accuracy: 0.6417 - val_loss: 1.6794 - learning_rate: 5.0624e-06
Epoch 96/300
1413/1413 - 227s - 160ms/step - accuracy: 0.4316 - loss: 2.6788 - val_accuracy: 0.6497 - val_loss: 1.6862 - learning_rate: 5.0624e-06
Epoch 97/300
1413/1413 - 220s - 156ms/step - accuracy: 0.4249 - loss: 2.6812 - val_accuracy: 0.6322 - val_loss: 1.7076 - learning_rate: 5.0624e-06
Epoch 98/300

Epoch 98: ReduceLROnPlateau reducing learning rate to 2.531192876631394e-06.
1413/1413 - 223s - 157ms/step - accuracy: 0.4319 - loss: 2.6675 - val_accuracy: 0.6298 - val_loss: 1.6806 - learning_rate: 5.0624e-06
Epoch 99/300
1413/1413 - 221s - 157ms/step - accuracy: 0.4251 - loss: 2.6973 - val_accuracy: 0.6401 - val_loss: 1.6679 - learning_rate: 2.5312e-06
Epoch 100/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4339 - loss: 2.6749 - val_accuracy: 0.6497 - val_loss: 1.6728 - learning_rate: 2.5312e-06
Epoch 101/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4218 - loss: 2.7123 - val_accuracy: 0.6449 - val_loss: 1.6864 - learning_rate: 2.5312e-06
Epoch 102/300
1413/1413 - 220s - 156ms/step - accuracy: 0.4300 - loss: 2.6789 - val_accuracy: 0.6465 - val_loss: 1.6664 - learning_rate: 2.5312e-06
Epoch 103/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4368 - loss: 2.6827 - val_accuracy: 0.6497 - val_loss: 1.6578 - learning_rate: 2.5312e-06
Epoch 104/300
1413/1413 - 219s - 155ms/step - accuracy: 0.4354 - loss: 2.6420 - val_accuracy: 0.6457 - val_loss: 1.6803 - learning_rate: 2.5312e-06
Epoch 105/300
1413/1413 - 221s - 156ms/step - accuracy: 0.4303 - loss: 2.6717 - val_accuracy: 0.6473 - val_loss: 1.6818 - learning_rate: 2.5312e-06
Epoch 106/300
1413/1413 - 221s - 157ms/step - accuracy: 0.4302 - loss: 2.6471 - val_accuracy: 0.6497 - val_loss: 1.6680 - learning_rate: 2.5312e-06
Epoch 107/300
1413/1413 - 220s - 156ms/step - accuracy: 0.4293 - loss: 2.6668 - val_accuracy: 0.6497 - val_loss: 1.6645 - learning_rate: 2.5312e-06
Epoch 108/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4370 - loss: 2.6275 - val_accuracy: 0.6473 - val_loss: 1.6653 - learning_rate: 2.5312e-06
Epoch 109/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4367 - loss: 2.6512 - val_accuracy: 0.6465 - val_loss: 1.6851 - learning_rate: 2.5312e-06
Epoch 110/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4306 - loss: 2.6956 - val_accuracy: 0.6457 - val_loss: 1.6714 - learning_rate: 2.5312e-06
Epoch 111/300

Epoch 111: ReduceLROnPlateau reducing learning rate to 1.265596438315697e-06.
1413/1413 - 222s - 157ms/step - accuracy: 0.4258 - loss: 2.7037 - val_accuracy: 0.6449 - val_loss: 1.6885 - learning_rate: 2.5312e-06
Epoch 112/300
1413/1413 - 228s - 161ms/step - accuracy: 0.4351 - loss: 2.6827 - val_accuracy: 0.6521 - val_loss: 1.6825 - learning_rate: 1.2656e-06
Epoch 113/300
1413/1413 - 221s - 157ms/step - accuracy: 0.4350 - loss: 2.6455 - val_accuracy: 0.6489 - val_loss: 1.6708 - learning_rate: 1.2656e-06
Epoch 114/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4332 - loss: 2.6804 - val_accuracy: 0.6521 - val_loss: 1.6628 - learning_rate: 1.2656e-06
Epoch 115/300
1413/1413 - 224s - 158ms/step - accuracy: 0.4326 - loss: 2.6645 - val_accuracy: 0.6497 - val_loss: 1.6642 - learning_rate: 1.2656e-06
Epoch 116/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4264 - loss: 2.6726 - val_accuracy: 0.6505 - val_loss: 1.6629 - learning_rate: 1.2656e-06
Epoch 117/300
1413/1413 - 221s - 156ms/step - accuracy: 0.4278 - loss: 2.6673 - val_accuracy: 0.6449 - val_loss: 1.6555 - learning_rate: 1.2656e-06
Epoch 118/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4305 - loss: 2.6857 - val_accuracy: 0.6497 - val_loss: 1.6664 - learning_rate: 1.2656e-06
Epoch 119/300
1413/1413 - 220s - 156ms/step - accuracy: 0.4309 - loss: 2.6737 - val_accuracy: 0.6409 - val_loss: 1.6726 - learning_rate: 1.2656e-06
Epoch 120/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4294 - loss: 2.6579 - val_accuracy: 0.6481 - val_loss: 1.6706 - learning_rate: 1.2656e-06
Epoch 121/300
1413/1413 - 221s - 156ms/step - accuracy: 0.4263 - loss: 2.6757 - val_accuracy: 0.6457 - val_loss: 1.6612 - learning_rate: 1.2656e-06
Epoch 122/300
1413/1413 - 224s - 158ms/step - accuracy: 0.4355 - loss: 2.6841 - val_accuracy: 0.6441 - val_loss: 1.6578 - learning_rate: 1.2656e-06
Epoch 123/300
1413/1413 - 221s - 157ms/step - accuracy: 0.4356 - loss: 2.6629 - val_accuracy: 0.6481 - val_loss: 1.6703 - learning_rate: 1.2656e-06
Epoch 124/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4264 - loss: 2.6857 - val_accuracy: 0.6497 - val_loss: 1.6589 - learning_rate: 1.2656e-06
Epoch 125/300

Epoch 125: ReduceLROnPlateau reducing learning rate to 1e-06.
1413/1413 - 220s - 155ms/step - accuracy: 0.4332 - loss: 2.6611 - val_accuracy: 0.6441 - val_loss: 1.6661 - learning_rate: 1.2656e-06
Epoch 126/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4320 - loss: 2.6742 - val_accuracy: 0.6497 - val_loss: 1.6698 - learning_rate: 1.0000e-06
Epoch 127/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4267 - loss: 2.6807 - val_accuracy: 0.6489 - val_loss: 1.6630 - learning_rate: 1.0000e-06
Epoch 128/300
1413/1413 - 224s - 158ms/step - accuracy: 0.4308 - loss: 2.6548 - val_accuracy: 0.6473 - val_loss: 1.6617 - learning_rate: 1.0000e-06
Epoch 129/300
1413/1413 - 221s - 157ms/step - accuracy: 0.4265 - loss: 2.6746 - val_accuracy: 0.6521 - val_loss: 1.6677 - learning_rate: 1.0000e-06
Epoch 130/300
1413/1413 - 225s - 160ms/step - accuracy: 0.4373 - loss: 2.6653 - val_accuracy: 0.6489 - val_loss: 1.6746 - learning_rate: 1.0000e-06
Epoch 131/300
1413/1413 - 218s - 154ms/step - accuracy: 0.4317 - loss: 2.6619 - val_accuracy: 0.6529 - val_loss: 1.6658 - learning_rate: 1.0000e-06
Epoch 132/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4368 - loss: 2.6304 - val_accuracy: 0.6521 - val_loss: 1.6590 - learning_rate: 1.0000e-06
Epoch 133/300
1413/1413 - 219s - 155ms/step - accuracy: 0.4338 - loss: 2.6708 - val_accuracy: 0.6489 - val_loss: 1.6714 - learning_rate: 1.0000e-06
Epoch 133: early stopping
Restoring model weights from the end of the best epoch: 117.
Fold 2 Evaluation results: [1.6547132730484009, 0.6449044346809387]
              precision    recall  f1-score   support

        1820       0.82      0.85      0.83        62
        1821       0.85      0.81      0.83        57
        1822       0.00      0.00      0.00         1
        1823       0.00      0.00      0.00         2
        1824       0.00      0.00      0.00         1
        1825       0.00      0.00      0.00         2
        1826       0.00      0.00      0.00         3
        1827       0.86      0.76      0.81        25
        1828       0.00      0.00      0.00         1
        1829       0.56      1.00      0.71         5
        1830       0.69      0.52      0.59        56
        1831       0.82      0.87      0.85       134
        1832       0.71      0.85      0.77        68
        1833       0.94      0.84      0.89        19
        1834       0.60      0.83      0.70        29
        1835       0.00      0.00      0.00         2
        1836       0.00      0.00      0.00         3
        1837       0.25      0.14      0.18         7
        1838       0.50      0.25      0.33         4
        1839       0.00      0.00      0.00         0
        1840       0.61      0.63      0.62        43
        1841       0.76      0.69      0.72       108
        1842       0.67      0.40      0.50         5
        1843       1.00      0.17      0.29         6
        1844       0.00      0.00      0.00         1
        1845       0.00      0.00      0.00         1
        1846       0.44      0.67      0.53         6
        1847       0.00      0.00      0.00         2
        1848       0.33      0.17      0.22         6
        1849       0.38      0.60      0.46         5
        1850       0.49      0.62      0.55        48
        1851       0.78      0.68      0.72        77
        1852       0.00      0.00      0.00         7
        1853       0.00      0.00      0.00         6
        1854       0.00      0.00      0.00         2
        1855       0.62      0.42      0.50        24
        1856       0.47      0.58      0.52        12
        1857       0.54      0.65      0.59        31
        1858       0.00      0.00      0.00         2
        1859       0.00      0.00      0.00         3
        1860       0.31      0.31      0.31        64
        1861       0.78      0.82      0.80        85
        1862       0.43      0.53      0.48        19
        1863       0.50      0.50      0.50        18
        1864       0.36      0.29      0.32        17
        1865       0.60      1.00      0.75         6
        1866       0.00      0.00      0.00         5
        1867       0.31      0.45      0.37        11
        1868       0.00      0.00      0.00         8
        1869       0.00      0.00      0.00         5
        1870       0.41      0.63      0.50        30
        1871       0.75      0.88      0.81        49
        1872       0.60      0.43      0.50         7
        1873       0.14      0.10      0.12        10
        1874       0.00      0.00      0.00         5
        1875       0.29      0.36      0.32        14
        1876       0.80      0.80      0.80        10
        1877       0.40      0.33      0.36         6
        1878       0.44      0.44      0.44         9
        1879       0.00      0.00      0.00         2

    accuracy                           0.64      1256
   macro avg       0.36      0.36      0.35      1256
weighted avg       0.63      0.64      0.63      1256

Matthews Correlation Coefficient: 0.627
Macro avg F1: 0.352
Weighted avg F1: 0.632
Micro avg F1: 0.645
Top-3 Accuracy: 0.864
Top-5 Accuracy: 0.905
Micro ROC AUC  = 0.99
Macro ROC AUC (present classes) = 0.98
Classification MAE (in years): 2.98

Fold 2 Misclassification Analysis:
Near misses (within 2 years): 124 out of 446 misclassifications (27.80%)
Big misses (greater than 10 years): 202
MAE with outliers: 2.98
MAE without outliers: 1.95 (improvement: 1.03)

10 Worst misclassifications:
Image: data/datasets/public/1820/1820_020met.jpg, True: 1820, Predicted: 1876, Error: 56
Image: data/datasets/private/1820/1825_040_Zrzut ekranu 2022-07-26 211114.png, True: 1825, Predicted: 1878, Error: 53
Image: data/datasets/private/1830/1830_74etsy.jpg, True: 1830, Predicted: 1875, Error: 45
Image: data/datasets/public/1870/1876_1953vna.jpg, True: 1876, Predicted: 1832, Error: 44
Image: data/datasets/public/1830/1832_1087vna.jpg, True: 1832, Predicted: 1876, Error: 44
Image: data/datasets/public/1820/1823_53vna.jpg, True: 1823, Predicted: 1865, Error: 42
Image: data/datasets/public/1860/1862_1622vna.jpg, True: 1862, Predicted: 1820, Error: 42
Image: data/datasets/public/1860/1862_22washington.jpg, True: 1862, Predicted: 1820, Error: 42
Image: data/datasets/private/1820/1820_039_Zrzut ekranu 2022-07-26 211152.png, True: 1820, Predicted: 1860, Error: 40
Image: data/datasets/public/1820/1820_019met.jpg, True: 1820, Predicted: 1860, Error: 40

===== Fold 3 =====

===== Fine Tuning 7 layers! =====
Epoch 1/300
1413/1413 - 244s - 173ms/step - accuracy: 0.1230 - loss: 4.6381 - val_accuracy: 0.1640 - val_loss: 4.9664 - learning_rate: 1.6200e-04
Epoch 2/300
1413/1413 - 223s - 158ms/step - accuracy: 0.1953 - loss: 3.9992 - val_accuracy: 0.2174 - val_loss: 4.6928 - learning_rate: 1.6200e-04
Epoch 3/300
1413/1413 - 219s - 155ms/step - accuracy: 0.2245 - loss: 3.8045 - val_accuracy: 0.2930 - val_loss: 4.1604 - learning_rate: 1.6200e-04
Epoch 4/300
1413/1413 - 223s - 158ms/step - accuracy: 0.2435 - loss: 3.6759 - val_accuracy: 0.1998 - val_loss: 4.8704 - learning_rate: 1.6200e-04
Epoch 5/300
1413/1413 - 222s - 157ms/step - accuracy: 0.2555 - loss: 3.6229 - val_accuracy: 0.2564 - val_loss: 3.8672 - learning_rate: 1.6200e-04
Epoch 6/300
1413/1413 - 221s - 157ms/step - accuracy: 0.2651 - loss: 3.5587 - val_accuracy: 0.1935 - val_loss: 4.4987 - learning_rate: 1.6200e-04
Epoch 7/300
1413/1413 - 225s - 159ms/step - accuracy: 0.2683 - loss: 3.5324 - val_accuracy: 0.3511 - val_loss: 3.1419 - learning_rate: 1.6200e-04
Epoch 8/300
1413/1413 - 222s - 157ms/step - accuracy: 0.2835 - loss: 3.4483 - val_accuracy: 0.4188 - val_loss: 2.8571 - learning_rate: 1.6200e-04
Epoch 9/300
1413/1413 - 224s - 159ms/step - accuracy: 0.2930 - loss: 3.3990 - val_accuracy: 0.3957 - val_loss: 2.8743 - learning_rate: 1.6200e-04
Epoch 10/300
1413/1413 - 220s - 156ms/step - accuracy: 0.2949 - loss: 3.3803 - val_accuracy: 0.3989 - val_loss: 2.9260 - learning_rate: 1.6200e-04
Epoch 11/300
1413/1413 - 225s - 159ms/step - accuracy: 0.3028 - loss: 3.3573 - val_accuracy: 0.4682 - val_loss: 2.7362 - learning_rate: 1.6200e-04
Epoch 12/300
1413/1413 - 223s - 158ms/step - accuracy: 0.3040 - loss: 3.3278 - val_accuracy: 0.2046 - val_loss: 4.4086 - learning_rate: 1.6200e-04
Epoch 13/300
1413/1413 - 266s - 188ms/step - accuracy: 0.3109 - loss: 3.2997 - val_accuracy: 0.4713 - val_loss: 2.4662 - learning_rate: 1.6200e-04
Epoch 14/300
1413/1413 - 226s - 160ms/step - accuracy: 0.3189 - loss: 3.2503 - val_accuracy: 0.3822 - val_loss: 3.3028 - learning_rate: 1.6200e-04
Epoch 15/300
1413/1413 - 224s - 159ms/step - accuracy: 0.3196 - loss: 3.2626 - val_accuracy: 0.4697 - val_loss: 2.3699 - learning_rate: 1.6200e-04
Epoch 16/300
1413/1413 - 226s - 160ms/step - accuracy: 0.3249 - loss: 3.2577 - val_accuracy: 0.4490 - val_loss: 2.7950 - learning_rate: 1.6200e-04
Epoch 17/300
1413/1413 - 225s - 159ms/step - accuracy: 0.3254 - loss: 3.2393 - val_accuracy: 0.3662 - val_loss: 2.9945 - learning_rate: 1.6200e-04
Epoch 18/300
1413/1413 - 222s - 157ms/step - accuracy: 0.3232 - loss: 3.2028 - val_accuracy: 0.4530 - val_loss: 2.6589 - learning_rate: 1.6200e-04
Epoch 19/300
1413/1413 - 223s - 158ms/step - accuracy: 0.3335 - loss: 3.1744 - val_accuracy: 0.3392 - val_loss: 2.9248 - learning_rate: 1.6200e-04
Epoch 20/300
1413/1413 - 224s - 159ms/step - accuracy: 0.3342 - loss: 3.1482 - val_accuracy: 0.4260 - val_loss: 2.4984 - learning_rate: 1.6200e-04
Epoch 21/300
1413/1413 - 229s - 162ms/step - accuracy: 0.3391 - loss: 3.1535 - val_accuracy: 0.5151 - val_loss: 2.2106 - learning_rate: 1.6200e-04
Epoch 22/300
1413/1413 - 220s - 156ms/step - accuracy: 0.3401 - loss: 3.1308 - val_accuracy: 0.5048 - val_loss: 2.3058 - learning_rate: 1.6200e-04
Epoch 23/300
1413/1413 - 225s - 159ms/step - accuracy: 0.3435 - loss: 3.1260 - val_accuracy: 0.4825 - val_loss: 2.5698 - learning_rate: 1.6200e-04
Epoch 24/300
1413/1413 - 224s - 158ms/step - accuracy: 0.3427 - loss: 3.1357 - val_accuracy: 0.4522 - val_loss: 2.6701 - learning_rate: 1.6200e-04
Epoch 25/300
1413/1413 - 224s - 159ms/step - accuracy: 0.3449 - loss: 3.0969 - val_accuracy: 0.4156 - val_loss: 2.7249 - learning_rate: 1.6200e-04
Epoch 26/300
1413/1413 - 237s - 167ms/step - accuracy: 0.3448 - loss: 3.0885 - val_accuracy: 0.4140 - val_loss: 2.6926 - learning_rate: 1.6200e-04
Epoch 27/300
1413/1413 - 239s - 169ms/step - accuracy: 0.3502 - loss: 3.0750 - val_accuracy: 0.4498 - val_loss: 2.6273 - learning_rate: 1.6200e-04
Epoch 28/300
1413/1413 - 235s - 166ms/step - accuracy: 0.3524 - loss: 3.0732 - val_accuracy: 0.4124 - val_loss: 2.7907 - learning_rate: 1.6200e-04
Epoch 29/300

Epoch 29: ReduceLROnPlateau reducing learning rate to 8.099817205220461e-05.
1413/1413 - 240s - 170ms/step - accuracy: 0.3550 - loss: 3.0467 - val_accuracy: 0.3432 - val_loss: 3.4609 - learning_rate: 1.6200e-04
Epoch 30/300
1413/1413 - 231s - 164ms/step - accuracy: 0.3725 - loss: 2.9699 - val_accuracy: 0.5175 - val_loss: 2.1991 - learning_rate: 8.0998e-05
Epoch 31/300
1413/1413 - 238s - 169ms/step - accuracy: 0.3710 - loss: 2.9674 - val_accuracy: 0.5446 - val_loss: 2.3296 - learning_rate: 8.0998e-05
Epoch 32/300
1413/1413 - 240s - 170ms/step - accuracy: 0.3754 - loss: 2.9517 - val_accuracy: 0.5183 - val_loss: 2.1905 - learning_rate: 8.0998e-05
Epoch 33/300
1413/1413 - 240s - 170ms/step - accuracy: 0.3803 - loss: 2.9299 - val_accuracy: 0.5119 - val_loss: 2.2952 - learning_rate: 8.0998e-05
Epoch 34/300
1413/1413 - 239s - 169ms/step - accuracy: 0.3789 - loss: 2.9439 - val_accuracy: 0.5096 - val_loss: 2.7054 - learning_rate: 8.0998e-05
Epoch 35/300
1413/1413 - 234s - 166ms/step - accuracy: 0.3780 - loss: 2.9382 - val_accuracy: 0.5518 - val_loss: 2.1870 - learning_rate: 8.0998e-05
Epoch 36/300
1413/1413 - 239s - 169ms/step - accuracy: 0.3741 - loss: 2.9288 - val_accuracy: 0.4674 - val_loss: 2.2865 - learning_rate: 8.0998e-05
Epoch 37/300
1413/1413 - 235s - 167ms/step - accuracy: 0.3819 - loss: 2.9422 - val_accuracy: 0.4443 - val_loss: 2.9029 - learning_rate: 8.0998e-05
Epoch 38/300
1413/1413 - 240s - 170ms/step - accuracy: 0.3834 - loss: 2.9114 - val_accuracy: 0.5932 - val_loss: 1.8921 - learning_rate: 8.0998e-05
Epoch 39/300
1413/1413 - 235s - 166ms/step - accuracy: 0.3800 - loss: 2.9100 - val_accuracy: 0.5438 - val_loss: 2.0378 - learning_rate: 8.0998e-05
Epoch 40/300
1413/1413 - 241s - 170ms/step - accuracy: 0.3875 - loss: 2.8673 - val_accuracy: 0.5661 - val_loss: 2.1377 - learning_rate: 8.0998e-05
Epoch 41/300
1413/1413 - 235s - 166ms/step - accuracy: 0.3924 - loss: 2.8899 - val_accuracy: 0.4873 - val_loss: 2.3679 - learning_rate: 8.0998e-05
Epoch 42/300
1413/1413 - 239s - 169ms/step - accuracy: 0.3918 - loss: 2.8775 - val_accuracy: 0.6043 - val_loss: 1.9235 - learning_rate: 8.0998e-05
Epoch 43/300
1413/1413 - 234s - 166ms/step - accuracy: 0.3877 - loss: 2.8924 - val_accuracy: 0.5908 - val_loss: 1.8711 - learning_rate: 8.0998e-05
Epoch 44/300
1413/1413 - 234s - 166ms/step - accuracy: 0.3882 - loss: 2.8921 - val_accuracy: 0.5740 - val_loss: 2.0549 - learning_rate: 8.0998e-05
Epoch 45/300
1413/1413 - 240s - 170ms/step - accuracy: 0.3877 - loss: 2.8926 - val_accuracy: 0.5685 - val_loss: 1.8147 - learning_rate: 8.0998e-05
Epoch 46/300
1413/1413 - 235s - 167ms/step - accuracy: 0.3858 - loss: 2.8746 - val_accuracy: 0.5231 - val_loss: 2.3102 - learning_rate: 8.0998e-05
Epoch 47/300
1413/1413 - 231s - 164ms/step - accuracy: 0.3994 - loss: 2.8473 - val_accuracy: 0.5701 - val_loss: 2.0069 - learning_rate: 8.0998e-05
Epoch 48/300
1413/1413 - 234s - 166ms/step - accuracy: 0.3924 - loss: 2.8672 - val_accuracy: 0.5223 - val_loss: 2.3421 - learning_rate: 8.0998e-05
Epoch 49/300
1413/1413 - 239s - 169ms/step - accuracy: 0.3969 - loss: 2.8482 - val_accuracy: 0.4833 - val_loss: 2.3660 - learning_rate: 8.0998e-05
Epoch 50/300
1413/1413 - 239s - 169ms/step - accuracy: 0.3972 - loss: 2.8661 - val_accuracy: 0.5502 - val_loss: 2.0688 - learning_rate: 8.0998e-05
Epoch 51/300
1413/1413 - 235s - 166ms/step - accuracy: 0.3881 - loss: 2.8578 - val_accuracy: 0.5430 - val_loss: 2.0567 - learning_rate: 8.0998e-05
Epoch 52/300
1413/1413 - 235s - 166ms/step - accuracy: 0.3949 - loss: 2.8288 - val_accuracy: 0.5732 - val_loss: 1.9250 - learning_rate: 8.0998e-05
Epoch 53/300
1413/1413 - 235s - 167ms/step - accuracy: 0.3993 - loss: 2.8402 - val_accuracy: 0.6035 - val_loss: 1.8139 - learning_rate: 8.0998e-05
Epoch 54/300
1413/1413 - 238s - 168ms/step - accuracy: 0.4033 - loss: 2.8058 - val_accuracy: 0.5764 - val_loss: 1.9897 - learning_rate: 8.0998e-05
Epoch 55/300
1413/1413 - 236s - 167ms/step - accuracy: 0.3988 - loss: 2.8377 - val_accuracy: 0.5326 - val_loss: 2.3747 - learning_rate: 8.0998e-05
Epoch 56/300
1413/1413 - 238s - 168ms/step - accuracy: 0.3916 - loss: 2.8424 - val_accuracy: 0.5175 - val_loss: 2.4565 - learning_rate: 8.0998e-05
Epoch 57/300
1413/1413 - 234s - 166ms/step - accuracy: 0.3946 - loss: 2.8532 - val_accuracy: 0.6162 - val_loss: 1.7905 - learning_rate: 8.0998e-05
Epoch 58/300
1413/1413 - 235s - 166ms/step - accuracy: 0.4018 - loss: 2.8108 - val_accuracy: 0.6218 - val_loss: 1.7205 - learning_rate: 8.0998e-05
Epoch 59/300
1413/1413 - 238s - 169ms/step - accuracy: 0.4015 - loss: 2.8251 - val_accuracy: 0.5693 - val_loss: 1.8856 - learning_rate: 8.0998e-05
Epoch 60/300
1413/1413 - 235s - 166ms/step - accuracy: 0.3987 - loss: 2.8346 - val_accuracy: 0.5947 - val_loss: 1.9561 - learning_rate: 8.0998e-05
Epoch 61/300
1413/1413 - 240s - 170ms/step - accuracy: 0.4017 - loss: 2.8092 - val_accuracy: 0.5844 - val_loss: 1.9560 - learning_rate: 8.0998e-05
Epoch 62/300
1413/1413 - 235s - 166ms/step - accuracy: 0.3996 - loss: 2.8187 - val_accuracy: 0.5271 - val_loss: 2.2710 - learning_rate: 8.0998e-05
Epoch 63/300
1413/1413 - 237s - 167ms/step - accuracy: 0.4023 - loss: 2.7883 - val_accuracy: 0.4562 - val_loss: 2.6098 - learning_rate: 8.0998e-05
Epoch 64/300
1413/1413 - 240s - 170ms/step - accuracy: 0.4053 - loss: 2.7891 - val_accuracy: 0.5677 - val_loss: 2.0717 - learning_rate: 8.0998e-05
Epoch 65/300
1413/1413 - 235s - 166ms/step - accuracy: 0.4127 - loss: 2.7702 - val_accuracy: 0.5494 - val_loss: 2.2329 - learning_rate: 8.0998e-05
Epoch 66/300

Epoch 66: ReduceLROnPlateau reducing learning rate to 4.0499086026102304e-05.
1413/1413 - 240s - 170ms/step - accuracy: 0.4037 - loss: 2.8185 - val_accuracy: 0.5884 - val_loss: 1.9637 - learning_rate: 8.0998e-05
Epoch 67/300
1413/1413 - 232s - 164ms/step - accuracy: 0.4159 - loss: 2.7644 - val_accuracy: 0.6441 - val_loss: 1.7335 - learning_rate: 4.0499e-05
Epoch 68/300
1413/1413 - 237s - 168ms/step - accuracy: 0.4137 - loss: 2.7472 - val_accuracy: 0.6481 - val_loss: 1.6522 - learning_rate: 4.0499e-05
Epoch 69/300
1413/1413 - 236s - 167ms/step - accuracy: 0.4140 - loss: 2.7464 - val_accuracy: 0.6146 - val_loss: 1.7318 - learning_rate: 4.0499e-05
Epoch 70/300
1413/1413 - 237s - 168ms/step - accuracy: 0.4136 - loss: 2.7292 - val_accuracy: 0.6401 - val_loss: 1.6077 - learning_rate: 4.0499e-05
Epoch 71/300
1413/1413 - 235s - 166ms/step - accuracy: 0.4107 - loss: 2.7559 - val_accuracy: 0.6226 - val_loss: 1.8318 - learning_rate: 4.0499e-05
Epoch 72/300
1413/1413 - 236s - 167ms/step - accuracy: 0.4187 - loss: 2.7259 - val_accuracy: 0.6521 - val_loss: 1.6127 - learning_rate: 4.0499e-05
Epoch 73/300
1413/1413 - 235s - 166ms/step - accuracy: 0.4235 - loss: 2.7031 - val_accuracy: 0.5900 - val_loss: 1.9894 - learning_rate: 4.0499e-05
Epoch 74/300
1413/1413 - 235s - 166ms/step - accuracy: 0.4216 - loss: 2.7340 - val_accuracy: 0.6146 - val_loss: 1.7333 - learning_rate: 4.0499e-05
Epoch 75/300
1413/1413 - 240s - 170ms/step - accuracy: 0.4173 - loss: 2.7479 - val_accuracy: 0.6409 - val_loss: 1.6599 - learning_rate: 4.0499e-05
Epoch 76/300
1413/1413 - 237s - 168ms/step - accuracy: 0.4175 - loss: 2.7187 - val_accuracy: 0.6107 - val_loss: 1.7533 - learning_rate: 4.0499e-05
Epoch 77/300
1413/1413 - 235s - 167ms/step - accuracy: 0.4251 - loss: 2.6984 - val_accuracy: 0.6139 - val_loss: 1.8761 - learning_rate: 4.0499e-05
Epoch 78/300

Epoch 78: ReduceLROnPlateau reducing learning rate to 2.0249543013051152e-05.
1413/1413 - 237s - 168ms/step - accuracy: 0.4231 - loss: 2.7314 - val_accuracy: 0.6330 - val_loss: 1.7146 - learning_rate: 4.0499e-05
Epoch 79/300
1413/1413 - 239s - 169ms/step - accuracy: 0.4269 - loss: 2.6848 - val_accuracy: 0.6425 - val_loss: 1.6440 - learning_rate: 2.0250e-05
Epoch 80/300
1413/1413 - 235s - 167ms/step - accuracy: 0.4282 - loss: 2.6765 - val_accuracy: 0.6497 - val_loss: 1.6097 - learning_rate: 2.0250e-05
Epoch 81/300
1413/1413 - 237s - 168ms/step - accuracy: 0.4252 - loss: 2.6805 - val_accuracy: 0.6624 - val_loss: 1.5949 - learning_rate: 2.0250e-05
Epoch 82/300
1413/1413 - 235s - 167ms/step - accuracy: 0.4362 - loss: 2.6705 - val_accuracy: 0.6330 - val_loss: 1.6622 - learning_rate: 2.0250e-05
Epoch 83/300
1413/1413 - 236s - 167ms/step - accuracy: 0.4254 - loss: 2.6933 - val_accuracy: 0.6393 - val_loss: 1.6330 - learning_rate: 2.0250e-05
Epoch 84/300
1413/1413 - 240s - 170ms/step - accuracy: 0.4299 - loss: 2.6600 - val_accuracy: 0.6489 - val_loss: 1.5796 - learning_rate: 2.0250e-05
Epoch 85/300
1413/1413 - 235s - 166ms/step - accuracy: 0.4271 - loss: 2.6635 - val_accuracy: 0.6505 - val_loss: 1.6664 - learning_rate: 2.0250e-05
Epoch 86/300
1413/1413 - 238s - 169ms/step - accuracy: 0.4248 - loss: 2.6689 - val_accuracy: 0.6624 - val_loss: 1.5167 - learning_rate: 2.0250e-05
Epoch 87/300
1413/1413 - 232s - 164ms/step - accuracy: 0.4233 - loss: 2.6898 - val_accuracy: 0.6401 - val_loss: 1.6095 - learning_rate: 2.0250e-05
Epoch 88/300
1413/1413 - 238s - 168ms/step - accuracy: 0.4351 - loss: 2.6450 - val_accuracy: 0.6457 - val_loss: 1.5828 - learning_rate: 2.0250e-05
Epoch 89/300
1413/1413 - 236s - 167ms/step - accuracy: 0.4336 - loss: 2.6584 - val_accuracy: 0.6465 - val_loss: 1.5524 - learning_rate: 2.0250e-05
Epoch 90/300
1413/1413 - 237s - 167ms/step - accuracy: 0.4331 - loss: 2.6578 - val_accuracy: 0.6521 - val_loss: 1.5665 - learning_rate: 2.0250e-05
Epoch 91/300
1413/1413 - 236s - 167ms/step - accuracy: 0.4287 - loss: 2.6462 - val_accuracy: 0.6505 - val_loss: 1.5784 - learning_rate: 2.0250e-05
Epoch 92/300
1413/1413 - 232s - 164ms/step - accuracy: 0.4286 - loss: 2.6572 - val_accuracy: 0.6258 - val_loss: 1.7497 - learning_rate: 2.0250e-05
Epoch 93/300
1413/1413 - 244s - 173ms/step - accuracy: 0.4292 - loss: 2.6674 - val_accuracy: 0.6592 - val_loss: 1.5364 - learning_rate: 2.0250e-05
Epoch 94/300

Epoch 94: ReduceLROnPlateau reducing learning rate to 1.0124771506525576e-05.
1413/1413 - 243s - 172ms/step - accuracy: 0.4335 - loss: 2.6635 - val_accuracy: 0.6576 - val_loss: 1.5805 - learning_rate: 2.0250e-05
Epoch 95/300
1413/1413 - 239s - 169ms/step - accuracy: 0.4344 - loss: 2.6526 - val_accuracy: 0.6656 - val_loss: 1.5549 - learning_rate: 1.0125e-05
Epoch 96/300
1413/1413 - 244s - 173ms/step - accuracy: 0.4411 - loss: 2.6278 - val_accuracy: 0.6720 - val_loss: 1.4977 - learning_rate: 1.0125e-05
Epoch 97/300
1413/1413 - 234s - 166ms/step - accuracy: 0.4332 - loss: 2.6483 - val_accuracy: 0.6672 - val_loss: 1.5296 - learning_rate: 1.0125e-05
Epoch 98/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4364 - loss: 2.6387 - val_accuracy: 0.6624 - val_loss: 1.5090 - learning_rate: 1.0125e-05
Epoch 99/300
1413/1413 - 230s - 162ms/step - accuracy: 0.4387 - loss: 2.6417 - val_accuracy: 0.6688 - val_loss: 1.4779 - learning_rate: 1.0125e-05
Epoch 100/300
1413/1413 - 228s - 161ms/step - accuracy: 0.4414 - loss: 2.6243 - val_accuracy: 0.6624 - val_loss: 1.5418 - learning_rate: 1.0125e-05
Epoch 101/300
1413/1413 - 228s - 161ms/step - accuracy: 0.4385 - loss: 2.6385 - val_accuracy: 0.6696 - val_loss: 1.4804 - learning_rate: 1.0125e-05
Epoch 102/300
1413/1413 - 224s - 159ms/step - accuracy: 0.4402 - loss: 2.6291 - val_accuracy: 0.6712 - val_loss: 1.4915 - learning_rate: 1.0125e-05
Epoch 103/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4411 - loss: 2.6422 - val_accuracy: 0.6656 - val_loss: 1.5189 - learning_rate: 1.0125e-05
Epoch 104/300
1413/1413 - 228s - 161ms/step - accuracy: 0.4423 - loss: 2.6146 - val_accuracy: 0.6632 - val_loss: 1.5502 - learning_rate: 1.0125e-05
Epoch 105/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4382 - loss: 2.6312 - val_accuracy: 0.6672 - val_loss: 1.5513 - learning_rate: 1.0125e-05
Epoch 106/300
1413/1413 - 228s - 161ms/step - accuracy: 0.4394 - loss: 2.6214 - val_accuracy: 0.6704 - val_loss: 1.4824 - learning_rate: 1.0125e-05
Epoch 107/300

Epoch 107: ReduceLROnPlateau reducing learning rate to 5.062385753262788e-06.
1413/1413 - 225s - 160ms/step - accuracy: 0.4394 - loss: 2.6297 - val_accuracy: 0.6712 - val_loss: 1.5047 - learning_rate: 1.0125e-05
Epoch 108/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4468 - loss: 2.5757 - val_accuracy: 0.6720 - val_loss: 1.4932 - learning_rate: 5.0624e-06
Epoch 109/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4329 - loss: 2.6262 - val_accuracy: 0.6736 - val_loss: 1.4870 - learning_rate: 5.0624e-06
Epoch 110/300
1413/1413 - 230s - 163ms/step - accuracy: 0.4408 - loss: 2.6154 - val_accuracy: 0.6839 - val_loss: 1.4711 - learning_rate: 5.0624e-06
Epoch 111/300
1413/1413 - 230s - 163ms/step - accuracy: 0.4413 - loss: 2.6112 - val_accuracy: 0.6839 - val_loss: 1.4646 - learning_rate: 5.0624e-06
Epoch 112/300
1413/1413 - 227s - 161ms/step - accuracy: 0.4398 - loss: 2.6103 - val_accuracy: 0.6799 - val_loss: 1.4634 - learning_rate: 5.0624e-06
Epoch 113/300
1413/1413 - 230s - 163ms/step - accuracy: 0.4476 - loss: 2.5913 - val_accuracy: 0.6712 - val_loss: 1.4959 - learning_rate: 5.0624e-06
Epoch 114/300
1413/1413 - 227s - 161ms/step - accuracy: 0.4453 - loss: 2.5793 - val_accuracy: 0.6768 - val_loss: 1.4791 - learning_rate: 5.0624e-06
Epoch 115/300
1413/1413 - 230s - 163ms/step - accuracy: 0.4536 - loss: 2.5781 - val_accuracy: 0.6783 - val_loss: 1.4759 - learning_rate: 5.0624e-06
Epoch 116/300
1413/1413 - 230s - 163ms/step - accuracy: 0.4466 - loss: 2.6028 - val_accuracy: 0.6720 - val_loss: 1.4758 - learning_rate: 5.0624e-06
Epoch 117/300
1413/1413 - 230s - 163ms/step - accuracy: 0.4412 - loss: 2.5893 - val_accuracy: 0.6712 - val_loss: 1.4944 - learning_rate: 5.0624e-06
Epoch 118/300
1413/1413 - 227s - 161ms/step - accuracy: 0.4446 - loss: 2.6094 - val_accuracy: 0.6712 - val_loss: 1.4885 - learning_rate: 5.0624e-06
Epoch 119/300
1413/1413 - 228s - 161ms/step - accuracy: 0.4406 - loss: 2.6157 - val_accuracy: 0.6791 - val_loss: 1.4924 - learning_rate: 5.0624e-06
Epoch 120/300

Epoch 120: ReduceLROnPlateau reducing learning rate to 2.531192876631394e-06.
1413/1413 - 227s - 161ms/step - accuracy: 0.4417 - loss: 2.6249 - val_accuracy: 0.6720 - val_loss: 1.5008 - learning_rate: 5.0624e-06
Epoch 121/300
1413/1413 - 227s - 160ms/step - accuracy: 0.4391 - loss: 2.6251 - val_accuracy: 0.6823 - val_loss: 1.4708 - learning_rate: 2.5312e-06
Epoch 122/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4467 - loss: 2.5734 - val_accuracy: 0.6760 - val_loss: 1.4588 - learning_rate: 2.5312e-06
Epoch 123/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4379 - loss: 2.6052 - val_accuracy: 0.6807 - val_loss: 1.4642 - learning_rate: 2.5312e-06
Epoch 124/300
1413/1413 - 227s - 160ms/step - accuracy: 0.4463 - loss: 2.5927 - val_accuracy: 0.6736 - val_loss: 1.4807 - learning_rate: 2.5312e-06
Epoch 125/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4414 - loss: 2.5963 - val_accuracy: 0.6720 - val_loss: 1.4856 - learning_rate: 2.5312e-06
Epoch 126/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4428 - loss: 2.6170 - val_accuracy: 0.6823 - val_loss: 1.4698 - learning_rate: 2.5312e-06
Epoch 127/300
1413/1413 - 227s - 160ms/step - accuracy: 0.4488 - loss: 2.6050 - val_accuracy: 0.6783 - val_loss: 1.4652 - learning_rate: 2.5312e-06
Epoch 128/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4480 - loss: 2.6039 - val_accuracy: 0.6736 - val_loss: 1.4556 - learning_rate: 2.5312e-06
Epoch 129/300
1413/1413 - 228s - 161ms/step - accuracy: 0.4493 - loss: 2.6050 - val_accuracy: 0.6768 - val_loss: 1.4858 - learning_rate: 2.5312e-06
Epoch 130/300
1413/1413 - 225s - 160ms/step - accuracy: 0.4391 - loss: 2.6149 - val_accuracy: 0.6775 - val_loss: 1.4736 - learning_rate: 2.5312e-06
Epoch 131/300
1413/1413 - 221s - 157ms/step - accuracy: 0.4495 - loss: 2.5993 - val_accuracy: 0.6791 - val_loss: 1.4708 - learning_rate: 2.5312e-06
Epoch 132/300
1413/1413 - 231s - 163ms/step - accuracy: 0.4495 - loss: 2.5903 - val_accuracy: 0.6768 - val_loss: 1.5040 - learning_rate: 2.5312e-06
Epoch 133/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4491 - loss: 2.5838 - val_accuracy: 0.6752 - val_loss: 1.4784 - learning_rate: 2.5312e-06
Epoch 134/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4394 - loss: 2.6390 - val_accuracy: 0.6768 - val_loss: 1.4639 - learning_rate: 2.5312e-06
Epoch 135/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4438 - loss: 2.6170 - val_accuracy: 0.6799 - val_loss: 1.4590 - learning_rate: 2.5312e-06
Epoch 136/300

Epoch 136: ReduceLROnPlateau reducing learning rate to 1.265596438315697e-06.
1413/1413 - 224s - 159ms/step - accuracy: 0.4521 - loss: 2.5716 - val_accuracy: 0.6775 - val_loss: 1.4674 - learning_rate: 2.5312e-06
Epoch 137/300
1413/1413 - 227s - 161ms/step - accuracy: 0.4428 - loss: 2.5928 - val_accuracy: 0.6768 - val_loss: 1.4614 - learning_rate: 1.2656e-06
Epoch 138/300
1413/1413 - 228s - 161ms/step - accuracy: 0.4366 - loss: 2.6257 - val_accuracy: 0.6783 - val_loss: 1.4630 - learning_rate: 1.2656e-06
Epoch 139/300
1413/1413 - 228s - 161ms/step - accuracy: 0.4434 - loss: 2.6050 - val_accuracy: 0.6791 - val_loss: 1.4732 - learning_rate: 1.2656e-06
Epoch 140/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4493 - loss: 2.6038 - val_accuracy: 0.6783 - val_loss: 1.4809 - learning_rate: 1.2656e-06
Epoch 141/300
1413/1413 - 227s - 161ms/step - accuracy: 0.4519 - loss: 2.5778 - val_accuracy: 0.6752 - val_loss: 1.4693 - learning_rate: 1.2656e-06
Epoch 142/300
1413/1413 - 227s - 161ms/step - accuracy: 0.4450 - loss: 2.5809 - val_accuracy: 0.6768 - val_loss: 1.4687 - learning_rate: 1.2656e-06
Epoch 143/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4475 - loss: 2.5821 - val_accuracy: 0.6807 - val_loss: 1.4532 - learning_rate: 1.2656e-06
Epoch 144/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4456 - loss: 2.6134 - val_accuracy: 0.6799 - val_loss: 1.4629 - learning_rate: 1.2656e-06
Epoch 145/300
1413/1413 - 224s - 159ms/step - accuracy: 0.4502 - loss: 2.5770 - val_accuracy: 0.6855 - val_loss: 1.4614 - learning_rate: 1.2656e-06
Epoch 146/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4448 - loss: 2.5936 - val_accuracy: 0.6831 - val_loss: 1.4609 - learning_rate: 1.2656e-06
Epoch 147/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4478 - loss: 2.5821 - val_accuracy: 0.6760 - val_loss: 1.4640 - learning_rate: 1.2656e-06
Epoch 148/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4497 - loss: 2.6043 - val_accuracy: 0.6783 - val_loss: 1.4558 - learning_rate: 1.2656e-06
Epoch 149/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4486 - loss: 2.5956 - val_accuracy: 0.6791 - val_loss: 1.4636 - learning_rate: 1.2656e-06
Epoch 150/300
1413/1413 - 221s - 157ms/step - accuracy: 0.4406 - loss: 2.6083 - val_accuracy: 0.6815 - val_loss: 1.4490 - learning_rate: 1.2656e-06
Epoch 151/300
1413/1413 - 228s - 161ms/step - accuracy: 0.4481 - loss: 2.5828 - val_accuracy: 0.6775 - val_loss: 1.4679 - learning_rate: 1.2656e-06
Epoch 152/300
1413/1413 - 227s - 160ms/step - accuracy: 0.4486 - loss: 2.5837 - val_accuracy: 0.6807 - val_loss: 1.4672 - learning_rate: 1.2656e-06
Epoch 153/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4441 - loss: 2.5896 - val_accuracy: 0.6768 - val_loss: 1.4736 - learning_rate: 1.2656e-06
Epoch 154/300
1413/1413 - 231s - 164ms/step - accuracy: 0.4562 - loss: 2.5844 - val_accuracy: 0.6815 - val_loss: 1.4452 - learning_rate: 1.2656e-06
Epoch 155/300
1413/1413 - 224s - 159ms/step - accuracy: 0.4443 - loss: 2.5973 - val_accuracy: 0.6807 - val_loss: 1.4551 - learning_rate: 1.2656e-06
Epoch 156/300
1413/1413 - 231s - 163ms/step - accuracy: 0.4461 - loss: 2.5842 - val_accuracy: 0.6823 - val_loss: 1.4551 - learning_rate: 1.2656e-06
Epoch 157/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4454 - loss: 2.5972 - val_accuracy: 0.6823 - val_loss: 1.4580 - learning_rate: 1.2656e-06
Epoch 158/300
1413/1413 - 231s - 163ms/step - accuracy: 0.4503 - loss: 2.5747 - val_accuracy: 0.6791 - val_loss: 1.4526 - learning_rate: 1.2656e-06
Epoch 159/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4476 - loss: 2.5943 - val_accuracy: 0.6799 - val_loss: 1.4597 - learning_rate: 1.2656e-06
Epoch 160/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4495 - loss: 2.5626 - val_accuracy: 0.6791 - val_loss: 1.4551 - learning_rate: 1.2656e-06
Epoch 161/300
1413/1413 - 228s - 161ms/step - accuracy: 0.4452 - loss: 2.5835 - val_accuracy: 0.6815 - val_loss: 1.4585 - learning_rate: 1.2656e-06
Epoch 162/300

Epoch 162: ReduceLROnPlateau reducing learning rate to 1e-06.
1413/1413 - 229s - 162ms/step - accuracy: 0.4432 - loss: 2.5984 - val_accuracy: 0.6839 - val_loss: 1.4552 - learning_rate: 1.2656e-06
Epoch 163/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4414 - loss: 2.6174 - val_accuracy: 0.6855 - val_loss: 1.4538 - learning_rate: 1.0000e-06
Epoch 164/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4424 - loss: 2.5877 - val_accuracy: 0.6799 - val_loss: 1.4527 - learning_rate: 1.0000e-06
Epoch 165/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4492 - loss: 2.5958 - val_accuracy: 0.6768 - val_loss: 1.4705 - learning_rate: 1.0000e-06
Epoch 166/300
1413/1413 - 224s - 159ms/step - accuracy: 0.4442 - loss: 2.5846 - val_accuracy: 0.6775 - val_loss: 1.4572 - learning_rate: 1.0000e-06
Epoch 167/300
1413/1413 - 230s - 163ms/step - accuracy: 0.4495 - loss: 2.5749 - val_accuracy: 0.6783 - val_loss: 1.4512 - learning_rate: 1.0000e-06
Epoch 168/300
1413/1413 - 228s - 161ms/step - accuracy: 0.4490 - loss: 2.5829 - val_accuracy: 0.6799 - val_loss: 1.4583 - learning_rate: 1.0000e-06
Epoch 169/300
1413/1413 - 227s - 160ms/step - accuracy: 0.4449 - loss: 2.5970 - val_accuracy: 0.6839 - val_loss: 1.4645 - learning_rate: 1.0000e-06
Epoch 170/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4493 - loss: 2.5802 - val_accuracy: 0.6831 - val_loss: 1.4534 - learning_rate: 1.0000e-06
Epoch 170: early stopping
Restoring model weights from the end of the best epoch: 154.
Fold 3 Evaluation results: [1.454471230506897, 0.6815286874771118]
              precision    recall  f1-score   support

        1820       0.85      0.84      0.85        62
        1821       0.88      0.88      0.88        57
        1822       0.00      0.00      0.00         1
        1823       0.00      0.00      0.00         2
        1824       0.00      0.00      0.00         1
        1825       0.00      0.00      0.00         2
        1826       0.00      0.00      0.00         3
        1827       0.95      0.76      0.84        25
        1828       0.00      0.00      0.00         2
        1829       0.50      0.80      0.62         5
        1830       0.72      0.61      0.66        56
        1831       0.80      0.87      0.83       134
        1832       0.70      0.90      0.79        68
        1833       0.89      0.89      0.89        19
        1834       0.74      0.83      0.78        30
        1835       0.00      0.00      0.00         2
        1836       0.33      0.33      0.33         3
        1837       0.10      0.14      0.12         7
        1838       0.00      0.00      0.00         4
        1839       0.00      0.00      0.00         1
        1840       0.76      0.72      0.74        43
        1841       0.80      0.67      0.73       108
        1842       0.33      0.40      0.36         5
        1843       1.00      0.17      0.29         6
        1844       0.00      0.00      0.00         0
        1845       0.00      0.00      0.00         1
        1846       0.40      0.80      0.53         5
        1847       0.50      0.50      0.50         2
        1848       0.50      0.33      0.40         6
        1849       0.40      0.40      0.40         5
        1850       0.55      0.66      0.60        47
        1851       0.77      0.87      0.82        77
        1852       0.00      0.00      0.00         7
        1853       1.00      0.17      0.29         6
        1854       0.17      0.50      0.25         2
        1855       0.47      0.39      0.43        23
        1856       0.40      0.33      0.36        12
        1857       0.50      0.68      0.58        31
        1858       0.00      0.00      0.00         2
        1859       0.00      0.00      0.00         3
        1860       0.44      0.36      0.40        64
        1861       0.89      0.88      0.89        85
        1862       0.40      0.53      0.45        19
        1863       0.45      0.56      0.50        18
        1864       0.65      0.65      0.65        17
        1865       0.33      0.50      0.40         6
        1866       0.00      0.00      0.00         6
        1867       0.29      0.70      0.41        10
        1868       0.00      0.00      0.00         8
        1869       0.00      0.00      0.00         5
        1870       0.47      0.57      0.52        30
        1871       0.77      0.82      0.80        50
        1872       0.20      0.29      0.24         7
        1873       0.22      0.18      0.20        11
        1874       0.50      0.20      0.29         5
        1875       0.58      0.50      0.54        14
        1876       0.89      0.80      0.84        10
        1877       0.57      0.67      0.62         6
        1878       0.71      0.56      0.62         9
        1879       0.00      0.00      0.00         1

    accuracy                           0.68      1256
   macro avg       0.41      0.40      0.39      1256
weighted avg       0.67      0.68      0.67      1256

Matthews Correlation Coefficient: 0.666
Macro avg F1: 0.387
Weighted avg F1: 0.669
Micro avg F1: 0.682
Top-3 Accuracy: 0.876
Top-5 Accuracy: 0.920
Micro ROC AUC  = 0.99
Macro ROC AUC (present classes) = 0.98
Classification MAE (in years): 2.50

Fold 3 Misclassification Analysis:
Near misses (within 2 years): 117 out of 400 misclassifications (29.25%)
Big misses (greater than 10 years): 158
MAE with outliers: 2.50
MAE without outliers: 1.63 (improvement: 0.86)

10 Worst misclassifications:
Image: data/datasets/public/1820/1828_3011vna.jpg, True: 1828, Predicted: 1876, Error: 48
Image: data/datasets/public/1820/1820_033met.jpg, True: 1820, Predicted: 1867, Error: 47
Image: data/datasets/public/1820/1820_037met.jpg, True: 1820, Predicted: 1867, Error: 47
Image: data/datasets/public/1860/1865_30washington.jpg, True: 1865, Predicted: 1821, Error: 44
Image: data/datasets/private/1820/1820_62etsy.jpg, True: 1820, Predicted: 1863, Error: 43
Image: data/datasets/private/1860/1861_859etsy.jpg, True: 1861, Predicted: 1821, Error: 40
Image: data/datasets/public/1870/1873_017met.jpg, True: 1873, Predicted: 1840, Error: 33
Image: data/datasets/public/1860/1863_1385vna.jpg, True: 1863, Predicted: 1830, Error: 33
Image: data/datasets/public/1860/1865_693vna.jpg, True: 1865, Predicted: 1832, Error: 33
Image: data/datasets/public/1830/1830_70vna.jpg, True: 1830, Predicted: 1861, Error: 31

===== Fold 4 =====

===== Fine Tuning 7 layers! =====
Epoch 1/300
1413/1413 - 252s - 178ms/step - accuracy: 0.1351 - loss: 4.4174 - val_accuracy: 0.1489 - val_loss: 4.4113 - learning_rate: 1.6200e-04
Epoch 2/300
1413/1413 - 228s - 161ms/step - accuracy: 0.1874 - loss: 3.9930 - val_accuracy: 0.2707 - val_loss: 3.7718 - learning_rate: 1.6200e-04
Epoch 3/300
1413/1413 - 226s - 160ms/step - accuracy: 0.2225 - loss: 3.8354 - val_accuracy: 0.3256 - val_loss: 3.5498 - learning_rate: 1.6200e-04
Epoch 4/300
1413/1413 - 230s - 163ms/step - accuracy: 0.2424 - loss: 3.6875 - val_accuracy: 0.2428 - val_loss: 5.0761 - learning_rate: 1.6200e-04
Epoch 5/300
1413/1413 - 229s - 162ms/step - accuracy: 0.2553 - loss: 3.6066 - val_accuracy: 0.2516 - val_loss: 3.3893 - learning_rate: 1.6200e-04
Epoch 6/300
1413/1413 - 228s - 161ms/step - accuracy: 0.2712 - loss: 3.5339 - val_accuracy: 0.3073 - val_loss: 3.5740 - learning_rate: 1.6200e-04
Epoch 7/300
1413/1413 - 228s - 162ms/step - accuracy: 0.2768 - loss: 3.5007 - val_accuracy: 0.3893 - val_loss: 3.0529 - learning_rate: 1.6200e-04
Epoch 8/300
1413/1413 - 229s - 162ms/step - accuracy: 0.2896 - loss: 3.4256 - val_accuracy: 0.4156 - val_loss: 2.7462 - learning_rate: 1.6200e-04
Epoch 9/300
1413/1413 - 227s - 161ms/step - accuracy: 0.2896 - loss: 3.4250 - val_accuracy: 0.2874 - val_loss: 5.3568 - learning_rate: 1.6200e-04
Epoch 10/300
1413/1413 - 230s - 162ms/step - accuracy: 0.3028 - loss: 3.3755 - val_accuracy: 0.3201 - val_loss: 3.5252 - learning_rate: 1.6200e-04
Epoch 11/300
1413/1413 - 229s - 162ms/step - accuracy: 0.3057 - loss: 3.3331 - val_accuracy: 0.3360 - val_loss: 3.7867 - learning_rate: 1.6200e-04
Epoch 12/300
1413/1413 - 233s - 165ms/step - accuracy: 0.3074 - loss: 3.3356 - val_accuracy: 0.3941 - val_loss: 3.5843 - learning_rate: 1.6200e-04
Epoch 13/300
1413/1413 - 231s - 163ms/step - accuracy: 0.3116 - loss: 3.2905 - val_accuracy: 0.3854 - val_loss: 3.0309 - learning_rate: 1.6200e-04
Epoch 14/300
1413/1413 - 229s - 162ms/step - accuracy: 0.3165 - loss: 3.2712 - val_accuracy: 0.3949 - val_loss: 3.4792 - learning_rate: 1.6200e-04
Epoch 15/300
1413/1413 - 229s - 162ms/step - accuracy: 0.3219 - loss: 3.2279 - val_accuracy: 0.3105 - val_loss: 3.4702 - learning_rate: 1.6200e-04
Epoch 16/300
1413/1413 - 229s - 162ms/step - accuracy: 0.3269 - loss: 3.2172 - val_accuracy: 0.4785 - val_loss: 2.3718 - learning_rate: 1.6200e-04
Epoch 17/300
1413/1413 - 228s - 161ms/step - accuracy: 0.3255 - loss: 3.1941 - val_accuracy: 0.4164 - val_loss: 2.9010 - learning_rate: 1.6200e-04
Epoch 18/300
1413/1413 - 224s - 158ms/step - accuracy: 0.3254 - loss: 3.1807 - val_accuracy: 0.4841 - val_loss: 2.3032 - learning_rate: 1.6200e-04
Epoch 19/300
1413/1413 - 228s - 161ms/step - accuracy: 0.3336 - loss: 3.1551 - val_accuracy: 0.3185 - val_loss: 4.0225 - learning_rate: 1.6200e-04
Epoch 20/300
1413/1413 - 221s - 157ms/step - accuracy: 0.3403 - loss: 3.1379 - val_accuracy: 0.3551 - val_loss: 3.6831 - learning_rate: 1.6200e-04
Epoch 21/300
1413/1413 - 223s - 158ms/step - accuracy: 0.3406 - loss: 3.1260 - val_accuracy: 0.4307 - val_loss: 2.8221 - learning_rate: 1.6200e-04
Epoch 22/300
1413/1413 - 222s - 157ms/step - accuracy: 0.3447 - loss: 3.1447 - val_accuracy: 0.3025 - val_loss: 4.0928 - learning_rate: 1.6200e-04
Epoch 23/300
1413/1413 - 227s - 160ms/step - accuracy: 0.3398 - loss: 3.1057 - val_accuracy: 0.3965 - val_loss: 2.7107 - learning_rate: 1.6200e-04
Epoch 24/300
1413/1413 - 224s - 159ms/step - accuracy: 0.3463 - loss: 3.1014 - val_accuracy: 0.5597 - val_loss: 2.2561 - learning_rate: 1.6200e-04
Epoch 25/300
1413/1413 - 225s - 159ms/step - accuracy: 0.3453 - loss: 3.0603 - val_accuracy: 0.4140 - val_loss: 3.7515 - learning_rate: 1.6200e-04
Epoch 26/300
1413/1413 - 222s - 157ms/step - accuracy: 0.3530 - loss: 3.0831 - val_accuracy: 0.4650 - val_loss: 2.5393 - learning_rate: 1.6200e-04
Epoch 27/300
1413/1413 - 226s - 160ms/step - accuracy: 0.3554 - loss: 3.0367 - val_accuracy: 0.4682 - val_loss: 2.8510 - learning_rate: 1.6200e-04
Epoch 28/300
1413/1413 - 220s - 156ms/step - accuracy: 0.3562 - loss: 3.0498 - val_accuracy: 0.4833 - val_loss: 2.4135 - learning_rate: 1.6200e-04
Epoch 29/300
1413/1413 - 228s - 161ms/step - accuracy: 0.3602 - loss: 3.0183 - val_accuracy: 0.4737 - val_loss: 2.5443 - learning_rate: 1.6200e-04
Epoch 30/300
1413/1413 - 223s - 158ms/step - accuracy: 0.3606 - loss: 3.0434 - val_accuracy: 0.4936 - val_loss: 2.2771 - learning_rate: 1.6200e-04
Epoch 31/300
1413/1413 - 229s - 162ms/step - accuracy: 0.3560 - loss: 3.0189 - val_accuracy: 0.4865 - val_loss: 2.4452 - learning_rate: 1.6200e-04
Epoch 32/300

Epoch 32: ReduceLROnPlateau reducing learning rate to 8.099817205220461e-05.
1413/1413 - 226s - 160ms/step - accuracy: 0.3677 - loss: 3.0036 - val_accuracy: 0.4331 - val_loss: 2.4713 - learning_rate: 1.6200e-04
Epoch 33/300
1413/1413 - 228s - 162ms/step - accuracy: 0.3763 - loss: 2.9190 - val_accuracy: 0.5597 - val_loss: 2.0138 - learning_rate: 8.0998e-05
Epoch 34/300
1413/1413 - 227s - 161ms/step - accuracy: 0.3806 - loss: 2.9258 - val_accuracy: 0.5398 - val_loss: 2.2642 - learning_rate: 8.0998e-05
Epoch 35/300
1413/1413 - 229s - 162ms/step - accuracy: 0.3818 - loss: 2.8931 - val_accuracy: 0.4912 - val_loss: 2.5608 - learning_rate: 8.0998e-05
Epoch 36/300
1413/1413 - 229s - 162ms/step - accuracy: 0.3786 - loss: 2.8947 - val_accuracy: 0.5748 - val_loss: 2.2119 - learning_rate: 8.0998e-05
Epoch 37/300
1413/1413 - 261s - 185ms/step - accuracy: 0.3930 - loss: 2.8618 - val_accuracy: 0.5486 - val_loss: 2.4043 - learning_rate: 8.0998e-05
Epoch 38/300
1413/1413 - 227s - 161ms/step - accuracy: 0.3803 - loss: 2.8890 - val_accuracy: 0.4578 - val_loss: 2.4975 - learning_rate: 8.0998e-05
Epoch 39/300
1413/1413 - 224s - 158ms/step - accuracy: 0.3840 - loss: 2.9033 - val_accuracy: 0.5756 - val_loss: 1.9704 - learning_rate: 8.0998e-05
Epoch 40/300
1413/1413 - 228s - 161ms/step - accuracy: 0.3956 - loss: 2.8648 - val_accuracy: 0.5358 - val_loss: 2.0974 - learning_rate: 8.0998e-05
Epoch 41/300
1413/1413 - 227s - 161ms/step - accuracy: 0.3864 - loss: 2.8869 - val_accuracy: 0.5478 - val_loss: 1.9407 - learning_rate: 8.0998e-05
Epoch 42/300
1413/1413 - 226s - 160ms/step - accuracy: 0.3927 - loss: 2.8513 - val_accuracy: 0.6011 - val_loss: 1.9927 - learning_rate: 8.0998e-05
Epoch 43/300
1413/1413 - 228s - 162ms/step - accuracy: 0.3875 - loss: 2.8704 - val_accuracy: 0.5382 - val_loss: 2.1470 - learning_rate: 8.0998e-05
Epoch 44/300
1413/1413 - 228s - 162ms/step - accuracy: 0.4002 - loss: 2.8417 - val_accuracy: 0.5462 - val_loss: 1.9817 - learning_rate: 8.0998e-05
Epoch 45/300
1413/1413 - 228s - 161ms/step - accuracy: 0.3899 - loss: 2.8681 - val_accuracy: 0.5533 - val_loss: 2.1329 - learning_rate: 8.0998e-05
Epoch 46/300
1413/1413 - 224s - 158ms/step - accuracy: 0.3920 - loss: 2.8546 - val_accuracy: 0.5541 - val_loss: 2.2041 - learning_rate: 8.0998e-05
Epoch 47/300
1413/1413 - 229s - 162ms/step - accuracy: 0.3946 - loss: 2.8537 - val_accuracy: 0.5653 - val_loss: 1.9978 - learning_rate: 8.0998e-05
Epoch 48/300
1413/1413 - 224s - 158ms/step - accuracy: 0.3959 - loss: 2.8326 - val_accuracy: 0.5963 - val_loss: 1.9498 - learning_rate: 8.0998e-05
Epoch 49/300

Epoch 49: ReduceLROnPlateau reducing learning rate to 4.0499086026102304e-05.
1413/1413 - 227s - 161ms/step - accuracy: 0.3956 - loss: 2.8471 - val_accuracy: 0.5748 - val_loss: 2.0422 - learning_rate: 8.0998e-05
Epoch 50/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4108 - loss: 2.7742 - val_accuracy: 0.6234 - val_loss: 1.8257 - learning_rate: 4.0499e-05
Epoch 51/300
1413/1413 - 224s - 159ms/step - accuracy: 0.4074 - loss: 2.7733 - val_accuracy: 0.6298 - val_loss: 1.8266 - learning_rate: 4.0499e-05
Epoch 52/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4117 - loss: 2.7616 - val_accuracy: 0.6154 - val_loss: 1.8493 - learning_rate: 4.0499e-05
Epoch 53/300
1413/1413 - 224s - 159ms/step - accuracy: 0.4116 - loss: 2.7688 - val_accuracy: 0.5955 - val_loss: 2.0645 - learning_rate: 4.0499e-05
Epoch 54/300
1413/1413 - 268s - 189ms/step - accuracy: 0.4087 - loss: 2.7327 - val_accuracy: 0.6075 - val_loss: 1.8115 - learning_rate: 4.0499e-05
Epoch 55/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4179 - loss: 2.7447 - val_accuracy: 0.5796 - val_loss: 2.1798 - learning_rate: 4.0499e-05
Epoch 56/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4103 - loss: 2.7600 - val_accuracy: 0.5597 - val_loss: 2.2823 - learning_rate: 4.0499e-05
Epoch 57/300
1413/1413 - 233s - 165ms/step - accuracy: 0.4114 - loss: 2.7677 - val_accuracy: 0.6210 - val_loss: 1.8812 - learning_rate: 4.0499e-05
Epoch 58/300
1413/1413 - 228s - 162ms/step - accuracy: 0.4140 - loss: 2.7445 - val_accuracy: 0.6218 - val_loss: 1.7491 - learning_rate: 4.0499e-05
Epoch 59/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4112 - loss: 2.7521 - val_accuracy: 0.5876 - val_loss: 2.0006 - learning_rate: 4.0499e-05
Epoch 60/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4137 - loss: 2.7488 - val_accuracy: 0.5597 - val_loss: 2.0373 - learning_rate: 4.0499e-05
Epoch 61/300
1413/1413 - 230s - 163ms/step - accuracy: 0.4112 - loss: 2.7699 - val_accuracy: 0.6075 - val_loss: 1.8888 - learning_rate: 4.0499e-05
Epoch 62/300
1413/1413 - 230s - 163ms/step - accuracy: 0.4156 - loss: 2.7498 - val_accuracy: 0.6194 - val_loss: 1.7979 - learning_rate: 4.0499e-05
Epoch 63/300
1413/1413 - 227s - 161ms/step - accuracy: 0.4182 - loss: 2.7282 - val_accuracy: 0.6075 - val_loss: 1.8259 - learning_rate: 4.0499e-05
Epoch 64/300
1413/1413 - 230s - 163ms/step - accuracy: 0.4224 - loss: 2.7436 - val_accuracy: 0.5828 - val_loss: 1.8885 - learning_rate: 4.0499e-05
Epoch 65/300
1413/1413 - 227s - 161ms/step - accuracy: 0.4206 - loss: 2.7450 - val_accuracy: 0.6258 - val_loss: 1.7502 - learning_rate: 4.0499e-05
Epoch 66/300

Epoch 66: ReduceLROnPlateau reducing learning rate to 2.0249543013051152e-05.
1413/1413 - 228s - 162ms/step - accuracy: 0.4156 - loss: 2.7444 - val_accuracy: 0.6131 - val_loss: 1.8120 - learning_rate: 4.0499e-05
Epoch 67/300
1413/1413 - 260s - 184ms/step - accuracy: 0.4239 - loss: 2.6847 - val_accuracy: 0.6393 - val_loss: 1.7134 - learning_rate: 2.0250e-05
Epoch 68/300
1413/1413 - 231s - 164ms/step - accuracy: 0.4176 - loss: 2.6910 - val_accuracy: 0.5717 - val_loss: 2.1524 - learning_rate: 2.0250e-05
Epoch 69/300
1413/1413 - 228s - 161ms/step - accuracy: 0.4294 - loss: 2.7058 - val_accuracy: 0.6210 - val_loss: 1.7365 - learning_rate: 2.0250e-05
Epoch 70/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4297 - loss: 2.6989 - val_accuracy: 0.6226 - val_loss: 1.8219 - learning_rate: 2.0250e-05
Epoch 71/300
1413/1413 - 224s - 159ms/step - accuracy: 0.4191 - loss: 2.7235 - val_accuracy: 0.6457 - val_loss: 1.7371 - learning_rate: 2.0250e-05
Epoch 72/300
1413/1413 - 227s - 160ms/step - accuracy: 0.4275 - loss: 2.6887 - val_accuracy: 0.6162 - val_loss: 1.7498 - learning_rate: 2.0250e-05
Epoch 73/300
1413/1413 - 221s - 157ms/step - accuracy: 0.4258 - loss: 2.7321 - val_accuracy: 0.6354 - val_loss: 1.7222 - learning_rate: 2.0250e-05
Epoch 74/300
1413/1413 - 224s - 159ms/step - accuracy: 0.4252 - loss: 2.6752 - val_accuracy: 0.6298 - val_loss: 1.7246 - learning_rate: 2.0250e-05
Epoch 75/300
1413/1413 - 220s - 156ms/step - accuracy: 0.4204 - loss: 2.6985 - val_accuracy: 0.6266 - val_loss: 1.7059 - learning_rate: 2.0250e-05
Epoch 76/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4255 - loss: 2.6784 - val_accuracy: 0.6202 - val_loss: 1.8226 - learning_rate: 2.0250e-05
Epoch 77/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4237 - loss: 2.7075 - val_accuracy: 0.6186 - val_loss: 1.7429 - learning_rate: 2.0250e-05
Epoch 78/300
1413/1413 - 221s - 157ms/step - accuracy: 0.4271 - loss: 2.6919 - val_accuracy: 0.6393 - val_loss: 1.6532 - learning_rate: 2.0250e-05
Epoch 79/300
1413/1413 - 228s - 161ms/step - accuracy: 0.4300 - loss: 2.6534 - val_accuracy: 0.6027 - val_loss: 1.8819 - learning_rate: 2.0250e-05
Epoch 80/300
1413/1413 - 234s - 166ms/step - accuracy: 0.4325 - loss: 2.6861 - val_accuracy: 0.6338 - val_loss: 1.7524 - learning_rate: 2.0250e-05
Epoch 81/300
1413/1413 - 238s - 168ms/step - accuracy: 0.4266 - loss: 2.6672 - val_accuracy: 0.6139 - val_loss: 1.8580 - learning_rate: 2.0250e-05
Epoch 82/300
1413/1413 - 234s - 166ms/step - accuracy: 0.4330 - loss: 2.6890 - val_accuracy: 0.6481 - val_loss: 1.6516 - learning_rate: 2.0250e-05
Epoch 83/300
1413/1413 - 240s - 170ms/step - accuracy: 0.4238 - loss: 2.7077 - val_accuracy: 0.6361 - val_loss: 1.7357 - learning_rate: 2.0250e-05
Epoch 84/300
1413/1413 - 234s - 165ms/step - accuracy: 0.4184 - loss: 2.7189 - val_accuracy: 0.6338 - val_loss: 1.7205 - learning_rate: 2.0250e-05
Epoch 85/300
1413/1413 - 227s - 161ms/step - accuracy: 0.4262 - loss: 2.7032 - val_accuracy: 0.6369 - val_loss: 1.7834 - learning_rate: 2.0250e-05
Epoch 86/300
1413/1413 - 227s - 160ms/step - accuracy: 0.4253 - loss: 2.6802 - val_accuracy: 0.6322 - val_loss: 1.7221 - learning_rate: 2.0250e-05
Epoch 87/300
1413/1413 - 227s - 160ms/step - accuracy: 0.4266 - loss: 2.6977 - val_accuracy: 0.6433 - val_loss: 1.6684 - learning_rate: 2.0250e-05
Epoch 88/300
1413/1413 - 231s - 164ms/step - accuracy: 0.4201 - loss: 2.7081 - val_accuracy: 0.6290 - val_loss: 1.7861 - learning_rate: 2.0250e-05
Epoch 89/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4292 - loss: 2.6657 - val_accuracy: 0.6338 - val_loss: 1.8042 - learning_rate: 2.0250e-05
Epoch 90/300

Epoch 90: ReduceLROnPlateau reducing learning rate to 1.0124771506525576e-05.
1413/1413 - 228s - 161ms/step - accuracy: 0.4316 - loss: 2.6591 - val_accuracy: 0.6393 - val_loss: 1.6746 - learning_rate: 2.0250e-05
Epoch 91/300
1413/1413 - 224s - 159ms/step - accuracy: 0.4347 - loss: 2.6612 - val_accuracy: 0.6521 - val_loss: 1.6213 - learning_rate: 1.0125e-05
Epoch 92/300
1413/1413 - 228s - 161ms/step - accuracy: 0.4285 - loss: 2.6839 - val_accuracy: 0.6521 - val_loss: 1.6430 - learning_rate: 1.0125e-05
Epoch 93/300
1413/1413 - 235s - 167ms/step - accuracy: 0.4312 - loss: 2.6586 - val_accuracy: 0.6354 - val_loss: 1.6737 - learning_rate: 1.0125e-05
Epoch 94/300
1413/1413 - 235s - 166ms/step - accuracy: 0.4313 - loss: 2.6714 - val_accuracy: 0.6457 - val_loss: 1.7089 - learning_rate: 1.0125e-05
Epoch 95/300
1413/1413 - 237s - 167ms/step - accuracy: 0.4313 - loss: 2.6518 - val_accuracy: 0.6377 - val_loss: 1.6782 - learning_rate: 1.0125e-05
Epoch 96/300
1413/1413 - 237s - 168ms/step - accuracy: 0.4344 - loss: 2.6534 - val_accuracy: 0.6489 - val_loss: 1.6841 - learning_rate: 1.0125e-05
Epoch 97/300
1413/1413 - 234s - 166ms/step - accuracy: 0.4354 - loss: 2.6383 - val_accuracy: 0.6298 - val_loss: 1.6673 - learning_rate: 1.0125e-05
Epoch 98/300
1413/1413 - 239s - 169ms/step - accuracy: 0.4404 - loss: 2.6482 - val_accuracy: 0.6505 - val_loss: 1.6372 - learning_rate: 1.0125e-05
Epoch 99/300

Epoch 99: ReduceLROnPlateau reducing learning rate to 5.062385753262788e-06.
1413/1413 - 235s - 167ms/step - accuracy: 0.4394 - loss: 2.6340 - val_accuracy: 0.6258 - val_loss: 1.7868 - learning_rate: 1.0125e-05
Epoch 100/300
1413/1413 - 240s - 170ms/step - accuracy: 0.4381 - loss: 2.6194 - val_accuracy: 0.6433 - val_loss: 1.6329 - learning_rate: 5.0624e-06
Epoch 101/300
1413/1413 - 237s - 168ms/step - accuracy: 0.4362 - loss: 2.6409 - val_accuracy: 0.6489 - val_loss: 1.6394 - learning_rate: 5.0624e-06
Epoch 102/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4313 - loss: 2.6317 - val_accuracy: 0.6561 - val_loss: 1.6614 - learning_rate: 5.0624e-06
Epoch 103/300
1413/1413 - 228s - 162ms/step - accuracy: 0.4381 - loss: 2.6554 - val_accuracy: 0.6473 - val_loss: 1.6409 - learning_rate: 5.0624e-06
Epoch 104/300
1413/1413 - 224s - 158ms/step - accuracy: 0.4381 - loss: 2.6293 - val_accuracy: 0.6497 - val_loss: 1.6356 - learning_rate: 5.0624e-06
Epoch 105/300
1413/1413 - 276s - 196ms/step - accuracy: 0.4342 - loss: 2.6594 - val_accuracy: 0.6608 - val_loss: 1.6063 - learning_rate: 5.0624e-06
Epoch 106/300
1413/1413 - 231s - 164ms/step - accuracy: 0.4416 - loss: 2.6275 - val_accuracy: 0.6537 - val_loss: 1.6344 - learning_rate: 5.0624e-06
Epoch 107/300
1413/1413 - 240s - 170ms/step - accuracy: 0.4405 - loss: 2.5986 - val_accuracy: 0.6465 - val_loss: 1.6646 - learning_rate: 5.0624e-06
Epoch 108/300
1413/1413 - 236s - 167ms/step - accuracy: 0.4401 - loss: 2.6452 - val_accuracy: 0.6481 - val_loss: 1.6400 - learning_rate: 5.0624e-06
Epoch 109/300
1413/1413 - 236s - 167ms/step - accuracy: 0.4360 - loss: 2.6355 - val_accuracy: 0.6592 - val_loss: 1.6402 - learning_rate: 5.0624e-06
Epoch 110/300
1413/1413 - 237s - 167ms/step - accuracy: 0.4442 - loss: 2.6066 - val_accuracy: 0.6441 - val_loss: 1.6546 - learning_rate: 5.0624e-06
Epoch 111/300
1413/1413 - 239s - 169ms/step - accuracy: 0.4393 - loss: 2.6393 - val_accuracy: 0.6441 - val_loss: 1.6613 - learning_rate: 5.0624e-06
Epoch 112/300
1413/1413 - 240s - 170ms/step - accuracy: 0.4573 - loss: 2.6137 - val_accuracy: 0.6497 - val_loss: 1.6402 - learning_rate: 5.0624e-06
Epoch 113/300
1413/1413 - 240s - 170ms/step - accuracy: 0.4341 - loss: 2.6424 - val_accuracy: 0.6505 - val_loss: 1.5876 - learning_rate: 5.0624e-06
Epoch 114/300
1413/1413 - 236s - 167ms/step - accuracy: 0.4414 - loss: 2.6232 - val_accuracy: 0.6473 - val_loss: 1.6500 - learning_rate: 5.0624e-06
Epoch 115/300
1413/1413 - 235s - 166ms/step - accuracy: 0.4394 - loss: 2.6333 - val_accuracy: 0.6481 - val_loss: 1.6127 - learning_rate: 5.0624e-06
Epoch 116/300
1413/1413 - 240s - 170ms/step - accuracy: 0.4411 - loss: 2.6184 - val_accuracy: 0.6465 - val_loss: 1.6207 - learning_rate: 5.0624e-06
Epoch 117/300
1413/1413 - 234s - 166ms/step - accuracy: 0.4399 - loss: 2.6211 - val_accuracy: 0.6489 - val_loss: 1.6350 - learning_rate: 5.0624e-06
Epoch 118/300
1413/1413 - 240s - 170ms/step - accuracy: 0.4319 - loss: 2.6435 - val_accuracy: 0.6553 - val_loss: 1.6241 - learning_rate: 5.0624e-06
Epoch 119/300
1413/1413 - 235s - 167ms/step - accuracy: 0.4375 - loss: 2.6314 - val_accuracy: 0.6561 - val_loss: 1.6499 - learning_rate: 5.0624e-06
Epoch 120/300
1413/1413 - 228s - 161ms/step - accuracy: 0.4353 - loss: 2.6286 - val_accuracy: 0.6481 - val_loss: 1.5946 - learning_rate: 5.0624e-06
Epoch 121/300

Epoch 121: ReduceLROnPlateau reducing learning rate to 2.531192876631394e-06.
1413/1413 - 223s - 158ms/step - accuracy: 0.4432 - loss: 2.6198 - val_accuracy: 0.6529 - val_loss: 1.6189 - learning_rate: 5.0624e-06
Epoch 122/300
1413/1413 - 228s - 161ms/step - accuracy: 0.4447 - loss: 2.6067 - val_accuracy: 0.6537 - val_loss: 1.6153 - learning_rate: 2.5312e-06
Epoch 123/300
1413/1413 - 227s - 161ms/step - accuracy: 0.4403 - loss: 2.6191 - val_accuracy: 0.6529 - val_loss: 1.6129 - learning_rate: 2.5312e-06
Epoch 124/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4383 - loss: 2.6226 - val_accuracy: 0.6537 - val_loss: 1.6380 - learning_rate: 2.5312e-06
Epoch 125/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4369 - loss: 2.5988 - val_accuracy: 0.6521 - val_loss: 1.6170 - learning_rate: 2.5312e-06
Epoch 126/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4405 - loss: 2.6269 - val_accuracy: 0.6545 - val_loss: 1.6243 - learning_rate: 2.5312e-06
Epoch 127/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4394 - loss: 2.6183 - val_accuracy: 0.6489 - val_loss: 1.6221 - learning_rate: 2.5312e-06
Epoch 128/300
1413/1413 - 230s - 163ms/step - accuracy: 0.4382 - loss: 2.6398 - val_accuracy: 0.6561 - val_loss: 1.6283 - learning_rate: 2.5312e-06
Epoch 129/300

Epoch 129: ReduceLROnPlateau reducing learning rate to 1.265596438315697e-06.
1413/1413 - 224s - 158ms/step - accuracy: 0.4429 - loss: 2.5962 - val_accuracy: 0.6505 - val_loss: 1.6274 - learning_rate: 2.5312e-06
Epoch 129: early stopping
Restoring model weights from the end of the best epoch: 113.
Fold 4 Evaluation results: [1.595448613166809, 0.6504777073860168]
              precision    recall  f1-score   support

        1820       0.73      0.87      0.79        62
        1821       0.93      0.90      0.91        58
        1822       0.00      0.00      0.00         1
        1823       0.00      0.00      0.00         2
        1824       0.00      0.00      0.00         1
        1825       0.00      0.00      0.00         2
        1826       0.00      0.00      0.00         3
        1827       0.87      0.80      0.83        25
        1828       0.00      0.00      0.00         2
        1829       0.57      1.00      0.73         4
        1830       0.65      0.77      0.70        56
        1831       0.80      0.92      0.86       134
        1832       0.71      0.82      0.76        68
        1833       0.82      0.95      0.88        19
        1834       0.63      0.63      0.63        30
        1835       0.00      0.00      0.00         2
        1836       0.17      0.33      0.22         3
        1837       0.38      0.43      0.40         7
        1838       0.00      0.00      0.00         4
        1839       0.00      0.00      0.00         1
        1840       0.55      0.67      0.60        43
        1841       0.77      0.58      0.66       108
        1842       1.00      0.80      0.89         5
        1843       0.33      0.17      0.22         6
        1844       0.00      0.00      0.00         0
        1845       0.00      0.00      0.00         1
        1846       0.57      0.80      0.67         5
        1847       0.00      0.00      0.00         2
        1848       0.00      0.00      0.00         6
        1849       0.14      0.20      0.17         5
        1850       0.38      0.51      0.44        47
        1851       0.77      0.75      0.76        77
        1852       0.00      0.00      0.00         7
        1853       0.25      0.17      0.20         6
        1854       0.25      0.50      0.33         2
        1855       0.50      0.43      0.47        23
        1856       0.45      0.42      0.43        12
        1857       0.61      0.71      0.66        31
        1858       0.00      0.00      0.00         2
        1859       0.00      0.00      0.00         3
        1860       0.35      0.34      0.35        64
        1861       0.80      0.78      0.79        85
        1862       0.40      0.21      0.28        19
        1863       0.65      0.83      0.73        18
        1864       0.36      0.29      0.32        17
        1865       0.40      0.67      0.50         6
        1866       0.33      0.17      0.22         6
        1867       0.29      0.20      0.24        10
        1868       0.00      0.00      0.00         8
        1869       0.00      0.00      0.00         5
        1870       0.51      0.67      0.58        30
        1871       0.73      0.88      0.80        49
        1872       1.00      0.14      0.25         7
        1873       0.00      0.00      0.00        11
        1874       0.00      0.00      0.00         6
        1875       0.26      0.36      0.30        14
        1876       0.80      0.80      0.80        10
        1877       0.14      0.33      0.20         6
        1878       0.75      0.33      0.46         9
        1879       0.00      0.00      0.00         1

    accuracy                           0.65      1256
   macro avg       0.36      0.37      0.35      1256
weighted avg       0.63      0.65      0.63      1256

Matthews Correlation Coefficient: 0.633
Macro avg F1: 0.351
Weighted avg F1: 0.630
Micro avg F1: 0.650
Top-3 Accuracy: 0.851
Top-5 Accuracy: 0.906
Micro ROC AUC  = 0.99
Macro ROC AUC (present classes) = 0.98
Classification MAE (in years): 3.21

Fold 4 Misclassification Analysis:
Near misses (within 2 years): 100 out of 439 misclassifications (22.78%)
Big misses (greater than 10 years): 209
MAE with outliers: 3.21
MAE without outliers: 2.01 (improvement: 1.20)

10 Worst misclassifications:
Image: data/datasets/public/1870/1877_035met.jpg, True: 1877, Predicted: 1820, Error: 57
Image: data/datasets/public/1870/1876_382vna.jpg, True: 1876, Predicted: 1820, Error: 56
Image: data/datasets/public/1870/1870_79wikimedia2.jpg, True: 1870, Predicted: 1820, Error: 50
Image: data/datasets/public/1820/1820_029met.jpg, True: 1820, Predicted: 1870, Error: 50
Image: data/datasets/public/1820/1826_58washington.jpg, True: 1826, Predicted: 1876, Error: 50
Image: data/datasets/public/1860/1868_049met.jpg, True: 1868, Predicted: 1820, Error: 48
Image: data/datasets/public/1870/1877_004met.jpg, True: 1877, Predicted: 1830, Error: 47
Image: data/datasets/private/1860/1861_857etsy.jpg, True: 1861, Predicted: 1820, Error: 41
Image: data/datasets/public/1870/1873_1812vna.jpg, True: 1873, Predicted: 1832, Error: 41
Image: data/datasets/public/1860/1860_11wikimedia2.jpg, True: 1860, Predicted: 1820, Error: 40

===== Fold 5 =====

===== Fine Tuning 7 layers! =====
Epoch 1/300
1413/1413 - 251s - 177ms/step - accuracy: 0.1327 - loss: 4.3874 - val_accuracy: 0.1561 - val_loss: 3.9041 - learning_rate: 1.6200e-04
Epoch 2/300
1413/1413 - 223s - 158ms/step - accuracy: 0.2047 - loss: 3.9540 - val_accuracy: 0.3097 - val_loss: 3.7382 - learning_rate: 1.6200e-04
Epoch 3/300
1413/1413 - 224s - 159ms/step - accuracy: 0.2334 - loss: 3.7805 - val_accuracy: 0.3153 - val_loss: 3.2766 - learning_rate: 1.6200e-04
Epoch 4/300
1413/1413 - 224s - 159ms/step - accuracy: 0.2498 - loss: 3.6860 - val_accuracy: 0.3280 - val_loss: 3.4123 - learning_rate: 1.6200e-04
Epoch 5/300
1413/1413 - 223s - 158ms/step - accuracy: 0.2593 - loss: 3.5783 - val_accuracy: 0.3790 - val_loss: 3.1657 - learning_rate: 1.6200e-04
Epoch 6/300
1413/1413 - 227s - 160ms/step - accuracy: 0.2651 - loss: 3.5485 - val_accuracy: 0.2922 - val_loss: 3.6637 - learning_rate: 1.6200e-04
Epoch 7/300
1413/1413 - 224s - 158ms/step - accuracy: 0.2794 - loss: 3.4801 - val_accuracy: 0.2818 - val_loss: 3.9097 - learning_rate: 1.6200e-04
Epoch 8/300
1413/1413 - 222s - 157ms/step - accuracy: 0.2881 - loss: 3.4260 - val_accuracy: 0.3487 - val_loss: 3.0898 - learning_rate: 1.6200e-04
Epoch 9/300
1413/1413 - 230s - 163ms/step - accuracy: 0.2896 - loss: 3.3950 - val_accuracy: 0.4021 - val_loss: 2.9489 - learning_rate: 1.6200e-04
Epoch 10/300
1413/1413 - 225s - 159ms/step - accuracy: 0.3046 - loss: 3.3850 - val_accuracy: 0.4164 - val_loss: 2.8237 - learning_rate: 1.6200e-04
Epoch 11/300
1413/1413 - 224s - 159ms/step - accuracy: 0.3153 - loss: 3.3337 - val_accuracy: 0.4658 - val_loss: 2.7786 - learning_rate: 1.6200e-04
Epoch 12/300
1413/1413 - 226s - 160ms/step - accuracy: 0.3105 - loss: 3.3101 - val_accuracy: 0.4260 - val_loss: 2.4997 - learning_rate: 1.6200e-04
Epoch 13/300
1413/1413 - 226s - 160ms/step - accuracy: 0.3126 - loss: 3.2931 - val_accuracy: 0.3607 - val_loss: 2.8039 - learning_rate: 1.6200e-04
Epoch 14/300
1413/1413 - 226s - 160ms/step - accuracy: 0.3194 - loss: 3.2453 - val_accuracy: 0.2651 - val_loss: 3.8868 - learning_rate: 1.6200e-04
Epoch 15/300
1413/1413 - 225s - 159ms/step - accuracy: 0.3249 - loss: 3.2486 - val_accuracy: 0.4602 - val_loss: 2.8070 - learning_rate: 1.6200e-04
Epoch 16/300
1413/1413 - 227s - 161ms/step - accuracy: 0.3298 - loss: 3.2134 - val_accuracy: 0.4061 - val_loss: 3.1568 - learning_rate: 1.6200e-04
Epoch 17/300
1413/1413 - 226s - 160ms/step - accuracy: 0.3326 - loss: 3.2099 - val_accuracy: 0.4546 - val_loss: 2.5649 - learning_rate: 1.6200e-04
Epoch 18/300
1413/1413 - 225s - 159ms/step - accuracy: 0.3337 - loss: 3.1919 - val_accuracy: 0.3455 - val_loss: 3.4187 - learning_rate: 1.6200e-04
Epoch 19/300
1413/1413 - 226s - 160ms/step - accuracy: 0.3318 - loss: 3.1789 - val_accuracy: 0.4180 - val_loss: 3.0141 - learning_rate: 1.6200e-04
Epoch 20/300

Epoch 20: ReduceLROnPlateau reducing learning rate to 8.099817205220461e-05.
1413/1413 - 224s - 159ms/step - accuracy: 0.3410 - loss: 3.1605 - val_accuracy: 0.1521 - val_loss: 4.6245 - learning_rate: 1.6200e-04
Epoch 21/300
1413/1413 - 267s - 189ms/step - accuracy: 0.3544 - loss: 3.0922 - val_accuracy: 0.5430 - val_loss: 2.1838 - learning_rate: 8.0998e-05
Epoch 22/300
1413/1413 - 230s - 163ms/step - accuracy: 0.3516 - loss: 3.0862 - val_accuracy: 0.5271 - val_loss: 2.3944 - learning_rate: 8.0998e-05
Epoch 23/300
1413/1413 - 229s - 162ms/step - accuracy: 0.3536 - loss: 3.0467 - val_accuracy: 0.5350 - val_loss: 2.3875 - learning_rate: 8.0998e-05
Epoch 24/300
1413/1413 - 230s - 163ms/step - accuracy: 0.3611 - loss: 3.0488 - val_accuracy: 0.5438 - val_loss: 2.1169 - learning_rate: 8.0998e-05
Epoch 25/300
1413/1413 - 229s - 162ms/step - accuracy: 0.3621 - loss: 3.0260 - val_accuracy: 0.4952 - val_loss: 2.3164 - learning_rate: 8.0998e-05
Epoch 26/300
1413/1413 - 230s - 163ms/step - accuracy: 0.3567 - loss: 3.0584 - val_accuracy: 0.3798 - val_loss: 2.9121 - learning_rate: 8.0998e-05
Epoch 27/300
1413/1413 - 228s - 162ms/step - accuracy: 0.3644 - loss: 3.0365 - val_accuracy: 0.3965 - val_loss: 3.5429 - learning_rate: 8.0998e-05
Epoch 28/300
1413/1413 - 229s - 162ms/step - accuracy: 0.3590 - loss: 3.0493 - val_accuracy: 0.5159 - val_loss: 2.4473 - learning_rate: 8.0998e-05
Epoch 29/300
1413/1413 - 228s - 162ms/step - accuracy: 0.3705 - loss: 3.0388 - val_accuracy: 0.5701 - val_loss: 2.0720 - learning_rate: 8.0998e-05
Epoch 30/300
1413/1413 - 231s - 163ms/step - accuracy: 0.3730 - loss: 2.9906 - val_accuracy: 0.4379 - val_loss: 3.2435 - learning_rate: 8.0998e-05
Epoch 31/300
1413/1413 - 233s - 165ms/step - accuracy: 0.3688 - loss: 3.0176 - val_accuracy: 0.5127 - val_loss: 2.2337 - learning_rate: 8.0998e-05
Epoch 32/300
1413/1413 - 232s - 164ms/step - accuracy: 0.3680 - loss: 3.0098 - val_accuracy: 0.5223 - val_loss: 2.3568 - learning_rate: 8.0998e-05
Epoch 33/300
1413/1413 - 230s - 163ms/step - accuracy: 0.3718 - loss: 2.9628 - val_accuracy: 0.4889 - val_loss: 2.8251 - learning_rate: 8.0998e-05
Epoch 34/300
1413/1413 - 230s - 163ms/step - accuracy: 0.3654 - loss: 2.9937 - val_accuracy: 0.5422 - val_loss: 2.2133 - learning_rate: 8.0998e-05
Epoch 35/300
1413/1413 - 232s - 164ms/step - accuracy: 0.3773 - loss: 2.9494 - val_accuracy: 0.3830 - val_loss: 3.0231 - learning_rate: 8.0998e-05
Epoch 36/300
1413/1413 - 229s - 162ms/step - accuracy: 0.3795 - loss: 2.9470 - val_accuracy: 0.4761 - val_loss: 2.3244 - learning_rate: 8.0998e-05
Epoch 37/300
1413/1413 - 233s - 165ms/step - accuracy: 0.3766 - loss: 2.9560 - val_accuracy: 0.5884 - val_loss: 1.9681 - learning_rate: 8.0998e-05
Epoch 38/300
1413/1413 - 230s - 163ms/step - accuracy: 0.3759 - loss: 2.9414 - val_accuracy: 0.5653 - val_loss: 2.0484 - learning_rate: 8.0998e-05
Epoch 39/300
1413/1413 - 230s - 163ms/step - accuracy: 0.3764 - loss: 2.9380 - val_accuracy: 0.5573 - val_loss: 2.1269 - learning_rate: 8.0998e-05
Epoch 40/300
1413/1413 - 223s - 157ms/step - accuracy: 0.3810 - loss: 2.9364 - val_accuracy: 0.6003 - val_loss: 1.9223 - learning_rate: 8.0998e-05
Epoch 41/300
1413/1413 - 225s - 160ms/step - accuracy: 0.3780 - loss: 2.9425 - val_accuracy: 0.5605 - val_loss: 2.1973 - learning_rate: 8.0998e-05
Epoch 42/300
1413/1413 - 228s - 162ms/step - accuracy: 0.3874 - loss: 2.8921 - val_accuracy: 0.5525 - val_loss: 2.1080 - learning_rate: 8.0998e-05
Epoch 43/300
1413/1413 - 230s - 163ms/step - accuracy: 0.3840 - loss: 2.9022 - val_accuracy: 0.5454 - val_loss: 2.1548 - learning_rate: 8.0998e-05
Epoch 44/300
1413/1413 - 233s - 165ms/step - accuracy: 0.3897 - loss: 2.9118 - val_accuracy: 0.4825 - val_loss: 2.4942 - learning_rate: 8.0998e-05
Epoch 45/300
1413/1413 - 226s - 160ms/step - accuracy: 0.3804 - loss: 2.9130 - val_accuracy: 0.5207 - val_loss: 2.1332 - learning_rate: 8.0998e-05
Epoch 46/300
1413/1413 - 233s - 165ms/step - accuracy: 0.3877 - loss: 2.9319 - val_accuracy: 0.5852 - val_loss: 2.0029 - learning_rate: 8.0998e-05
Epoch 47/300
1413/1413 - 231s - 164ms/step - accuracy: 0.3826 - loss: 2.9035 - val_accuracy: 0.4753 - val_loss: 2.6465 - learning_rate: 8.0998e-05
Epoch 48/300

Epoch 48: ReduceLROnPlateau reducing learning rate to 4.0499086026102304e-05.
1413/1413 - 234s - 165ms/step - accuracy: 0.3895 - loss: 2.8994 - val_accuracy: 0.3782 - val_loss: 3.6999 - learning_rate: 8.0998e-05
Epoch 49/300
1413/1413 - 229s - 162ms/step - accuracy: 0.3952 - loss: 2.8506 - val_accuracy: 0.5040 - val_loss: 2.5619 - learning_rate: 4.0499e-05
Epoch 50/300
1413/1413 - 232s - 164ms/step - accuracy: 0.3956 - loss: 2.8165 - val_accuracy: 0.5932 - val_loss: 1.9268 - learning_rate: 4.0499e-05
Epoch 51/300
1413/1413 - 230s - 163ms/step - accuracy: 0.4023 - loss: 2.8262 - val_accuracy: 0.5573 - val_loss: 1.9448 - learning_rate: 4.0499e-05
Epoch 52/300
1413/1413 - 235s - 166ms/step - accuracy: 0.3954 - loss: 2.8211 - val_accuracy: 0.5884 - val_loss: 1.9466 - learning_rate: 4.0499e-05
Epoch 53/300
1413/1413 - 230s - 163ms/step - accuracy: 0.3993 - loss: 2.8300 - val_accuracy: 0.5653 - val_loss: 1.9820 - learning_rate: 4.0499e-05
Epoch 54/300
1413/1413 - 231s - 164ms/step - accuracy: 0.4018 - loss: 2.8220 - val_accuracy: 0.6154 - val_loss: 1.8391 - learning_rate: 4.0499e-05
Epoch 55/300
1413/1413 - 234s - 166ms/step - accuracy: 0.4040 - loss: 2.8131 - val_accuracy: 0.5788 - val_loss: 1.9888 - learning_rate: 4.0499e-05
Epoch 56/300
1413/1413 - 238s - 169ms/step - accuracy: 0.3996 - loss: 2.8352 - val_accuracy: 0.5892 - val_loss: 1.9661 - learning_rate: 4.0499e-05
Epoch 57/300
1413/1413 - 234s - 166ms/step - accuracy: 0.4090 - loss: 2.8053 - val_accuracy: 0.5955 - val_loss: 1.9176 - learning_rate: 4.0499e-05
Epoch 58/300
1413/1413 - 238s - 168ms/step - accuracy: 0.4079 - loss: 2.7961 - val_accuracy: 0.5772 - val_loss: 2.0442 - learning_rate: 4.0499e-05
Epoch 59/300
1413/1413 - 232s - 164ms/step - accuracy: 0.4007 - loss: 2.8209 - val_accuracy: 0.5764 - val_loss: 1.8894 - learning_rate: 4.0499e-05
Epoch 60/300
1413/1413 - 235s - 167ms/step - accuracy: 0.4061 - loss: 2.8201 - val_accuracy: 0.6186 - val_loss: 1.7668 - learning_rate: 4.0499e-05
Epoch 61/300
1413/1413 - 256s - 182ms/step - accuracy: 0.4080 - loss: 2.8173 - val_accuracy: 0.4817 - val_loss: 2.5785 - learning_rate: 4.0499e-05
Epoch 62/300
1413/1413 - 231s - 164ms/step - accuracy: 0.4106 - loss: 2.7968 - val_accuracy: 0.5939 - val_loss: 1.9622 - learning_rate: 4.0499e-05
Epoch 63/300
1413/1413 - 232s - 164ms/step - accuracy: 0.4061 - loss: 2.8120 - val_accuracy: 0.5709 - val_loss: 2.1021 - learning_rate: 4.0499e-05
Epoch 64/300
1413/1413 - 232s - 164ms/step - accuracy: 0.4102 - loss: 2.7920 - val_accuracy: 0.5788 - val_loss: 2.0739 - learning_rate: 4.0499e-05
Epoch 65/300
1413/1413 - 233s - 165ms/step - accuracy: 0.4105 - loss: 2.7908 - val_accuracy: 0.6043 - val_loss: 1.8853 - learning_rate: 4.0499e-05
Epoch 66/300
1413/1413 - 235s - 167ms/step - accuracy: 0.4085 - loss: 2.7691 - val_accuracy: 0.5605 - val_loss: 2.0121 - learning_rate: 4.0499e-05
Epoch 67/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4062 - loss: 2.7866 - val_accuracy: 0.6075 - val_loss: 1.7939 - learning_rate: 4.0499e-05
Epoch 68/300

Epoch 68: ReduceLROnPlateau reducing learning rate to 2.0249543013051152e-05.
1413/1413 - 235s - 167ms/step - accuracy: 0.4073 - loss: 2.7990 - val_accuracy: 0.5725 - val_loss: 2.1190 - learning_rate: 4.0499e-05
Epoch 69/300
1413/1413 - 231s - 163ms/step - accuracy: 0.4241 - loss: 2.7277 - val_accuracy: 0.6298 - val_loss: 1.7181 - learning_rate: 2.0250e-05
Epoch 70/300
1413/1413 - 231s - 164ms/step - accuracy: 0.4198 - loss: 2.7467 - val_accuracy: 0.6091 - val_loss: 1.7793 - learning_rate: 2.0250e-05
Epoch 71/300
1413/1413 - 232s - 164ms/step - accuracy: 0.4131 - loss: 2.7572 - val_accuracy: 0.6234 - val_loss: 1.7599 - learning_rate: 2.0250e-05
Epoch 72/300
1413/1413 - 232s - 164ms/step - accuracy: 0.4177 - loss: 2.7261 - val_accuracy: 0.6099 - val_loss: 1.8067 - learning_rate: 2.0250e-05
Epoch 73/300
1413/1413 - 263s - 186ms/step - accuracy: 0.4214 - loss: 2.7388 - val_accuracy: 0.6083 - val_loss: 1.7431 - learning_rate: 2.0250e-05
Epoch 74/300
1413/1413 - 230s - 163ms/step - accuracy: 0.4200 - loss: 2.7412 - val_accuracy: 0.6178 - val_loss: 1.7572 - learning_rate: 2.0250e-05
Epoch 75/300
1413/1413 - 263s - 186ms/step - accuracy: 0.4147 - loss: 2.7460 - val_accuracy: 0.6162 - val_loss: 1.7617 - learning_rate: 2.0250e-05
Epoch 76/300
1413/1413 - 233s - 165ms/step - accuracy: 0.4263 - loss: 2.7238 - val_accuracy: 0.6154 - val_loss: 1.7420 - learning_rate: 2.0250e-05
Epoch 77/300

Epoch 77: ReduceLROnPlateau reducing learning rate to 1.0124771506525576e-05.
1413/1413 - 231s - 163ms/step - accuracy: 0.4175 - loss: 2.7136 - val_accuracy: 0.6242 - val_loss: 1.7693 - learning_rate: 2.0250e-05
Epoch 78/300
1413/1413 - 234s - 166ms/step - accuracy: 0.4265 - loss: 2.7141 - val_accuracy: 0.6298 - val_loss: 1.7611 - learning_rate: 1.0125e-05
Epoch 79/300
1413/1413 - 230s - 163ms/step - accuracy: 0.4217 - loss: 2.6979 - val_accuracy: 0.6338 - val_loss: 1.7570 - learning_rate: 1.0125e-05
Epoch 80/300
1413/1413 - 235s - 167ms/step - accuracy: 0.4235 - loss: 2.7018 - val_accuracy: 0.6354 - val_loss: 1.7659 - learning_rate: 1.0125e-05
Epoch 81/300
1413/1413 - 233s - 165ms/step - accuracy: 0.4198 - loss: 2.7299 - val_accuracy: 0.6282 - val_loss: 1.7325 - learning_rate: 1.0125e-05
Epoch 82/300
1413/1413 - 231s - 164ms/step - accuracy: 0.4202 - loss: 2.7124 - val_accuracy: 0.6298 - val_loss: 1.7419 - learning_rate: 1.0125e-05
Epoch 83/300
1413/1413 - 234s - 165ms/step - accuracy: 0.4291 - loss: 2.7036 - val_accuracy: 0.6146 - val_loss: 1.7975 - learning_rate: 1.0125e-05
Epoch 84/300
1413/1413 - 231s - 163ms/step - accuracy: 0.4204 - loss: 2.7110 - val_accuracy: 0.6186 - val_loss: 1.8252 - learning_rate: 1.0125e-05
Epoch 85/300
1413/1413 - 233s - 165ms/step - accuracy: 0.4233 - loss: 2.7084 - val_accuracy: 0.6338 - val_loss: 1.7177 - learning_rate: 1.0125e-05
Epoch 86/300
1413/1413 - 228s - 161ms/step - accuracy: 0.4240 - loss: 2.6881 - val_accuracy: 0.6306 - val_loss: 1.7909 - learning_rate: 1.0125e-05
Epoch 87/300
1413/1413 - 231s - 163ms/step - accuracy: 0.4211 - loss: 2.7006 - val_accuracy: 0.6298 - val_loss: 1.7445 - learning_rate: 1.0125e-05
Epoch 88/300
1413/1413 - 232s - 164ms/step - accuracy: 0.4344 - loss: 2.6780 - val_accuracy: 0.6290 - val_loss: 1.7449 - learning_rate: 1.0125e-05
Epoch 89/300
1413/1413 - 233s - 165ms/step - accuracy: 0.4249 - loss: 2.6948 - val_accuracy: 0.6266 - val_loss: 1.7423 - learning_rate: 1.0125e-05
Epoch 90/300
1413/1413 - 228s - 162ms/step - accuracy: 0.4274 - loss: 2.6901 - val_accuracy: 0.6385 - val_loss: 1.6748 - learning_rate: 1.0125e-05
Epoch 91/300
1413/1413 - 231s - 164ms/step - accuracy: 0.4352 - loss: 2.6748 - val_accuracy: 0.6330 - val_loss: 1.7234 - learning_rate: 1.0125e-05
Epoch 92/300
1413/1413 - 234s - 166ms/step - accuracy: 0.4235 - loss: 2.6941 - val_accuracy: 0.6250 - val_loss: 1.7288 - learning_rate: 1.0125e-05
Epoch 93/300
1413/1413 - 234s - 165ms/step - accuracy: 0.4255 - loss: 2.6924 - val_accuracy: 0.6202 - val_loss: 1.7091 - learning_rate: 1.0125e-05
Epoch 94/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4272 - loss: 2.6935 - val_accuracy: 0.6131 - val_loss: 1.7512 - learning_rate: 1.0125e-05
Epoch 95/300
1413/1413 - 233s - 165ms/step - accuracy: 0.4243 - loss: 2.6863 - val_accuracy: 0.6330 - val_loss: 1.7372 - learning_rate: 1.0125e-05
Epoch 96/300
1413/1413 - 230s - 163ms/step - accuracy: 0.4297 - loss: 2.6850 - val_accuracy: 0.6298 - val_loss: 1.7586 - learning_rate: 1.0125e-05
Epoch 97/300
1413/1413 - 233s - 165ms/step - accuracy: 0.4231 - loss: 2.6867 - val_accuracy: 0.6361 - val_loss: 1.6695 - learning_rate: 1.0125e-05
Epoch 98/300
1413/1413 - 230s - 162ms/step - accuracy: 0.4261 - loss: 2.7040 - val_accuracy: 0.6401 - val_loss: 1.7017 - learning_rate: 1.0125e-05
Epoch 99/300
1413/1413 - 232s - 164ms/step - accuracy: 0.4282 - loss: 2.7235 - val_accuracy: 0.6361 - val_loss: 1.6795 - learning_rate: 1.0125e-05
Epoch 100/300
1413/1413 - 230s - 163ms/step - accuracy: 0.4249 - loss: 2.6888 - val_accuracy: 0.6178 - val_loss: 1.7436 - learning_rate: 1.0125e-05
Epoch 101/300
1413/1413 - 233s - 165ms/step - accuracy: 0.4306 - loss: 2.6796 - val_accuracy: 0.6457 - val_loss: 1.7123 - learning_rate: 1.0125e-05
Epoch 102/300
1413/1413 - 230s - 163ms/step - accuracy: 0.4340 - loss: 2.6835 - val_accuracy: 0.6417 - val_loss: 1.6981 - learning_rate: 1.0125e-05
Epoch 103/300
1413/1413 - 237s - 167ms/step - accuracy: 0.4288 - loss: 2.6802 - val_accuracy: 0.6377 - val_loss: 1.7065 - learning_rate: 1.0125e-05
Epoch 104/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4238 - loss: 2.6853 - val_accuracy: 0.6385 - val_loss: 1.6896 - learning_rate: 1.0125e-05
Epoch 105/300

Epoch 105: ReduceLROnPlateau reducing learning rate to 5.062385753262788e-06.
1413/1413 - 231s - 163ms/step - accuracy: 0.4286 - loss: 2.6692 - val_accuracy: 0.6306 - val_loss: 1.7460 - learning_rate: 1.0125e-05
Epoch 106/300
1413/1413 - 231s - 163ms/step - accuracy: 0.4348 - loss: 2.6657 - val_accuracy: 0.6425 - val_loss: 1.6527 - learning_rate: 5.0624e-06
Epoch 107/300
1413/1413 - 233s - 165ms/step - accuracy: 0.4415 - loss: 2.6538 - val_accuracy: 0.6298 - val_loss: 1.7117 - learning_rate: 5.0624e-06
Epoch 108/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4289 - loss: 2.6648 - val_accuracy: 0.6449 - val_loss: 1.6379 - learning_rate: 5.0624e-06
Epoch 109/300
1413/1413 - 234s - 166ms/step - accuracy: 0.4355 - loss: 2.6726 - val_accuracy: 0.6401 - val_loss: 1.6637 - learning_rate: 5.0624e-06
Epoch 110/300
1413/1413 - 227s - 161ms/step - accuracy: 0.4316 - loss: 2.6724 - val_accuracy: 0.6346 - val_loss: 1.6521 - learning_rate: 5.0624e-06
Epoch 111/300
1413/1413 - 233s - 165ms/step - accuracy: 0.4259 - loss: 2.6752 - val_accuracy: 0.6433 - val_loss: 1.6582 - learning_rate: 5.0624e-06
Epoch 112/300
1413/1413 - 231s - 163ms/step - accuracy: 0.4329 - loss: 2.6632 - val_accuracy: 0.6377 - val_loss: 1.6852 - learning_rate: 5.0624e-06
Epoch 113/300
1413/1413 - 232s - 164ms/step - accuracy: 0.4360 - loss: 2.6521 - val_accuracy: 0.6401 - val_loss: 1.6894 - learning_rate: 5.0624e-06
Epoch 114/300
1413/1413 - 231s - 163ms/step - accuracy: 0.4324 - loss: 2.6560 - val_accuracy: 0.6409 - val_loss: 1.6892 - learning_rate: 5.0624e-06
Epoch 115/300
1413/1413 - 238s - 168ms/step - accuracy: 0.4299 - loss: 2.6537 - val_accuracy: 0.6338 - val_loss: 1.6471 - learning_rate: 5.0624e-06
Epoch 116/300

Epoch 116: ReduceLROnPlateau reducing learning rate to 2.531192876631394e-06.
1413/1413 - 229s - 162ms/step - accuracy: 0.4346 - loss: 2.6673 - val_accuracy: 0.6393 - val_loss: 1.6763 - learning_rate: 5.0624e-06
Epoch 117/300
1413/1413 - 234s - 165ms/step - accuracy: 0.4377 - loss: 2.6514 - val_accuracy: 0.6441 - val_loss: 1.6614 - learning_rate: 2.5312e-06
Epoch 118/300
1413/1413 - 232s - 164ms/step - accuracy: 0.4386 - loss: 2.6563 - val_accuracy: 0.6417 - val_loss: 1.6723 - learning_rate: 2.5312e-06
Epoch 119/300
1413/1413 - 231s - 163ms/step - accuracy: 0.4328 - loss: 2.6664 - val_accuracy: 0.6393 - val_loss: 1.6685 - learning_rate: 2.5312e-06
Epoch 120/300
1413/1413 - 232s - 164ms/step - accuracy: 0.4332 - loss: 2.6696 - val_accuracy: 0.6441 - val_loss: 1.6760 - learning_rate: 2.5312e-06
Epoch 121/300
1413/1413 - 230s - 163ms/step - accuracy: 0.4350 - loss: 2.6618 - val_accuracy: 0.6409 - val_loss: 1.6577 - learning_rate: 2.5312e-06
Epoch 122/300
1413/1413 - 234s - 165ms/step - accuracy: 0.4443 - loss: 2.6205 - val_accuracy: 0.6465 - val_loss: 1.6510 - learning_rate: 2.5312e-06
Epoch 123/300
1413/1413 - 231s - 163ms/step - accuracy: 0.4390 - loss: 2.6444 - val_accuracy: 0.6346 - val_loss: 1.6500 - learning_rate: 2.5312e-06
Epoch 124/300

Epoch 124: ReduceLROnPlateau reducing learning rate to 1.265596438315697e-06.
1413/1413 - 229s - 162ms/step - accuracy: 0.4332 - loss: 2.6725 - val_accuracy: 0.6473 - val_loss: 1.6424 - learning_rate: 2.5312e-06
Epoch 124: early stopping
Restoring model weights from the end of the best epoch: 108.
Fold 5 Evaluation results: [1.637897253036499, 0.6449044346809387]
              precision    recall  f1-score   support

        1820       0.72      0.85      0.78        61
        1821       0.91      0.88      0.89        58
        1822       0.00      0.00      0.00         2
        1823       0.00      0.00      0.00         1
        1824       0.00      0.00      0.00         1
        1825       0.00      0.00      0.00         2
        1826       0.00      0.00      0.00         2
        1827       0.75      0.60      0.67        25
        1828       0.00      0.00      0.00         2
        1829       0.50      1.00      0.67         4
        1830       0.73      0.68      0.70        56
        1831       0.79      0.91      0.85       135
        1832       0.69      0.84      0.75        68
        1833       0.83      0.79      0.81        19
        1834       0.52      0.59      0.55        29
        1835       0.00      0.00      0.00         2
        1836       0.00      0.00      0.00         3
        1837       0.33      0.50      0.40         6
        1838       1.00      0.25      0.40         4
        1839       0.00      0.00      0.00         1
        1840       0.66      0.67      0.67        43
        1841       0.73      0.62      0.67       107
        1842       0.43      0.60      0.50         5
        1843       1.00      0.67      0.80         6
        1844       0.00      0.00      0.00         0
        1845       0.00      0.00      0.00         1
        1846       0.43      0.60      0.50         5
        1847       0.00      0.00      0.00         2
        1848       0.25      0.17      0.20         6
        1849       0.40      0.40      0.40         5
        1850       0.45      0.55      0.50        47
        1851       0.74      0.83      0.79        77
        1852       0.00      0.00      0.00         8
        1853       0.50      0.17      0.25         6
        1854       0.00      0.00      0.00         2
        1855       0.45      0.39      0.42        23
        1856       0.50      0.25      0.33        12
        1857       0.52      0.74      0.61        31
        1858       0.00      0.00      0.00         3
        1859       0.00      0.00      0.00         3
        1860       0.38      0.34      0.36        65
        1861       0.79      0.73      0.76        85
        1862       0.38      0.42      0.40        19
        1863       0.73      0.61      0.67        18
        1864       0.33      0.18      0.23        17
        1865       0.38      0.71      0.50         7
        1866       0.00      0.00      0.00         6
        1867       0.30      0.30      0.30        10
        1868       0.00      0.00      0.00         7
        1869       0.00      0.00      0.00         5
        1870       0.50      0.61      0.55        31
        1871       0.75      0.73      0.74        49
        1872       0.43      0.43      0.43         7
        1873       0.20      0.09      0.12        11
        1874       0.33      0.33      0.33         6
        1875       0.29      0.64      0.40        14
        1876       0.89      0.80      0.84        10
        1877       0.50      0.50      0.50         6
        1878       0.83      0.56      0.67         9
        1879       0.00      0.00      0.00         1

    accuracy                           0.64      1256
   macro avg       0.38      0.38      0.37      1256
weighted avg       0.63      0.64      0.63      1256

Matthews Correlation Coefficient: 0.627
Macro avg F1: 0.365
Weighted avg F1: 0.630
Micro avg F1: 0.645
Top-3 Accuracy: 0.855
Top-5 Accuracy: 0.913
Micro ROC AUC  = 0.99
Macro ROC AUC (present classes) = 0.97
Classification MAE (in years): 2.98

Fold 5 Misclassification Analysis:
Near misses (within 2 years): 118 out of 446 misclassifications (26.46%)
Big misses (greater than 10 years): 199
MAE with outliers: 2.98
MAE without outliers: 1.99 (improvement: 0.99)

10 Worst misclassifications:
Image: data/datasets/public/1820/1820_033_001met.jpg, True: 1820, Predicted: 1870, Error: 50
Image: data/datasets/public/1820/1827_2382vna.jpg, True: 1827, Predicted: 1871, Error: 44
Image: data/datasets/public/1870/1876_373vna.jpg, True: 1876, Predicted: 1832, Error: 44
Image: data/datasets/private/1860/1862_25et.jpg, True: 1862, Predicted: 1820, Error: 42
Image: data/datasets/public/1830/1830_175wikimedia2.jpg, True: 1830, Predicted: 1871, Error: 41
Image: data/datasets/private/1860/1861_562etsy.jpg, True: 1861, Predicted: 1821, Error: 40
Image: data/datasets/private/1860/1860_139et.jpg, True: 1860, Predicted: 1820, Error: 40
Image: data/datasets/public/1820/1823_2600vna.jpg, True: 1823, Predicted: 1860, Error: 37
Image: data/datasets/public/1860/1868_007met.jpg, True: 1868, Predicted: 1832, Error: 36
Image: data/datasets/private/1860/1862_60et.jpg, True: 1862, Predicted: 1827, Error: 35

===== Fold 6 =====

===== Fine Tuning 7 layers! =====
Epoch 1/300
1413/1413 - 254s - 180ms/step - accuracy: 0.1232 - loss: 4.5673 - val_accuracy: 0.2229 - val_loss: 4.5949 - learning_rate: 1.6200e-04
Epoch 2/300
1413/1413 - 233s - 165ms/step - accuracy: 0.1999 - loss: 3.9900 - val_accuracy: 0.2118 - val_loss: 4.0966 - learning_rate: 1.6200e-04
Epoch 3/300
1413/1413 - 235s - 166ms/step - accuracy: 0.2291 - loss: 3.7896 - val_accuracy: 0.2826 - val_loss: 3.4889 - learning_rate: 1.6200e-04
Epoch 4/300
1413/1413 - 232s - 164ms/step - accuracy: 0.2400 - loss: 3.6986 - val_accuracy: 0.3105 - val_loss: 3.2787 - learning_rate: 1.6200e-04
Epoch 5/300
1413/1413 - 229s - 162ms/step - accuracy: 0.2588 - loss: 3.5995 - val_accuracy: 0.3511 - val_loss: 3.0352 - learning_rate: 1.6200e-04
Epoch 6/300
1413/1413 - 235s - 166ms/step - accuracy: 0.2710 - loss: 3.5231 - val_accuracy: 0.2468 - val_loss: 4.8049 - learning_rate: 1.6200e-04
Epoch 7/300
1413/1413 - 229s - 162ms/step - accuracy: 0.2797 - loss: 3.4840 - val_accuracy: 0.3161 - val_loss: 3.6717 - learning_rate: 1.6200e-04
Epoch 8/300
1413/1413 - 235s - 166ms/step - accuracy: 0.2829 - loss: 3.4388 - val_accuracy: 0.4061 - val_loss: 2.9507 - learning_rate: 1.6200e-04
Epoch 9/300
1413/1413 - 232s - 164ms/step - accuracy: 0.2970 - loss: 3.3971 - val_accuracy: 0.4339 - val_loss: 2.6754 - learning_rate: 1.6200e-04
Epoch 10/300
1413/1413 - 232s - 164ms/step - accuracy: 0.2956 - loss: 3.3962 - val_accuracy: 0.3830 - val_loss: 3.2512 - learning_rate: 1.6200e-04
Epoch 11/300
1413/1413 - 232s - 164ms/step - accuracy: 0.3087 - loss: 3.3346 - val_accuracy: 0.4084 - val_loss: 3.2982 - learning_rate: 1.6200e-04
Epoch 12/300
1413/1413 - 234s - 166ms/step - accuracy: 0.3082 - loss: 3.3109 - val_accuracy: 0.4307 - val_loss: 2.9392 - learning_rate: 1.6200e-04
Epoch 13/300
1413/1413 - 234s - 165ms/step - accuracy: 0.3130 - loss: 3.2780 - val_accuracy: 0.4315 - val_loss: 3.0725 - learning_rate: 1.6200e-04
Epoch 14/300
1413/1413 - 230s - 163ms/step - accuracy: 0.3139 - loss: 3.2763 - val_accuracy: 0.4061 - val_loss: 3.0497 - learning_rate: 1.6200e-04
Epoch 15/300
1413/1413 - 229s - 162ms/step - accuracy: 0.3158 - loss: 3.2543 - val_accuracy: 0.4013 - val_loss: 3.3393 - learning_rate: 1.6200e-04
Epoch 16/300
1413/1413 - 234s - 166ms/step - accuracy: 0.3258 - loss: 3.2166 - val_accuracy: 0.3686 - val_loss: 3.2163 - learning_rate: 1.6200e-04
Epoch 17/300

Epoch 17: ReduceLROnPlateau reducing learning rate to 8.099817205220461e-05.
1413/1413 - 229s - 162ms/step - accuracy: 0.3240 - loss: 3.1926 - val_accuracy: 0.4148 - val_loss: 2.7900 - learning_rate: 1.6200e-04
Epoch 18/300
1413/1413 - 229s - 162ms/step - accuracy: 0.3381 - loss: 3.1415 - val_accuracy: 0.4817 - val_loss: 2.8086 - learning_rate: 8.0998e-05
Epoch 19/300
1413/1413 - 234s - 165ms/step - accuracy: 0.3431 - loss: 3.1049 - val_accuracy: 0.5502 - val_loss: 2.1744 - learning_rate: 8.0998e-05
Epoch 20/300
1413/1413 - 229s - 162ms/step - accuracy: 0.3458 - loss: 3.1008 - val_accuracy: 0.4602 - val_loss: 3.0650 - learning_rate: 8.0998e-05
Epoch 21/300
1413/1413 - 232s - 164ms/step - accuracy: 0.3509 - loss: 3.0805 - val_accuracy: 0.5414 - val_loss: 2.2148 - learning_rate: 8.0998e-05
Epoch 22/300
1413/1413 - 235s - 167ms/step - accuracy: 0.3486 - loss: 3.0843 - val_accuracy: 0.4904 - val_loss: 2.4688 - learning_rate: 8.0998e-05
Epoch 23/300
1413/1413 - 229s - 162ms/step - accuracy: 0.3551 - loss: 3.0962 - val_accuracy: 0.4817 - val_loss: 2.8768 - learning_rate: 8.0998e-05
Epoch 24/300
1413/1413 - 238s - 168ms/step - accuracy: 0.3564 - loss: 3.0636 - val_accuracy: 0.5525 - val_loss: 2.1972 - learning_rate: 8.0998e-05
Epoch 25/300
1413/1413 - 236s - 167ms/step - accuracy: 0.3589 - loss: 3.0221 - val_accuracy: 0.4610 - val_loss: 2.7837 - learning_rate: 8.0998e-05
Epoch 26/300
1413/1413 - 237s - 168ms/step - accuracy: 0.3566 - loss: 3.0406 - val_accuracy: 0.5223 - val_loss: 2.2346 - learning_rate: 8.0998e-05
Epoch 27/300
1413/1413 - 232s - 164ms/step - accuracy: 0.3576 - loss: 3.0240 - val_accuracy: 0.5772 - val_loss: 2.1448 - learning_rate: 8.0998e-05
Epoch 28/300
1413/1413 - 230s - 163ms/step - accuracy: 0.3601 - loss: 3.0159 - val_accuracy: 0.5263 - val_loss: 2.4495 - learning_rate: 8.0998e-05
Epoch 29/300
1413/1413 - 235s - 166ms/step - accuracy: 0.3606 - loss: 3.0060 - val_accuracy: 0.5167 - val_loss: 2.5420 - learning_rate: 8.0998e-05
Epoch 30/300
1413/1413 - 229s - 162ms/step - accuracy: 0.3714 - loss: 2.9915 - val_accuracy: 0.5645 - val_loss: 2.0703 - learning_rate: 8.0998e-05
Epoch 31/300
1413/1413 - 234s - 165ms/step - accuracy: 0.3628 - loss: 2.9831 - val_accuracy: 0.4323 - val_loss: 2.8675 - learning_rate: 8.0998e-05
Epoch 32/300
1413/1413 - 229s - 162ms/step - accuracy: 0.3677 - loss: 2.9714 - val_accuracy: 0.5709 - val_loss: 2.0696 - learning_rate: 8.0998e-05
Epoch 33/300
1413/1413 - 233s - 165ms/step - accuracy: 0.3708 - loss: 2.9541 - val_accuracy: 0.5510 - val_loss: 2.1726 - learning_rate: 8.0998e-05
Epoch 34/300
1413/1413 - 235s - 166ms/step - accuracy: 0.3735 - loss: 2.9704 - val_accuracy: 0.5072 - val_loss: 2.5369 - learning_rate: 8.0998e-05
Epoch 35/300
1413/1413 - 234s - 166ms/step - accuracy: 0.3745 - loss: 2.9342 - val_accuracy: 0.5637 - val_loss: 1.9950 - learning_rate: 8.0998e-05
Epoch 36/300
1413/1413 - 229s - 162ms/step - accuracy: 0.3691 - loss: 2.9746 - val_accuracy: 0.5701 - val_loss: 2.1660 - learning_rate: 8.0998e-05
Epoch 37/300
1413/1413 - 230s - 163ms/step - accuracy: 0.3723 - loss: 2.9763 - val_accuracy: 0.5008 - val_loss: 2.4853 - learning_rate: 8.0998e-05
Epoch 38/300
1413/1413 - 227s - 161ms/step - accuracy: 0.3679 - loss: 2.9688 - val_accuracy: 0.5303 - val_loss: 2.1439 - learning_rate: 8.0998e-05
Epoch 39/300
1413/1413 - 235s - 166ms/step - accuracy: 0.3743 - loss: 2.9482 - val_accuracy: 0.5231 - val_loss: 2.5309 - learning_rate: 8.0998e-05
Epoch 40/300
1413/1413 - 231s - 163ms/step - accuracy: 0.3799 - loss: 2.9332 - val_accuracy: 0.5414 - val_loss: 2.1847 - learning_rate: 8.0998e-05
Epoch 41/300
1413/1413 - 230s - 163ms/step - accuracy: 0.3805 - loss: 2.9537 - val_accuracy: 0.6011 - val_loss: 1.9798 - learning_rate: 8.0998e-05
Epoch 42/300
1413/1413 - 230s - 163ms/step - accuracy: 0.3755 - loss: 2.9417 - val_accuracy: 0.6051 - val_loss: 1.9080 - learning_rate: 8.0998e-05
Epoch 43/300
1413/1413 - 229s - 162ms/step - accuracy: 0.3826 - loss: 2.9105 - val_accuracy: 0.5064 - val_loss: 2.3922 - learning_rate: 8.0998e-05
Epoch 44/300
1413/1413 - 234s - 165ms/step - accuracy: 0.3814 - loss: 2.9144 - val_accuracy: 0.5510 - val_loss: 2.0128 - learning_rate: 8.0998e-05
Epoch 45/300
1413/1413 - 232s - 164ms/step - accuracy: 0.3841 - loss: 2.9118 - val_accuracy: 0.5645 - val_loss: 2.2171 - learning_rate: 8.0998e-05
Epoch 46/300
1413/1413 - 230s - 163ms/step - accuracy: 0.3824 - loss: 2.9161 - val_accuracy: 0.5621 - val_loss: 2.0463 - learning_rate: 8.0998e-05
Epoch 47/300
1413/1413 - 232s - 164ms/step - accuracy: 0.3819 - loss: 2.8980 - val_accuracy: 0.5852 - val_loss: 2.0875 - learning_rate: 8.0998e-05
Epoch 48/300
1413/1413 - 234s - 166ms/step - accuracy: 0.3832 - loss: 2.9099 - val_accuracy: 0.5518 - val_loss: 2.1928 - learning_rate: 8.0998e-05
Epoch 49/300
1413/1413 - 232s - 164ms/step - accuracy: 0.3951 - loss: 2.8686 - val_accuracy: 0.5446 - val_loss: 1.9872 - learning_rate: 8.0998e-05
Epoch 50/300

Epoch 50: ReduceLROnPlateau reducing learning rate to 4.0499086026102304e-05.
1413/1413 - 230s - 163ms/step - accuracy: 0.3875 - loss: 2.9021 - val_accuracy: 0.4881 - val_loss: 2.6093 - learning_rate: 8.0998e-05
Epoch 51/300
1413/1413 - 236s - 167ms/step - accuracy: 0.3988 - loss: 2.8360 - val_accuracy: 0.5637 - val_loss: 2.1067 - learning_rate: 4.0499e-05
Epoch 52/300
1413/1413 - 232s - 164ms/step - accuracy: 0.4003 - loss: 2.8163 - val_accuracy: 0.5740 - val_loss: 2.0235 - learning_rate: 4.0499e-05
Epoch 53/300
1413/1413 - 230s - 163ms/step - accuracy: 0.4041 - loss: 2.8201 - val_accuracy: 0.5852 - val_loss: 2.1334 - learning_rate: 4.0499e-05
Epoch 54/300
1413/1413 - 233s - 165ms/step - accuracy: 0.4067 - loss: 2.8129 - val_accuracy: 0.5924 - val_loss: 1.9268 - learning_rate: 4.0499e-05
Epoch 55/300
1413/1413 - 230s - 162ms/step - accuracy: 0.4070 - loss: 2.8190 - val_accuracy: 0.5971 - val_loss: 1.9317 - learning_rate: 4.0499e-05
Epoch 56/300
1413/1413 - 233s - 165ms/step - accuracy: 0.4064 - loss: 2.8066 - val_accuracy: 0.6282 - val_loss: 1.8547 - learning_rate: 4.0499e-05
Epoch 57/300
1413/1413 - 230s - 163ms/step - accuracy: 0.4032 - loss: 2.8123 - val_accuracy: 0.5955 - val_loss: 1.9703 - learning_rate: 4.0499e-05
Epoch 58/300
1413/1413 - 233s - 165ms/step - accuracy: 0.3981 - loss: 2.8151 - val_accuracy: 0.5939 - val_loss: 2.0493 - learning_rate: 4.0499e-05
Epoch 59/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4018 - loss: 2.7967 - val_accuracy: 0.5414 - val_loss: 2.0603 - learning_rate: 4.0499e-05
Epoch 60/300
1413/1413 - 233s - 165ms/step - accuracy: 0.4035 - loss: 2.7712 - val_accuracy: 0.5382 - val_loss: 2.1966 - learning_rate: 4.0499e-05
Epoch 61/300
1413/1413 - 234s - 166ms/step - accuracy: 0.4140 - loss: 2.7760 - val_accuracy: 0.5868 - val_loss: 2.0546 - learning_rate: 4.0499e-05
Epoch 62/300
1413/1413 - 233s - 165ms/step - accuracy: 0.4071 - loss: 2.7745 - val_accuracy: 0.5732 - val_loss: 2.0312 - learning_rate: 4.0499e-05
Epoch 63/300
1413/1413 - 230s - 163ms/step - accuracy: 0.4023 - loss: 2.8204 - val_accuracy: 0.5605 - val_loss: 2.0755 - learning_rate: 4.0499e-05
Epoch 64/300

Epoch 64: ReduceLROnPlateau reducing learning rate to 2.0249543013051152e-05.
1413/1413 - 229s - 162ms/step - accuracy: 0.4033 - loss: 2.8080 - val_accuracy: 0.5963 - val_loss: 2.0476 - learning_rate: 4.0499e-05
Epoch 65/300
1413/1413 - 233s - 165ms/step - accuracy: 0.4123 - loss: 2.7770 - val_accuracy: 0.6234 - val_loss: 1.7744 - learning_rate: 2.0250e-05
Epoch 66/300
1413/1413 - 235s - 166ms/step - accuracy: 0.4103 - loss: 2.7753 - val_accuracy: 0.6537 - val_loss: 1.8109 - learning_rate: 2.0250e-05
Epoch 67/300
1413/1413 - 230s - 163ms/step - accuracy: 0.4162 - loss: 2.7487 - val_accuracy: 0.6465 - val_loss: 1.7343 - learning_rate: 2.0250e-05
Epoch 68/300
1413/1413 - 234s - 165ms/step - accuracy: 0.4119 - loss: 2.7655 - val_accuracy: 0.6290 - val_loss: 1.8390 - learning_rate: 2.0250e-05
Epoch 69/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4182 - loss: 2.7546 - val_accuracy: 0.6210 - val_loss: 1.8664 - learning_rate: 2.0250e-05
Epoch 70/300
1413/1413 - 231s - 164ms/step - accuracy: 0.4157 - loss: 2.7602 - val_accuracy: 0.6521 - val_loss: 1.7138 - learning_rate: 2.0250e-05
Epoch 71/300
1413/1413 - 232s - 164ms/step - accuracy: 0.4143 - loss: 2.7560 - val_accuracy: 0.6178 - val_loss: 1.7812 - learning_rate: 2.0250e-05
Epoch 72/300
1413/1413 - 231s - 164ms/step - accuracy: 0.4193 - loss: 2.7417 - val_accuracy: 0.6465 - val_loss: 1.7865 - learning_rate: 2.0250e-05
Epoch 73/300
1413/1413 - 232s - 164ms/step - accuracy: 0.4143 - loss: 2.7477 - val_accuracy: 0.6178 - val_loss: 1.8853 - learning_rate: 2.0250e-05
Epoch 74/300
1413/1413 - 228s - 162ms/step - accuracy: 0.4107 - loss: 2.7725 - val_accuracy: 0.6178 - val_loss: 1.8029 - learning_rate: 2.0250e-05
Epoch 75/300
1413/1413 - 237s - 168ms/step - accuracy: 0.4193 - loss: 2.7452 - val_accuracy: 0.6361 - val_loss: 1.8226 - learning_rate: 2.0250e-05
Epoch 76/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4169 - loss: 2.7360 - val_accuracy: 0.6091 - val_loss: 1.9207 - learning_rate: 2.0250e-05
Epoch 77/300
1413/1413 - 228s - 161ms/step - accuracy: 0.4140 - loss: 2.7416 - val_accuracy: 0.6019 - val_loss: 1.8994 - learning_rate: 2.0250e-05
Epoch 78/300

Epoch 78: ReduceLROnPlateau reducing learning rate to 1.0124771506525576e-05.
1413/1413 - 224s - 159ms/step - accuracy: 0.4190 - loss: 2.7369 - val_accuracy: 0.6441 - val_loss: 1.7571 - learning_rate: 2.0250e-05
Epoch 79/300
1413/1413 - 230s - 163ms/step - accuracy: 0.4234 - loss: 2.7197 - val_accuracy: 0.6473 - val_loss: 1.7606 - learning_rate: 1.0125e-05
Epoch 80/300
1413/1413 - 227s - 161ms/step - accuracy: 0.4187 - loss: 2.7224 - val_accuracy: 0.6568 - val_loss: 1.6786 - learning_rate: 1.0125e-05
Epoch 81/300
1413/1413 - 242s - 171ms/step - accuracy: 0.4285 - loss: 2.6936 - val_accuracy: 0.6449 - val_loss: 1.7670 - learning_rate: 1.0125e-05
Epoch 82/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4268 - loss: 2.7201 - val_accuracy: 0.6465 - val_loss: 1.7501 - learning_rate: 1.0125e-05
Epoch 83/300
1413/1413 - 267s - 189ms/step - accuracy: 0.4262 - loss: 2.7239 - val_accuracy: 0.6505 - val_loss: 1.7557 - learning_rate: 1.0125e-05
Epoch 84/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4239 - loss: 2.6992 - val_accuracy: 0.6481 - val_loss: 1.7027 - learning_rate: 1.0125e-05
Epoch 85/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4321 - loss: 2.6692 - val_accuracy: 0.6473 - val_loss: 1.7563 - learning_rate: 1.0125e-05
Epoch 86/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4133 - loss: 2.7228 - val_accuracy: 0.6242 - val_loss: 1.7937 - learning_rate: 1.0125e-05
Epoch 87/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4153 - loss: 2.7138 - val_accuracy: 0.6377 - val_loss: 1.7588 - learning_rate: 1.0125e-05
Epoch 88/300

Epoch 88: ReduceLROnPlateau reducing learning rate to 5.062385753262788e-06.
1413/1413 - 259s - 183ms/step - accuracy: 0.4203 - loss: 2.7110 - val_accuracy: 0.6377 - val_loss: 1.7764 - learning_rate: 1.0125e-05
Epoch 89/300
1413/1413 - 231s - 164ms/step - accuracy: 0.4231 - loss: 2.7330 - val_accuracy: 0.6545 - val_loss: 1.7072 - learning_rate: 5.0624e-06
Epoch 90/300
1413/1413 - 227s - 161ms/step - accuracy: 0.4230 - loss: 2.7112 - val_accuracy: 0.6600 - val_loss: 1.7225 - learning_rate: 5.0624e-06
Epoch 91/300
1413/1413 - 234s - 165ms/step - accuracy: 0.4270 - loss: 2.6982 - val_accuracy: 0.6537 - val_loss: 1.7126 - learning_rate: 5.0624e-06
Epoch 92/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4256 - loss: 2.6841 - val_accuracy: 0.6553 - val_loss: 1.6988 - learning_rate: 5.0624e-06
Epoch 93/300
1413/1413 - 231s - 163ms/step - accuracy: 0.4302 - loss: 2.6917 - val_accuracy: 0.6640 - val_loss: 1.6817 - learning_rate: 5.0624e-06
Epoch 94/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4258 - loss: 2.6932 - val_accuracy: 0.6640 - val_loss: 1.6981 - learning_rate: 5.0624e-06
Epoch 95/300
1413/1413 - 228s - 161ms/step - accuracy: 0.4271 - loss: 2.6796 - val_accuracy: 0.6640 - val_loss: 1.6925 - learning_rate: 5.0624e-06
Epoch 96/300

Epoch 96: ReduceLROnPlateau reducing learning rate to 2.531192876631394e-06.
1413/1413 - 226s - 160ms/step - accuracy: 0.4268 - loss: 2.7147 - val_accuracy: 0.6465 - val_loss: 1.7334 - learning_rate: 5.0624e-06
Epoch 96: early stopping
Restoring model weights from the end of the best epoch: 80.
Fold 6 Evaluation results: [1.688331961631775, 0.6568471193313599]
              precision    recall  f1-score   support

        1820       0.81      0.82      0.81        61
        1821       0.91      0.91      0.91        58
        1822       0.00      0.00      0.00         2
        1823       0.00      0.00      0.00         1
        1824       0.00      0.00      0.00         1
        1825       0.00      0.00      0.00         2
        1826       0.00      0.00      0.00         2
        1827       0.83      0.76      0.79        25
        1828       0.00      0.00      0.00         2
        1829       0.27      0.75      0.40         4
        1830       0.66      0.59      0.62        56
        1831       0.82      0.90      0.86       135
        1832       0.69      0.78      0.73        68
        1833       0.86      1.00      0.93        19
        1834       0.50      0.76      0.60        29
        1835       0.00      0.00      0.00         2
        1836       0.50      0.33      0.40         3
        1837       0.30      0.50      0.38         6
        1838       0.00      0.00      0.00         4
        1839       0.00      0.00      0.00         1
        1840       0.55      0.57      0.56        42
        1841       0.74      0.68      0.71       107
        1842       0.43      0.50      0.46         6
        1843       0.29      0.33      0.31         6
        1844       0.00      0.00      0.00         0
        1845       0.00      0.00      0.00         1
        1846       0.67      0.33      0.44         6
        1847       0.00      0.00      0.00         2
        1848       0.00      0.00      0.00         5
        1849       0.20      0.20      0.20         5
        1850       0.48      0.60      0.53        48
        1851       0.81      0.73      0.77        77
        1852       0.00      0.00      0.00         8
        1853       0.00      0.00      0.00         6
        1854       0.00      0.00      0.00         2
        1855       0.46      0.52      0.49        23
        1856       0.35      0.50      0.41        12
        1857       0.67      0.58      0.62        31
        1858       0.00      0.00      0.00         3
        1859       0.00      0.00      0.00         3
        1860       0.44      0.49      0.46        65
        1861       0.89      0.85      0.87        85
        1862       0.47      0.47      0.47        19
        1863       0.53      0.56      0.54        18
        1864       0.50      0.24      0.32        17
        1865       0.50      0.29      0.36         7
        1866       0.00      0.00      0.00         6
        1867       0.21      0.30      0.25        10
        1868       0.00      0.00      0.00         7
        1869       0.00      0.00      0.00         6
        1870       0.51      0.61      0.56        31
        1871       0.78      0.82      0.80        49
        1872       0.40      0.57      0.47         7
        1873       0.14      0.09      0.11        11
        1874       1.00      0.40      0.57         5
        1875       0.50      0.64      0.56        14
        1876       0.60      0.90      0.72        10
        1877       0.60      0.60      0.60         5
        1878       0.38      0.33      0.35         9
        1879       0.00      0.00      0.00         1

    accuracy                           0.66      1256
   macro avg       0.35      0.36      0.35      1256
weighted avg       0.64      0.66      0.64      1256

Matthews Correlation Coefficient: 0.640
Macro avg F1: 0.349
Weighted avg F1: 0.644
Micro avg F1: 0.657
Top-3 Accuracy: 0.847
Top-5 Accuracy: 0.896
Micro ROC AUC  = 0.99
Macro ROC AUC (present classes) = 0.97
Classification MAE (in years): 3.19

Fold 6 Misclassification Analysis:
Near misses (within 2 years): 88 out of 431 misclassifications (20.42%)
Big misses (greater than 10 years): 192
MAE with outliers: 3.19
MAE without outliers: 2.08 (improvement: 1.11)

10 Worst misclassifications:
Image: data/datasets/public/1870/1879_9wikimedia2.jpg, True: 1879, Predicted: 1820, Error: 59
Image: data/datasets/private/1870/1871_40etsy.jpg, True: 1871, Predicted: 1821, Error: 50
Image: data/datasets/public/1820/1826_36washington.jpg, True: 1826, Predicted: 1876, Error: 50
Image: data/datasets/public/1820/1828_3021vna.jpg, True: 1828, Predicted: 1876, Error: 48
Image: data/datasets/public/1820/1828_3013vna.jpg, True: 1828, Predicted: 1876, Error: 48
Image: data/datasets/public/1820/1820_049met.jpg, True: 1820, Predicted: 1867, Error: 47
Image: data/datasets/public/1830/1830_107_001wikimedia2.jpg, True: 1830, Predicted: 1876, Error: 46
Image: data/datasets/private/1820/1825_032_Zrzut ekranu 2022-07-26 202117.png, True: 1825, Predicted: 1871, Error: 46
Image: data/datasets/public/1830/1832_2122vna.jpg, True: 1832, Predicted: 1876, Error: 44
Image: data/datasets/private/1860/1862_4et.jpg, True: 1862, Predicted: 1820, Error: 42

===== Fold 7 =====

===== Fine Tuning 7 layers! =====
Epoch 1/300
1413/1413 - 256s - 181ms/step - accuracy: 0.1336 - loss: 4.3893 - val_accuracy: 0.1608 - val_loss: 5.1261 - learning_rate: 1.6200e-04
Epoch 2/300
1413/1413 - 225s - 159ms/step - accuracy: 0.1913 - loss: 3.9408 - val_accuracy: 0.1943 - val_loss: 4.0307 - learning_rate: 1.6200e-04
Epoch 3/300
1413/1413 - 263s - 186ms/step - accuracy: 0.2196 - loss: 3.7883 - val_accuracy: 0.2699 - val_loss: 3.4437 - learning_rate: 1.6200e-04
Epoch 4/300
1413/1413 - 227s - 161ms/step - accuracy: 0.2438 - loss: 3.6851 - val_accuracy: 0.3424 - val_loss: 3.6775 - learning_rate: 1.6200e-04
Epoch 5/300
1413/1413 - 228s - 161ms/step - accuracy: 0.2504 - loss: 3.6292 - val_accuracy: 0.2890 - val_loss: 3.5744 - learning_rate: 1.6200e-04
Epoch 6/300
1413/1413 - 259s - 183ms/step - accuracy: 0.2632 - loss: 3.5685 - val_accuracy: 0.3201 - val_loss: 3.0671 - learning_rate: 1.6200e-04
Epoch 7/300
1413/1413 - 227s - 161ms/step - accuracy: 0.2791 - loss: 3.4893 - val_accuracy: 0.4037 - val_loss: 3.0617 - learning_rate: 1.6200e-04
Epoch 8/300
1413/1413 - 229s - 162ms/step - accuracy: 0.2843 - loss: 3.4569 - val_accuracy: 0.4355 - val_loss: 2.6533 - learning_rate: 1.6200e-04
Epoch 9/300
1413/1413 - 223s - 158ms/step - accuracy: 0.2867 - loss: 3.4262 - val_accuracy: 0.3583 - val_loss: 3.2845 - learning_rate: 1.6200e-04
Epoch 10/300
1413/1413 - 227s - 160ms/step - accuracy: 0.3014 - loss: 3.3939 - val_accuracy: 0.4793 - val_loss: 2.8030 - learning_rate: 1.6200e-04
Epoch 11/300
1413/1413 - 221s - 156ms/step - accuracy: 0.2995 - loss: 3.3436 - val_accuracy: 0.4387 - val_loss: 2.7023 - learning_rate: 1.6200e-04
Epoch 12/300
1413/1413 - 227s - 161ms/step - accuracy: 0.3054 - loss: 3.3165 - val_accuracy: 0.4538 - val_loss: 2.8219 - learning_rate: 1.6200e-04
Epoch 13/300
1413/1413 - 221s - 157ms/step - accuracy: 0.3115 - loss: 3.3092 - val_accuracy: 0.3177 - val_loss: 3.4130 - learning_rate: 1.6200e-04
Epoch 14/300
1413/1413 - 229s - 162ms/step - accuracy: 0.3185 - loss: 3.2720 - val_accuracy: 0.4602 - val_loss: 2.5277 - learning_rate: 1.6200e-04
Epoch 15/300
1413/1413 - 225s - 159ms/step - accuracy: 0.3211 - loss: 3.2645 - val_accuracy: 0.3631 - val_loss: 3.3141 - learning_rate: 1.6200e-04
Epoch 16/300
1413/1413 - 267s - 189ms/step - accuracy: 0.3193 - loss: 3.2492 - val_accuracy: 0.3591 - val_loss: 2.9358 - learning_rate: 1.6200e-04
Epoch 17/300
1413/1413 - 228s - 161ms/step - accuracy: 0.3258 - loss: 3.2306 - val_accuracy: 0.4817 - val_loss: 2.3789 - learning_rate: 1.6200e-04
Epoch 18/300
1413/1413 - 228s - 162ms/step - accuracy: 0.3399 - loss: 3.1650 - val_accuracy: 0.4435 - val_loss: 3.0918 - learning_rate: 1.6200e-04
Epoch 19/300
1413/1413 - 225s - 159ms/step - accuracy: 0.3315 - loss: 3.1981 - val_accuracy: 0.4936 - val_loss: 2.3748 - learning_rate: 1.6200e-04
Epoch 20/300
1413/1413 - 228s - 161ms/step - accuracy: 0.3353 - loss: 3.1607 - val_accuracy: 0.3631 - val_loss: 2.9475 - learning_rate: 1.6200e-04
Epoch 21/300
1413/1413 - 223s - 158ms/step - accuracy: 0.3356 - loss: 3.1675 - val_accuracy: 0.4427 - val_loss: 2.7406 - learning_rate: 1.6200e-04
Epoch 22/300
1413/1413 - 225s - 159ms/step - accuracy: 0.3341 - loss: 3.1270 - val_accuracy: 0.4674 - val_loss: 2.5708 - learning_rate: 1.6200e-04
Epoch 23/300
1413/1413 - 231s - 163ms/step - accuracy: 0.3467 - loss: 3.0966 - val_accuracy: 0.4793 - val_loss: 2.3817 - learning_rate: 1.6200e-04
Epoch 24/300
1413/1413 - 227s - 161ms/step - accuracy: 0.3428 - loss: 3.1060 - val_accuracy: 0.2938 - val_loss: 3.6933 - learning_rate: 1.6200e-04
Epoch 25/300
1413/1413 - 230s - 163ms/step - accuracy: 0.3432 - loss: 3.0998 - val_accuracy: 0.3217 - val_loss: 4.3281 - learning_rate: 1.6200e-04
Epoch 26/300
1413/1413 - 226s - 160ms/step - accuracy: 0.3491 - loss: 3.0658 - val_accuracy: 0.1887 - val_loss: 6.2115 - learning_rate: 1.6200e-04
Epoch 27/300

Epoch 27: ReduceLROnPlateau reducing learning rate to 8.099817205220461e-05.
1413/1413 - 225s - 159ms/step - accuracy: 0.3502 - loss: 3.0652 - val_accuracy: 0.4968 - val_loss: 2.3979 - learning_rate: 1.6200e-04
Epoch 28/300
1413/1413 - 226s - 160ms/step - accuracy: 0.3629 - loss: 2.9828 - val_accuracy: 0.5454 - val_loss: 2.1226 - learning_rate: 8.0998e-05
Epoch 29/300
1413/1413 - 226s - 160ms/step - accuracy: 0.3675 - loss: 2.9522 - val_accuracy: 0.5533 - val_loss: 2.2830 - learning_rate: 8.0998e-05
Epoch 30/300
1413/1413 - 226s - 160ms/step - accuracy: 0.3742 - loss: 2.9641 - val_accuracy: 0.5725 - val_loss: 2.1425 - learning_rate: 8.0998e-05
Epoch 31/300
1413/1413 - 231s - 163ms/step - accuracy: 0.3649 - loss: 2.9712 - val_accuracy: 0.5836 - val_loss: 1.9622 - learning_rate: 8.0998e-05
Epoch 32/300
1413/1413 - 232s - 164ms/step - accuracy: 0.3724 - loss: 2.9311 - val_accuracy: 0.5557 - val_loss: 2.2814 - learning_rate: 8.0998e-05
Epoch 33/300
1413/1413 - 259s - 183ms/step - accuracy: 0.3841 - loss: 2.9203 - val_accuracy: 0.5701 - val_loss: 2.0183 - learning_rate: 8.0998e-05
Epoch 34/300
1413/1413 - 258s - 182ms/step - accuracy: 0.3799 - loss: 2.9136 - val_accuracy: 0.4912 - val_loss: 2.6478 - learning_rate: 8.0998e-05
Epoch 35/300
1413/1413 - 229s - 162ms/step - accuracy: 0.3780 - loss: 2.9201 - val_accuracy: 0.5939 - val_loss: 1.9485 - learning_rate: 8.0998e-05
Epoch 36/300
1413/1413 - 229s - 162ms/step - accuracy: 0.3819 - loss: 2.9376 - val_accuracy: 0.6051 - val_loss: 1.9303 - learning_rate: 8.0998e-05
Epoch 37/300
1413/1413 - 228s - 161ms/step - accuracy: 0.3815 - loss: 2.9081 - val_accuracy: 0.4435 - val_loss: 2.4657 - learning_rate: 8.0998e-05
Epoch 38/300
1413/1413 - 229s - 162ms/step - accuracy: 0.3822 - loss: 2.8946 - val_accuracy: 0.5573 - val_loss: 2.0934 - learning_rate: 8.0998e-05
Epoch 39/300
1413/1413 - 231s - 164ms/step - accuracy: 0.3862 - loss: 2.8786 - val_accuracy: 0.6099 - val_loss: 1.8889 - learning_rate: 8.0998e-05
Epoch 40/300
1413/1413 - 228s - 161ms/step - accuracy: 0.3875 - loss: 2.8799 - val_accuracy: 0.5669 - val_loss: 2.0158 - learning_rate: 8.0998e-05
Epoch 41/300
1413/1413 - 226s - 160ms/step - accuracy: 0.3807 - loss: 2.9150 - val_accuracy: 0.5924 - val_loss: 1.9719 - learning_rate: 8.0998e-05
Epoch 42/300
1413/1413 - 262s - 185ms/step - accuracy: 0.3870 - loss: 2.9040 - val_accuracy: 0.5549 - val_loss: 2.0939 - learning_rate: 8.0998e-05
Epoch 43/300
1413/1413 - 234s - 166ms/step - accuracy: 0.3898 - loss: 2.8725 - val_accuracy: 0.5438 - val_loss: 2.2446 - learning_rate: 8.0998e-05
Epoch 44/300
1413/1413 - 234s - 166ms/step - accuracy: 0.3911 - loss: 2.8921 - val_accuracy: 0.5358 - val_loss: 2.3008 - learning_rate: 8.0998e-05
Epoch 45/300
1413/1413 - 224s - 159ms/step - accuracy: 0.3858 - loss: 2.8855 - val_accuracy: 0.5326 - val_loss: 2.1758 - learning_rate: 8.0998e-05
Epoch 46/300
1413/1413 - 265s - 187ms/step - accuracy: 0.3854 - loss: 2.8796 - val_accuracy: 0.6298 - val_loss: 1.7949 - learning_rate: 8.0998e-05
Epoch 47/300
1413/1413 - 231s - 164ms/step - accuracy: 0.3938 - loss: 2.8721 - val_accuracy: 0.4164 - val_loss: 2.6520 - learning_rate: 8.0998e-05
Epoch 48/300
1413/1413 - 231s - 164ms/step - accuracy: 0.3929 - loss: 2.8520 - val_accuracy: 0.4626 - val_loss: 2.9024 - learning_rate: 8.0998e-05
Epoch 49/300
1413/1413 - 226s - 160ms/step - accuracy: 0.3929 - loss: 2.8609 - val_accuracy: 0.5135 - val_loss: 2.7701 - learning_rate: 8.0998e-05
Epoch 50/300
1413/1413 - 228s - 162ms/step - accuracy: 0.3903 - loss: 2.8604 - val_accuracy: 0.6043 - val_loss: 1.8562 - learning_rate: 8.0998e-05
Epoch 51/300
1413/1413 - 224s - 159ms/step - accuracy: 0.3949 - loss: 2.8373 - val_accuracy: 0.5661 - val_loss: 2.0944 - learning_rate: 8.0998e-05
Epoch 52/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4037 - loss: 2.8248 - val_accuracy: 0.3957 - val_loss: 3.1463 - learning_rate: 8.0998e-05
Epoch 53/300
1413/1413 - 229s - 162ms/step - accuracy: 0.3952 - loss: 2.8358 - val_accuracy: 0.6051 - val_loss: 1.8858 - learning_rate: 8.0998e-05
Epoch 54/300

Epoch 54: ReduceLROnPlateau reducing learning rate to 4.0499086026102304e-05.
1413/1413 - 233s - 165ms/step - accuracy: 0.3990 - loss: 2.8228 - val_accuracy: 0.5828 - val_loss: 2.0061 - learning_rate: 8.0998e-05
Epoch 55/300
1413/1413 - 228s - 162ms/step - accuracy: 0.4096 - loss: 2.7852 - val_accuracy: 0.6123 - val_loss: 1.8293 - learning_rate: 4.0499e-05
Epoch 56/300
1413/1413 - 224s - 159ms/step - accuracy: 0.4080 - loss: 2.7628 - val_accuracy: 0.6417 - val_loss: 1.6572 - learning_rate: 4.0499e-05
Epoch 57/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4094 - loss: 2.7527 - val_accuracy: 0.6274 - val_loss: 1.9391 - learning_rate: 4.0499e-05
Epoch 58/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4140 - loss: 2.7530 - val_accuracy: 0.6051 - val_loss: 1.7483 - learning_rate: 4.0499e-05
Epoch 59/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4131 - loss: 2.7468 - val_accuracy: 0.6330 - val_loss: 1.7197 - learning_rate: 4.0499e-05
Epoch 60/300
1413/1413 - 227s - 161ms/step - accuracy: 0.4117 - loss: 2.7606 - val_accuracy: 0.6266 - val_loss: 1.7303 - learning_rate: 4.0499e-05
Epoch 61/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4083 - loss: 2.7647 - val_accuracy: 0.6465 - val_loss: 1.6714 - learning_rate: 4.0499e-05
Epoch 62/300
1413/1413 - 228s - 162ms/step - accuracy: 0.4175 - loss: 2.7384 - val_accuracy: 0.6027 - val_loss: 1.8727 - learning_rate: 4.0499e-05
Epoch 63/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4175 - loss: 2.7619 - val_accuracy: 0.5979 - val_loss: 1.8525 - learning_rate: 4.0499e-05
Epoch 64/300

Epoch 64: ReduceLROnPlateau reducing learning rate to 2.0249543013051152e-05.
1413/1413 - 228s - 161ms/step - accuracy: 0.4232 - loss: 2.7394 - val_accuracy: 0.5828 - val_loss: 1.9497 - learning_rate: 4.0499e-05
Epoch 65/300
1413/1413 - 227s - 161ms/step - accuracy: 0.4158 - loss: 2.7215 - val_accuracy: 0.6529 - val_loss: 1.6305 - learning_rate: 2.0250e-05
Epoch 66/300
1413/1413 - 263s - 186ms/step - accuracy: 0.4233 - loss: 2.6983 - val_accuracy: 0.6505 - val_loss: 1.6339 - learning_rate: 2.0250e-05
Epoch 67/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4186 - loss: 2.7140 - val_accuracy: 0.6258 - val_loss: 1.6466 - learning_rate: 2.0250e-05
Epoch 68/300
1413/1413 - 220s - 156ms/step - accuracy: 0.4179 - loss: 2.7149 - val_accuracy: 0.6417 - val_loss: 1.7355 - learning_rate: 2.0250e-05
Epoch 69/300
1413/1413 - 227s - 161ms/step - accuracy: 0.4275 - loss: 2.6762 - val_accuracy: 0.6433 - val_loss: 1.6411 - learning_rate: 2.0250e-05
Epoch 70/300
1413/1413 - 224s - 158ms/step - accuracy: 0.4264 - loss: 2.6840 - val_accuracy: 0.6529 - val_loss: 1.6034 - learning_rate: 2.0250e-05
Epoch 71/300
1413/1413 - 234s - 166ms/step - accuracy: 0.4286 - loss: 2.6729 - val_accuracy: 0.6361 - val_loss: 1.6948 - learning_rate: 2.0250e-05
Epoch 72/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4176 - loss: 2.7218 - val_accuracy: 0.6027 - val_loss: 1.8190 - learning_rate: 2.0250e-05
Epoch 73/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4221 - loss: 2.7046 - val_accuracy: 0.6274 - val_loss: 1.6459 - learning_rate: 2.0250e-05
Epoch 74/300
1413/1413 - 227s - 161ms/step - accuracy: 0.4174 - loss: 2.7061 - val_accuracy: 0.6385 - val_loss: 1.6905 - learning_rate: 2.0250e-05
Epoch 75/300
1413/1413 - 219s - 155ms/step - accuracy: 0.4270 - loss: 2.6983 - val_accuracy: 0.6417 - val_loss: 1.6484 - learning_rate: 2.0250e-05
Epoch 76/300
1413/1413 - 238s - 168ms/step - accuracy: 0.4211 - loss: 2.7174 - val_accuracy: 0.5924 - val_loss: 1.8022 - learning_rate: 2.0250e-05
Epoch 77/300
1413/1413 - 227s - 161ms/step - accuracy: 0.4263 - loss: 2.6846 - val_accuracy: 0.6481 - val_loss: 1.6194 - learning_rate: 2.0250e-05
Epoch 78/300

Epoch 78: ReduceLROnPlateau reducing learning rate to 1.0124771506525576e-05.
1413/1413 - 231s - 163ms/step - accuracy: 0.4303 - loss: 2.6953 - val_accuracy: 0.6385 - val_loss: 1.6315 - learning_rate: 2.0250e-05
Epoch 79/300
1413/1413 - 228s - 161ms/step - accuracy: 0.4274 - loss: 2.6770 - val_accuracy: 0.6648 - val_loss: 1.5935 - learning_rate: 1.0125e-05
Epoch 80/300
1413/1413 - 237s - 167ms/step - accuracy: 0.4261 - loss: 2.6807 - val_accuracy: 0.6393 - val_loss: 1.6838 - learning_rate: 1.0125e-05
Epoch 81/300
1413/1413 - 224s - 159ms/step - accuracy: 0.4310 - loss: 2.6515 - val_accuracy: 0.6393 - val_loss: 1.6373 - learning_rate: 1.0125e-05
Epoch 82/300
1413/1413 - 230s - 163ms/step - accuracy: 0.4241 - loss: 2.6744 - val_accuracy: 0.6545 - val_loss: 1.6050 - learning_rate: 1.0125e-05
Epoch 83/300
1413/1413 - 227s - 160ms/step - accuracy: 0.4326 - loss: 2.6727 - val_accuracy: 0.6473 - val_loss: 1.5988 - learning_rate: 1.0125e-05
Epoch 84/300
1413/1413 - 266s - 188ms/step - accuracy: 0.4252 - loss: 2.6820 - val_accuracy: 0.6656 - val_loss: 1.5717 - learning_rate: 1.0125e-05
Epoch 85/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4280 - loss: 2.6656 - val_accuracy: 0.6457 - val_loss: 1.6217 - learning_rate: 1.0125e-05
Epoch 86/300
1413/1413 - 236s - 167ms/step - accuracy: 0.4366 - loss: 2.6672 - val_accuracy: 0.6553 - val_loss: 1.6162 - learning_rate: 1.0125e-05
Epoch 87/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4398 - loss: 2.6488 - val_accuracy: 0.6680 - val_loss: 1.5558 - learning_rate: 1.0125e-05
Epoch 88/300
1413/1413 - 258s - 183ms/step - accuracy: 0.4311 - loss: 2.6643 - val_accuracy: 0.6481 - val_loss: 1.5623 - learning_rate: 1.0125e-05
Epoch 89/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4324 - loss: 2.6361 - val_accuracy: 0.6529 - val_loss: 1.5820 - learning_rate: 1.0125e-05
Epoch 90/300
1413/1413 - 233s - 165ms/step - accuracy: 0.4346 - loss: 2.6537 - val_accuracy: 0.6545 - val_loss: 1.6560 - learning_rate: 1.0125e-05
Epoch 91/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4332 - loss: 2.6774 - val_accuracy: 0.6576 - val_loss: 1.5378 - learning_rate: 1.0125e-05
Epoch 92/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4286 - loss: 2.6781 - val_accuracy: 0.6664 - val_loss: 1.5593 - learning_rate: 1.0125e-05
Epoch 93/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4327 - loss: 2.6712 - val_accuracy: 0.6600 - val_loss: 1.5754 - learning_rate: 1.0125e-05
Epoch 94/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4311 - loss: 2.6743 - val_accuracy: 0.6561 - val_loss: 1.5640 - learning_rate: 1.0125e-05
Epoch 95/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4363 - loss: 2.6469 - val_accuracy: 0.6688 - val_loss: 1.5625 - learning_rate: 1.0125e-05
Epoch 96/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4312 - loss: 2.6525 - val_accuracy: 0.6576 - val_loss: 1.5840 - learning_rate: 1.0125e-05
Epoch 97/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4291 - loss: 2.6577 - val_accuracy: 0.6608 - val_loss: 1.5796 - learning_rate: 1.0125e-05
Epoch 98/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4389 - loss: 2.6301 - val_accuracy: 0.6592 - val_loss: 1.5777 - learning_rate: 1.0125e-05
Epoch 99/300

Epoch 99: ReduceLROnPlateau reducing learning rate to 5.062385753262788e-06.
1413/1413 - 226s - 160ms/step - accuracy: 0.4340 - loss: 2.6600 - val_accuracy: 0.6624 - val_loss: 1.5606 - learning_rate: 1.0125e-05
Epoch 100/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4406 - loss: 2.6283 - val_accuracy: 0.6696 - val_loss: 1.5443 - learning_rate: 5.0624e-06
Epoch 101/300
1413/1413 - 234s - 165ms/step - accuracy: 0.4346 - loss: 2.6386 - val_accuracy: 0.6680 - val_loss: 1.5567 - learning_rate: 5.0624e-06
Epoch 102/300
1413/1413 - 224s - 159ms/step - accuracy: 0.4374 - loss: 2.6474 - val_accuracy: 0.6616 - val_loss: 1.5298 - learning_rate: 5.0624e-06
Epoch 103/300
1413/1413 - 224s - 159ms/step - accuracy: 0.4343 - loss: 2.6474 - val_accuracy: 0.6680 - val_loss: 1.5529 - learning_rate: 5.0624e-06
Epoch 104/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4320 - loss: 2.6323 - val_accuracy: 0.6640 - val_loss: 1.5620 - learning_rate: 5.0624e-06
Epoch 105/300
1413/1413 - 233s - 165ms/step - accuracy: 0.4371 - loss: 2.6338 - val_accuracy: 0.6576 - val_loss: 1.5691 - learning_rate: 5.0624e-06
Epoch 106/300
1413/1413 - 224s - 158ms/step - accuracy: 0.4401 - loss: 2.6441 - val_accuracy: 0.6760 - val_loss: 1.5250 - learning_rate: 5.0624e-06
Epoch 107/300
1413/1413 - 227s - 161ms/step - accuracy: 0.4349 - loss: 2.6428 - val_accuracy: 0.6656 - val_loss: 1.5650 - learning_rate: 5.0624e-06
Epoch 108/300
1413/1413 - 220s - 156ms/step - accuracy: 0.4422 - loss: 2.6373 - val_accuracy: 0.6680 - val_loss: 1.5594 - learning_rate: 5.0624e-06
Epoch 109/300
1413/1413 - 224s - 159ms/step - accuracy: 0.4380 - loss: 2.6366 - val_accuracy: 0.6712 - val_loss: 1.5418 - learning_rate: 5.0624e-06
Epoch 110/300
1413/1413 - 234s - 166ms/step - accuracy: 0.4417 - loss: 2.6231 - val_accuracy: 0.6704 - val_loss: 1.5466 - learning_rate: 5.0624e-06
Epoch 111/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4430 - loss: 2.6398 - val_accuracy: 0.6672 - val_loss: 1.5505 - learning_rate: 5.0624e-06
Epoch 112/300
1413/1413 - 230s - 163ms/step - accuracy: 0.4387 - loss: 2.6362 - val_accuracy: 0.6584 - val_loss: 1.5548 - learning_rate: 5.0624e-06
Epoch 113/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4384 - loss: 2.6340 - val_accuracy: 0.6632 - val_loss: 1.5519 - learning_rate: 5.0624e-06
Epoch 114/300

Epoch 114: ReduceLROnPlateau reducing learning rate to 2.531192876631394e-06.
1413/1413 - 226s - 160ms/step - accuracy: 0.4367 - loss: 2.6393 - val_accuracy: 0.6632 - val_loss: 1.5501 - learning_rate: 5.0624e-06
Epoch 115/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4455 - loss: 2.6171 - val_accuracy: 0.6736 - val_loss: 1.5326 - learning_rate: 2.5312e-06
Epoch 116/300
1413/1413 - 257s - 182ms/step - accuracy: 0.4317 - loss: 2.6175 - val_accuracy: 0.6680 - val_loss: 1.5383 - learning_rate: 2.5312e-06
Epoch 117/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4388 - loss: 2.6301 - val_accuracy: 0.6680 - val_loss: 1.5519 - learning_rate: 2.5312e-06
Epoch 118/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4429 - loss: 2.6046 - val_accuracy: 0.6712 - val_loss: 1.5379 - learning_rate: 2.5312e-06
Epoch 119/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4396 - loss: 2.6218 - val_accuracy: 0.6712 - val_loss: 1.5438 - learning_rate: 2.5312e-06
Epoch 120/300
1413/1413 - 220s - 156ms/step - accuracy: 0.4442 - loss: 2.6124 - val_accuracy: 0.6704 - val_loss: 1.5464 - learning_rate: 2.5312e-06
Epoch 121/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4345 - loss: 2.6453 - val_accuracy: 0.6608 - val_loss: 1.5559 - learning_rate: 2.5312e-06
Epoch 122/300

Epoch 122: ReduceLROnPlateau reducing learning rate to 1.265596438315697e-06.
1413/1413 - 226s - 160ms/step - accuracy: 0.4463 - loss: 2.5983 - val_accuracy: 0.6624 - val_loss: 1.5398 - learning_rate: 2.5312e-06
Epoch 122: early stopping
Restoring model weights from the end of the best epoch: 106.
Fold 7 Evaluation results: [1.5228911638259888, 0.6759554147720337]
              precision    recall  f1-score   support

        1820       0.75      0.87      0.80        61
        1821       0.91      0.74      0.82        58
        1822       0.00      0.00      0.00         2
        1823       0.00      0.00      0.00         1
        1824       0.00      0.00      0.00         1
        1825       0.00      0.00      0.00         2
        1826       0.00      0.00      0.00         2
        1827       0.88      0.84      0.86        25
        1828       0.00      0.00      0.00         2
        1829       0.43      0.75      0.55         4
        1830       0.68      0.64      0.66        56
        1831       0.76      0.90      0.83       135
        1832       0.68      0.94      0.79        68
        1833       0.83      1.00      0.90        19
        1834       0.67      0.55      0.60        29
        1835       0.00      0.00      0.00         2
        1836       0.27      0.75      0.40         4
        1837       0.33      0.33      0.33         6
        1838       0.00      0.00      0.00         4
        1839       0.00      0.00      0.00         1
        1840       0.59      0.55      0.57        42
        1841       0.81      0.65      0.73       107
        1842       0.67      0.67      0.67         6
        1843       1.00      0.17      0.29         6
        1844       0.00      0.00      0.00         0
        1845       0.00      0.00      0.00         1
        1846       0.67      0.67      0.67         6
        1847       0.00      0.00      0.00         2
        1848       0.25      0.20      0.22         5
        1849       0.33      0.40      0.36         5
        1850       0.55      0.67      0.60        48
        1851       0.80      0.86      0.82        77
        1852       0.00      0.00      0.00         8
        1853       0.50      0.17      0.25         6
        1854       0.33      0.50      0.40         2
        1855       0.50      0.48      0.49        23
        1856       0.50      0.67      0.57        12
        1857       0.66      0.68      0.67        31
        1858       0.00      0.00      0.00         3
        1859       0.00      0.00      0.00         2
        1860       0.44      0.40      0.42        65
        1861       0.90      0.85      0.87        85
        1862       0.39      0.47      0.43        19
        1863       0.54      0.72      0.62        18
        1864       0.50      0.41      0.45        17
        1865       0.44      0.57      0.50         7
        1866       0.00      0.00      0.00         6
        1867       0.36      0.50      0.42        10
        1868       0.00      0.00      0.00         7
        1869       0.00      0.00      0.00         6
        1870       0.44      0.65      0.53        31
        1871       0.84      0.73      0.78        49
        1872       0.62      0.71      0.67         7
        1873       0.25      0.09      0.13        11
        1874       0.29      0.40      0.33         5
        1875       0.39      0.50      0.44        14
        1876       0.91      1.00      0.95        10
        1877       0.40      0.40      0.40         5
        1878       0.75      0.33      0.46         9
        1879       0.00      0.00      0.00         1

    accuracy                           0.68      1256
   macro avg       0.40      0.41      0.39      1256
weighted avg       0.66      0.68      0.66      1256

Matthews Correlation Coefficient: 0.660
Macro avg F1: 0.387
Weighted avg F1: 0.660
Micro avg F1: 0.676
Top-3 Accuracy: 0.873
Top-5 Accuracy: 0.911
Micro ROC AUC  = 0.99
Macro ROC AUC (present classes) = 0.98
Classification MAE (in years): 2.79

Fold 7 Misclassification Analysis:
Near misses (within 2 years): 101 out of 407 misclassifications (24.82%)
Big misses (greater than 10 years): 181
MAE with outliers: 2.79
MAE without outliers: 1.85 (improvement: 0.95)

10 Worst misclassifications:
Image: data/datasets/public/1870/1879_26wikimedia2.jpg, True: 1879, Predicted: 1820, Error: 59
Image: data/datasets/public/1870/1870_19_001wikimedia2.jpg, True: 1870, Predicted: 1820, Error: 50
Image: data/datasets/private/1870/1871_393etsy.jpg, True: 1871, Predicted: 1821, Error: 50
Image: data/datasets/public/1820/1820_048met.jpg, True: 1820, Predicted: 1867, Error: 47
Image: data/datasets/public/1870/1878_491vna.jpg, True: 1878, Predicted: 1832, Error: 46
Image: data/datasets/private/1820/1826_037_Zrzut ekranu 2022-07-26 211520.png, True: 1826, Predicted: 1870, Error: 44
Image: data/datasets/private/1860/1862_2et.jpg, True: 1862, Predicted: 1820, Error: 42
Image: data/datasets/public/1820/1820_031met.jpg, True: 1820, Predicted: 1860, Error: 40
Image: data/datasets/public/1860/1860_048met.jpg, True: 1860, Predicted: 1820, Error: 40
Image: data/datasets/public/1860/1860_045met.jpg, True: 1860, Predicted: 1820, Error: 40

===== Fold 8 =====

===== Fine Tuning 7 layers! =====
Epoch 1/300
1413/1413 - 252s - 178ms/step - accuracy: 0.1273 - loss: 4.4200 - val_accuracy: 0.2134 - val_loss: 4.3323 - learning_rate: 1.6200e-04
Epoch 2/300
1413/1413 - 225s - 159ms/step - accuracy: 0.1949 - loss: 3.9280 - val_accuracy: 0.2922 - val_loss: 3.6746 - learning_rate: 1.6200e-04
Epoch 3/300
1413/1413 - 228s - 161ms/step - accuracy: 0.2283 - loss: 3.7667 - val_accuracy: 0.2882 - val_loss: 3.7365 - learning_rate: 1.6200e-04
Epoch 4/300
1413/1413 - 225s - 159ms/step - accuracy: 0.2448 - loss: 3.6606 - val_accuracy: 0.3439 - val_loss: 3.1370 - learning_rate: 1.6200e-04
Epoch 5/300
1413/1413 - 223s - 158ms/step - accuracy: 0.2540 - loss: 3.5958 - val_accuracy: 0.3185 - val_loss: 2.9680 - learning_rate: 1.6200e-04
Epoch 6/300
1413/1413 - 227s - 160ms/step - accuracy: 0.2727 - loss: 3.5126 - val_accuracy: 0.3814 - val_loss: 2.9996 - learning_rate: 1.6200e-04
Epoch 7/300
1413/1413 - 260s - 184ms/step - accuracy: 0.2755 - loss: 3.4704 - val_accuracy: 0.4451 - val_loss: 2.6659 - learning_rate: 1.6200e-04
Epoch 8/300
1413/1413 - 227s - 161ms/step - accuracy: 0.2810 - loss: 3.4476 - val_accuracy: 0.2611 - val_loss: 4.0184 - learning_rate: 1.6200e-04
Epoch 9/300
1413/1413 - 230s - 163ms/step - accuracy: 0.2905 - loss: 3.4023 - val_accuracy: 0.1409 - val_loss: 6.2114 - learning_rate: 1.6200e-04
Epoch 10/300
1413/1413 - 226s - 160ms/step - accuracy: 0.2946 - loss: 3.3842 - val_accuracy: 0.3607 - val_loss: 3.6708 - learning_rate: 1.6200e-04
Epoch 11/300
1413/1413 - 224s - 158ms/step - accuracy: 0.3050 - loss: 3.3372 - val_accuracy: 0.4538 - val_loss: 2.4562 - learning_rate: 1.6200e-04
Epoch 12/300
1413/1413 - 229s - 162ms/step - accuracy: 0.3084 - loss: 3.3313 - val_accuracy: 0.5072 - val_loss: 2.3666 - learning_rate: 1.6200e-04
Epoch 13/300
1413/1413 - 225s - 159ms/step - accuracy: 0.3139 - loss: 3.2646 - val_accuracy: 0.4283 - val_loss: 2.8006 - learning_rate: 1.6200e-04
Epoch 14/300
1413/1413 - 232s - 164ms/step - accuracy: 0.3158 - loss: 3.2744 - val_accuracy: 0.4212 - val_loss: 3.0010 - learning_rate: 1.6200e-04
Epoch 15/300
1413/1413 - 223s - 158ms/step - accuracy: 0.3209 - loss: 3.2537 - val_accuracy: 0.5159 - val_loss: 2.5372 - learning_rate: 1.6200e-04
Epoch 16/300
1413/1413 - 226s - 160ms/step - accuracy: 0.3234 - loss: 3.2304 - val_accuracy: 0.3408 - val_loss: 3.3732 - learning_rate: 1.6200e-04
Epoch 17/300
1413/1413 - 225s - 159ms/step - accuracy: 0.3223 - loss: 3.2109 - val_accuracy: 0.4753 - val_loss: 2.6290 - learning_rate: 1.6200e-04
Epoch 18/300
1413/1413 - 229s - 162ms/step - accuracy: 0.3286 - loss: 3.1964 - val_accuracy: 0.4140 - val_loss: 3.3032 - learning_rate: 1.6200e-04
Epoch 19/300
1413/1413 - 229s - 162ms/step - accuracy: 0.3326 - loss: 3.1873 - val_accuracy: 0.4427 - val_loss: 2.7589 - learning_rate: 1.6200e-04
Epoch 20/300

Epoch 20: ReduceLROnPlateau reducing learning rate to 8.099817205220461e-05.
1413/1413 - 224s - 159ms/step - accuracy: 0.3368 - loss: 3.1546 - val_accuracy: 0.3686 - val_loss: 3.2910 - learning_rate: 1.6200e-04
Epoch 21/300
1413/1413 - 228s - 161ms/step - accuracy: 0.3495 - loss: 3.0817 - val_accuracy: 0.5247 - val_loss: 2.2200 - learning_rate: 8.0998e-05
Epoch 22/300
1413/1413 - 230s - 163ms/step - accuracy: 0.3555 - loss: 3.0721 - val_accuracy: 0.5088 - val_loss: 2.3591 - learning_rate: 8.0998e-05
Epoch 23/300
1413/1413 - 226s - 160ms/step - accuracy: 0.3499 - loss: 3.0671 - val_accuracy: 0.5573 - val_loss: 2.0501 - learning_rate: 8.0998e-05
Epoch 24/300
1413/1413 - 227s - 161ms/step - accuracy: 0.3555 - loss: 3.0378 - val_accuracy: 0.4506 - val_loss: 2.6791 - learning_rate: 8.0998e-05
Epoch 25/300
1413/1413 - 224s - 159ms/step - accuracy: 0.3597 - loss: 3.0387 - val_accuracy: 0.5502 - val_loss: 2.2565 - learning_rate: 8.0998e-05
Epoch 26/300
1413/1413 - 224s - 159ms/step - accuracy: 0.3638 - loss: 3.0163 - val_accuracy: 0.5024 - val_loss: 2.4685 - learning_rate: 8.0998e-05
Epoch 27/300
1413/1413 - 225s - 159ms/step - accuracy: 0.3645 - loss: 3.0099 - val_accuracy: 0.4968 - val_loss: 2.2132 - learning_rate: 8.0998e-05
Epoch 28/300
1413/1413 - 225s - 159ms/step - accuracy: 0.3704 - loss: 2.9955 - val_accuracy: 0.5167 - val_loss: 2.3336 - learning_rate: 8.0998e-05
Epoch 29/300
1413/1413 - 230s - 163ms/step - accuracy: 0.3612 - loss: 3.0128 - val_accuracy: 0.5374 - val_loss: 2.1511 - learning_rate: 8.0998e-05
Epoch 30/300
1413/1413 - 224s - 159ms/step - accuracy: 0.3688 - loss: 2.9903 - val_accuracy: 0.5016 - val_loss: 2.2095 - learning_rate: 8.0998e-05
Epoch 31/300
1413/1413 - 229s - 162ms/step - accuracy: 0.3642 - loss: 2.9875 - val_accuracy: 0.5605 - val_loss: 1.9880 - learning_rate: 8.0998e-05
Epoch 32/300
1413/1413 - 224s - 158ms/step - accuracy: 0.3694 - loss: 3.0013 - val_accuracy: 0.5446 - val_loss: 2.0052 - learning_rate: 8.0998e-05
Epoch 33/300
1413/1413 - 228s - 161ms/step - accuracy: 0.3729 - loss: 2.9864 - val_accuracy: 0.4785 - val_loss: 2.4084 - learning_rate: 8.0998e-05
Epoch 34/300
1413/1413 - 225s - 159ms/step - accuracy: 0.3688 - loss: 2.9827 - val_accuracy: 0.5358 - val_loss: 2.3528 - learning_rate: 8.0998e-05
Epoch 35/300
1413/1413 - 224s - 158ms/step - accuracy: 0.3772 - loss: 2.9614 - val_accuracy: 0.5486 - val_loss: 2.1132 - learning_rate: 8.0998e-05
Epoch 36/300
1413/1413 - 265s - 187ms/step - accuracy: 0.3748 - loss: 2.9687 - val_accuracy: 0.5104 - val_loss: 2.0616 - learning_rate: 8.0998e-05
Epoch 37/300
1413/1413 - 225s - 159ms/step - accuracy: 0.3742 - loss: 2.9766 - val_accuracy: 0.5518 - val_loss: 2.1312 - learning_rate: 8.0998e-05
Epoch 38/300
1413/1413 - 231s - 163ms/step - accuracy: 0.3755 - loss: 2.9355 - val_accuracy: 0.5510 - val_loss: 1.9355 - learning_rate: 8.0998e-05
Epoch 39/300
1413/1413 - 226s - 160ms/step - accuracy: 0.3732 - loss: 2.9445 - val_accuracy: 0.5390 - val_loss: 2.1984 - learning_rate: 8.0998e-05
Epoch 40/300
1413/1413 - 229s - 162ms/step - accuracy: 0.3851 - loss: 2.9427 - val_accuracy: 0.5438 - val_loss: 2.0169 - learning_rate: 8.0998e-05
Epoch 41/300
1413/1413 - 225s - 159ms/step - accuracy: 0.3841 - loss: 2.9165 - val_accuracy: 0.5382 - val_loss: 2.1751 - learning_rate: 8.0998e-05
Epoch 42/300
1413/1413 - 227s - 161ms/step - accuracy: 0.3857 - loss: 2.9199 - val_accuracy: 0.6083 - val_loss: 1.8257 - learning_rate: 8.0998e-05
Epoch 43/300
1413/1413 - 226s - 160ms/step - accuracy: 0.3892 - loss: 2.9103 - val_accuracy: 0.5725 - val_loss: 2.0473 - learning_rate: 8.0998e-05
Epoch 44/300
1413/1413 - 228s - 161ms/step - accuracy: 0.3856 - loss: 2.9103 - val_accuracy: 0.5892 - val_loss: 1.8832 - learning_rate: 8.0998e-05
Epoch 45/300
1413/1413 - 226s - 160ms/step - accuracy: 0.3802 - loss: 2.9050 - val_accuracy: 0.5693 - val_loss: 2.0407 - learning_rate: 8.0998e-05
Epoch 46/300
1413/1413 - 229s - 162ms/step - accuracy: 0.3848 - loss: 2.8980 - val_accuracy: 0.5828 - val_loss: 1.9752 - learning_rate: 8.0998e-05
Epoch 47/300
1413/1413 - 223s - 158ms/step - accuracy: 0.3980 - loss: 2.8699 - val_accuracy: 0.6059 - val_loss: 1.8212 - learning_rate: 8.0998e-05
Epoch 48/300
1413/1413 - 225s - 159ms/step - accuracy: 0.3814 - loss: 2.9021 - val_accuracy: 0.5518 - val_loss: 1.9782 - learning_rate: 8.0998e-05
Epoch 49/300
1413/1413 - 227s - 161ms/step - accuracy: 0.3884 - loss: 2.8876 - val_accuracy: 0.5406 - val_loss: 2.0779 - learning_rate: 8.0998e-05
Epoch 50/300
1413/1413 - 223s - 158ms/step - accuracy: 0.3909 - loss: 2.8796 - val_accuracy: 0.5215 - val_loss: 2.2415 - learning_rate: 8.0998e-05
Epoch 51/300
1413/1413 - 229s - 162ms/step - accuracy: 0.3942 - loss: 2.8496 - val_accuracy: 0.5215 - val_loss: 2.5821 - learning_rate: 8.0998e-05
Epoch 52/300
1413/1413 - 224s - 158ms/step - accuracy: 0.3890 - loss: 2.8577 - val_accuracy: 0.6091 - val_loss: 1.9466 - learning_rate: 8.0998e-05
Epoch 53/300
1413/1413 - 227s - 160ms/step - accuracy: 0.3890 - loss: 2.8691 - val_accuracy: 0.6178 - val_loss: 1.8078 - learning_rate: 8.0998e-05
Epoch 54/300
1413/1413 - 224s - 158ms/step - accuracy: 0.3884 - loss: 2.8566 - val_accuracy: 0.5788 - val_loss: 2.0982 - learning_rate: 8.0998e-05
Epoch 55/300
1413/1413 - 228s - 161ms/step - accuracy: 0.3901 - loss: 2.8671 - val_accuracy: 0.6027 - val_loss: 1.8892 - learning_rate: 8.0998e-05
Epoch 56/300
1413/1413 - 224s - 158ms/step - accuracy: 0.3941 - loss: 2.8556 - val_accuracy: 0.5939 - val_loss: 1.9590 - learning_rate: 8.0998e-05
Epoch 57/300
1413/1413 - 228s - 161ms/step - accuracy: 0.3945 - loss: 2.8464 - val_accuracy: 0.5756 - val_loss: 1.8677 - learning_rate: 8.0998e-05
Epoch 58/300
1413/1413 - 223s - 157ms/step - accuracy: 0.3992 - loss: 2.8343 - val_accuracy: 0.5995 - val_loss: 1.8014 - learning_rate: 8.0998e-05
Epoch 59/300
1413/1413 - 229s - 162ms/step - accuracy: 0.3991 - loss: 2.8372 - val_accuracy: 0.4538 - val_loss: 2.5635 - learning_rate: 8.0998e-05
Epoch 60/300
1413/1413 - 226s - 160ms/step - accuracy: 0.3903 - loss: 2.8501 - val_accuracy: 0.5995 - val_loss: 1.8589 - learning_rate: 8.0998e-05
Epoch 61/300
1413/1413 - 222s - 157ms/step - accuracy: 0.3966 - loss: 2.8574 - val_accuracy: 0.6385 - val_loss: 1.7683 - learning_rate: 8.0998e-05
Epoch 62/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4039 - loss: 2.8052 - val_accuracy: 0.5167 - val_loss: 2.6360 - learning_rate: 8.0998e-05
Epoch 63/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4072 - loss: 2.8052 - val_accuracy: 0.6210 - val_loss: 1.8949 - learning_rate: 8.0998e-05
Epoch 64/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4067 - loss: 2.8234 - val_accuracy: 0.6003 - val_loss: 1.9869 - learning_rate: 8.0998e-05
Epoch 65/300
1413/1413 - 223s - 158ms/step - accuracy: 0.3996 - loss: 2.8159 - val_accuracy: 0.6234 - val_loss: 1.6989 - learning_rate: 8.0998e-05
Epoch 66/300
1413/1413 - 228s - 162ms/step - accuracy: 0.4014 - loss: 2.8272 - val_accuracy: 0.5748 - val_loss: 1.9528 - learning_rate: 8.0998e-05
Epoch 67/300
1413/1413 - 224s - 158ms/step - accuracy: 0.3975 - loss: 2.8176 - val_accuracy: 0.5701 - val_loss: 2.1364 - learning_rate: 8.0998e-05
Epoch 68/300
1413/1413 - 227s - 160ms/step - accuracy: 0.4017 - loss: 2.8372 - val_accuracy: 0.5796 - val_loss: 1.9627 - learning_rate: 8.0998e-05
Epoch 69/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4010 - loss: 2.8152 - val_accuracy: 0.5971 - val_loss: 1.8084 - learning_rate: 8.0998e-05
Epoch 70/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4073 - loss: 2.7772 - val_accuracy: 0.6035 - val_loss: 1.7787 - learning_rate: 8.0998e-05
Epoch 71/300
1413/1413 - 227s - 161ms/step - accuracy: 0.4020 - loss: 2.8074 - val_accuracy: 0.5740 - val_loss: 2.0906 - learning_rate: 8.0998e-05
Epoch 72/300
1413/1413 - 225s - 160ms/step - accuracy: 0.4038 - loss: 2.7992 - val_accuracy: 0.6067 - val_loss: 1.8447 - learning_rate: 8.0998e-05
Epoch 73/300

Epoch 73: ReduceLROnPlateau reducing learning rate to 4.0499086026102304e-05.
1413/1413 - 226s - 160ms/step - accuracy: 0.3993 - loss: 2.8170 - val_accuracy: 0.5311 - val_loss: 2.2035 - learning_rate: 8.0998e-05
Epoch 74/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4118 - loss: 2.7463 - val_accuracy: 0.6616 - val_loss: 1.6770 - learning_rate: 4.0499e-05
Epoch 75/300
1413/1413 - 224s - 158ms/step - accuracy: 0.4156 - loss: 2.7411 - val_accuracy: 0.6186 - val_loss: 1.6968 - learning_rate: 4.0499e-05
Epoch 76/300
1413/1413 - 227s - 161ms/step - accuracy: 0.4199 - loss: 2.7485 - val_accuracy: 0.6346 - val_loss: 1.7269 - learning_rate: 4.0499e-05
Epoch 77/300
1413/1413 - 232s - 165ms/step - accuracy: 0.4214 - loss: 2.7203 - val_accuracy: 0.5780 - val_loss: 1.8734 - learning_rate: 4.0499e-05
Epoch 78/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4303 - loss: 2.7086 - val_accuracy: 0.6417 - val_loss: 1.6683 - learning_rate: 4.0499e-05
Epoch 79/300
1413/1413 - 225s - 160ms/step - accuracy: 0.4153 - loss: 2.7362 - val_accuracy: 0.6314 - val_loss: 1.6567 - learning_rate: 4.0499e-05
Epoch 80/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4222 - loss: 2.7047 - val_accuracy: 0.6393 - val_loss: 1.6647 - learning_rate: 4.0499e-05
Epoch 81/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4259 - loss: 2.7069 - val_accuracy: 0.6385 - val_loss: 1.6598 - learning_rate: 4.0499e-05
Epoch 82/300
1413/1413 - 228s - 161ms/step - accuracy: 0.4216 - loss: 2.6940 - val_accuracy: 0.6369 - val_loss: 1.8291 - learning_rate: 4.0499e-05
Epoch 83/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4271 - loss: 2.6912 - val_accuracy: 0.6346 - val_loss: 1.7527 - learning_rate: 4.0499e-05
Epoch 84/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4278 - loss: 2.6877 - val_accuracy: 0.5422 - val_loss: 2.2419 - learning_rate: 4.0499e-05
Epoch 85/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4220 - loss: 2.7142 - val_accuracy: 0.5525 - val_loss: 2.1724 - learning_rate: 4.0499e-05
Epoch 86/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4188 - loss: 2.7160 - val_accuracy: 0.6521 - val_loss: 1.5866 - learning_rate: 4.0499e-05
Epoch 87/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4240 - loss: 2.7027 - val_accuracy: 0.6600 - val_loss: 1.6529 - learning_rate: 4.0499e-05
Epoch 88/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4233 - loss: 2.6965 - val_accuracy: 0.5581 - val_loss: 1.9622 - learning_rate: 4.0499e-05
Epoch 89/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4325 - loss: 2.6680 - val_accuracy: 0.6377 - val_loss: 1.6451 - learning_rate: 4.0499e-05
Epoch 90/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4274 - loss: 2.6896 - val_accuracy: 0.6115 - val_loss: 1.8017 - learning_rate: 4.0499e-05
Epoch 91/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4277 - loss: 2.6905 - val_accuracy: 0.6369 - val_loss: 1.6668 - learning_rate: 4.0499e-05
Epoch 92/300
1413/1413 - 235s - 166ms/step - accuracy: 0.4283 - loss: 2.6718 - val_accuracy: 0.6361 - val_loss: 1.7235 - learning_rate: 4.0499e-05
Epoch 93/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4337 - loss: 2.6640 - val_accuracy: 0.5693 - val_loss: 2.0246 - learning_rate: 4.0499e-05
Epoch 94/300

Epoch 94: ReduceLROnPlateau reducing learning rate to 2.0249543013051152e-05.
1413/1413 - 225s - 159ms/step - accuracy: 0.4283 - loss: 2.6958 - val_accuracy: 0.6489 - val_loss: 1.6965 - learning_rate: 4.0499e-05
Epoch 95/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4345 - loss: 2.6378 - val_accuracy: 0.6369 - val_loss: 1.6707 - learning_rate: 2.0250e-05
Epoch 96/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4299 - loss: 2.6669 - val_accuracy: 0.6377 - val_loss: 1.6284 - learning_rate: 2.0250e-05
Epoch 97/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4396 - loss: 2.6518 - val_accuracy: 0.6553 - val_loss: 1.5950 - learning_rate: 2.0250e-05
Epoch 98/300
1413/1413 - 213s - 151ms/step - accuracy: 0.4331 - loss: 2.6477 - val_accuracy: 0.6712 - val_loss: 1.5631 - learning_rate: 2.0250e-05
Epoch 99/300
1413/1413 - 212s - 150ms/step - accuracy: 0.4304 - loss: 2.6698 - val_accuracy: 0.5947 - val_loss: 1.9221 - learning_rate: 2.0250e-05
Epoch 100/300
1413/1413 - 215s - 152ms/step - accuracy: 0.4319 - loss: 2.6433 - val_accuracy: 0.6489 - val_loss: 1.6180 - learning_rate: 2.0250e-05
Epoch 101/300
1413/1413 - 219s - 155ms/step - accuracy: 0.4367 - loss: 2.6515 - val_accuracy: 0.6648 - val_loss: 1.5855 - learning_rate: 2.0250e-05
Epoch 102/300
1413/1413 - 212s - 150ms/step - accuracy: 0.4377 - loss: 2.6367 - val_accuracy: 0.6632 - val_loss: 1.6416 - learning_rate: 2.0250e-05
Epoch 103/300
1413/1413 - 218s - 154ms/step - accuracy: 0.4381 - loss: 2.6126 - val_accuracy: 0.6592 - val_loss: 1.6442 - learning_rate: 2.0250e-05
Epoch 104/300
1413/1413 - 215s - 152ms/step - accuracy: 0.4340 - loss: 2.6281 - val_accuracy: 0.6760 - val_loss: 1.4894 - learning_rate: 2.0250e-05
Epoch 105/300
1413/1413 - 263s - 186ms/step - accuracy: 0.4441 - loss: 2.6393 - val_accuracy: 0.6696 - val_loss: 1.5274 - learning_rate: 2.0250e-05
Epoch 106/300
1413/1413 - 216s - 153ms/step - accuracy: 0.4353 - loss: 2.6479 - val_accuracy: 0.6600 - val_loss: 1.5617 - learning_rate: 2.0250e-05
Epoch 107/300
1413/1413 - 215s - 152ms/step - accuracy: 0.4355 - loss: 2.6307 - val_accuracy: 0.6656 - val_loss: 1.5399 - learning_rate: 2.0250e-05
Epoch 108/300
1413/1413 - 217s - 154ms/step - accuracy: 0.4339 - loss: 2.6379 - val_accuracy: 0.6393 - val_loss: 1.6422 - learning_rate: 2.0250e-05
Epoch 109/300
1413/1413 - 216s - 153ms/step - accuracy: 0.4354 - loss: 2.6354 - val_accuracy: 0.6823 - val_loss: 1.4691 - learning_rate: 2.0250e-05
Epoch 110/300
1413/1413 - 219s - 155ms/step - accuracy: 0.4440 - loss: 2.6183 - val_accuracy: 0.6553 - val_loss: 1.5818 - learning_rate: 2.0250e-05
Epoch 111/300
1413/1413 - 216s - 153ms/step - accuracy: 0.4356 - loss: 2.6410 - val_accuracy: 0.6648 - val_loss: 1.5535 - learning_rate: 2.0250e-05
Epoch 112/300
1413/1413 - 216s - 153ms/step - accuracy: 0.4344 - loss: 2.6249 - val_accuracy: 0.6911 - val_loss: 1.5443 - learning_rate: 2.0250e-05
Epoch 113/300
1413/1413 - 215s - 152ms/step - accuracy: 0.4330 - loss: 2.6418 - val_accuracy: 0.6529 - val_loss: 1.5559 - learning_rate: 2.0250e-05
Epoch 114/300
1413/1413 - 216s - 153ms/step - accuracy: 0.4469 - loss: 2.6122 - val_accuracy: 0.6529 - val_loss: 1.6812 - learning_rate: 2.0250e-05
Epoch 115/300
1413/1413 - 262s - 185ms/step - accuracy: 0.4386 - loss: 2.6393 - val_accuracy: 0.6529 - val_loss: 1.6239 - learning_rate: 2.0250e-05
Epoch 116/300
1413/1413 - 217s - 154ms/step - accuracy: 0.4401 - loss: 2.6117 - val_accuracy: 0.6704 - val_loss: 1.5110 - learning_rate: 2.0250e-05
Epoch 117/300

Epoch 117: ReduceLROnPlateau reducing learning rate to 1.0124771506525576e-05.
1413/1413 - 215s - 152ms/step - accuracy: 0.4388 - loss: 2.6296 - val_accuracy: 0.6728 - val_loss: 1.5954 - learning_rate: 2.0250e-05
Epoch 118/300
1413/1413 - 216s - 153ms/step - accuracy: 0.4463 - loss: 2.5956 - val_accuracy: 0.6712 - val_loss: 1.5188 - learning_rate: 1.0125e-05
Epoch 119/300
1413/1413 - 215s - 152ms/step - accuracy: 0.4497 - loss: 2.5627 - val_accuracy: 0.6935 - val_loss: 1.4819 - learning_rate: 1.0125e-05
Epoch 120/300
1413/1413 - 216s - 153ms/step - accuracy: 0.4473 - loss: 2.5892 - val_accuracy: 0.6807 - val_loss: 1.5056 - learning_rate: 1.0125e-05
Epoch 121/300
1413/1413 - 217s - 154ms/step - accuracy: 0.4440 - loss: 2.6090 - val_accuracy: 0.6871 - val_loss: 1.4804 - learning_rate: 1.0125e-05
Epoch 122/300
1413/1413 - 216s - 153ms/step - accuracy: 0.4509 - loss: 2.5855 - val_accuracy: 0.6815 - val_loss: 1.4995 - learning_rate: 1.0125e-05
Epoch 123/300
1413/1413 - 216s - 153ms/step - accuracy: 0.4523 - loss: 2.5604 - val_accuracy: 0.6903 - val_loss: 1.4565 - learning_rate: 1.0125e-05
Epoch 124/300
1413/1413 - 221s - 156ms/step - accuracy: 0.4486 - loss: 2.5707 - val_accuracy: 0.6696 - val_loss: 1.5584 - learning_rate: 1.0125e-05
Epoch 125/300
1413/1413 - 213s - 151ms/step - accuracy: 0.4495 - loss: 2.5762 - val_accuracy: 0.6927 - val_loss: 1.4670 - learning_rate: 1.0125e-05
Epoch 126/300
1413/1413 - 216s - 153ms/step - accuracy: 0.4493 - loss: 2.5950 - val_accuracy: 0.6847 - val_loss: 1.5048 - learning_rate: 1.0125e-05
Epoch 127/300
1413/1413 - 218s - 154ms/step - accuracy: 0.4513 - loss: 2.5886 - val_accuracy: 0.6919 - val_loss: 1.4686 - learning_rate: 1.0125e-05
Epoch 128/300
1413/1413 - 215s - 152ms/step - accuracy: 0.4483 - loss: 2.5789 - val_accuracy: 0.6648 - val_loss: 1.5220 - learning_rate: 1.0125e-05
Epoch 129/300
1413/1413 - 216s - 153ms/step - accuracy: 0.4502 - loss: 2.5817 - val_accuracy: 0.6704 - val_loss: 1.5211 - learning_rate: 1.0125e-05
Epoch 130/300
1413/1413 - 219s - 155ms/step - accuracy: 0.4500 - loss: 2.5758 - val_accuracy: 0.6847 - val_loss: 1.5137 - learning_rate: 1.0125e-05
Epoch 131/300

Epoch 131: ReduceLROnPlateau reducing learning rate to 5.062385753262788e-06.
1413/1413 - 217s - 153ms/step - accuracy: 0.4460 - loss: 2.5857 - val_accuracy: 0.6847 - val_loss: 1.4678 - learning_rate: 1.0125e-05
Epoch 132/300
1413/1413 - 218s - 154ms/step - accuracy: 0.4413 - loss: 2.5790 - val_accuracy: 0.6863 - val_loss: 1.4833 - learning_rate: 5.0624e-06
Epoch 133/300
1413/1413 - 216s - 153ms/step - accuracy: 0.4470 - loss: 2.5753 - val_accuracy: 0.6927 - val_loss: 1.4577 - learning_rate: 5.0624e-06
Epoch 134/300
1413/1413 - 262s - 186ms/step - accuracy: 0.4487 - loss: 2.5832 - val_accuracy: 0.6935 - val_loss: 1.4575 - learning_rate: 5.0624e-06
Epoch 135/300
1413/1413 - 219s - 155ms/step - accuracy: 0.4478 - loss: 2.5918 - val_accuracy: 0.6895 - val_loss: 1.4656 - learning_rate: 5.0624e-06
Epoch 136/300
1413/1413 - 216s - 153ms/step - accuracy: 0.4534 - loss: 2.5677 - val_accuracy: 0.6863 - val_loss: 1.4463 - learning_rate: 5.0624e-06
Epoch 137/300
1413/1413 - 213s - 151ms/step - accuracy: 0.4516 - loss: 2.5771 - val_accuracy: 0.6919 - val_loss: 1.4494 - learning_rate: 5.0624e-06
Epoch 138/300
1413/1413 - 217s - 154ms/step - accuracy: 0.4488 - loss: 2.5727 - val_accuracy: 0.6919 - val_loss: 1.4555 - learning_rate: 5.0624e-06
Epoch 139/300
1413/1413 - 215s - 152ms/step - accuracy: 0.4526 - loss: 2.5778 - val_accuracy: 0.6807 - val_loss: 1.4918 - learning_rate: 5.0624e-06
Epoch 140/300
1413/1413 - 219s - 155ms/step - accuracy: 0.4582 - loss: 2.5433 - val_accuracy: 0.6975 - val_loss: 1.4643 - learning_rate: 5.0624e-06
Epoch 141/300
1413/1413 - 219s - 155ms/step - accuracy: 0.4469 - loss: 2.5851 - val_accuracy: 0.6887 - val_loss: 1.4759 - learning_rate: 5.0624e-06
Epoch 142/300
1413/1413 - 216s - 153ms/step - accuracy: 0.4553 - loss: 2.5519 - val_accuracy: 0.6831 - val_loss: 1.4796 - learning_rate: 5.0624e-06
Epoch 143/300
1413/1413 - 218s - 154ms/step - accuracy: 0.4544 - loss: 2.5776 - val_accuracy: 0.6903 - val_loss: 1.4585 - learning_rate: 5.0624e-06
Epoch 144/300

Epoch 144: ReduceLROnPlateau reducing learning rate to 2.531192876631394e-06.
1413/1413 - 217s - 153ms/step - accuracy: 0.4591 - loss: 2.5545 - val_accuracy: 0.6879 - val_loss: 1.4931 - learning_rate: 5.0624e-06
Epoch 145/300
1413/1413 - 220s - 155ms/step - accuracy: 0.4540 - loss: 2.5659 - val_accuracy: 0.6863 - val_loss: 1.4529 - learning_rate: 2.5312e-06
Epoch 146/300
1413/1413 - 215s - 152ms/step - accuracy: 0.4486 - loss: 2.5827 - val_accuracy: 0.6919 - val_loss: 1.4707 - learning_rate: 2.5312e-06
Epoch 147/300
1413/1413 - 215s - 152ms/step - accuracy: 0.4487 - loss: 2.5892 - val_accuracy: 0.6855 - val_loss: 1.4652 - learning_rate: 2.5312e-06
Epoch 148/300
1413/1413 - 266s - 188ms/step - accuracy: 0.4528 - loss: 2.5600 - val_accuracy: 0.6919 - val_loss: 1.4422 - learning_rate: 2.5312e-06
Epoch 149/300
1413/1413 - 212s - 150ms/step - accuracy: 0.4481 - loss: 2.5870 - val_accuracy: 0.6935 - val_loss: 1.4480 - learning_rate: 2.5312e-06
Epoch 150/300
1413/1413 - 215s - 152ms/step - accuracy: 0.4525 - loss: 2.5745 - val_accuracy: 0.6935 - val_loss: 1.4471 - learning_rate: 2.5312e-06
Epoch 151/300
1413/1413 - 219s - 155ms/step - accuracy: 0.4541 - loss: 2.5542 - val_accuracy: 0.6951 - val_loss: 1.4480 - learning_rate: 2.5312e-06
Epoch 152/300
1413/1413 - 217s - 153ms/step - accuracy: 0.4532 - loss: 2.5530 - val_accuracy: 0.7014 - val_loss: 1.4470 - learning_rate: 2.5312e-06
Epoch 153/300
1413/1413 - 219s - 155ms/step - accuracy: 0.4528 - loss: 2.5628 - val_accuracy: 0.6951 - val_loss: 1.4534 - learning_rate: 2.5312e-06
Epoch 154/300
1413/1413 - 219s - 155ms/step - accuracy: 0.4582 - loss: 2.5477 - val_accuracy: 0.6911 - val_loss: 1.4506 - learning_rate: 2.5312e-06
Epoch 155/300
1413/1413 - 215s - 152ms/step - accuracy: 0.4511 - loss: 2.5602 - val_accuracy: 0.6943 - val_loss: 1.4427 - learning_rate: 2.5312e-06
Epoch 156/300

Epoch 156: ReduceLROnPlateau reducing learning rate to 1.265596438315697e-06.
1413/1413 - 219s - 155ms/step - accuracy: 0.4548 - loss: 2.5707 - val_accuracy: 0.6879 - val_loss: 1.4614 - learning_rate: 2.5312e-06
Epoch 157/300
1413/1413 - 215s - 152ms/step - accuracy: 0.4518 - loss: 2.5797 - val_accuracy: 0.6967 - val_loss: 1.4418 - learning_rate: 1.2656e-06
Epoch 158/300
1413/1413 - 265s - 188ms/step - accuracy: 0.4603 - loss: 2.5453 - val_accuracy: 0.6990 - val_loss: 1.4436 - learning_rate: 1.2656e-06
Epoch 159/300
1413/1413 - 217s - 154ms/step - accuracy: 0.4513 - loss: 2.5638 - val_accuracy: 0.6967 - val_loss: 1.4325 - learning_rate: 1.2656e-06
Epoch 160/300
1413/1413 - 214s - 151ms/step - accuracy: 0.4557 - loss: 2.5512 - val_accuracy: 0.6927 - val_loss: 1.4435 - learning_rate: 1.2656e-06
Epoch 161/300
1413/1413 - 217s - 154ms/step - accuracy: 0.4572 - loss: 2.5655 - val_accuracy: 0.6959 - val_loss: 1.4504 - learning_rate: 1.2656e-06
Epoch 162/300
1413/1413 - 219s - 155ms/step - accuracy: 0.4595 - loss: 2.5211 - val_accuracy: 0.6935 - val_loss: 1.4446 - learning_rate: 1.2656e-06
Epoch 163/300
1413/1413 - 217s - 154ms/step - accuracy: 0.4562 - loss: 2.5710 - val_accuracy: 0.6911 - val_loss: 1.4587 - learning_rate: 1.2656e-06
Epoch 164/300
1413/1413 - 214s - 152ms/step - accuracy: 0.4634 - loss: 2.5263 - val_accuracy: 0.6959 - val_loss: 1.4431 - learning_rate: 1.2656e-06
Epoch 165/300
1413/1413 - 216s - 153ms/step - accuracy: 0.4503 - loss: 2.5634 - val_accuracy: 0.6959 - val_loss: 1.4551 - learning_rate: 1.2656e-06
Epoch 166/300
1413/1413 - 219s - 155ms/step - accuracy: 0.4601 - loss: 2.5624 - val_accuracy: 0.6959 - val_loss: 1.4378 - learning_rate: 1.2656e-06
Epoch 167/300

Epoch 167: ReduceLROnPlateau reducing learning rate to 1e-06.
1413/1413 - 222s - 157ms/step - accuracy: 0.4579 - loss: 2.5300 - val_accuracy: 0.6935 - val_loss: 1.4534 - learning_rate: 1.2656e-06
Epoch 168/300
1413/1413 - 216s - 153ms/step - accuracy: 0.4431 - loss: 2.5653 - val_accuracy: 0.6982 - val_loss: 1.4482 - learning_rate: 1.0000e-06
Epoch 169/300
1413/1413 - 217s - 153ms/step - accuracy: 0.4560 - loss: 2.5369 - val_accuracy: 0.6935 - val_loss: 1.4463 - learning_rate: 1.0000e-06
Epoch 170/300
1413/1413 - 219s - 155ms/step - accuracy: 0.4603 - loss: 2.5407 - val_accuracy: 0.6935 - val_loss: 1.4492 - learning_rate: 1.0000e-06
Epoch 171/300
1413/1413 - 217s - 154ms/step - accuracy: 0.4596 - loss: 2.5489 - val_accuracy: 0.6982 - val_loss: 1.4558 - learning_rate: 1.0000e-06
Epoch 172/300
1413/1413 - 213s - 151ms/step - accuracy: 0.4489 - loss: 2.5629 - val_accuracy: 0.6927 - val_loss: 1.4493 - learning_rate: 1.0000e-06
Epoch 173/300
1413/1413 - 216s - 153ms/step - accuracy: 0.4570 - loss: 2.5687 - val_accuracy: 0.6959 - val_loss: 1.4562 - learning_rate: 1.0000e-06
Epoch 174/300
1413/1413 - 217s - 153ms/step - accuracy: 0.4550 - loss: 2.5465 - val_accuracy: 0.6935 - val_loss: 1.4591 - learning_rate: 1.0000e-06
Epoch 175/300
1413/1413 - 217s - 154ms/step - accuracy: 0.4578 - loss: 2.5671 - val_accuracy: 0.6975 - val_loss: 1.4498 - learning_rate: 1.0000e-06
Epoch 175: early stopping
Restoring model weights from the end of the best epoch: 159.
Fold 8 Evaluation results: [1.4284343719482422, 0.6966560482978821]
              precision    recall  f1-score   support

        1820       0.84      0.87      0.86        62
        1821       0.96      0.84      0.90        57
        1822       0.00      0.00      0.00         2
        1823       0.00      0.00      0.00         1
        1824       0.00      0.00      0.00         1
        1825       1.00      0.50      0.67         2
        1826       0.00      0.00      0.00         2
        1827       0.96      0.92      0.94        25
        1828       0.00      0.00      0.00         2
        1829       0.75      0.75      0.75         4
        1830       0.76      0.73      0.75        56
        1831       0.79      0.93      0.85       135
        1832       0.76      0.82      0.79        68
        1833       1.00      1.00      1.00        19
        1834       0.64      0.79      0.71        29
        1835       0.00      0.00      0.00         2
        1836       0.50      0.50      0.50         4
        1837       0.20      0.50      0.29         6
        1838       1.00      0.75      0.86         4
        1839       0.00      0.00      0.00         1
        1840       0.67      0.62      0.64        42
        1841       0.76      0.65      0.70       107
        1842       0.67      0.33      0.44         6
        1843       0.75      0.60      0.67         5
        1844       0.00      0.00      0.00         0
        1845       0.00      0.00      0.00         1
        1846       0.43      0.50      0.46         6
        1847       0.00      0.00      0.00         2
        1848       0.00      0.00      0.00         5
        1849       0.22      0.40      0.29         5
        1850       0.63      0.65      0.64        48
        1851       0.74      0.79      0.77        77
        1852       0.00      0.00      0.00         8
        1853       0.40      0.29      0.33         7
        1854       0.25      0.67      0.36         3
        1855       0.43      0.43      0.43        23
        1856       0.58      0.58      0.58        12
        1857       0.55      0.71      0.62        31
        1858       0.00      0.00      0.00         2
        1859       0.00      0.00      0.00         2
        1860       0.56      0.48      0.52        65
        1861       0.80      0.78      0.79        85
        1862       0.50      0.47      0.49        19
        1863       0.50      0.58      0.54        19
        1864       0.50      0.76      0.60        17
        1865       0.60      0.86      0.71         7
        1866       0.00      0.00      0.00         6
        1867       0.47      0.70      0.56        10
        1868       0.00      0.00      0.00         7
        1869       0.00      0.00      0.00         6
        1870       0.56      0.74      0.64        31
        1871       0.83      0.82      0.82        49
        1872       0.27      0.43      0.33         7
        1873       0.60      0.27      0.38        11
        1874       0.33      0.40      0.36         5
        1875       0.57      0.31      0.40        13
        1876       0.82      0.90      0.86        10
        1877       0.38      0.60      0.46         5
        1878       0.60      0.33      0.43         9
        1879       0.00      0.00      0.00         1

    accuracy                           0.70      1256
   macro avg       0.44      0.44      0.43      1256
weighted avg       0.68      0.70      0.68      1256

Matthews Correlation Coefficient: 0.682
Macro avg F1: 0.428
Weighted avg F1: 0.685
Micro avg F1: 0.697
Top-3 Accuracy: 0.885
Top-5 Accuracy: 0.928
Micro ROC AUC  = 0.99
Macro ROC AUC (present classes) = 0.98
Classification MAE (in years): 2.55

Fold 8 Misclassification Analysis:
Near misses (within 2 years): 101 out of 381 misclassifications (26.51%)
Big misses (greater than 10 years): 170
MAE with outliers: 2.55
MAE without outliers: 1.69 (improvement: 0.86)

10 Worst misclassifications:
Image: data/datasets/public/1870/1876_11washington.jpg, True: 1876, Predicted: 1820, Error: 56
Image: data/datasets/private/1820/1820_033_Zrzut ekranu 2022-07-26 200310.png, True: 1820, Predicted: 1870, Error: 50
Image: data/datasets/public/1870/1870_035met.jpg, True: 1870, Predicted: 1820, Error: 50
Image: data/datasets/public/1820/1827_822vna.jpg, True: 1827, Predicted: 1876, Error: 49
Image: data/datasets/public/1830/1832_1252vna.jpg, True: 1832, Predicted: 1876, Error: 44
Image: data/datasets/public/1870/1873_012met.jpg, True: 1873, Predicted: 1832, Error: 41
Image: data/datasets/public/1820/1820_38wikimedia2.jpg, True: 1820, Predicted: 1861, Error: 41
Image: data/datasets/public/1820/1820_038met.jpg, True: 1820, Predicted: 1860, Error: 40
Image: data/datasets/public/1820/1820_045met.jpg, True: 1820, Predicted: 1860, Error: 40
Image: data/datasets/public/1870/1870_23wikimedia2.jpg, True: 1870, Predicted: 1830, Error: 40

===== Fold 9 =====

===== Fine Tuning 7 layers! =====
Epoch 1/300
1413/1413 - 236s - 167ms/step - accuracy: 0.1400 - loss: 4.4103 - val_accuracy: 0.2167 - val_loss: 4.0598 - learning_rate: 1.6200e-04
Epoch 2/300
1413/1413 - 218s - 154ms/step - accuracy: 0.1952 - loss: 3.9874 - val_accuracy: 0.1378 - val_loss: 3.8141 - learning_rate: 1.6200e-04
Epoch 3/300
1413/1413 - 215s - 152ms/step - accuracy: 0.2270 - loss: 3.8052 - val_accuracy: 0.3538 - val_loss: 3.3409 - learning_rate: 1.6200e-04
Epoch 4/300
1413/1413 - 218s - 154ms/step - accuracy: 0.2471 - loss: 3.6906 - val_accuracy: 0.3594 - val_loss: 3.2049 - learning_rate: 1.6200e-04
Epoch 5/300
1413/1413 - 217s - 154ms/step - accuracy: 0.2597 - loss: 3.6082 - val_accuracy: 0.2980 - val_loss: 3.6873 - learning_rate: 1.6200e-04
Epoch 6/300
1413/1413 - 217s - 154ms/step - accuracy: 0.2731 - loss: 3.5267 - val_accuracy: 0.2693 - val_loss: 3.9975 - learning_rate: 1.6200e-04
Epoch 7/300
1413/1413 - 220s - 156ms/step - accuracy: 0.2845 - loss: 3.4824 - val_accuracy: 0.3633 - val_loss: 2.9841 - learning_rate: 1.6200e-04
Epoch 8/300
1413/1413 - 219s - 155ms/step - accuracy: 0.2841 - loss: 3.4536 - val_accuracy: 0.4311 - val_loss: 2.9374 - learning_rate: 1.6200e-04
Epoch 9/300
1413/1413 - 218s - 154ms/step - accuracy: 0.2849 - loss: 3.4304 - val_accuracy: 0.2988 - val_loss: 3.6305 - learning_rate: 1.6200e-04
Epoch 10/300
1413/1413 - 216s - 153ms/step - accuracy: 0.3023 - loss: 3.3786 - val_accuracy: 0.2988 - val_loss: 3.6153 - learning_rate: 1.6200e-04
Epoch 11/300
1413/1413 - 218s - 154ms/step - accuracy: 0.3042 - loss: 3.3564 - val_accuracy: 0.3737 - val_loss: 2.8362 - learning_rate: 1.6200e-04
Epoch 12/300
1413/1413 - 219s - 155ms/step - accuracy: 0.3091 - loss: 3.3249 - val_accuracy: 0.3586 - val_loss: 2.8695 - learning_rate: 1.6200e-04
Epoch 13/300
1413/1413 - 217s - 153ms/step - accuracy: 0.3142 - loss: 3.3016 - val_accuracy: 0.3530 - val_loss: 3.5706 - learning_rate: 1.6200e-04
Epoch 14/300
1413/1413 - 221s - 156ms/step - accuracy: 0.3149 - loss: 3.2912 - val_accuracy: 0.4016 - val_loss: 3.0195 - learning_rate: 1.6200e-04
Epoch 15/300
1413/1413 - 218s - 154ms/step - accuracy: 0.3168 - loss: 3.2604 - val_accuracy: 0.4183 - val_loss: 2.7681 - learning_rate: 1.6200e-04
Epoch 16/300
1413/1413 - 215s - 152ms/step - accuracy: 0.3254 - loss: 3.2297 - val_accuracy: 0.2446 - val_loss: 3.8900 - learning_rate: 1.6200e-04
Epoch 17/300
1413/1413 - 220s - 156ms/step - accuracy: 0.3248 - loss: 3.2204 - val_accuracy: 0.4143 - val_loss: 2.7157 - learning_rate: 1.6200e-04
Epoch 18/300
1413/1413 - 217s - 153ms/step - accuracy: 0.3278 - loss: 3.2021 - val_accuracy: 0.4813 - val_loss: 2.5509 - learning_rate: 1.6200e-04
Epoch 19/300
1413/1413 - 265s - 188ms/step - accuracy: 0.3348 - loss: 3.1923 - val_accuracy: 0.4295 - val_loss: 2.6854 - learning_rate: 1.6200e-04
Epoch 20/300
1413/1413 - 215s - 152ms/step - accuracy: 0.3344 - loss: 3.1596 - val_accuracy: 0.3442 - val_loss: 3.6682 - learning_rate: 1.6200e-04
Epoch 21/300
1413/1413 - 218s - 154ms/step - accuracy: 0.3453 - loss: 3.1322 - val_accuracy: 0.4382 - val_loss: 2.7851 - learning_rate: 1.6200e-04
Epoch 22/300
1413/1413 - 219s - 155ms/step - accuracy: 0.3431 - loss: 3.1384 - val_accuracy: 0.4104 - val_loss: 3.1794 - learning_rate: 1.6200e-04
Epoch 23/300
1413/1413 - 217s - 154ms/step - accuracy: 0.3454 - loss: 3.1104 - val_accuracy: 0.4892 - val_loss: 2.3622 - learning_rate: 1.6200e-04
Epoch 24/300
1413/1413 - 221s - 157ms/step - accuracy: 0.3463 - loss: 3.1292 - val_accuracy: 0.4438 - val_loss: 2.7011 - learning_rate: 1.6200e-04
Epoch 25/300
1413/1413 - 217s - 153ms/step - accuracy: 0.3440 - loss: 3.0824 - val_accuracy: 0.2558 - val_loss: 4.1545 - learning_rate: 1.6200e-04
Epoch 26/300
1413/1413 - 217s - 153ms/step - accuracy: 0.3508 - loss: 3.0806 - val_accuracy: 0.4725 - val_loss: 2.3996 - learning_rate: 1.6200e-04
Epoch 27/300
1413/1413 - 220s - 156ms/step - accuracy: 0.3499 - loss: 3.0805 - val_accuracy: 0.5378 - val_loss: 2.1910 - learning_rate: 1.6200e-04
Epoch 28/300
1413/1413 - 221s - 156ms/step - accuracy: 0.3581 - loss: 3.0473 - val_accuracy: 0.4582 - val_loss: 2.5599 - learning_rate: 1.6200e-04
Epoch 29/300
1413/1413 - 220s - 156ms/step - accuracy: 0.3529 - loss: 3.0512 - val_accuracy: 0.4765 - val_loss: 2.4812 - learning_rate: 1.6200e-04
Epoch 30/300
1413/1413 - 221s - 156ms/step - accuracy: 0.3499 - loss: 3.0744 - val_accuracy: 0.5068 - val_loss: 2.3604 - learning_rate: 1.6200e-04
Epoch 31/300
1413/1413 - 216s - 153ms/step - accuracy: 0.3538 - loss: 3.0526 - val_accuracy: 0.4550 - val_loss: 2.8388 - learning_rate: 1.6200e-04
Epoch 32/300
1413/1413 - 216s - 153ms/step - accuracy: 0.3597 - loss: 3.0287 - val_accuracy: 0.2693 - val_loss: 5.3565 - learning_rate: 1.6200e-04
Epoch 33/300
1413/1413 - 220s - 156ms/step - accuracy: 0.3623 - loss: 3.0162 - val_accuracy: 0.4040 - val_loss: 2.8336 - learning_rate: 1.6200e-04
Epoch 34/300
1413/1413 - 217s - 154ms/step - accuracy: 0.3660 - loss: 3.0083 - val_accuracy: 0.3139 - val_loss: 3.5518 - learning_rate: 1.6200e-04
Epoch 35/300
1413/1413 - 216s - 153ms/step - accuracy: 0.3638 - loss: 3.0241 - val_accuracy: 0.5530 - val_loss: 2.1554 - learning_rate: 1.6200e-04
Epoch 36/300
1413/1413 - 220s - 156ms/step - accuracy: 0.3665 - loss: 2.9869 - val_accuracy: 0.4614 - val_loss: 2.6210 - learning_rate: 1.6200e-04
Epoch 37/300
1413/1413 - 218s - 154ms/step - accuracy: 0.3698 - loss: 2.9976 - val_accuracy: 0.2797 - val_loss: 4.6449 - learning_rate: 1.6200e-04
Epoch 38/300
1413/1413 - 219s - 155ms/step - accuracy: 0.3762 - loss: 3.0048 - val_accuracy: 0.5482 - val_loss: 2.1469 - learning_rate: 1.6200e-04
Epoch 39/300
1413/1413 - 218s - 154ms/step - accuracy: 0.3730 - loss: 2.9560 - val_accuracy: 0.5307 - val_loss: 2.2727 - learning_rate: 1.6200e-04
Epoch 40/300
1413/1413 - 220s - 156ms/step - accuracy: 0.3822 - loss: 2.9269 - val_accuracy: 0.5116 - val_loss: 2.3495 - learning_rate: 1.6200e-04
Epoch 41/300
1413/1413 - 221s - 157ms/step - accuracy: 0.3740 - loss: 2.9630 - val_accuracy: 0.4677 - val_loss: 2.5010 - learning_rate: 1.6200e-04
Epoch 42/300
1413/1413 - 221s - 157ms/step - accuracy: 0.3801 - loss: 2.9551 - val_accuracy: 0.5689 - val_loss: 2.0506 - learning_rate: 1.6200e-04
Epoch 43/300
1413/1413 - 216s - 153ms/step - accuracy: 0.3787 - loss: 2.9297 - val_accuracy: 0.5092 - val_loss: 2.2036 - learning_rate: 1.6200e-04
Epoch 44/300
1413/1413 - 221s - 156ms/step - accuracy: 0.3795 - loss: 2.9186 - val_accuracy: 0.5355 - val_loss: 2.2250 - learning_rate: 1.6200e-04
Epoch 45/300
1413/1413 - 218s - 154ms/step - accuracy: 0.3765 - loss: 2.9126 - val_accuracy: 0.4287 - val_loss: 3.3450 - learning_rate: 1.6200e-04
Epoch 46/300
1413/1413 - 216s - 153ms/step - accuracy: 0.3807 - loss: 2.9313 - val_accuracy: 0.4701 - val_loss: 2.8553 - learning_rate: 1.6200e-04
Epoch 47/300
1413/1413 - 226s - 160ms/step - accuracy: 0.3790 - loss: 2.9299 - val_accuracy: 0.4916 - val_loss: 2.4580 - learning_rate: 1.6200e-04
Epoch 48/300
1413/1413 - 221s - 156ms/step - accuracy: 0.3870 - loss: 2.9025 - val_accuracy: 0.4478 - val_loss: 2.5460 - learning_rate: 1.6200e-04
Epoch 49/300
1413/1413 - 227s - 161ms/step - accuracy: 0.3934 - loss: 2.8973 - val_accuracy: 0.5235 - val_loss: 2.0547 - learning_rate: 1.6200e-04
Epoch 50/300

Epoch 50: ReduceLROnPlateau reducing learning rate to 8.099817205220461e-05.
1413/1413 - 219s - 155ms/step - accuracy: 0.3804 - loss: 2.9170 - val_accuracy: 0.4462 - val_loss: 3.0234 - learning_rate: 1.6200e-04
Epoch 51/300
1413/1413 - 223s - 158ms/step - accuracy: 0.3992 - loss: 2.8157 - val_accuracy: 0.5299 - val_loss: 2.3523 - learning_rate: 8.0998e-05
Epoch 52/300
1413/1413 - 221s - 156ms/step - accuracy: 0.4043 - loss: 2.8203 - val_accuracy: 0.5944 - val_loss: 1.7976 - learning_rate: 8.0998e-05
Epoch 53/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4033 - loss: 2.8092 - val_accuracy: 0.5928 - val_loss: 1.8672 - learning_rate: 8.0998e-05
Epoch 54/300
1413/1413 - 220s - 156ms/step - accuracy: 0.3982 - loss: 2.8044 - val_accuracy: 0.5928 - val_loss: 1.9207 - learning_rate: 8.0998e-05
Epoch 55/300
1413/1413 - 224s - 158ms/step - accuracy: 0.4117 - loss: 2.7809 - val_accuracy: 0.5769 - val_loss: 2.0252 - learning_rate: 8.0998e-05
Epoch 56/300
1413/1413 - 217s - 154ms/step - accuracy: 0.4091 - loss: 2.7835 - val_accuracy: 0.5426 - val_loss: 2.1858 - learning_rate: 8.0998e-05
Epoch 57/300
1413/1413 - 217s - 153ms/step - accuracy: 0.4057 - loss: 2.7697 - val_accuracy: 0.5992 - val_loss: 1.8939 - learning_rate: 8.0998e-05
Epoch 58/300
1413/1413 - 221s - 157ms/step - accuracy: 0.4072 - loss: 2.7755 - val_accuracy: 0.5753 - val_loss: 1.9642 - learning_rate: 8.0998e-05
Epoch 59/300
1413/1413 - 216s - 153ms/step - accuracy: 0.4048 - loss: 2.7864 - val_accuracy: 0.6135 - val_loss: 1.8992 - learning_rate: 8.0998e-05
Epoch 60/300
1413/1413 - 219s - 155ms/step - accuracy: 0.4106 - loss: 2.7509 - val_accuracy: 0.6127 - val_loss: 1.7853 - learning_rate: 8.0998e-05
Epoch 61/300
1413/1413 - 217s - 154ms/step - accuracy: 0.4051 - loss: 2.7794 - val_accuracy: 0.6167 - val_loss: 1.8429 - learning_rate: 8.0998e-05
Epoch 62/300
1413/1413 - 217s - 153ms/step - accuracy: 0.4126 - loss: 2.7571 - val_accuracy: 0.5570 - val_loss: 2.1463 - learning_rate: 8.0998e-05
Epoch 63/300
1413/1413 - 219s - 155ms/step - accuracy: 0.4141 - loss: 2.7476 - val_accuracy: 0.5857 - val_loss: 1.9874 - learning_rate: 8.0998e-05
Epoch 64/300
1413/1413 - 215s - 152ms/step - accuracy: 0.4122 - loss: 2.7509 - val_accuracy: 0.5705 - val_loss: 2.1052 - learning_rate: 8.0998e-05
Epoch 65/300
1413/1413 - 216s - 153ms/step - accuracy: 0.4199 - loss: 2.7199 - val_accuracy: 0.6199 - val_loss: 1.8106 - learning_rate: 8.0998e-05
Epoch 66/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4223 - loss: 2.7191 - val_accuracy: 0.5641 - val_loss: 2.1361 - learning_rate: 8.0998e-05
Epoch 67/300
1413/1413 - 260s - 184ms/step - accuracy: 0.4178 - loss: 2.7401 - val_accuracy: 0.6096 - val_loss: 1.8245 - learning_rate: 8.0998e-05
Epoch 68/300

Epoch 68: ReduceLROnPlateau reducing learning rate to 4.0499086026102304e-05.
1413/1413 - 218s - 154ms/step - accuracy: 0.4166 - loss: 2.7282 - val_accuracy: 0.5275 - val_loss: 2.8174 - learning_rate: 8.0998e-05
Epoch 69/300
1413/1413 - 223s - 157ms/step - accuracy: 0.4183 - loss: 2.7327 - val_accuracy: 0.6430 - val_loss: 1.6804 - learning_rate: 4.0499e-05
Epoch 70/300
1413/1413 - 217s - 153ms/step - accuracy: 0.4199 - loss: 2.7062 - val_accuracy: 0.6470 - val_loss: 1.7683 - learning_rate: 4.0499e-05
Epoch 71/300
1413/1413 - 219s - 155ms/step - accuracy: 0.4259 - loss: 2.7059 - val_accuracy: 0.6207 - val_loss: 1.7639 - learning_rate: 4.0499e-05
Epoch 72/300
1413/1413 - 220s - 156ms/step - accuracy: 0.4239 - loss: 2.6777 - val_accuracy: 0.6072 - val_loss: 1.7673 - learning_rate: 4.0499e-05
Epoch 73/300
1413/1413 - 227s - 161ms/step - accuracy: 0.4273 - loss: 2.6910 - val_accuracy: 0.6175 - val_loss: 1.8739 - learning_rate: 4.0499e-05
Epoch 74/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4258 - loss: 2.6896 - val_accuracy: 0.6494 - val_loss: 1.6233 - learning_rate: 4.0499e-05
Epoch 75/300
1413/1413 - 219s - 155ms/step - accuracy: 0.4313 - loss: 2.6587 - val_accuracy: 0.6382 - val_loss: 1.6833 - learning_rate: 4.0499e-05
Epoch 76/300
1413/1413 - 231s - 163ms/step - accuracy: 0.4309 - loss: 2.6669 - val_accuracy: 0.6510 - val_loss: 1.6738 - learning_rate: 4.0499e-05
Epoch 77/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4235 - loss: 2.6687 - val_accuracy: 0.6311 - val_loss: 1.6939 - learning_rate: 4.0499e-05
Epoch 78/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4292 - loss: 2.6533 - val_accuracy: 0.6319 - val_loss: 1.6974 - learning_rate: 4.0499e-05
Epoch 79/300
1413/1413 - 224s - 159ms/step - accuracy: 0.4237 - loss: 2.6780 - val_accuracy: 0.5960 - val_loss: 1.9660 - learning_rate: 4.0499e-05
Epoch 80/300
1413/1413 - 269s - 190ms/step - accuracy: 0.4338 - loss: 2.6660 - val_accuracy: 0.6271 - val_loss: 1.6994 - learning_rate: 4.0499e-05
Epoch 81/300
1413/1413 - 221s - 157ms/step - accuracy: 0.4382 - loss: 2.6415 - val_accuracy: 0.6375 - val_loss: 1.6646 - learning_rate: 4.0499e-05
Epoch 82/300

Epoch 82: ReduceLROnPlateau reducing learning rate to 2.0249543013051152e-05.
1413/1413 - 223s - 158ms/step - accuracy: 0.4308 - loss: 2.6823 - val_accuracy: 0.6390 - val_loss: 1.6761 - learning_rate: 4.0499e-05
Epoch 83/300
1413/1413 - 235s - 166ms/step - accuracy: 0.4344 - loss: 2.6228 - val_accuracy: 0.6622 - val_loss: 1.6528 - learning_rate: 2.0250e-05
Epoch 84/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4362 - loss: 2.6480 - val_accuracy: 0.6629 - val_loss: 1.6023 - learning_rate: 2.0250e-05
Epoch 85/300
1413/1413 - 264s - 187ms/step - accuracy: 0.4432 - loss: 2.6252 - val_accuracy: 0.6526 - val_loss: 1.6223 - learning_rate: 2.0250e-05
Epoch 86/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4422 - loss: 2.6209 - val_accuracy: 0.6207 - val_loss: 1.7763 - learning_rate: 2.0250e-05
Epoch 87/300
1413/1413 - 224s - 159ms/step - accuracy: 0.4440 - loss: 2.5981 - val_accuracy: 0.6574 - val_loss: 1.6011 - learning_rate: 2.0250e-05
Epoch 88/300
1413/1413 - 228s - 161ms/step - accuracy: 0.4380 - loss: 2.6171 - val_accuracy: 0.6462 - val_loss: 1.6478 - learning_rate: 2.0250e-05
Epoch 89/300
1413/1413 - 224s - 159ms/step - accuracy: 0.4452 - loss: 2.6087 - val_accuracy: 0.6398 - val_loss: 1.6262 - learning_rate: 2.0250e-05
Epoch 90/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4426 - loss: 2.6291 - val_accuracy: 0.6598 - val_loss: 1.6213 - learning_rate: 2.0250e-05
Epoch 91/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4401 - loss: 2.6289 - val_accuracy: 0.6494 - val_loss: 1.7032 - learning_rate: 2.0250e-05
Epoch 92/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4375 - loss: 2.6414 - val_accuracy: 0.6502 - val_loss: 1.6436 - learning_rate: 2.0250e-05
Epoch 93/300
1413/1413 - 220s - 155ms/step - accuracy: 0.4432 - loss: 2.6076 - val_accuracy: 0.6622 - val_loss: 1.6358 - learning_rate: 2.0250e-05
Epoch 94/300
1413/1413 - 217s - 153ms/step - accuracy: 0.4434 - loss: 2.6185 - val_accuracy: 0.6582 - val_loss: 1.6565 - learning_rate: 2.0250e-05
Epoch 95/300

Epoch 95: ReduceLROnPlateau reducing learning rate to 1.0124771506525576e-05.
1413/1413 - 261s - 185ms/step - accuracy: 0.4413 - loss: 2.6086 - val_accuracy: 0.6454 - val_loss: 1.6369 - learning_rate: 2.0250e-05
Epoch 96/300
1413/1413 - 217s - 154ms/step - accuracy: 0.4483 - loss: 2.5861 - val_accuracy: 0.6701 - val_loss: 1.5732 - learning_rate: 1.0125e-05
Epoch 97/300
1413/1413 - 216s - 153ms/step - accuracy: 0.4490 - loss: 2.6032 - val_accuracy: 0.6622 - val_loss: 1.5758 - learning_rate: 1.0125e-05
Epoch 98/300
1413/1413 - 220s - 156ms/step - accuracy: 0.4429 - loss: 2.5964 - val_accuracy: 0.6622 - val_loss: 1.5701 - learning_rate: 1.0125e-05
Epoch 99/300
1413/1413 - 217s - 154ms/step - accuracy: 0.4388 - loss: 2.6116 - val_accuracy: 0.6637 - val_loss: 1.5898 - learning_rate: 1.0125e-05
Epoch 100/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4451 - loss: 2.6001 - val_accuracy: 0.6606 - val_loss: 1.5598 - learning_rate: 1.0125e-05
Epoch 101/300
1413/1413 - 258s - 182ms/step - accuracy: 0.4495 - loss: 2.5695 - val_accuracy: 0.6645 - val_loss: 1.6058 - learning_rate: 1.0125e-05
Epoch 102/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4442 - loss: 2.5898 - val_accuracy: 0.6725 - val_loss: 1.5587 - learning_rate: 1.0125e-05
Epoch 103/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4482 - loss: 2.5857 - val_accuracy: 0.6717 - val_loss: 1.5758 - learning_rate: 1.0125e-05
Epoch 104/300
1413/1413 - 217s - 153ms/step - accuracy: 0.4504 - loss: 2.5929 - val_accuracy: 0.6733 - val_loss: 1.5877 - learning_rate: 1.0125e-05
Epoch 105/300
1413/1413 - 217s - 153ms/step - accuracy: 0.4500 - loss: 2.5657 - val_accuracy: 0.6685 - val_loss: 1.5637 - learning_rate: 1.0125e-05
Epoch 106/300
1413/1413 - 265s - 187ms/step - accuracy: 0.4504 - loss: 2.5832 - val_accuracy: 0.6629 - val_loss: 1.5681 - learning_rate: 1.0125e-05
Epoch 107/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4457 - loss: 2.5945 - val_accuracy: 0.6725 - val_loss: 1.5530 - learning_rate: 1.0125e-05
Epoch 108/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4452 - loss: 2.5812 - val_accuracy: 0.6701 - val_loss: 1.5756 - learning_rate: 1.0125e-05
Epoch 109/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4495 - loss: 2.5937 - val_accuracy: 0.6598 - val_loss: 1.6082 - learning_rate: 1.0125e-05
Epoch 110/300
1413/1413 - 227s - 161ms/step - accuracy: 0.4429 - loss: 2.6019 - val_accuracy: 0.6701 - val_loss: 1.5613 - learning_rate: 1.0125e-05
Epoch 111/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4444 - loss: 2.6099 - val_accuracy: 0.6590 - val_loss: 1.5617 - learning_rate: 1.0125e-05
Epoch 112/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4484 - loss: 2.5905 - val_accuracy: 0.6797 - val_loss: 1.5387 - learning_rate: 1.0125e-05
Epoch 113/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4533 - loss: 2.5572 - val_accuracy: 0.6669 - val_loss: 1.5509 - learning_rate: 1.0125e-05
Epoch 114/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4472 - loss: 2.5787 - val_accuracy: 0.6725 - val_loss: 1.5715 - learning_rate: 1.0125e-05
Epoch 115/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4529 - loss: 2.5434 - val_accuracy: 0.6637 - val_loss: 1.5964 - learning_rate: 1.0125e-05
Epoch 116/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4434 - loss: 2.6095 - val_accuracy: 0.6622 - val_loss: 1.6541 - learning_rate: 1.0125e-05
Epoch 117/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4499 - loss: 2.5660 - val_accuracy: 0.6558 - val_loss: 1.6091 - learning_rate: 1.0125e-05
Epoch 118/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4475 - loss: 2.6013 - val_accuracy: 0.6677 - val_loss: 1.5378 - learning_rate: 1.0125e-05
Epoch 119/300
1413/1413 - 232s - 164ms/step - accuracy: 0.4577 - loss: 2.5423 - val_accuracy: 0.6534 - val_loss: 1.6676 - learning_rate: 1.0125e-05
Epoch 120/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4545 - loss: 2.5727 - val_accuracy: 0.6574 - val_loss: 1.6085 - learning_rate: 1.0125e-05
Epoch 121/300
1413/1413 - 224s - 159ms/step - accuracy: 0.4500 - loss: 2.5637 - val_accuracy: 0.6653 - val_loss: 1.5752 - learning_rate: 1.0125e-05
Epoch 122/300
1413/1413 - 228s - 161ms/step - accuracy: 0.4509 - loss: 2.5786 - val_accuracy: 0.6614 - val_loss: 1.5768 - learning_rate: 1.0125e-05
Epoch 123/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4512 - loss: 2.5771 - val_accuracy: 0.6701 - val_loss: 1.5575 - learning_rate: 1.0125e-05
Epoch 124/300
1413/1413 - 224s - 159ms/step - accuracy: 0.4475 - loss: 2.5822 - val_accuracy: 0.6669 - val_loss: 1.5695 - learning_rate: 1.0125e-05
Epoch 125/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4520 - loss: 2.5710 - val_accuracy: 0.6717 - val_loss: 1.5442 - learning_rate: 1.0125e-05
Epoch 126/300

Epoch 126: ReduceLROnPlateau reducing learning rate to 5.062385753262788e-06.
1413/1413 - 223s - 158ms/step - accuracy: 0.4498 - loss: 2.5775 - val_accuracy: 0.6645 - val_loss: 1.5692 - learning_rate: 1.0125e-05
Epoch 127/300
1413/1413 - 228s - 161ms/step - accuracy: 0.4540 - loss: 2.5601 - val_accuracy: 0.6701 - val_loss: 1.5520 - learning_rate: 5.0624e-06
Epoch 128/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4536 - loss: 2.5669 - val_accuracy: 0.6701 - val_loss: 1.5378 - learning_rate: 5.0624e-06
Epoch 129/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4537 - loss: 2.5591 - val_accuracy: 0.6725 - val_loss: 1.5503 - learning_rate: 5.0624e-06
Epoch 130/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4597 - loss: 2.5517 - val_accuracy: 0.6614 - val_loss: 1.5474 - learning_rate: 5.0624e-06
Epoch 131/300
1413/1413 - 224s - 158ms/step - accuracy: 0.4538 - loss: 2.5533 - val_accuracy: 0.6717 - val_loss: 1.5468 - learning_rate: 5.0624e-06
Epoch 132/300
1413/1413 - 230s - 163ms/step - accuracy: 0.4526 - loss: 2.5956 - val_accuracy: 0.6629 - val_loss: 1.5519 - learning_rate: 5.0624e-06
Epoch 133/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4586 - loss: 2.5385 - val_accuracy: 0.6693 - val_loss: 1.5562 - learning_rate: 5.0624e-06
Epoch 134/300
1413/1413 - 229s - 162ms/step - accuracy: 0.4540 - loss: 2.5326 - val_accuracy: 0.6749 - val_loss: 1.5365 - learning_rate: 5.0624e-06
Epoch 135/300
1413/1413 - 217s - 154ms/step - accuracy: 0.4582 - loss: 2.5364 - val_accuracy: 0.6693 - val_loss: 1.5682 - learning_rate: 5.0624e-06
Epoch 136/300
1413/1413 - 216s - 153ms/step - accuracy: 0.4597 - loss: 2.5529 - val_accuracy: 0.6741 - val_loss: 1.5436 - learning_rate: 5.0624e-06
Epoch 137/300
1413/1413 - 220s - 156ms/step - accuracy: 0.4582 - loss: 2.5478 - val_accuracy: 0.6749 - val_loss: 1.5341 - learning_rate: 5.0624e-06
Epoch 138/300
1413/1413 - 218s - 154ms/step - accuracy: 0.4589 - loss: 2.5277 - val_accuracy: 0.6741 - val_loss: 1.5345 - learning_rate: 5.0624e-06
Epoch 139/300
1413/1413 - 224s - 158ms/step - accuracy: 0.4607 - loss: 2.5237 - val_accuracy: 0.6765 - val_loss: 1.5383 - learning_rate: 5.0624e-06
Epoch 140/300
1413/1413 - 253s - 179ms/step - accuracy: 0.4541 - loss: 2.5552 - val_accuracy: 0.6693 - val_loss: 1.5511 - learning_rate: 5.0624e-06
Epoch 141/300
1413/1413 - 216s - 153ms/step - accuracy: 0.4494 - loss: 2.5563 - val_accuracy: 0.6717 - val_loss: 1.5284 - learning_rate: 5.0624e-06
Epoch 142/300
1413/1413 - 217s - 153ms/step - accuracy: 0.4559 - loss: 2.5534 - val_accuracy: 0.6653 - val_loss: 1.5497 - learning_rate: 5.0624e-06
Epoch 143/300
1413/1413 - 219s - 155ms/step - accuracy: 0.4564 - loss: 2.5516 - val_accuracy: 0.6693 - val_loss: 1.5717 - learning_rate: 5.0624e-06
Epoch 144/300
1413/1413 - 215s - 152ms/step - accuracy: 0.4531 - loss: 2.5623 - val_accuracy: 0.6685 - val_loss: 1.5392 - learning_rate: 5.0624e-06
Epoch 145/300
1413/1413 - 221s - 156ms/step - accuracy: 0.4552 - loss: 2.5460 - val_accuracy: 0.6781 - val_loss: 1.5377 - learning_rate: 5.0624e-06
Epoch 146/300
1413/1413 - 218s - 154ms/step - accuracy: 0.4536 - loss: 2.5525 - val_accuracy: 0.6797 - val_loss: 1.5410 - learning_rate: 5.0624e-06
Epoch 147/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4492 - loss: 2.5850 - val_accuracy: 0.6757 - val_loss: 1.5348 - learning_rate: 5.0624e-06
Epoch 148/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4521 - loss: 2.5576 - val_accuracy: 0.6709 - val_loss: 1.5519 - learning_rate: 5.0624e-06
Epoch 149/300
1413/1413 - 219s - 155ms/step - accuracy: 0.4516 - loss: 2.5590 - val_accuracy: 0.6725 - val_loss: 1.5227 - learning_rate: 5.0624e-06
Epoch 150/300
1413/1413 - 216s - 153ms/step - accuracy: 0.4549 - loss: 2.5458 - val_accuracy: 0.6765 - val_loss: 1.5326 - learning_rate: 5.0624e-06
Epoch 151/300
1413/1413 - 217s - 154ms/step - accuracy: 0.4535 - loss: 2.5676 - val_accuracy: 0.6661 - val_loss: 1.5453 - learning_rate: 5.0624e-06
Epoch 152/300
1413/1413 - 218s - 155ms/step - accuracy: 0.4559 - loss: 2.5457 - val_accuracy: 0.6741 - val_loss: 1.5272 - learning_rate: 5.0624e-06
Epoch 153/300
1413/1413 - 217s - 154ms/step - accuracy: 0.4519 - loss: 2.5432 - val_accuracy: 0.6829 - val_loss: 1.5486 - learning_rate: 5.0624e-06
Epoch 154/300
1413/1413 - 266s - 188ms/step - accuracy: 0.4572 - loss: 2.5314 - val_accuracy: 0.6669 - val_loss: 1.5309 - learning_rate: 5.0624e-06
Epoch 155/300
1413/1413 - 217s - 154ms/step - accuracy: 0.4490 - loss: 2.5809 - val_accuracy: 0.6773 - val_loss: 1.5418 - learning_rate: 5.0624e-06
Epoch 156/300
1413/1413 - 218s - 154ms/step - accuracy: 0.4566 - loss: 2.5496 - val_accuracy: 0.6773 - val_loss: 1.5505 - learning_rate: 5.0624e-06
Epoch 157/300

Epoch 157: ReduceLROnPlateau reducing learning rate to 2.531192876631394e-06.
1413/1413 - 218s - 154ms/step - accuracy: 0.4605 - loss: 2.5602 - val_accuracy: 0.6813 - val_loss: 1.5441 - learning_rate: 5.0624e-06
Epoch 158/300
1413/1413 - 217s - 154ms/step - accuracy: 0.4560 - loss: 2.5300 - val_accuracy: 0.6805 - val_loss: 1.5322 - learning_rate: 2.5312e-06
Epoch 159/300
1413/1413 - 217s - 154ms/step - accuracy: 0.4647 - loss: 2.5076 - val_accuracy: 0.6829 - val_loss: 1.5300 - learning_rate: 2.5312e-06
Epoch 160/300
1413/1413 - 217s - 153ms/step - accuracy: 0.4537 - loss: 2.5490 - val_accuracy: 0.6781 - val_loss: 1.5207 - learning_rate: 2.5312e-06
Epoch 161/300
1413/1413 - 267s - 189ms/step - accuracy: 0.4628 - loss: 2.5439 - val_accuracy: 0.6829 - val_loss: 1.5415 - learning_rate: 2.5312e-06
Epoch 162/300
1413/1413 - 218s - 154ms/step - accuracy: 0.4634 - loss: 2.5421 - val_accuracy: 0.6765 - val_loss: 1.5260 - learning_rate: 2.5312e-06
Epoch 163/300
1413/1413 - 215s - 152ms/step - accuracy: 0.4558 - loss: 2.5595 - val_accuracy: 0.6773 - val_loss: 1.5384 - learning_rate: 2.5312e-06
Epoch 164/300
1413/1413 - 222s - 157ms/step - accuracy: 0.4550 - loss: 2.5460 - val_accuracy: 0.6797 - val_loss: 1.5338 - learning_rate: 2.5312e-06
Epoch 165/300
1413/1413 - 217s - 153ms/step - accuracy: 0.4649 - loss: 2.5236 - val_accuracy: 0.6765 - val_loss: 1.5433 - learning_rate: 2.5312e-06
Epoch 166/300
1413/1413 - 220s - 156ms/step - accuracy: 0.4590 - loss: 2.5376 - val_accuracy: 0.6805 - val_loss: 1.5186 - learning_rate: 2.5312e-06
Epoch 167/300
1413/1413 - 214s - 152ms/step - accuracy: 0.4552 - loss: 2.5523 - val_accuracy: 0.6733 - val_loss: 1.5468 - learning_rate: 2.5312e-06
Epoch 168/300
1413/1413 - 216s - 153ms/step - accuracy: 0.4623 - loss: 2.4975 - val_accuracy: 0.6741 - val_loss: 1.5376 - learning_rate: 2.5312e-06
Epoch 169/300
1413/1413 - 220s - 156ms/step - accuracy: 0.4556 - loss: 2.5319 - val_accuracy: 0.6701 - val_loss: 1.5442 - learning_rate: 2.5312e-06
Epoch 170/300
1413/1413 - 227s - 161ms/step - accuracy: 0.4605 - loss: 2.5360 - val_accuracy: 0.6813 - val_loss: 1.5312 - learning_rate: 2.5312e-06
Epoch 171/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4591 - loss: 2.5250 - val_accuracy: 0.6781 - val_loss: 1.5332 - learning_rate: 2.5312e-06
Epoch 172/300
1413/1413 - 223s - 158ms/step - accuracy: 0.4564 - loss: 2.5363 - val_accuracy: 0.6813 - val_loss: 1.5355 - learning_rate: 2.5312e-06
Epoch 173/300
1413/1413 - 230s - 163ms/step - accuracy: 0.4512 - loss: 2.5510 - val_accuracy: 0.6789 - val_loss: 1.5313 - learning_rate: 2.5312e-06
Epoch 174/300
1413/1413 - 231s - 163ms/step - accuracy: 0.4581 - loss: 2.5764 - val_accuracy: 0.6845 - val_loss: 1.5151 - learning_rate: 2.5312e-06
Epoch 175/300
1413/1413 - 227s - 161ms/step - accuracy: 0.4513 - loss: 2.5409 - val_accuracy: 0.6765 - val_loss: 1.5103 - learning_rate: 2.5312e-06
Epoch 176/300
1413/1413 - 230s - 163ms/step - accuracy: 0.4590 - loss: 2.5426 - val_accuracy: 0.6773 - val_loss: 1.5284 - learning_rate: 2.5312e-06
Epoch 177/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4451 - loss: 2.5957 - val_accuracy: 0.6781 - val_loss: 1.5139 - learning_rate: 2.5312e-06
Epoch 178/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4566 - loss: 2.5319 - val_accuracy: 0.6741 - val_loss: 1.5294 - learning_rate: 2.5312e-06
Epoch 179/300
1413/1413 - 225s - 159ms/step - accuracy: 0.4580 - loss: 2.5443 - val_accuracy: 0.6773 - val_loss: 1.5237 - learning_rate: 2.5312e-06
Epoch 180/300
1413/1413 - 224s - 159ms/step - accuracy: 0.4519 - loss: 2.5389 - val_accuracy: 0.6773 - val_loss: 1.5370 - learning_rate: 2.5312e-06
Epoch 181/300
1413/1413 - 228s - 161ms/step - accuracy: 0.4608 - loss: 2.5401 - val_accuracy: 0.6773 - val_loss: 1.5198 - learning_rate: 2.5312e-06
Epoch 182/300
1413/1413 - 226s - 160ms/step - accuracy: 0.4515 - loss: 2.5643 - val_accuracy: 0.6805 - val_loss: 1.5169 - learning_rate: 2.5312e-06
Epoch 183/300

Epoch 183: ReduceLROnPlateau reducing learning rate to 1.265596438315697e-06.
1413/1413 - 227s - 161ms/step - accuracy: 0.4579 - loss: 2.5351 - val_accuracy: 0.6741 - val_loss: 1.5358 - learning_rate: 2.5312e-06
Epoch 184/300
1413/1413 - 224s - 159ms/step - accuracy: 0.4574 - loss: 2.5362 - val_accuracy: 0.6789 - val_loss: 1.5255 - learning_rate: 1.2656e-06
Epoch 185/300
1413/1413 - 228s - 162ms/step - accuracy: 0.4573 - loss: 2.5464 - val_accuracy: 0.6765 - val_loss: 1.5316 - learning_rate: 1.2656e-06
Epoch 186/300
1413/1413 - 227s - 161ms/step - accuracy: 0.4659 - loss: 2.5104 - val_accuracy: 0.6741 - val_loss: 1.5365 - learning_rate: 1.2656e-06
Epoch 187/300
1413/1413 - 227s - 161ms/step - accuracy: 0.4649 - loss: 2.5031 - val_accuracy: 0.6757 - val_loss: 1.5267 - learning_rate: 1.2656e-06
Epoch 188/300
1413/1413 - 230s - 163ms/step - accuracy: 0.4603 - loss: 2.5411 - val_accuracy: 0.6733 - val_loss: 1.5236 - learning_rate: 1.2656e-06
Epoch 189/300
1413/1413 - 227s - 161ms/step - accuracy: 0.4537 - loss: 2.5636 - val_accuracy: 0.6741 - val_loss: 1.5369 - learning_rate: 1.2656e-06
Epoch 190/300
1413/1413 - 230s - 163ms/step - accuracy: 0.4607 - loss: 2.5297 - val_accuracy: 0.6797 - val_loss: 1.5430 - learning_rate: 1.2656e-06
Epoch 191/300

Epoch 191: ReduceLROnPlateau reducing learning rate to 1e-06.
1413/1413 - 226s - 160ms/step - accuracy: 0.4561 - loss: 2.5191 - val_accuracy: 0.6813 - val_loss: 1.5223 - learning_rate: 1.2656e-06
Epoch 191: early stopping
Restoring model weights from the end of the best epoch: 175.
Fold 9 Evaluation results: [1.5164860486984253, 0.6764940023422241]
              precision    recall  f1-score   support

        1820       0.81      0.84      0.83        62
        1821       0.84      0.89      0.86        57
        1822       0.00      0.00      0.00         1
        1823       0.00      0.00      0.00         1
        1824       0.00      0.00      0.00         1
        1825       0.00      0.00      0.00         2
        1826       0.00      0.00      0.00         2
        1827       0.87      0.80      0.83        25
        1828       1.00      0.50      0.67         2
        1829       0.67      1.00      0.80         4
        1830       0.78      0.68      0.72        56
        1831       0.88      0.87      0.88       134
        1832       0.67      0.75      0.71        68
        1833       0.86      0.95      0.90        19
        1834       0.51      0.76      0.61        29
        1835       0.00      0.00      0.00         2
        1836       0.00      0.00      0.00         4
        1837       0.13      0.33      0.19         6
        1838       0.67      0.50      0.57         4
        1839       0.00      0.00      0.00         1
        1840       0.71      0.63      0.67        43
        1841       0.76      0.68      0.72       107
        1842       0.57      0.67      0.62         6
        1843       0.67      0.40      0.50         5
        1844       0.00      0.00      0.00         0
        1845       0.00      0.00      0.00         1
        1846       0.43      0.50      0.46         6
        1847       1.00      0.50      0.67         2
        1848       0.67      0.40      0.50         5
        1849       0.29      0.33      0.31         6
        1850       0.57      0.73      0.64        48
        1851       0.75      0.82      0.78        77
        1852       0.33      0.14      0.20         7
        1853       0.00      0.00      0.00         7
        1854       0.20      0.33      0.25         3
        1855       0.79      0.48      0.59        23
        1856       0.80      0.33      0.47        12
        1857       0.62      0.77      0.69        30
        1858       0.00      0.00      0.00         2
        1859       0.00      0.00      0.00         2
        1860       0.51      0.43      0.47        65
        1861       0.83      0.76      0.80        85
        1862       0.41      0.63      0.50        19
        1863       0.52      0.58      0.55        19
        1864       0.42      0.65      0.51        17
        1865       0.22      0.29      0.25         7
        1866       0.33      0.17      0.22         6
        1867       0.29      0.55      0.38        11
        1868       0.00      0.00      0.00         7
        1869       0.00      0.00      0.00         5
        1870       0.60      0.58      0.59        31
        1871       0.75      0.80      0.77        49
        1872       0.67      0.57      0.62         7
        1873       0.31      0.40      0.35        10
        1874       0.60      0.60      0.60         5
        1875       0.60      0.21      0.32        14
        1876       0.80      0.80      0.80        10
        1877       0.20      0.20      0.20         5
        1878       0.23      0.33      0.27         9
        1879       0.00      0.00      0.00         2

    accuracy                           0.68      1255
   macro avg       0.44      0.42      0.41      1255
weighted avg       0.68      0.68      0.67      1255

Matthews Correlation Coefficient: 0.661
Macro avg F1: 0.414
Weighted avg F1: 0.670
Micro avg F1: 0.676
Top-3 Accuracy: 0.876
Top-5 Accuracy: 0.921
Micro ROC AUC  = 0.99
Macro ROC AUC (present classes) = 0.98
Classification MAE (in years): 2.84

Fold 9 Misclassification Analysis:
Near misses (within 2 years): 115 out of 406 misclassifications (28.33%)
Big misses (greater than 10 years): 183
MAE with outliers: 2.84
MAE without outliers: 1.78 (improvement: 1.06)

10 Worst misclassifications:
Image: data/datasets/public/1820/1826_6washington.jpg, True: 1826, Predicted: 1876, Error: 50
Image: data/datasets/private/1870/1871_26etsy.jpg, True: 1871, Predicted: 1821, Error: 50
Image: data/datasets/public/1820/1820_22wikimedia2.jpg, True: 1820, Predicted: 1870, Error: 50
Image: data/datasets/public/1870/1878_470vna.jpg, True: 1878, Predicted: 1832, Error: 46
Image: data/datasets/private/1820/1820_179etsy.jpg, True: 1820, Predicted: 1863, Error: 43
Image: data/datasets/public/1860/1860_055met.jpg, True: 1860, Predicted: 1820, Error: 40
Image: data/datasets/private/1820/1821_504etsy.jpg, True: 1821, Predicted: 1861, Error: 40
Image: data/datasets/public/1860/1860_1483vna.jpg, True: 1860, Predicted: 1820, Error: 40
Image: data/datasets/public/1870/1870_73wikimedia2.jpg, True: 1870, Predicted: 1830, Error: 40
Image: data/datasets/private/1860/1860_31et.jpg, True: 1860, Predicted: 1820, Error: 40

Mean MAE over all folds: 2.9077  0.2349
Mean accuracy over all folds: 0.6641  0.0166
Mean Matthews Correlation Coefficient: 0.6474  0.0175

=== Total running time: 90 hours, 7 minutes, 38 seconds ===

