Using model: NASNetMobile.
TensorFlow Version: 2.19.0
Num GPUs Available: 1
Using GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')
Test fold: 3
model_name: NASNetMobile
input_shape: (224, 224, 3)
Epoch 1/100
707/707 - 178s - 252ms/step - accuracy: 0.3122 - loss: 4.1686 - val_accuracy: 0.2771 - val_loss: 4.2040 - learning_rate: 0.0100
Epoch 2/100
707/707 - 114s - 161ms/step - accuracy: 0.3491 - loss: 4.6374 - val_accuracy: 0.3400 - val_loss: 4.2083 - learning_rate: 0.0100
Epoch 3/100
707/707 - 107s - 151ms/step - accuracy: 0.3800 - loss: 4.5857 - val_accuracy: 0.3041 - val_loss: 5.2307 - learning_rate: 0.0100
Epoch 4/100
707/707 - 101s - 143ms/step - accuracy: 0.3830 - loss: 4.9193 - val_accuracy: 0.3798 - val_loss: 4.6121 - learning_rate: 0.0100
Epoch 5/100
707/707 - 105s - 148ms/step - accuracy: 0.3788 - loss: 4.9926 - val_accuracy: 0.3877 - val_loss: 4.3407 - learning_rate: 0.0100
Epoch 6/100

Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.
707/707 - 100s - 142ms/step - accuracy: 0.3964 - loss: 4.9628 - val_accuracy: 0.3726 - val_loss: 4.5847 - learning_rate: 0.0100
Epoch 7/100
707/707 - 105s - 148ms/step - accuracy: 0.4249 - loss: 4.0970 - val_accuracy: 0.4467 - val_loss: 3.4154 - learning_rate: 1.0000e-03
Epoch 8/100
707/707 - 107s - 151ms/step - accuracy: 0.4415 - loss: 3.8933 - val_accuracy: 0.4379 - val_loss: 3.3226 - learning_rate: 1.0000e-03
Epoch 9/100
707/707 - 107s - 152ms/step - accuracy: 0.4480 - loss: 3.5154 - val_accuracy: 0.4546 - val_loss: 3.2479 - learning_rate: 1.0000e-03
Epoch 10/100
707/707 - 108s - 153ms/step - accuracy: 0.4471 - loss: 3.4409 - val_accuracy: 0.4347 - val_loss: 3.3085 - learning_rate: 1.0000e-03
Epoch 11/100
707/707 - 105s - 148ms/step - accuracy: 0.4564 - loss: 3.2287 - val_accuracy: 0.4172 - val_loss: 3.3195 - learning_rate: 1.0000e-03
Epoch 12/100
707/707 - 103s - 146ms/step - accuracy: 0.4668 - loss: 3.0983 - val_accuracy: 0.4475 - val_loss: 3.0209 - learning_rate: 1.0000e-03
Epoch 13/100
707/707 - 99s - 140ms/step - accuracy: 0.4685 - loss: 3.0434 - val_accuracy: 0.4435 - val_loss: 3.1564 - learning_rate: 1.0000e-03
Epoch 14/100
707/707 - 103s - 145ms/step - accuracy: 0.4847 - loss: 2.8926 - val_accuracy: 0.4419 - val_loss: 3.1017 - learning_rate: 1.0000e-03
Epoch 15/100
707/707 - 100s - 141ms/step - accuracy: 0.4782 - loss: 2.8761 - val_accuracy: 0.4315 - val_loss: 2.8264 - learning_rate: 1.0000e-03
Epoch 16/100
707/707 - 151s - 213ms/step - accuracy: 0.4763 - loss: 2.7508 - val_accuracy: 0.4435 - val_loss: 3.0988 - learning_rate: 1.0000e-03
Epoch 17/100
707/707 - 105s - 149ms/step - accuracy: 0.4792 - loss: 2.7401 - val_accuracy: 0.4578 - val_loss: 2.8344 - learning_rate: 1.0000e-03
Epoch 18/100
707/707 - 117s - 166ms/step - accuracy: 0.4830 - loss: 2.6475 - val_accuracy: 0.4666 - val_loss: 2.6940 - learning_rate: 1.0000e-03
Epoch 19/100
707/707 - 128s - 181ms/step - accuracy: 0.4823 - loss: 2.6023 - val_accuracy: 0.4506 - val_loss: 2.8134 - learning_rate: 1.0000e-03
Epoch 20/100
707/707 - 120s - 170ms/step - accuracy: 0.4941 - loss: 2.5232 - val_accuracy: 0.4283 - val_loss: 2.9307 - learning_rate: 1.0000e-03
Epoch 21/100
707/707 - 119s - 168ms/step - accuracy: 0.4995 - loss: 2.4340 - val_accuracy: 0.4427 - val_loss: 2.8797 - learning_rate: 1.0000e-03
Epoch 22/100
707/707 - 119s - 168ms/step - accuracy: 0.4941 - loss: 2.4132 - val_accuracy: 0.4618 - val_loss: 2.8127 - learning_rate: 1.0000e-03
Epoch 23/100

Epoch 23: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.
707/707 - 121s - 171ms/step - accuracy: 0.5012 - loss: 2.3199 - val_accuracy: 0.4475 - val_loss: 2.8689 - learning_rate: 1.0000e-03
Epoch 24/100
707/707 - 125s - 177ms/step - accuracy: 0.4949 - loss: 2.3179 - val_accuracy: 0.4610 - val_loss: 2.7752 - learning_rate: 1.0000e-04
Epoch 25/100
707/707 - 123s - 173ms/step - accuracy: 0.4846 - loss: 2.4558 - val_accuracy: 0.4745 - val_loss: 2.6588 - learning_rate: 1.0000e-04
Epoch 26/100
707/707 - 121s - 171ms/step - accuracy: 0.4995 - loss: 2.2742 - val_accuracy: 0.4697 - val_loss: 2.6817 - learning_rate: 1.0000e-04
Epoch 27/100
707/707 - 108s - 152ms/step - accuracy: 0.5047 - loss: 2.2408 - val_accuracy: 0.4705 - val_loss: 2.6637 - learning_rate: 1.0000e-04
Epoch 28/100
707/707 - 103s - 146ms/step - accuracy: 0.4909 - loss: 2.3331 - val_accuracy: 0.4753 - val_loss: 2.6325 - learning_rate: 1.0000e-04
Epoch 29/100
707/707 - 112s - 159ms/step - accuracy: 0.4987 - loss: 2.3139 - val_accuracy: 0.4705 - val_loss: 2.5842 - learning_rate: 1.0000e-04
Epoch 30/100
707/707 - 115s - 163ms/step - accuracy: 0.5046 - loss: 2.2099 - val_accuracy: 0.4642 - val_loss: 2.6101 - learning_rate: 1.0000e-04
Epoch 31/100
707/707 - 121s - 170ms/step - accuracy: 0.4983 - loss: 2.2836 - val_accuracy: 0.4729 - val_loss: 2.6009 - learning_rate: 1.0000e-04
Epoch 32/100
707/707 - 124s - 176ms/step - accuracy: 0.4948 - loss: 2.2215 - val_accuracy: 0.4705 - val_loss: 2.6145 - learning_rate: 1.0000e-04
Epoch 33/100
707/707 - 121s - 172ms/step - accuracy: 0.5054 - loss: 2.1893 - val_accuracy: 0.4737 - val_loss: 2.6061 - learning_rate: 1.0000e-04
Epoch 34/100
707/707 - 122s - 172ms/step - accuracy: 0.5023 - loss: 2.2398 - val_accuracy: 0.4785 - val_loss: 2.5677 - learning_rate: 1.0000e-04
Epoch 35/100
707/707 - 122s - 173ms/step - accuracy: 0.5033 - loss: 2.2680 - val_accuracy: 0.4713 - val_loss: 2.5016 - learning_rate: 1.0000e-04
Epoch 36/100
707/707 - 116s - 164ms/step - accuracy: 0.5107 - loss: 2.2114 - val_accuracy: 0.4825 - val_loss: 2.5061 - learning_rate: 1.0000e-04
Epoch 37/100
707/707 - 115s - 162ms/step - accuracy: 0.4991 - loss: 2.1932 - val_accuracy: 0.4777 - val_loss: 2.5101 - learning_rate: 1.0000e-04
Epoch 38/100
707/707 - 119s - 169ms/step - accuracy: 0.5083 - loss: 2.1625 - val_accuracy: 0.4753 - val_loss: 2.5061 - learning_rate: 1.0000e-04
Epoch 39/100
707/707 - 121s - 171ms/step - accuracy: 0.5128 - loss: 2.1670 - val_accuracy: 0.4721 - val_loss: 2.5536 - learning_rate: 1.0000e-04
Epoch 40/100

Epoch 40: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.
707/707 - 123s - 173ms/step - accuracy: 0.5061 - loss: 2.1806 - val_accuracy: 0.4729 - val_loss: 2.5229 - learning_rate: 1.0000e-04
Epoch 41/100
707/707 - 124s - 175ms/step - accuracy: 0.5102 - loss: 2.1635 - val_accuracy: 0.4761 - val_loss: 2.5148 - learning_rate: 1.0000e-05
Epoch 42/100
707/707 - 122s - 173ms/step - accuracy: 0.5141 - loss: 2.1763 - val_accuracy: 0.4793 - val_loss: 2.5109 - learning_rate: 1.0000e-05
Epoch 43/100
707/707 - 119s - 168ms/step - accuracy: 0.5059 - loss: 2.1839 - val_accuracy: 0.4761 - val_loss: 2.5095 - learning_rate: 1.0000e-05
Epoch 44/100
707/707 - 117s - 165ms/step - accuracy: 0.5105 - loss: 2.1587 - val_accuracy: 0.4777 - val_loss: 2.5091 - learning_rate: 1.0000e-05
Epoch 45/100

Epoch 45: ReduceLROnPlateau reducing learning rate to 1e-06.
707/707 - 114s - 161ms/step - accuracy: 0.5020 - loss: 2.2144 - val_accuracy: 0.4801 - val_loss: 2.5050 - learning_rate: 1.0000e-05
Epoch 45: early stopping
Restoring model weights from the end of the best epoch: 35.
Fold 3 Evaluation results: [2.5016183853149414, 0.47133758664131165]
1/1 - 12s - 12s/step
1/1 - 0s - 136ms/step
1/1 - 0s - 139ms/step
1/1 - 0s - 138ms/step
1/1 - 0s - 135ms/step
1/1 - 0s - 131ms/step
1/1 - 0s - 137ms/step
1/1 - 0s - 138ms/step
1/1 - 0s - 144ms/step
1/1 - 0s - 134ms/step
1/1 - 0s - 138ms/step
1/1 - 0s - 139ms/step
1/1 - 0s - 137ms/step
1/1 - 0s - 140ms/step
1/1 - 0s - 136ms/step
1/1 - 0s - 134ms/step
1/1 - 0s - 137ms/step
1/1 - 0s - 147ms/step
1/1 - 0s - 144ms/step
1/1 - 0s - 136ms/step
1/1 - 0s - 143ms/step
1/1 - 0s - 142ms/step
1/1 - 0s - 136ms/step
1/1 - 0s - 138ms/step
1/1 - 0s - 138ms/step
1/1 - 0s - 135ms/step
1/1 - 0s - 136ms/step
1/1 - 0s - 138ms/step
1/1 - 0s - 134ms/step
1/1 - 0s - 138ms/step
1/1 - 0s - 136ms/step
1/1 - 0s - 137ms/step
1/1 - 0s - 135ms/step
1/1 - 0s - 136ms/step
1/1 - 0s - 141ms/step
1/1 - 0s - 139ms/step
1/1 - 0s - 140ms/step
1/1 - 0s - 155ms/step
1/1 - 0s - 139ms/step
1/1 - 0s - 147ms/step
1/1 - 0s - 133ms/step
1/1 - 0s - 137ms/step
1/1 - 0s - 142ms/step
1/1 - 0s - 136ms/step
1/1 - 0s - 135ms/step
1/1 - 0s - 146ms/step
1/1 - 0s - 146ms/step
1/1 - 0s - 142ms/step
1/1 - 0s - 146ms/step
1/1 - 0s - 140ms/step
1/1 - 0s - 139ms/step
1/1 - 0s - 139ms/step
1/1 - 0s - 134ms/step
1/1 - 0s - 129ms/step
1/1 - 0s - 131ms/step
1/1 - 0s - 134ms/step
1/1 - 0s - 132ms/step
1/1 - 0s - 130ms/step
1/1 - 0s - 134ms/step
1/1 - 0s - 134ms/step
1/1 - 0s - 134ms/step
1/1 - 0s - 131ms/step
1/1 - 0s - 132ms/step
1/1 - 0s - 137ms/step
1/1 - 0s - 134ms/step
1/1 - 0s - 133ms/step
1/1 - 0s - 129ms/step
1/1 - 0s - 145ms/step
1/1 - 0s - 138ms/step
1/1 - 0s - 144ms/step
1/1 - 0s - 146ms/step
1/1 - 0s - 150ms/step
1/1 - 0s - 143ms/step
1/1 - 0s - 134ms/step
1/1 - 0s - 135ms/step
1/1 - 0s - 139ms/step
1/1 - 0s - 139ms/step
1/1 - 0s - 139ms/step
1/1 - 10s - 10s/step
              precision    recall  f1-score   support

        1820       0.60      0.52      0.56        62
        1821       0.69      0.72      0.71        57
        1822       0.00      0.00      0.00         1
        1823       0.00      0.00      0.00         2
        1824       0.00      0.00      0.00         1
        1825       0.00      0.00      0.00         2
        1826       0.00      0.00      0.00         3
        1827       0.60      0.36      0.45        25
        1828       0.00      0.00      0.00         2
        1829       1.00      0.20      0.33         5
        1830       0.41      0.57      0.47        56
        1831       0.61      0.77      0.68       134
        1832       0.63      0.69      0.66        68
        1833       1.00      0.47      0.64        19
        1834       0.49      0.70      0.58        30
        1835       0.00      0.00      0.00         2
        1836       0.00      0.00      0.00         3
        1837       1.00      0.14      0.25         7
        1838       0.00      0.00      0.00         4
        1839       0.00      0.00      0.00         1
        1840       0.35      0.56      0.43        43
        1841       0.47      0.36      0.41       108
        1842       0.00      0.00      0.00         5
        1843       0.00      0.00      0.00         6
        1844       0.00      0.00      0.00         0
        1845       0.00      0.00      0.00         1
        1846       0.00      0.00      0.00         5
        1847       0.00      0.00      0.00         2
        1848       0.00      0.00      0.00         6
        1849       0.00      0.00      0.00         5
        1850       0.35      0.49      0.41        47
        1851       0.55      0.70      0.61        77
        1852       0.00      0.00      0.00         7
        1853       0.00      0.00      0.00         6
        1854       0.00      0.00      0.00         2
        1855       0.00      0.00      0.00        23
        1856       0.75      0.25      0.38        12
        1857       0.36      0.45      0.40        31
        1858       0.00      0.00      0.00         2
        1859       0.00      0.00      0.00         3
        1860       0.22      0.52      0.31        64
        1861       0.51      0.59      0.55        85
        1862       0.25      0.11      0.15        19
        1863       0.25      0.06      0.09        18
        1864       0.40      0.24      0.30        17
        1865       0.00      0.00      0.00         6
        1866       0.00      0.00      0.00         6
        1867       0.00      0.00      0.00        10
        1868       0.00      0.00      0.00         8
        1869       0.00      0.00      0.00         5
        1870       0.33      0.30      0.32        30
        1871       0.45      0.64      0.53        50
        1872       0.00      0.00      0.00         7
        1873       0.00      0.00      0.00        11
        1874       0.50      0.20      0.29         5
        1875       0.50      0.14      0.22        14
        1876       0.50      0.50      0.50        10
        1877       0.00      0.00      0.00         6
        1878       0.00      0.00      0.00         9
        1879       0.00      0.00      0.00         1

    accuracy                           0.47      1256
   macro avg       0.23      0.19      0.19      1256
weighted avg       0.44      0.47      0.44      1256

Macro avg F1: 0.187
Weighted avg F1: 0.437
Micro avg F1: 0.471
Top-3 Accuracy: 0.722
Top-5 Accuracy: 0.798
Classification MAE (in years): 5.57
Micro ROC AUC  = 0.95
Macro ROC AUC (present classes) = 0.92
Metrics: {'mae': 2.5016183853149414, 'accuracy': 0.47133758664131165}
Total running time: 1 hours, 28 minutes, 19 seconds
