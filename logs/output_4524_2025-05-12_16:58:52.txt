TensorFlow Version: 2.20.0-dev20250508
Num GPUs Available: 1
Using GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')

=== Using model: InceptionV3. ===
RUN ID: 2025-05-12_16:58:57

===== Fold 0 =====

===== Fine Tuning 7 layers! =====
Epoch 1/300
1413/1413 - 165s - 116ms/step - accuracy: 0.1927 - loss: 4.0268 - val_accuracy: 0.3344 - val_loss: 3.3708 - learning_rate: 6.8751e-04
Epoch 2/300
1413/1413 - 100s - 71ms/step - accuracy: 0.2720 - loss: 3.5308 - val_accuracy: 0.3981 - val_loss: 2.8880 - learning_rate: 6.8751e-04
Epoch 3/300
1413/1413 - 98s - 69ms/step - accuracy: 0.3001 - loss: 3.3622 - val_accuracy: 0.4554 - val_loss: 2.6941 - learning_rate: 6.8751e-04
Epoch 4/300
1413/1413 - 94s - 67ms/step - accuracy: 0.3304 - loss: 3.2289 - val_accuracy: 0.4379 - val_loss: 2.5684 - learning_rate: 6.8751e-04
Epoch 5/300
1413/1413 - 96s - 68ms/step - accuracy: 0.3443 - loss: 3.1841 - val_accuracy: 0.4697 - val_loss: 2.6307 - learning_rate: 6.8751e-04
Epoch 6/300
1413/1413 - 97s - 69ms/step - accuracy: 0.3437 - loss: 3.1202 - val_accuracy: 0.4944 - val_loss: 2.5063 - learning_rate: 6.8751e-04
Epoch 7/300
1413/1413 - 96s - 68ms/step - accuracy: 0.3589 - loss: 3.0858 - val_accuracy: 0.4952 - val_loss: 2.4394 - learning_rate: 6.8751e-04
Epoch 8/300
1413/1413 - 97s - 69ms/step - accuracy: 0.3613 - loss: 3.0518 - val_accuracy: 0.4817 - val_loss: 2.4580 - learning_rate: 6.8751e-04
Epoch 9/300
1413/1413 - 88s - 62ms/step - accuracy: 0.3711 - loss: 3.0200 - val_accuracy: 0.5183 - val_loss: 2.3148 - learning_rate: 6.8751e-04
Epoch 10/300
1413/1413 - 90s - 63ms/step - accuracy: 0.3731 - loss: 2.9898 - val_accuracy: 0.5199 - val_loss: 2.2993 - learning_rate: 6.8751e-04
Epoch 11/300
1413/1413 - 80s - 56ms/step - accuracy: 0.3780 - loss: 2.9798 - val_accuracy: 0.5311 - val_loss: 2.2915 - learning_rate: 6.8751e-04
Epoch 12/300
1413/1413 - 90s - 63ms/step - accuracy: 0.3800 - loss: 2.9484 - val_accuracy: 0.5024 - val_loss: 2.2802 - learning_rate: 6.8751e-04
Epoch 13/300
1413/1413 - 87s - 61ms/step - accuracy: 0.3795 - loss: 2.9557 - val_accuracy: 0.5271 - val_loss: 2.3191 - learning_rate: 6.8751e-04
Epoch 14/300
1413/1413 - 92s - 65ms/step - accuracy: 0.3885 - loss: 2.9330 - val_accuracy: 0.5088 - val_loss: 2.2229 - learning_rate: 6.8751e-04
Epoch 15/300
1413/1413 - 96s - 68ms/step - accuracy: 0.3870 - loss: 2.9201 - val_accuracy: 0.5334 - val_loss: 2.2465 - learning_rate: 6.8751e-04
Epoch 16/300
1413/1413 - 97s - 68ms/step - accuracy: 0.3927 - loss: 2.8966 - val_accuracy: 0.5151 - val_loss: 2.2921 - learning_rate: 6.8751e-04
Epoch 17/300
1413/1413 - 95s - 67ms/step - accuracy: 0.3890 - loss: 2.8974 - val_accuracy: 0.5390 - val_loss: 2.1582 - learning_rate: 6.8751e-04
Epoch 18/300
1413/1413 - 95s - 68ms/step - accuracy: 0.3868 - loss: 2.8926 - val_accuracy: 0.5366 - val_loss: 2.4170 - learning_rate: 6.8751e-04
Epoch 19/300
1413/1413 - 98s - 70ms/step - accuracy: 0.3964 - loss: 2.8668 - val_accuracy: 0.5406 - val_loss: 2.1501 - learning_rate: 6.8751e-04
Epoch 20/300
1413/1413 - 98s - 69ms/step - accuracy: 0.3984 - loss: 2.8393 - val_accuracy: 0.5311 - val_loss: 2.1421 - learning_rate: 6.8751e-04
Epoch 21/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4015 - loss: 2.8521 - val_accuracy: 0.5541 - val_loss: 2.1661 - learning_rate: 6.8751e-04
Epoch 22/300
1413/1413 - 95s - 68ms/step - accuracy: 0.4003 - loss: 2.8456 - val_accuracy: 0.5462 - val_loss: 2.1333 - learning_rate: 6.8751e-04
Epoch 23/300
1413/1413 - 96s - 68ms/step - accuracy: 0.3977 - loss: 2.8488 - val_accuracy: 0.5589 - val_loss: 2.1662 - learning_rate: 6.8751e-04
Epoch 24/300
1413/1413 - 97s - 68ms/step - accuracy: 0.3987 - loss: 2.8575 - val_accuracy: 0.5541 - val_loss: 2.1141 - learning_rate: 6.8751e-04
Epoch 25/300
1413/1413 - 95s - 68ms/step - accuracy: 0.4071 - loss: 2.8189 - val_accuracy: 0.5454 - val_loss: 2.1911 - learning_rate: 6.8751e-04
Epoch 26/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4097 - loss: 2.8010 - val_accuracy: 0.5446 - val_loss: 2.1610 - learning_rate: 6.8751e-04
Epoch 27/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4078 - loss: 2.8007 - val_accuracy: 0.5438 - val_loss: 2.1281 - learning_rate: 6.8751e-04
Epoch 28/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4051 - loss: 2.8113 - val_accuracy: 0.5382 - val_loss: 2.2047 - learning_rate: 6.8751e-04
Epoch 29/300
1413/1413 - 94s - 66ms/step - accuracy: 0.4158 - loss: 2.7852 - val_accuracy: 0.5470 - val_loss: 2.2146 - learning_rate: 6.8751e-04
Epoch 30/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4171 - loss: 2.7830 - val_accuracy: 0.5621 - val_loss: 2.0643 - learning_rate: 6.8751e-04
Epoch 31/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4099 - loss: 2.8094 - val_accuracy: 0.5589 - val_loss: 2.1440 - learning_rate: 6.8751e-04
Epoch 32/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4117 - loss: 2.7767 - val_accuracy: 0.5350 - val_loss: 2.0937 - learning_rate: 6.8751e-04
Epoch 33/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4133 - loss: 2.7942 - val_accuracy: 0.5637 - val_loss: 2.0585 - learning_rate: 6.8751e-04
Epoch 34/300
1413/1413 - 94s - 66ms/step - accuracy: 0.4195 - loss: 2.7855 - val_accuracy: 0.5685 - val_loss: 2.0317 - learning_rate: 6.8751e-04
Epoch 35/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4132 - loss: 2.7746 - val_accuracy: 0.5502 - val_loss: 2.1292 - learning_rate: 6.8751e-04
Epoch 36/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4191 - loss: 2.7680 - val_accuracy: 0.5605 - val_loss: 2.1473 - learning_rate: 6.8751e-04
Epoch 37/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4063 - loss: 2.8073 - val_accuracy: 0.5207 - val_loss: 2.1707 - learning_rate: 6.8751e-04
Epoch 38/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4138 - loss: 2.7796 - val_accuracy: 0.5669 - val_loss: 2.0547 - learning_rate: 6.8751e-04
Epoch 39/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4174 - loss: 2.7655 - val_accuracy: 0.5502 - val_loss: 2.1045 - learning_rate: 6.8751e-04
Epoch 40/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4198 - loss: 2.7448 - val_accuracy: 0.5812 - val_loss: 2.0168 - learning_rate: 6.8751e-04
Epoch 41/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4147 - loss: 2.7624 - val_accuracy: 0.5653 - val_loss: 1.9806 - learning_rate: 6.8751e-04
Epoch 42/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4227 - loss: 2.7387 - val_accuracy: 0.5589 - val_loss: 2.0357 - learning_rate: 6.8751e-04
Epoch 43/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4186 - loss: 2.7267 - val_accuracy: 0.5693 - val_loss: 2.0431 - learning_rate: 6.8751e-04
Epoch 44/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4263 - loss: 2.7401 - val_accuracy: 0.5589 - val_loss: 2.1330 - learning_rate: 6.8751e-04
Epoch 45/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4212 - loss: 2.7280 - val_accuracy: 0.5772 - val_loss: 1.9994 - learning_rate: 6.8751e-04
Epoch 46/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4256 - loss: 2.7163 - val_accuracy: 0.5462 - val_loss: 2.1218 - learning_rate: 6.8751e-04
Epoch 47/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4214 - loss: 2.7466 - val_accuracy: 0.5804 - val_loss: 2.0610 - learning_rate: 6.8751e-04
Epoch 48/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4207 - loss: 2.7499 - val_accuracy: 0.5876 - val_loss: 2.0410 - learning_rate: 6.8751e-04
Epoch 49/300

Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0003437538689468056.
1413/1413 - 98s - 69ms/step - accuracy: 0.4165 - loss: 2.7560 - val_accuracy: 0.5796 - val_loss: 2.0191 - learning_rate: 6.8751e-04
Epoch 50/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4387 - loss: 2.6409 - val_accuracy: 0.5804 - val_loss: 2.0207 - learning_rate: 3.4375e-04
Epoch 51/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4413 - loss: 2.6325 - val_accuracy: 0.5979 - val_loss: 1.9220 - learning_rate: 3.4375e-04
Epoch 52/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4358 - loss: 2.6419 - val_accuracy: 0.5939 - val_loss: 1.9906 - learning_rate: 3.4375e-04
Epoch 53/300
1413/1413 - 94s - 66ms/step - accuracy: 0.4394 - loss: 2.6218 - val_accuracy: 0.5963 - val_loss: 1.8784 - learning_rate: 3.4375e-04
Epoch 54/300
1413/1413 - 89s - 63ms/step - accuracy: 0.4476 - loss: 2.5713 - val_accuracy: 0.5987 - val_loss: 1.9001 - learning_rate: 3.4375e-04
Epoch 55/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4464 - loss: 2.6167 - val_accuracy: 0.6011 - val_loss: 1.9442 - learning_rate: 3.4375e-04
Epoch 56/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4461 - loss: 2.6139 - val_accuracy: 0.6051 - val_loss: 1.9393 - learning_rate: 3.4375e-04
Epoch 57/300
1413/1413 - 94s - 66ms/step - accuracy: 0.4470 - loss: 2.5936 - val_accuracy: 0.5876 - val_loss: 1.9294 - learning_rate: 3.4375e-04
Epoch 58/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4432 - loss: 2.5965 - val_accuracy: 0.5892 - val_loss: 1.9371 - learning_rate: 3.4375e-04
Epoch 59/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4432 - loss: 2.6062 - val_accuracy: 0.5932 - val_loss: 1.9126 - learning_rate: 3.4375e-04
Epoch 60/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4493 - loss: 2.5768 - val_accuracy: 0.5844 - val_loss: 1.9367 - learning_rate: 3.4375e-04
Epoch 61/300

Epoch 61: ReduceLROnPlateau reducing learning rate to 0.0001718769344734028.
1413/1413 - 93s - 66ms/step - accuracy: 0.4492 - loss: 2.5652 - val_accuracy: 0.5868 - val_loss: 1.9528 - learning_rate: 3.4375e-04
Epoch 62/300
1413/1413 - 95s - 68ms/step - accuracy: 0.4602 - loss: 2.5524 - val_accuracy: 0.5860 - val_loss: 1.9015 - learning_rate: 1.7188e-04
Epoch 63/300
1413/1413 - 94s - 66ms/step - accuracy: 0.4523 - loss: 2.5367 - val_accuracy: 0.6091 - val_loss: 1.8705 - learning_rate: 1.7188e-04
Epoch 64/300
1413/1413 - 95s - 68ms/step - accuracy: 0.4580 - loss: 2.5312 - val_accuracy: 0.6067 - val_loss: 1.8722 - learning_rate: 1.7188e-04
Epoch 65/300
1413/1413 - 94s - 66ms/step - accuracy: 0.4589 - loss: 2.4821 - val_accuracy: 0.6091 - val_loss: 1.8450 - learning_rate: 1.7188e-04
Epoch 66/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4609 - loss: 2.5405 - val_accuracy: 0.6051 - val_loss: 1.8979 - learning_rate: 1.7188e-04
Epoch 67/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4584 - loss: 2.5189 - val_accuracy: 0.6083 - val_loss: 1.8417 - learning_rate: 1.7188e-04
Epoch 68/300
1413/1413 - 94s - 66ms/step - accuracy: 0.4694 - loss: 2.4917 - val_accuracy: 0.6091 - val_loss: 1.8926 - learning_rate: 1.7188e-04
Epoch 69/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4633 - loss: 2.4887 - val_accuracy: 0.6091 - val_loss: 1.8442 - learning_rate: 1.7188e-04
Epoch 70/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4587 - loss: 2.5197 - val_accuracy: 0.6083 - val_loss: 1.8493 - learning_rate: 1.7188e-04
Epoch 71/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4583 - loss: 2.5283 - val_accuracy: 0.6027 - val_loss: 1.9049 - learning_rate: 1.7188e-04
Epoch 72/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4602 - loss: 2.5059 - val_accuracy: 0.6059 - val_loss: 1.9051 - learning_rate: 1.7188e-04
Epoch 73/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4586 - loss: 2.5288 - val_accuracy: 0.6059 - val_loss: 1.8663 - learning_rate: 1.7188e-04
Epoch 74/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4659 - loss: 2.4830 - val_accuracy: 0.6051 - val_loss: 1.8425 - learning_rate: 1.7188e-04
Epoch 75/300

Epoch 75: ReduceLROnPlateau reducing learning rate to 8.59384672367014e-05.
1413/1413 - 96s - 68ms/step - accuracy: 0.4736 - loss: 2.4805 - val_accuracy: 0.6099 - val_loss: 1.8431 - learning_rate: 1.7188e-04
Epoch 76/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4694 - loss: 2.4570 - val_accuracy: 0.6162 - val_loss: 1.8345 - learning_rate: 8.5938e-05
Epoch 77/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4714 - loss: 2.4719 - val_accuracy: 0.6178 - val_loss: 1.8361 - learning_rate: 8.5938e-05
Epoch 78/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4633 - loss: 2.5078 - val_accuracy: 0.6242 - val_loss: 1.8282 - learning_rate: 8.5938e-05
Epoch 79/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4717 - loss: 2.4826 - val_accuracy: 0.6139 - val_loss: 1.8387 - learning_rate: 8.5938e-05
Epoch 80/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4694 - loss: 2.4768 - val_accuracy: 0.6123 - val_loss: 1.8091 - learning_rate: 8.5938e-05
Epoch 81/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4709 - loss: 2.4666 - val_accuracy: 0.6194 - val_loss: 1.8080 - learning_rate: 8.5938e-05
Epoch 82/300
1413/1413 - 95s - 68ms/step - accuracy: 0.4710 - loss: 2.4527 - val_accuracy: 0.6186 - val_loss: 1.8231 - learning_rate: 8.5938e-05
Epoch 83/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4641 - loss: 2.4740 - val_accuracy: 0.6186 - val_loss: 1.8254 - learning_rate: 8.5938e-05
Epoch 84/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4722 - loss: 2.4472 - val_accuracy: 0.6115 - val_loss: 1.8314 - learning_rate: 8.5938e-05
Epoch 85/300
1413/1413 - 98s - 69ms/step - accuracy: 0.4748 - loss: 2.4437 - val_accuracy: 0.6059 - val_loss: 1.8039 - learning_rate: 8.5938e-05
Epoch 86/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4713 - loss: 2.4392 - val_accuracy: 0.6131 - val_loss: 1.7989 - learning_rate: 8.5938e-05
Epoch 87/300
1413/1413 - 97s - 68ms/step - accuracy: 0.4682 - loss: 2.4503 - val_accuracy: 0.6139 - val_loss: 1.7960 - learning_rate: 8.5938e-05
Epoch 88/300
1413/1413 - 94s - 66ms/step - accuracy: 0.4743 - loss: 2.4518 - val_accuracy: 0.6115 - val_loss: 1.8102 - learning_rate: 8.5938e-05
Epoch 89/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4775 - loss: 2.4195 - val_accuracy: 0.6170 - val_loss: 1.8079 - learning_rate: 8.5938e-05
Epoch 90/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4725 - loss: 2.4520 - val_accuracy: 0.6226 - val_loss: 1.8208 - learning_rate: 8.5938e-05
Epoch 91/300
1413/1413 - 94s - 66ms/step - accuracy: 0.4740 - loss: 2.4363 - val_accuracy: 0.6210 - val_loss: 1.8130 - learning_rate: 8.5938e-05
Epoch 92/300
1413/1413 - 91s - 64ms/step - accuracy: 0.4671 - loss: 2.4396 - val_accuracy: 0.6067 - val_loss: 1.8055 - learning_rate: 8.5938e-05
Epoch 93/300
1413/1413 - 94s - 66ms/step - accuracy: 0.4769 - loss: 2.4430 - val_accuracy: 0.6162 - val_loss: 1.8134 - learning_rate: 8.5938e-05
Epoch 94/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4727 - loss: 2.4444 - val_accuracy: 0.6107 - val_loss: 1.8234 - learning_rate: 8.5938e-05
Epoch 95/300

Epoch 95: ReduceLROnPlateau reducing learning rate to 4.29692336183507e-05.
1413/1413 - 94s - 66ms/step - accuracy: 0.4662 - loss: 2.4464 - val_accuracy: 0.6107 - val_loss: 1.8085 - learning_rate: 8.5938e-05
Epoch 96/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4739 - loss: 2.4463 - val_accuracy: 0.6091 - val_loss: 1.8273 - learning_rate: 4.2969e-05
Epoch 97/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4716 - loss: 2.4536 - val_accuracy: 0.6067 - val_loss: 1.8118 - learning_rate: 4.2969e-05
Epoch 98/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4731 - loss: 2.4431 - val_accuracy: 0.6139 - val_loss: 1.8094 - learning_rate: 4.2969e-05
Epoch 99/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4882 - loss: 2.3947 - val_accuracy: 0.6154 - val_loss: 1.7898 - learning_rate: 4.2969e-05
Epoch 100/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4741 - loss: 2.4291 - val_accuracy: 0.6139 - val_loss: 1.8022 - learning_rate: 4.2969e-05
Epoch 101/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4772 - loss: 2.4447 - val_accuracy: 0.6139 - val_loss: 1.8262 - learning_rate: 4.2969e-05
Epoch 102/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4800 - loss: 2.4384 - val_accuracy: 0.6194 - val_loss: 1.7959 - learning_rate: 4.2969e-05
Epoch 103/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4798 - loss: 2.4389 - val_accuracy: 0.6170 - val_loss: 1.7908 - learning_rate: 4.2969e-05
Epoch 104/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4813 - loss: 2.4117 - val_accuracy: 0.6154 - val_loss: 1.7911 - learning_rate: 4.2969e-05
Epoch 105/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4787 - loss: 2.4254 - val_accuracy: 0.6162 - val_loss: 1.8005 - learning_rate: 4.2969e-05
Epoch 106/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4885 - loss: 2.3961 - val_accuracy: 0.6154 - val_loss: 1.7884 - learning_rate: 4.2969e-05
Epoch 107/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4780 - loss: 2.4283 - val_accuracy: 0.6146 - val_loss: 1.7678 - learning_rate: 4.2969e-05
Epoch 108/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4768 - loss: 2.4349 - val_accuracy: 0.6154 - val_loss: 1.7886 - learning_rate: 4.2969e-05
Epoch 109/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4764 - loss: 2.4179 - val_accuracy: 0.6107 - val_loss: 1.7947 - learning_rate: 4.2969e-05
Epoch 110/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4764 - loss: 2.4382 - val_accuracy: 0.6218 - val_loss: 1.7980 - learning_rate: 4.2969e-05
Epoch 111/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4779 - loss: 2.4208 - val_accuracy: 0.6154 - val_loss: 1.7885 - learning_rate: 4.2969e-05
Epoch 112/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4766 - loss: 2.4280 - val_accuracy: 0.6123 - val_loss: 1.7886 - learning_rate: 4.2969e-05
Epoch 113/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4794 - loss: 2.4094 - val_accuracy: 0.6131 - val_loss: 1.7761 - learning_rate: 4.2969e-05
Epoch 114/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4790 - loss: 2.4215 - val_accuracy: 0.6162 - val_loss: 1.7808 - learning_rate: 4.2969e-05
Epoch 115/300

Epoch 115: ReduceLROnPlateau reducing learning rate to 2.148461680917535e-05.
1413/1413 - 93s - 66ms/step - accuracy: 0.4713 - loss: 2.4384 - val_accuracy: 0.6162 - val_loss: 1.8152 - learning_rate: 4.2969e-05
Epoch 116/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4747 - loss: 2.4297 - val_accuracy: 0.6131 - val_loss: 1.7811 - learning_rate: 2.1485e-05
Epoch 117/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4865 - loss: 2.4131 - val_accuracy: 0.6107 - val_loss: 1.7878 - learning_rate: 2.1485e-05
Epoch 118/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4830 - loss: 2.4199 - val_accuracy: 0.6131 - val_loss: 1.7855 - learning_rate: 2.1485e-05
Epoch 119/300
1413/1413 - 94s - 66ms/step - accuracy: 0.4724 - loss: 2.3997 - val_accuracy: 0.6139 - val_loss: 1.7915 - learning_rate: 2.1485e-05
Epoch 120/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4814 - loss: 2.3961 - val_accuracy: 0.6194 - val_loss: 1.7794 - learning_rate: 2.1485e-05
Epoch 121/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4751 - loss: 2.4350 - val_accuracy: 0.6178 - val_loss: 1.7808 - learning_rate: 2.1485e-05
Epoch 122/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4760 - loss: 2.4403 - val_accuracy: 0.6154 - val_loss: 1.7919 - learning_rate: 2.1485e-05
Epoch 123/300

Epoch 123: ReduceLROnPlateau reducing learning rate to 1.0742308404587675e-05.
1413/1413 - 96s - 68ms/step - accuracy: 0.4793 - loss: 2.3913 - val_accuracy: 0.6178 - val_loss: 1.7804 - learning_rate: 2.1485e-05
Epoch 123: early stopping
Restoring model weights from the end of the best epoch: 107.
Fold 0 Evaluation results: [1.7684578895568848, 0.6146496534347534]
              precision    recall  f1-score   support

        1820       0.84      0.79      0.82        62
        1821       0.87      0.82      0.85        57
        1822       0.00      0.00      0.00         1
        1823       0.00      0.00      0.00         1
        1824       0.00      0.00      0.00         1
        1825       1.00      0.67      0.80         3
        1826       0.00      0.00      0.00         2
        1827       0.71      0.80      0.75        25
        1828       0.00      0.00      0.00         1
        1829       0.67      0.80      0.73         5
        1830       0.58      0.73      0.65        56
        1831       0.82      0.87      0.84       134
        1832       0.84      0.69      0.75        67
        1833       0.89      0.84      0.86        19
        1834       0.38      0.52      0.43        29
        1835       0.00      0.00      0.00         2
        1836       0.00      0.00      0.00         4
        1837       0.43      0.50      0.46         6
        1838       0.00      0.00      0.00         3
        1839       0.00      0.00      0.00         1
        1840       0.53      0.70      0.60        43
        1841       0.70      0.64      0.67       108
        1842       1.00      0.67      0.80         6
        1843       0.00      0.00      0.00         6
        1844       0.00      0.00      0.00         1
        1845       0.00      0.00      0.00         1
        1846       0.50      0.33      0.40         6
        1847       0.00      0.00      0.00         2
        1848       0.29      0.40      0.33         5
        1849       0.20      0.17      0.18         6
        1850       0.31      0.46      0.37        48
        1851       0.74      0.65      0.69        77
        1852       0.20      0.14      0.17         7
        1853       0.50      0.14      0.22         7
        1854       0.00      0.00      0.00         3
        1855       0.50      0.13      0.21        23
        1856       1.00      0.67      0.80        12
        1857       0.39      0.63      0.48        30
        1858       0.00      0.00      0.00         2
        1859       0.00      0.00      0.00         2
        1860       0.32      0.37      0.35        65
        1861       0.76      0.85      0.80        85
        1862       0.38      0.26      0.31        19
        1863       0.59      0.53      0.56        19
        1864       0.38      0.35      0.36        17
        1865       0.43      0.43      0.43         7
        1866       0.33      0.20      0.25         5
        1867       0.50      0.27      0.35        11
        1868       0.00      0.00      0.00         7
        1869       0.00      0.00      0.00         5
        1870       0.38      0.58      0.46        31
        1871       0.77      0.67      0.72        49
        1872       0.38      0.43      0.40         7
        1873       0.08      0.10      0.09        10
        1874       0.50      0.20      0.29         5
        1875       0.44      0.29      0.35        14
        1876       1.00      1.00      1.00        10
        1877       0.75      0.60      0.67         5
        1878       0.50      0.44      0.47         9
        1879       0.00      0.00      0.00         2

    accuracy                           0.61      1256
   macro avg       0.39      0.36      0.36      1256
weighted avg       0.62      0.61      0.61      1256

Matthews Correlation Coefficient: 0.595
Macro avg F1: 0.362
Weighted avg F1: 0.608
Micro avg F1: 0.615
Top-3 Accuracy: 0.857
Top-5 Accuracy: 0.904
Micro ROC AUC  = 0.99
Macro ROC AUC (present classes) = 0.97
Classification MAE (in years): 3.18

Fold 0 Misclassification Analysis:
Near misses (within 2 years): 123 out of 484 misclassifications (25.41%)
MAE with outliers: 3.18
MAE without outliers: 2.09 (improvement: 1.10)

5 Worst misclassifications:
Image: data/datasets/public/1830/1832_163vna.jpg, True: 1820, Predicted: 1872, Error: 52
Image: data/datasets/public/1860/1860_25wikimedia2.jpg, True: 1820, Predicted: 1867, Error: 47
Image: data/datasets/private/1820/1821_203etsy.jpg, True: 1871, Predicted: 1827, Error: 44
Image: data/datasets/private/1840/1841_731etsy.jpg, True: 1878, Predicted: 1834, Error: 44
Image: data/datasets/private/1850/1851_83etsy.jpg, True: 1861, Predicted: 1820, Error: 41

===== Fold 1 =====

===== Fine Tuning 7 layers! =====
Epoch 1/300
1413/1413 - 121s - 86ms/step - accuracy: 0.1885 - loss: 4.0027 - val_accuracy: 0.3376 - val_loss: 3.3426 - learning_rate: 6.8751e-04
Epoch 2/300
1413/1413 - 95s - 68ms/step - accuracy: 0.2725 - loss: 3.5598 - val_accuracy: 0.3957 - val_loss: 2.9278 - learning_rate: 6.8751e-04
Epoch 3/300
1413/1413 - 95s - 67ms/step - accuracy: 0.3005 - loss: 3.3871 - val_accuracy: 0.3973 - val_loss: 2.8286 - learning_rate: 6.8751e-04
Epoch 4/300
1413/1413 - 94s - 66ms/step - accuracy: 0.3265 - loss: 3.2676 - val_accuracy: 0.4562 - val_loss: 2.5989 - learning_rate: 6.8751e-04
Epoch 5/300
1413/1413 - 96s - 68ms/step - accuracy: 0.3356 - loss: 3.1715 - val_accuracy: 0.4371 - val_loss: 2.6034 - learning_rate: 6.8751e-04
Epoch 6/300
1413/1413 - 99s - 70ms/step - accuracy: 0.3507 - loss: 3.1389 - val_accuracy: 0.4658 - val_loss: 2.5519 - learning_rate: 6.8751e-04
Epoch 7/300
1413/1413 - 98s - 69ms/step - accuracy: 0.3532 - loss: 3.0878 - val_accuracy: 0.4944 - val_loss: 2.4767 - learning_rate: 6.8751e-04
Epoch 8/300
1413/1413 - 102s - 72ms/step - accuracy: 0.3686 - loss: 3.0534 - val_accuracy: 0.4936 - val_loss: 2.3984 - learning_rate: 6.8751e-04
Epoch 9/300
1413/1413 - 108s - 76ms/step - accuracy: 0.3653 - loss: 3.0213 - val_accuracy: 0.5048 - val_loss: 2.3914 - learning_rate: 6.8751e-04
Epoch 10/300
1413/1413 - 105s - 75ms/step - accuracy: 0.3600 - loss: 3.0210 - val_accuracy: 0.5111 - val_loss: 2.3371 - learning_rate: 6.8751e-04
Epoch 11/300
1413/1413 - 110s - 78ms/step - accuracy: 0.3749 - loss: 2.9861 - val_accuracy: 0.5104 - val_loss: 2.2929 - learning_rate: 6.8751e-04
Epoch 12/300
1413/1413 - 109s - 77ms/step - accuracy: 0.3743 - loss: 2.9619 - val_accuracy: 0.5199 - val_loss: 2.2397 - learning_rate: 6.8751e-04
Epoch 13/300
1413/1413 - 110s - 78ms/step - accuracy: 0.3811 - loss: 2.9363 - val_accuracy: 0.5048 - val_loss: 2.3206 - learning_rate: 6.8751e-04
Epoch 14/300
1413/1413 - 108s - 76ms/step - accuracy: 0.3756 - loss: 2.9555 - val_accuracy: 0.5016 - val_loss: 2.3923 - learning_rate: 6.8751e-04
Epoch 15/300
1413/1413 - 109s - 77ms/step - accuracy: 0.3903 - loss: 2.9013 - val_accuracy: 0.5303 - val_loss: 2.2762 - learning_rate: 6.8751e-04
Epoch 16/300
1413/1413 - 108s - 77ms/step - accuracy: 0.3835 - loss: 2.9317 - val_accuracy: 0.5366 - val_loss: 2.1837 - learning_rate: 6.8751e-04
Epoch 17/300
1413/1413 - 109s - 77ms/step - accuracy: 0.3919 - loss: 2.8869 - val_accuracy: 0.5223 - val_loss: 2.1580 - learning_rate: 6.8751e-04
Epoch 18/300
1413/1413 - 106s - 75ms/step - accuracy: 0.3913 - loss: 2.8712 - val_accuracy: 0.5143 - val_loss: 2.2838 - learning_rate: 6.8751e-04
Epoch 19/300
1413/1413 - 106s - 75ms/step - accuracy: 0.4002 - loss: 2.8678 - val_accuracy: 0.5279 - val_loss: 2.2088 - learning_rate: 6.8751e-04
Epoch 20/300
1413/1413 - 96s - 68ms/step - accuracy: 0.3974 - loss: 2.8488 - val_accuracy: 0.5239 - val_loss: 2.1409 - learning_rate: 6.8751e-04
Epoch 21/300
1413/1413 - 97s - 69ms/step - accuracy: 0.3987 - loss: 2.8439 - val_accuracy: 0.5247 - val_loss: 2.1365 - learning_rate: 6.8751e-04
Epoch 22/300
1413/1413 - 104s - 73ms/step - accuracy: 0.3987 - loss: 2.8653 - val_accuracy: 0.5446 - val_loss: 2.1962 - learning_rate: 6.8751e-04
Epoch 23/300
1413/1413 - 101s - 71ms/step - accuracy: 0.4014 - loss: 2.8492 - val_accuracy: 0.5462 - val_loss: 2.1976 - learning_rate: 6.8751e-04
Epoch 24/300
1413/1413 - 101s - 72ms/step - accuracy: 0.4024 - loss: 2.8273 - val_accuracy: 0.5414 - val_loss: 2.1673 - learning_rate: 6.8751e-04
Epoch 25/300
1413/1413 - 102s - 72ms/step - accuracy: 0.4050 - loss: 2.8351 - val_accuracy: 0.5486 - val_loss: 2.0689 - learning_rate: 6.8751e-04
Epoch 26/300
1413/1413 - 101s - 72ms/step - accuracy: 0.4075 - loss: 2.7893 - val_accuracy: 0.5510 - val_loss: 2.1268 - learning_rate: 6.8751e-04
Epoch 27/300
1413/1413 - 105s - 74ms/step - accuracy: 0.4048 - loss: 2.8226 - val_accuracy: 0.5422 - val_loss: 2.1195 - learning_rate: 6.8751e-04
Epoch 28/300
1413/1413 - 101s - 71ms/step - accuracy: 0.4060 - loss: 2.8038 - val_accuracy: 0.5263 - val_loss: 2.1933 - learning_rate: 6.8751e-04
Epoch 29/300
1413/1413 - 104s - 74ms/step - accuracy: 0.4092 - loss: 2.7942 - val_accuracy: 0.5525 - val_loss: 2.1250 - learning_rate: 6.8751e-04
Epoch 30/300
1413/1413 - 102s - 72ms/step - accuracy: 0.4064 - loss: 2.7842 - val_accuracy: 0.5470 - val_loss: 2.0980 - learning_rate: 6.8751e-04
Epoch 31/300
1413/1413 - 103s - 73ms/step - accuracy: 0.4069 - loss: 2.8075 - val_accuracy: 0.5358 - val_loss: 2.0579 - learning_rate: 6.8751e-04
Epoch 32/300
1413/1413 - 103s - 73ms/step - accuracy: 0.4132 - loss: 2.7757 - val_accuracy: 0.5486 - val_loss: 2.1624 - learning_rate: 6.8751e-04
Epoch 33/300
1413/1413 - 101s - 72ms/step - accuracy: 0.4119 - loss: 2.7988 - val_accuracy: 0.5629 - val_loss: 2.0710 - learning_rate: 6.8751e-04
Epoch 34/300
1413/1413 - 98s - 69ms/step - accuracy: 0.4107 - loss: 2.8014 - val_accuracy: 0.5549 - val_loss: 2.0615 - learning_rate: 6.8751e-04
Epoch 35/300
1413/1413 - 98s - 70ms/step - accuracy: 0.4137 - loss: 2.7763 - val_accuracy: 0.5486 - val_loss: 2.0546 - learning_rate: 6.8751e-04
Epoch 36/300
1413/1413 - 99s - 70ms/step - accuracy: 0.4118 - loss: 2.7972 - val_accuracy: 0.5470 - val_loss: 2.0946 - learning_rate: 6.8751e-04
Epoch 37/300
1413/1413 - 99s - 70ms/step - accuracy: 0.4180 - loss: 2.7860 - val_accuracy: 0.5287 - val_loss: 2.0711 - learning_rate: 6.8751e-04
Epoch 38/300
1413/1413 - 98s - 69ms/step - accuracy: 0.4162 - loss: 2.7753 - val_accuracy: 0.5573 - val_loss: 2.0595 - learning_rate: 6.8751e-04
Epoch 39/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4176 - loss: 2.7498 - val_accuracy: 0.5135 - val_loss: 2.1614 - learning_rate: 6.8751e-04
Epoch 40/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4194 - loss: 2.7694 - val_accuracy: 0.5462 - val_loss: 2.0607 - learning_rate: 6.8751e-04
Epoch 41/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4169 - loss: 2.7652 - val_accuracy: 0.5557 - val_loss: 2.0953 - learning_rate: 6.8751e-04
Epoch 42/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4193 - loss: 2.7389 - val_accuracy: 0.5525 - val_loss: 2.0661 - learning_rate: 6.8751e-04
Epoch 43/300

Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0003437538689468056.
1413/1413 - 96s - 68ms/step - accuracy: 0.4248 - loss: 2.7235 - val_accuracy: 0.5669 - val_loss: 2.0884 - learning_rate: 6.8751e-04
Epoch 44/300
1413/1413 - 94s - 66ms/step - accuracy: 0.4402 - loss: 2.6459 - val_accuracy: 0.5613 - val_loss: 1.9759 - learning_rate: 3.4375e-04
Epoch 45/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4387 - loss: 2.6438 - val_accuracy: 0.5573 - val_loss: 2.0412 - learning_rate: 3.4375e-04
Epoch 46/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4426 - loss: 2.5991 - val_accuracy: 0.5621 - val_loss: 2.0225 - learning_rate: 3.4375e-04
Epoch 47/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4441 - loss: 2.5858 - val_accuracy: 0.5613 - val_loss: 1.9497 - learning_rate: 3.4375e-04
Epoch 48/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4450 - loss: 2.6012 - val_accuracy: 0.5836 - val_loss: 1.9460 - learning_rate: 3.4375e-04
Epoch 49/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4432 - loss: 2.6140 - val_accuracy: 0.5820 - val_loss: 1.9449 - learning_rate: 3.4375e-04
Epoch 50/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4426 - loss: 2.6130 - val_accuracy: 0.5955 - val_loss: 1.9352 - learning_rate: 3.4375e-04
Epoch 51/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4502 - loss: 2.5669 - val_accuracy: 0.5804 - val_loss: 1.9648 - learning_rate: 3.4375e-04
Epoch 52/300
1413/1413 - 102s - 72ms/step - accuracy: 0.4437 - loss: 2.6037 - val_accuracy: 0.5589 - val_loss: 1.9914 - learning_rate: 3.4375e-04
Epoch 53/300
1413/1413 - 106s - 75ms/step - accuracy: 0.4455 - loss: 2.5759 - val_accuracy: 0.5844 - val_loss: 1.9414 - learning_rate: 3.4375e-04
Epoch 54/300
1413/1413 - 107s - 76ms/step - accuracy: 0.4480 - loss: 2.5891 - val_accuracy: 0.5852 - val_loss: 1.9220 - learning_rate: 3.4375e-04
Epoch 55/300
1413/1413 - 106s - 75ms/step - accuracy: 0.4498 - loss: 2.5715 - val_accuracy: 0.5788 - val_loss: 1.9311 - learning_rate: 3.4375e-04
Epoch 56/300
1413/1413 - 108s - 77ms/step - accuracy: 0.4480 - loss: 2.5764 - val_accuracy: 0.5764 - val_loss: 1.9844 - learning_rate: 3.4375e-04
Epoch 57/300
1413/1413 - 107s - 76ms/step - accuracy: 0.4489 - loss: 2.5562 - val_accuracy: 0.5892 - val_loss: 1.9446 - learning_rate: 3.4375e-04
Epoch 58/300
1413/1413 - 105s - 75ms/step - accuracy: 0.4501 - loss: 2.5755 - val_accuracy: 0.5804 - val_loss: 1.9345 - learning_rate: 3.4375e-04
Epoch 59/300
1413/1413 - 104s - 74ms/step - accuracy: 0.4506 - loss: 2.5831 - val_accuracy: 0.5820 - val_loss: 1.9970 - learning_rate: 3.4375e-04
Epoch 60/300
1413/1413 - 103s - 73ms/step - accuracy: 0.4490 - loss: 2.5771 - val_accuracy: 0.5884 - val_loss: 1.9229 - learning_rate: 3.4375e-04
Epoch 61/300
1413/1413 - 105s - 74ms/step - accuracy: 0.4422 - loss: 2.5861 - val_accuracy: 0.5852 - val_loss: 1.9393 - learning_rate: 3.4375e-04
Epoch 62/300

Epoch 62: ReduceLROnPlateau reducing learning rate to 0.0001718769344734028.
1413/1413 - 103s - 73ms/step - accuracy: 0.4473 - loss: 2.5648 - val_accuracy: 0.5788 - val_loss: 1.9574 - learning_rate: 3.4375e-04
Epoch 63/300
1413/1413 - 102s - 72ms/step - accuracy: 0.4589 - loss: 2.5165 - val_accuracy: 0.5916 - val_loss: 1.9161 - learning_rate: 1.7188e-04
Epoch 64/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4631 - loss: 2.5091 - val_accuracy: 0.5916 - val_loss: 1.9038 - learning_rate: 1.7188e-04
Epoch 65/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4514 - loss: 2.5156 - val_accuracy: 0.5892 - val_loss: 1.8470 - learning_rate: 1.7188e-04
Epoch 66/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4641 - loss: 2.4618 - val_accuracy: 0.5892 - val_loss: 1.8658 - learning_rate: 1.7188e-04
Epoch 67/300
1413/1413 - 99s - 70ms/step - accuracy: 0.4612 - loss: 2.5086 - val_accuracy: 0.5932 - val_loss: 1.8944 - learning_rate: 1.7188e-04
Epoch 68/300
1413/1413 - 91s - 65ms/step - accuracy: 0.4601 - loss: 2.5049 - val_accuracy: 0.5979 - val_loss: 1.8726 - learning_rate: 1.7188e-04
Epoch 69/300
1413/1413 - 91s - 65ms/step - accuracy: 0.4720 - loss: 2.4768 - val_accuracy: 0.5924 - val_loss: 1.8511 - learning_rate: 1.7188e-04
Epoch 70/300
1413/1413 - 91s - 64ms/step - accuracy: 0.4680 - loss: 2.4682 - val_accuracy: 0.6067 - val_loss: 1.8763 - learning_rate: 1.7188e-04
Epoch 71/300
1413/1413 - 91s - 65ms/step - accuracy: 0.4709 - loss: 2.4830 - val_accuracy: 0.5924 - val_loss: 1.8771 - learning_rate: 1.7188e-04
Epoch 72/300
1413/1413 - 91s - 64ms/step - accuracy: 0.4711 - loss: 2.4483 - val_accuracy: 0.5932 - val_loss: 1.9067 - learning_rate: 1.7188e-04
Epoch 73/300
1413/1413 - 143s - 101ms/step - accuracy: 0.4689 - loss: 2.4787 - val_accuracy: 0.5971 - val_loss: 1.8193 - learning_rate: 1.7188e-04
Epoch 74/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4697 - loss: 2.4666 - val_accuracy: 0.5939 - val_loss: 1.8402 - learning_rate: 1.7188e-04
Epoch 75/300
1413/1413 - 94s - 66ms/step - accuracy: 0.4640 - loss: 2.4770 - val_accuracy: 0.5860 - val_loss: 1.8477 - learning_rate: 1.7188e-04
Epoch 76/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4780 - loss: 2.4767 - val_accuracy: 0.5955 - val_loss: 1.8882 - learning_rate: 1.7188e-04
Epoch 77/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4644 - loss: 2.4622 - val_accuracy: 0.6019 - val_loss: 1.8232 - learning_rate: 1.7188e-04
Epoch 78/300
1413/1413 - 91s - 64ms/step - accuracy: 0.4646 - loss: 2.4685 - val_accuracy: 0.6178 - val_loss: 1.8438 - learning_rate: 1.7188e-04
Epoch 79/300
1413/1413 - 91s - 64ms/step - accuracy: 0.4663 - loss: 2.4911 - val_accuracy: 0.6027 - val_loss: 1.8592 - learning_rate: 1.7188e-04
Epoch 80/300
1413/1413 - 88s - 62ms/step - accuracy: 0.4657 - loss: 2.4701 - val_accuracy: 0.5924 - val_loss: 1.8367 - learning_rate: 1.7188e-04
Epoch 81/300

Epoch 81: ReduceLROnPlateau reducing learning rate to 8.59384672367014e-05.
1413/1413 - 94s - 66ms/step - accuracy: 0.4770 - loss: 2.4600 - val_accuracy: 0.6019 - val_loss: 1.8372 - learning_rate: 1.7188e-04
Epoch 82/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4731 - loss: 2.4635 - val_accuracy: 0.6059 - val_loss: 1.8290 - learning_rate: 8.5938e-05
Epoch 83/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4744 - loss: 2.4414 - val_accuracy: 0.5987 - val_loss: 1.8232 - learning_rate: 8.5938e-05
Epoch 84/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4769 - loss: 2.4291 - val_accuracy: 0.5947 - val_loss: 1.8469 - learning_rate: 8.5938e-05
Epoch 85/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4708 - loss: 2.4513 - val_accuracy: 0.6035 - val_loss: 1.8303 - learning_rate: 8.5938e-05
Epoch 86/300
1413/1413 - 91s - 65ms/step - accuracy: 0.4730 - loss: 2.4446 - val_accuracy: 0.6019 - val_loss: 1.8356 - learning_rate: 8.5938e-05
Epoch 87/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4726 - loss: 2.4319 - val_accuracy: 0.5955 - val_loss: 1.8305 - learning_rate: 8.5938e-05
Epoch 88/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4777 - loss: 2.4062 - val_accuracy: 0.6154 - val_loss: 1.8022 - learning_rate: 8.5938e-05
Epoch 89/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4703 - loss: 2.4265 - val_accuracy: 0.6123 - val_loss: 1.8128 - learning_rate: 8.5938e-05
Epoch 90/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4749 - loss: 2.4083 - val_accuracy: 0.6146 - val_loss: 1.8080 - learning_rate: 8.5938e-05
Epoch 91/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4753 - loss: 2.4475 - val_accuracy: 0.6059 - val_loss: 1.8005 - learning_rate: 8.5938e-05
Epoch 92/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4800 - loss: 2.4094 - val_accuracy: 0.6123 - val_loss: 1.8240 - learning_rate: 8.5938e-05
Epoch 93/300
1413/1413 - 94s - 66ms/step - accuracy: 0.4662 - loss: 2.4448 - val_accuracy: 0.6075 - val_loss: 1.8373 - learning_rate: 8.5938e-05
Epoch 94/300
1413/1413 - 94s - 66ms/step - accuracy: 0.4802 - loss: 2.4108 - val_accuracy: 0.6051 - val_loss: 1.8034 - learning_rate: 8.5938e-05
Epoch 95/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4760 - loss: 2.4155 - val_accuracy: 0.6131 - val_loss: 1.8066 - learning_rate: 8.5938e-05
Epoch 96/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4752 - loss: 2.4191 - val_accuracy: 0.6083 - val_loss: 1.7945 - learning_rate: 8.5938e-05
Epoch 97/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4800 - loss: 2.4070 - val_accuracy: 0.6162 - val_loss: 1.8028 - learning_rate: 8.5938e-05
Epoch 98/300
1413/1413 - 94s - 66ms/step - accuracy: 0.4790 - loss: 2.4184 - val_accuracy: 0.6059 - val_loss: 1.8045 - learning_rate: 8.5938e-05
Epoch 99/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4779 - loss: 2.4260 - val_accuracy: 0.6178 - val_loss: 1.8244 - learning_rate: 8.5938e-05
Epoch 100/300
1413/1413 - 94s - 66ms/step - accuracy: 0.4797 - loss: 2.3954 - val_accuracy: 0.6154 - val_loss: 1.7907 - learning_rate: 8.5938e-05
Epoch 101/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4738 - loss: 2.3970 - val_accuracy: 0.6083 - val_loss: 1.7954 - learning_rate: 8.5938e-05
Epoch 102/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4766 - loss: 2.4349 - val_accuracy: 0.6162 - val_loss: 1.8004 - learning_rate: 8.5938e-05
Epoch 103/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4860 - loss: 2.3935 - val_accuracy: 0.6162 - val_loss: 1.7879 - learning_rate: 8.5938e-05
Epoch 104/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4816 - loss: 2.3934 - val_accuracy: 0.6154 - val_loss: 1.7738 - learning_rate: 8.5938e-05
Epoch 105/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4863 - loss: 2.4040 - val_accuracy: 0.6091 - val_loss: 1.8027 - learning_rate: 8.5938e-05
Epoch 106/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4822 - loss: 2.4020 - val_accuracy: 0.6091 - val_loss: 1.7955 - learning_rate: 8.5938e-05
Epoch 107/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4860 - loss: 2.3937 - val_accuracy: 0.6146 - val_loss: 1.7925 - learning_rate: 8.5938e-05
Epoch 108/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4778 - loss: 2.4094 - val_accuracy: 0.6051 - val_loss: 1.7934 - learning_rate: 8.5938e-05
Epoch 109/300
1413/1413 - 94s - 66ms/step - accuracy: 0.4813 - loss: 2.4029 - val_accuracy: 0.6083 - val_loss: 1.7877 - learning_rate: 8.5938e-05
Epoch 110/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4798 - loss: 2.4139 - val_accuracy: 0.6107 - val_loss: 1.7832 - learning_rate: 8.5938e-05
Epoch 111/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4800 - loss: 2.4110 - val_accuracy: 0.6123 - val_loss: 1.8036 - learning_rate: 8.5938e-05
Epoch 112/300

Epoch 112: ReduceLROnPlateau reducing learning rate to 4.29692336183507e-05.
1413/1413 - 95s - 67ms/step - accuracy: 0.4763 - loss: 2.4050 - val_accuracy: 0.6123 - val_loss: 1.8019 - learning_rate: 8.5938e-05
Epoch 113/300
1413/1413 - 97s - 68ms/step - accuracy: 0.4683 - loss: 2.3990 - val_accuracy: 0.6162 - val_loss: 1.7988 - learning_rate: 4.2969e-05
Epoch 114/300
1413/1413 - 95s - 68ms/step - accuracy: 0.4831 - loss: 2.3794 - val_accuracy: 0.6123 - val_loss: 1.7759 - learning_rate: 4.2969e-05
Epoch 115/300
1413/1413 - 95s - 68ms/step - accuracy: 0.4830 - loss: 2.3874 - val_accuracy: 0.6170 - val_loss: 1.7917 - learning_rate: 4.2969e-05
Epoch 116/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4804 - loss: 2.3961 - val_accuracy: 0.6146 - val_loss: 1.7829 - learning_rate: 4.2969e-05
Epoch 117/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4822 - loss: 2.3783 - val_accuracy: 0.6139 - val_loss: 1.7684 - learning_rate: 4.2969e-05
Epoch 118/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4808 - loss: 2.3778 - val_accuracy: 0.6139 - val_loss: 1.7806 - learning_rate: 4.2969e-05
Epoch 119/300
1413/1413 - 94s - 66ms/step - accuracy: 0.4861 - loss: 2.3817 - val_accuracy: 0.6115 - val_loss: 1.7671 - learning_rate: 4.2969e-05
Epoch 120/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4854 - loss: 2.3988 - val_accuracy: 0.6162 - val_loss: 1.8045 - learning_rate: 4.2969e-05
Epoch 121/300
1413/1413 - 91s - 64ms/step - accuracy: 0.4865 - loss: 2.3887 - val_accuracy: 0.6099 - val_loss: 1.7907 - learning_rate: 4.2969e-05
Epoch 122/300
1413/1413 - 98s - 70ms/step - accuracy: 0.4824 - loss: 2.3941 - val_accuracy: 0.6154 - val_loss: 1.7728 - learning_rate: 4.2969e-05
Epoch 123/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4823 - loss: 2.3829 - val_accuracy: 0.6162 - val_loss: 1.7755 - learning_rate: 4.2969e-05
Epoch 124/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4867 - loss: 2.3828 - val_accuracy: 0.6146 - val_loss: 1.7860 - learning_rate: 4.2969e-05
Epoch 125/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4770 - loss: 2.4234 - val_accuracy: 0.6186 - val_loss: 1.7918 - learning_rate: 4.2969e-05
Epoch 126/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4768 - loss: 2.4014 - val_accuracy: 0.6186 - val_loss: 1.7899 - learning_rate: 4.2969e-05
Epoch 127/300

Epoch 127: ReduceLROnPlateau reducing learning rate to 2.148461680917535e-05.
1413/1413 - 92s - 65ms/step - accuracy: 0.4809 - loss: 2.3854 - val_accuracy: 0.6186 - val_loss: 1.7874 - learning_rate: 4.2969e-05
Epoch 128/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4837 - loss: 2.3770 - val_accuracy: 0.6186 - val_loss: 1.7815 - learning_rate: 2.1485e-05
Epoch 129/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4920 - loss: 2.3591 - val_accuracy: 0.6258 - val_loss: 1.7787 - learning_rate: 2.1485e-05
Epoch 130/300
1413/1413 - 91s - 65ms/step - accuracy: 0.4839 - loss: 2.3951 - val_accuracy: 0.6250 - val_loss: 1.7708 - learning_rate: 2.1485e-05
Epoch 131/300
1413/1413 - 91s - 65ms/step - accuracy: 0.4871 - loss: 2.3412 - val_accuracy: 0.6218 - val_loss: 1.7822 - learning_rate: 2.1485e-05
Epoch 132/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4916 - loss: 2.3531 - val_accuracy: 0.6258 - val_loss: 1.7795 - learning_rate: 2.1485e-05
Epoch 133/300
1413/1413 - 91s - 64ms/step - accuracy: 0.4853 - loss: 2.3744 - val_accuracy: 0.6266 - val_loss: 1.7758 - learning_rate: 2.1485e-05
Epoch 134/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4802 - loss: 2.3775 - val_accuracy: 0.6170 - val_loss: 1.7826 - learning_rate: 2.1485e-05
Epoch 135/300

Epoch 135: ReduceLROnPlateau reducing learning rate to 1.0742308404587675e-05.
1413/1413 - 91s - 64ms/step - accuracy: 0.4908 - loss: 2.3697 - val_accuracy: 0.6226 - val_loss: 1.7786 - learning_rate: 2.1485e-05
Epoch 135: early stopping
Restoring model weights from the end of the best epoch: 119.
Fold 1 Evaluation results: [1.769932508468628, 0.6114649772644043]
              precision    recall  f1-score   support

        1820       0.69      0.79      0.74        62
        1821       0.88      0.79      0.83        57
        1822       0.00      0.00      0.00         1
        1823       1.00      1.00      1.00         1
        1824       1.00      1.00      1.00         1
        1825       0.00      0.00      0.00         2
        1826       0.00      0.00      0.00         2
        1827       0.79      0.76      0.78        25
        1828       0.00      0.00      0.00         1
        1829       0.80      0.80      0.80         5
        1830       0.51      0.59      0.55        56
        1831       0.74      0.87      0.80       134
        1832       0.84      0.76      0.80        68
        1833       0.95      0.95      0.95        19
        1834       0.48      0.55      0.52        29
        1835       0.00      0.00      0.00         3
        1836       0.75      0.75      0.75         4
        1837       0.33      0.43      0.38         7
        1838       0.00      0.00      0.00         3
        1839       0.00      0.00      0.00         0
        1840       0.60      0.70      0.65        43
        1841       0.69      0.59      0.64       108
        1842       0.57      0.80      0.67         5
        1843       0.43      0.50      0.46         6
        1844       0.00      0.00      0.00         1
        1845       0.00      0.00      0.00         2
        1846       0.20      0.17      0.18         6
        1847       0.00      0.00      0.00         2
        1848       0.00      0.00      0.00         6
        1849       0.00      0.00      0.00         6
        1850       0.42      0.56      0.48        48
        1851       0.83      0.70      0.76        77
        1852       0.33      0.14      0.20         7
        1853       0.17      0.17      0.17         6
        1854       0.00      0.00      0.00         3
        1855       0.43      0.12      0.19        24
        1856       0.71      1.00      0.83        12
        1857       0.33      0.40      0.36        30
        1858       0.00      0.00      0.00         2
        1859       0.00      0.00      0.00         2
        1860       0.38      0.33      0.35        64
        1861       0.77      0.88      0.82        85
        1862       0.24      0.28      0.26        18
        1863       0.38      0.42      0.40        19
        1864       0.40      0.35      0.38        17
        1865       0.43      0.50      0.46         6
        1866       0.33      0.60      0.43         5
        1867       0.20      0.09      0.12        11
        1868       0.00      0.00      0.00         7
        1869       1.00      0.20      0.33         5
        1870       0.26      0.35      0.30        31
        1871       0.77      0.73      0.75        49
        1872       0.33      0.12      0.18         8
        1873       0.36      0.40      0.38        10
        1874       0.25      0.20      0.22         5
        1875       0.50      0.43      0.46        14
        1876       0.78      0.70      0.74        10
        1877       0.50      0.20      0.29         5
        1878       0.40      0.67      0.50         9
        1879       0.00      0.00      0.00         2

    accuracy                           0.61      1256
   macro avg       0.40      0.39      0.38      1256
weighted avg       0.60      0.61      0.60      1256

Matthews Correlation Coefficient: 0.592
Macro avg F1: 0.381
Weighted avg F1: 0.600
Micro avg F1: 0.611
Top-3 Accuracy: 0.852
Top-5 Accuracy: 0.914
Micro ROC AUC  = 0.99
Macro ROC AUC (present classes) = 0.97
Classification MAE (in years): 3.27

Fold 1 Misclassification Analysis:
Near misses (within 2 years): 120 out of 488 misclassifications (24.59%)
MAE with outliers: 3.27
MAE without outliers: 2.17 (improvement: 1.10)

5 Worst misclassifications:
Image: data/datasets/private/1840/1841_505etsy.jpg, True: 1879, Predicted: 1820, Error: 59
Image: data/datasets/public/1830/1832_1828vna.jpg, True: 1877, Predicted: 1820, Error: 57
Image: data/datasets/private/1840/1841_201etsy.jpg, True: 1876, Predicted: 1820, Error: 56
Image: data/datasets/private/1870/1871_296etsy.jpg, True: 1820, Predicted: 1871, Error: 51
Image: data/datasets/private/1860/1861_362etsy.jpg, True: 1820, Predicted: 1870, Error: 50

===== Fold 2 =====

===== Fine Tuning 7 layers! =====
Epoch 1/300
1413/1413 - 119s - 85ms/step - accuracy: 0.1928 - loss: 4.0564 - val_accuracy: 0.3559 - val_loss: 3.3573 - learning_rate: 6.8751e-04
Epoch 2/300
1413/1413 - 93s - 66ms/step - accuracy: 0.2719 - loss: 3.5384 - val_accuracy: 0.3567 - val_loss: 3.0045 - learning_rate: 6.8751e-04
Epoch 3/300
1413/1413 - 94s - 66ms/step - accuracy: 0.2980 - loss: 3.3711 - val_accuracy: 0.4586 - val_loss: 2.5576 - learning_rate: 6.8751e-04
Epoch 4/300
1413/1413 - 91s - 65ms/step - accuracy: 0.3245 - loss: 3.2392 - val_accuracy: 0.4538 - val_loss: 2.4692 - learning_rate: 6.8751e-04
Epoch 5/300
1413/1413 - 92s - 65ms/step - accuracy: 0.3433 - loss: 3.1450 - val_accuracy: 0.4801 - val_loss: 2.4504 - learning_rate: 6.8751e-04
Epoch 6/300
1413/1413 - 91s - 64ms/step - accuracy: 0.3526 - loss: 3.1196 - val_accuracy: 0.4467 - val_loss: 2.4017 - learning_rate: 6.8751e-04
Epoch 7/300
1413/1413 - 92s - 65ms/step - accuracy: 0.3580 - loss: 3.0732 - val_accuracy: 0.4769 - val_loss: 2.3612 - learning_rate: 6.8751e-04
Epoch 8/300
1413/1413 - 92s - 65ms/step - accuracy: 0.3660 - loss: 3.0269 - val_accuracy: 0.4801 - val_loss: 2.4145 - learning_rate: 6.8751e-04
Epoch 9/300
1413/1413 - 92s - 65ms/step - accuracy: 0.3683 - loss: 2.9943 - val_accuracy: 0.4785 - val_loss: 2.4065 - learning_rate: 6.8751e-04
Epoch 10/300
1413/1413 - 91s - 64ms/step - accuracy: 0.3764 - loss: 2.9745 - val_accuracy: 0.4865 - val_loss: 2.3468 - learning_rate: 6.8751e-04
Epoch 11/300
1413/1413 - 92s - 65ms/step - accuracy: 0.3768 - loss: 2.9507 - val_accuracy: 0.4992 - val_loss: 2.3316 - learning_rate: 6.8751e-04
Epoch 12/300
1413/1413 - 92s - 65ms/step - accuracy: 0.3830 - loss: 2.9271 - val_accuracy: 0.4944 - val_loss: 2.2522 - learning_rate: 6.8751e-04
Epoch 13/300
1413/1413 - 94s - 66ms/step - accuracy: 0.3861 - loss: 2.9154 - val_accuracy: 0.5135 - val_loss: 2.3137 - learning_rate: 6.8751e-04
Epoch 14/300
1413/1413 - 91s - 64ms/step - accuracy: 0.3848 - loss: 2.9162 - val_accuracy: 0.5271 - val_loss: 2.1623 - learning_rate: 6.8751e-04
Epoch 15/300
1413/1413 - 94s - 66ms/step - accuracy: 0.3952 - loss: 2.8992 - val_accuracy: 0.5318 - val_loss: 2.1455 - learning_rate: 6.8751e-04
Epoch 16/300
1413/1413 - 92s - 65ms/step - accuracy: 0.3905 - loss: 2.8707 - val_accuracy: 0.5151 - val_loss: 2.2691 - learning_rate: 6.8751e-04
Epoch 17/300
1413/1413 - 93s - 65ms/step - accuracy: 0.3949 - loss: 2.8501 - val_accuracy: 0.5239 - val_loss: 2.2372 - learning_rate: 6.8751e-04
Epoch 18/300
1413/1413 - 89s - 63ms/step - accuracy: 0.4020 - loss: 2.8350 - val_accuracy: 0.5008 - val_loss: 2.1920 - learning_rate: 6.8751e-04
Epoch 19/300
1413/1413 - 91s - 64ms/step - accuracy: 0.3945 - loss: 2.8590 - val_accuracy: 0.5207 - val_loss: 2.2754 - learning_rate: 6.8751e-04
Epoch 20/300
1413/1413 - 89s - 63ms/step - accuracy: 0.4056 - loss: 2.7960 - val_accuracy: 0.5159 - val_loss: 2.1564 - learning_rate: 6.8751e-04
Epoch 21/300
1413/1413 - 90s - 64ms/step - accuracy: 0.3983 - loss: 2.8275 - val_accuracy: 0.5334 - val_loss: 2.1045 - learning_rate: 6.8751e-04
Epoch 22/300
1413/1413 - 90s - 64ms/step - accuracy: 0.4109 - loss: 2.8044 - val_accuracy: 0.5494 - val_loss: 2.0440 - learning_rate: 6.8751e-04
Epoch 23/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4052 - loss: 2.8023 - val_accuracy: 0.5358 - val_loss: 2.1452 - learning_rate: 6.8751e-04
Epoch 24/300
1413/1413 - 91s - 64ms/step - accuracy: 0.4079 - loss: 2.8124 - val_accuracy: 0.5613 - val_loss: 2.0934 - learning_rate: 6.8751e-04
Epoch 25/300
1413/1413 - 89s - 63ms/step - accuracy: 0.4073 - loss: 2.7925 - val_accuracy: 0.5454 - val_loss: 2.0748 - learning_rate: 6.8751e-04
Epoch 26/300
1413/1413 - 90s - 64ms/step - accuracy: 0.4094 - loss: 2.8076 - val_accuracy: 0.5287 - val_loss: 2.1157 - learning_rate: 6.8751e-04
Epoch 27/300
1413/1413 - 94s - 66ms/step - accuracy: 0.4035 - loss: 2.7952 - val_accuracy: 0.5462 - val_loss: 2.0727 - learning_rate: 6.8751e-04
Epoch 28/300
1413/1413 - 90s - 64ms/step - accuracy: 0.4141 - loss: 2.7901 - val_accuracy: 0.5565 - val_loss: 2.0555 - learning_rate: 6.8751e-04
Epoch 29/300
1413/1413 - 91s - 64ms/step - accuracy: 0.4171 - loss: 2.7546 - val_accuracy: 0.5486 - val_loss: 2.0532 - learning_rate: 6.8751e-04
Epoch 30/300

Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0003437538689468056.
1413/1413 - 89s - 63ms/step - accuracy: 0.4129 - loss: 2.7385 - val_accuracy: 0.5207 - val_loss: 2.1237 - learning_rate: 6.8751e-04
Epoch 31/300
1413/1413 - 90s - 64ms/step - accuracy: 0.4386 - loss: 2.6338 - val_accuracy: 0.5709 - val_loss: 1.9479 - learning_rate: 3.4375e-04
Epoch 32/300
1413/1413 - 91s - 64ms/step - accuracy: 0.4358 - loss: 2.6294 - val_accuracy: 0.5748 - val_loss: 1.9052 - learning_rate: 3.4375e-04
Epoch 33/300
1413/1413 - 90s - 64ms/step - accuracy: 0.4375 - loss: 2.6444 - val_accuracy: 0.5717 - val_loss: 1.9667 - learning_rate: 3.4375e-04
Epoch 34/300
1413/1413 - 91s - 64ms/step - accuracy: 0.4387 - loss: 2.6093 - val_accuracy: 0.5812 - val_loss: 1.9249 - learning_rate: 3.4375e-04
Epoch 35/300
1413/1413 - 90s - 64ms/step - accuracy: 0.4408 - loss: 2.6295 - val_accuracy: 0.5828 - val_loss: 1.9097 - learning_rate: 3.4375e-04
Epoch 36/300
1413/1413 - 91s - 64ms/step - accuracy: 0.4516 - loss: 2.5816 - val_accuracy: 0.5725 - val_loss: 1.9465 - learning_rate: 3.4375e-04
Epoch 37/300
1413/1413 - 91s - 64ms/step - accuracy: 0.4449 - loss: 2.5755 - val_accuracy: 0.5796 - val_loss: 1.9118 - learning_rate: 3.4375e-04
Epoch 38/300
1413/1413 - 91s - 65ms/step - accuracy: 0.4555 - loss: 2.5815 - val_accuracy: 0.5812 - val_loss: 1.8996 - learning_rate: 3.4375e-04
Epoch 39/300
1413/1413 - 90s - 64ms/step - accuracy: 0.4367 - loss: 2.5978 - val_accuracy: 0.5804 - val_loss: 1.8795 - learning_rate: 3.4375e-04
Epoch 40/300
1413/1413 - 91s - 64ms/step - accuracy: 0.4452 - loss: 2.5850 - val_accuracy: 0.5828 - val_loss: 1.9085 - learning_rate: 3.4375e-04
Epoch 41/300
1413/1413 - 90s - 64ms/step - accuracy: 0.4490 - loss: 2.6013 - val_accuracy: 0.5740 - val_loss: 1.9444 - learning_rate: 3.4375e-04
Epoch 42/300
1413/1413 - 91s - 64ms/step - accuracy: 0.4476 - loss: 2.5616 - val_accuracy: 0.5876 - val_loss: 1.8494 - learning_rate: 3.4375e-04
Epoch 43/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4420 - loss: 2.6076 - val_accuracy: 0.5740 - val_loss: 1.9384 - learning_rate: 3.4375e-04
Epoch 44/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4436 - loss: 2.6021 - val_accuracy: 0.5924 - val_loss: 1.8647 - learning_rate: 3.4375e-04
Epoch 45/300
1413/1413 - 94s - 66ms/step - accuracy: 0.4459 - loss: 2.5945 - val_accuracy: 0.5788 - val_loss: 1.9168 - learning_rate: 3.4375e-04
Epoch 46/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4506 - loss: 2.5710 - val_accuracy: 0.5868 - val_loss: 1.8831 - learning_rate: 3.4375e-04
Epoch 47/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4522 - loss: 2.5716 - val_accuracy: 0.5804 - val_loss: 1.8788 - learning_rate: 3.4375e-04
Epoch 48/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4561 - loss: 2.5332 - val_accuracy: 0.5852 - val_loss: 1.8589 - learning_rate: 3.4375e-04
Epoch 49/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4473 - loss: 2.5790 - val_accuracy: 0.5916 - val_loss: 1.8995 - learning_rate: 3.4375e-04
Epoch 50/300

Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0001718769344734028.
1413/1413 - 92s - 65ms/step - accuracy: 0.4544 - loss: 2.5395 - val_accuracy: 0.5868 - val_loss: 1.8869 - learning_rate: 3.4375e-04
Epoch 51/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4598 - loss: 2.5072 - val_accuracy: 0.5947 - val_loss: 1.8379 - learning_rate: 1.7188e-04
Epoch 52/300
1413/1413 - 91s - 65ms/step - accuracy: 0.4615 - loss: 2.4789 - val_accuracy: 0.6019 - val_loss: 1.8127 - learning_rate: 1.7188e-04
Epoch 53/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4603 - loss: 2.4931 - val_accuracy: 0.6027 - val_loss: 1.8191 - learning_rate: 1.7188e-04
Epoch 54/300
1413/1413 - 90s - 64ms/step - accuracy: 0.4639 - loss: 2.4875 - val_accuracy: 0.6083 - val_loss: 1.7908 - learning_rate: 1.7188e-04
Epoch 55/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4640 - loss: 2.4747 - val_accuracy: 0.6123 - val_loss: 1.8070 - learning_rate: 1.7188e-04
Epoch 56/300
1413/1413 - 91s - 64ms/step - accuracy: 0.4611 - loss: 2.4763 - val_accuracy: 0.6051 - val_loss: 1.8358 - learning_rate: 1.7188e-04
Epoch 57/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4748 - loss: 2.4488 - val_accuracy: 0.6043 - val_loss: 1.8177 - learning_rate: 1.7188e-04
Epoch 58/300
1413/1413 - 91s - 64ms/step - accuracy: 0.4663 - loss: 2.4594 - val_accuracy: 0.6075 - val_loss: 1.7918 - learning_rate: 1.7188e-04
Epoch 59/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4681 - loss: 2.4726 - val_accuracy: 0.6043 - val_loss: 1.8102 - learning_rate: 1.7188e-04
Epoch 60/300
1413/1413 - 90s - 64ms/step - accuracy: 0.4613 - loss: 2.4875 - val_accuracy: 0.6035 - val_loss: 1.7795 - learning_rate: 1.7188e-04
Epoch 61/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4733 - loss: 2.4375 - val_accuracy: 0.6011 - val_loss: 1.7757 - learning_rate: 1.7188e-04
Epoch 62/300
1413/1413 - 91s - 64ms/step - accuracy: 0.4713 - loss: 2.4759 - val_accuracy: 0.6067 - val_loss: 1.8139 - learning_rate: 1.7188e-04
Epoch 63/300
1413/1413 - 90s - 64ms/step - accuracy: 0.4646 - loss: 2.4729 - val_accuracy: 0.6027 - val_loss: 1.7909 - learning_rate: 1.7188e-04
Epoch 64/300
1413/1413 - 90s - 64ms/step - accuracy: 0.4679 - loss: 2.4645 - val_accuracy: 0.6083 - val_loss: 1.7759 - learning_rate: 1.7188e-04
Epoch 65/300
1413/1413 - 91s - 64ms/step - accuracy: 0.4774 - loss: 2.4433 - val_accuracy: 0.6043 - val_loss: 1.7900 - learning_rate: 1.7188e-04
Epoch 66/300
1413/1413 - 90s - 64ms/step - accuracy: 0.4642 - loss: 2.4562 - val_accuracy: 0.5979 - val_loss: 1.7929 - learning_rate: 1.7188e-04
Epoch 67/300
1413/1413 - 91s - 65ms/step - accuracy: 0.4656 - loss: 2.4797 - val_accuracy: 0.6123 - val_loss: 1.7828 - learning_rate: 1.7188e-04
Epoch 68/300
1413/1413 - 91s - 64ms/step - accuracy: 0.4667 - loss: 2.4578 - val_accuracy: 0.5971 - val_loss: 1.7794 - learning_rate: 1.7188e-04
Epoch 69/300
1413/1413 - 91s - 64ms/step - accuracy: 0.4696 - loss: 2.4615 - val_accuracy: 0.6123 - val_loss: 1.7540 - learning_rate: 1.7188e-04
Epoch 70/300
1413/1413 - 90s - 64ms/step - accuracy: 0.4777 - loss: 2.4389 - val_accuracy: 0.6011 - val_loss: 1.7929 - learning_rate: 1.7188e-04
Epoch 71/300
1413/1413 - 91s - 65ms/step - accuracy: 0.4642 - loss: 2.4676 - val_accuracy: 0.6027 - val_loss: 1.8108 - learning_rate: 1.7188e-04
Epoch 72/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4746 - loss: 2.4347 - val_accuracy: 0.6139 - val_loss: 1.7917 - learning_rate: 1.7188e-04
Epoch 73/300
1413/1413 - 90s - 64ms/step - accuracy: 0.4778 - loss: 2.4382 - val_accuracy: 0.6099 - val_loss: 1.7878 - learning_rate: 1.7188e-04
Epoch 74/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4688 - loss: 2.4219 - val_accuracy: 0.5995 - val_loss: 1.8211 - learning_rate: 1.7188e-04
Epoch 75/300
1413/1413 - 91s - 64ms/step - accuracy: 0.4787 - loss: 2.4234 - val_accuracy: 0.6107 - val_loss: 1.7811 - learning_rate: 1.7188e-04
Epoch 76/300
1413/1413 - 90s - 63ms/step - accuracy: 0.4712 - loss: 2.4494 - val_accuracy: 0.6027 - val_loss: 1.7826 - learning_rate: 1.7188e-04
Epoch 77/300

Epoch 77: ReduceLROnPlateau reducing learning rate to 8.59384672367014e-05.
1413/1413 - 91s - 64ms/step - accuracy: 0.4701 - loss: 2.4262 - val_accuracy: 0.6003 - val_loss: 1.8155 - learning_rate: 1.7188e-04
Epoch 78/300
1413/1413 - 91s - 64ms/step - accuracy: 0.4826 - loss: 2.4202 - val_accuracy: 0.6131 - val_loss: 1.7552 - learning_rate: 8.5938e-05
Epoch 79/300
1413/1413 - 91s - 64ms/step - accuracy: 0.4784 - loss: 2.4043 - val_accuracy: 0.6115 - val_loss: 1.7486 - learning_rate: 8.5938e-05
Epoch 80/300
1413/1413 - 91s - 64ms/step - accuracy: 0.4774 - loss: 2.4099 - val_accuracy: 0.6083 - val_loss: 1.7535 - learning_rate: 8.5938e-05
Epoch 81/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4754 - loss: 2.4305 - val_accuracy: 0.6107 - val_loss: 1.7427 - learning_rate: 8.5938e-05
Epoch 82/300
1413/1413 - 90s - 64ms/step - accuracy: 0.4839 - loss: 2.3976 - val_accuracy: 0.6067 - val_loss: 1.7543 - learning_rate: 8.5938e-05
Epoch 83/300
1413/1413 - 91s - 64ms/step - accuracy: 0.4754 - loss: 2.3910 - val_accuracy: 0.6091 - val_loss: 1.7458 - learning_rate: 8.5938e-05
Epoch 84/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4754 - loss: 2.4177 - val_accuracy: 0.6139 - val_loss: 1.7498 - learning_rate: 8.5938e-05
Epoch 85/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4760 - loss: 2.4037 - val_accuracy: 0.6115 - val_loss: 1.7577 - learning_rate: 8.5938e-05
Epoch 86/300
1413/1413 - 90s - 64ms/step - accuracy: 0.4786 - loss: 2.3735 - val_accuracy: 0.6131 - val_loss: 1.7446 - learning_rate: 8.5938e-05
Epoch 87/300
1413/1413 - 91s - 64ms/step - accuracy: 0.4731 - loss: 2.4223 - val_accuracy: 0.6075 - val_loss: 1.7386 - learning_rate: 8.5938e-05
Epoch 88/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4879 - loss: 2.3852 - val_accuracy: 0.6107 - val_loss: 1.7685 - learning_rate: 8.5938e-05
Epoch 89/300
1413/1413 - 91s - 65ms/step - accuracy: 0.4791 - loss: 2.4238 - val_accuracy: 0.6194 - val_loss: 1.7539 - learning_rate: 8.5938e-05
Epoch 90/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4785 - loss: 2.3731 - val_accuracy: 0.6154 - val_loss: 1.7357 - learning_rate: 8.5938e-05
Epoch 91/300
1413/1413 - 91s - 64ms/step - accuracy: 0.4885 - loss: 2.3737 - val_accuracy: 0.6226 - val_loss: 1.7398 - learning_rate: 8.5938e-05
Epoch 92/300
1413/1413 - 94s - 66ms/step - accuracy: 0.4822 - loss: 2.4021 - val_accuracy: 0.6115 - val_loss: 1.7337 - learning_rate: 8.5938e-05
Epoch 93/300
1413/1413 - 91s - 64ms/step - accuracy: 0.4833 - loss: 2.3922 - val_accuracy: 0.6242 - val_loss: 1.7212 - learning_rate: 8.5938e-05
Epoch 94/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4829 - loss: 2.3830 - val_accuracy: 0.6146 - val_loss: 1.7580 - learning_rate: 8.5938e-05
Epoch 95/300
1413/1413 - 91s - 65ms/step - accuracy: 0.4815 - loss: 2.3840 - val_accuracy: 0.6123 - val_loss: 1.7462 - learning_rate: 8.5938e-05
Epoch 96/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4786 - loss: 2.3782 - val_accuracy: 0.6154 - val_loss: 1.7184 - learning_rate: 8.5938e-05
Epoch 97/300
1413/1413 - 91s - 65ms/step - accuracy: 0.4774 - loss: 2.4186 - val_accuracy: 0.6210 - val_loss: 1.7334 - learning_rate: 8.5938e-05
Epoch 98/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4875 - loss: 2.4043 - val_accuracy: 0.6258 - val_loss: 1.7495 - learning_rate: 8.5938e-05
Epoch 99/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4828 - loss: 2.3922 - val_accuracy: 0.6139 - val_loss: 1.7464 - learning_rate: 8.5938e-05
Epoch 100/300
1413/1413 - 91s - 65ms/step - accuracy: 0.4839 - loss: 2.3678 - val_accuracy: 0.6139 - val_loss: 1.7240 - learning_rate: 8.5938e-05
Epoch 101/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4813 - loss: 2.3744 - val_accuracy: 0.6067 - val_loss: 1.7471 - learning_rate: 8.5938e-05
Epoch 102/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4779 - loss: 2.3819 - val_accuracy: 0.6234 - val_loss: 1.7301 - learning_rate: 8.5938e-05
Epoch 103/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4926 - loss: 2.3606 - val_accuracy: 0.6218 - val_loss: 1.7433 - learning_rate: 8.5938e-05
Epoch 104/300

Epoch 104: ReduceLROnPlateau reducing learning rate to 4.29692336183507e-05.
1413/1413 - 91s - 64ms/step - accuracy: 0.4777 - loss: 2.3702 - val_accuracy: 0.6202 - val_loss: 1.7197 - learning_rate: 8.5938e-05
Epoch 105/300
1413/1413 - 91s - 65ms/step - accuracy: 0.4938 - loss: 2.3450 - val_accuracy: 0.6178 - val_loss: 1.7227 - learning_rate: 4.2969e-05
Epoch 106/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4906 - loss: 2.3771 - val_accuracy: 0.6226 - val_loss: 1.7159 - learning_rate: 4.2969e-05
Epoch 107/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4911 - loss: 2.3262 - val_accuracy: 0.6314 - val_loss: 1.7106 - learning_rate: 4.2969e-05
Epoch 108/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4845 - loss: 2.3780 - val_accuracy: 0.6242 - val_loss: 1.7110 - learning_rate: 4.2969e-05
Epoch 109/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4877 - loss: 2.3387 - val_accuracy: 0.6322 - val_loss: 1.7024 - learning_rate: 4.2969e-05
Epoch 110/300
1413/1413 - 91s - 64ms/step - accuracy: 0.4863 - loss: 2.3629 - val_accuracy: 0.6186 - val_loss: 1.7186 - learning_rate: 4.2969e-05
Epoch 111/300
1413/1413 - 91s - 65ms/step - accuracy: 0.4911 - loss: 2.3451 - val_accuracy: 0.6266 - val_loss: 1.6927 - learning_rate: 4.2969e-05
Epoch 112/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4832 - loss: 2.3674 - val_accuracy: 0.6234 - val_loss: 1.7071 - learning_rate: 4.2969e-05
Epoch 113/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4915 - loss: 2.3321 - val_accuracy: 0.6282 - val_loss: 1.6967 - learning_rate: 4.2969e-05
Epoch 114/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4910 - loss: 2.3593 - val_accuracy: 0.6242 - val_loss: 1.7099 - learning_rate: 4.2969e-05
Epoch 115/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4853 - loss: 2.3717 - val_accuracy: 0.6202 - val_loss: 1.7204 - learning_rate: 4.2969e-05
Epoch 116/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4861 - loss: 2.3684 - val_accuracy: 0.6186 - val_loss: 1.7065 - learning_rate: 4.2969e-05
Epoch 117/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4906 - loss: 2.3586 - val_accuracy: 0.6218 - val_loss: 1.7194 - learning_rate: 4.2969e-05
Epoch 118/300
1413/1413 - 94s - 66ms/step - accuracy: 0.4907 - loss: 2.3275 - val_accuracy: 0.6226 - val_loss: 1.7119 - learning_rate: 4.2969e-05
Epoch 119/300

Epoch 119: ReduceLROnPlateau reducing learning rate to 2.148461680917535e-05.
1413/1413 - 93s - 66ms/step - accuracy: 0.4848 - loss: 2.3483 - val_accuracy: 0.6266 - val_loss: 1.7018 - learning_rate: 4.2969e-05
Epoch 120/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4890 - loss: 2.3651 - val_accuracy: 0.6258 - val_loss: 1.7205 - learning_rate: 2.1485e-05
Epoch 121/300
1413/1413 - 94s - 66ms/step - accuracy: 0.4973 - loss: 2.3120 - val_accuracy: 0.6266 - val_loss: 1.7065 - learning_rate: 2.1485e-05
Epoch 122/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4911 - loss: 2.3205 - val_accuracy: 0.6226 - val_loss: 1.7011 - learning_rate: 2.1485e-05
Epoch 123/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4925 - loss: 2.3229 - val_accuracy: 0.6298 - val_loss: 1.7092 - learning_rate: 2.1485e-05
Epoch 124/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4945 - loss: 2.3157 - val_accuracy: 0.6210 - val_loss: 1.7118 - learning_rate: 2.1485e-05
Epoch 125/300
1413/1413 - 97s - 68ms/step - accuracy: 0.4887 - loss: 2.3271 - val_accuracy: 0.6258 - val_loss: 1.7070 - learning_rate: 2.1485e-05
Epoch 126/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4983 - loss: 2.3321 - val_accuracy: 0.6258 - val_loss: 1.7054 - learning_rate: 2.1485e-05
Epoch 127/300

Epoch 127: ReduceLROnPlateau reducing learning rate to 1.0742308404587675e-05.
1413/1413 - 96s - 68ms/step - accuracy: 0.4950 - loss: 2.3443 - val_accuracy: 0.6202 - val_loss: 1.7069 - learning_rate: 2.1485e-05
Epoch 127: early stopping
Restoring model weights from the end of the best epoch: 111.
Fold 2 Evaluation results: [1.6977384090423584, 0.6265923380851746]
              precision    recall  f1-score   support

        1820       0.74      0.81      0.77        62
        1821       0.90      0.77      0.83        57
        1822       0.00      0.00      0.00         1
        1823       1.00      0.50      0.67         2
        1824       0.00      0.00      0.00         1
        1825       0.25      0.50      0.33         2
        1826       1.00      0.33      0.50         3
        1827       0.71      0.68      0.69        25
        1828       0.00      0.00      0.00         1
        1829       0.71      1.00      0.83         5
        1830       0.76      0.75      0.76        56
        1831       0.77      0.89      0.83       134
        1832       0.80      0.81      0.80        68
        1833       0.89      0.84      0.86        19
        1834       0.58      0.76      0.66        29
        1835       0.00      0.00      0.00         2
        1836       0.00      0.00      0.00         3
        1837       0.43      0.43      0.43         7
        1838       0.43      0.75      0.55         4
        1839       0.00      0.00      0.00         0
        1840       0.52      0.74      0.61        43
        1841       0.70      0.63      0.66       108
        1842       0.50      0.40      0.44         5
        1843       0.50      0.33      0.40         6
        1844       0.00      0.00      0.00         1
        1845       0.00      0.00      0.00         1
        1846       0.40      0.33      0.36         6
        1847       0.00      0.00      0.00         2
        1848       0.33      0.50      0.40         6
        1849       0.33      0.40      0.36         5
        1850       0.40      0.44      0.42        48
        1851       0.71      0.64      0.67        77
        1852       0.33      0.29      0.31         7
        1853       0.17      0.17      0.17         6
        1854       0.00      0.00      0.00         2
        1855       0.50      0.17      0.25        24
        1856       0.78      0.58      0.67        12
        1857       0.34      0.39      0.36        31
        1858       0.00      0.00      0.00         2
        1859       0.00      0.00      0.00         3
        1860       0.32      0.30      0.31        64
        1861       0.79      0.75      0.77        85
        1862       0.39      0.37      0.38        19
        1863       0.34      0.61      0.44        18
        1864       0.42      0.29      0.34        17
        1865       0.50      0.33      0.40         6
        1866       0.25      0.20      0.22         5
        1867       0.30      0.27      0.29        11
        1868       0.00      0.00      0.00         8
        1869       0.33      0.20      0.25         5
        1870       0.42      0.63      0.51        30
        1871       0.77      0.88      0.82        49
        1872       0.40      0.29      0.33         7
        1873       0.50      0.30      0.38        10
        1874       0.38      0.60      0.46         5
        1875       0.36      0.29      0.32        14
        1876       1.00      0.70      0.82        10
        1877       0.75      0.50      0.60         6
        1878       0.67      0.44      0.53         9
        1879       0.00      0.00      0.00         2

    accuracy                           0.63      1256
   macro avg       0.42      0.40      0.40      1256
weighted avg       0.62      0.63      0.62      1256

Matthews Correlation Coefficient: 0.608
Macro avg F1: 0.396
Weighted avg F1: 0.618
Micro avg F1: 0.627
Top-3 Accuracy: 0.859
Top-5 Accuracy: 0.911
Micro ROC AUC  = 0.99
Macro ROC AUC (present classes) = 0.98
Classification MAE (in years): 3.14

Fold 2 Misclassification Analysis:
Near misses (within 2 years): 111 out of 469 misclassifications (23.67%)
MAE with outliers: 3.14
MAE without outliers: 2.08 (improvement: 1.07)

5 Worst misclassifications:
Image: data/datasets/public/1830/1830_196wikimedia2.jpg, True: 1823, Predicted: 1870, Error: 47
Image: data/datasets/private/1820/1827_44etsy.jpg, True: 1866, Predicted: 1820, Error: 46
Image: data/datasets/private/1840/1841_843etsy.jpg, True: 1864, Predicted: 1820, Error: 44
Image: data/datasets/private/1870/1875_79et.jpg, True: 1876, Predicted: 1832, Error: 44
Image: data/datasets/private/1850/1851_94etsy.jpg, True: 1863, Predicted: 1820, Error: 43

===== Fold 3 =====

===== Fine Tuning 7 layers! =====
Epoch 1/300
1413/1413 - 122s - 86ms/step - accuracy: 0.1959 - loss: 3.9744 - val_accuracy: 0.3535 - val_loss: 3.3916 - learning_rate: 6.8751e-04
Epoch 2/300
1413/1413 - 95s - 67ms/step - accuracy: 0.2733 - loss: 3.5212 - val_accuracy: 0.3861 - val_loss: 2.8197 - learning_rate: 6.8751e-04
Epoch 3/300
1413/1413 - 96s - 68ms/step - accuracy: 0.3081 - loss: 3.3656 - val_accuracy: 0.4522 - val_loss: 2.6360 - learning_rate: 6.8751e-04
Epoch 4/300
1413/1413 - 94s - 66ms/step - accuracy: 0.3255 - loss: 3.2400 - val_accuracy: 0.4538 - val_loss: 2.5367 - learning_rate: 6.8751e-04
Epoch 5/300
1413/1413 - 96s - 68ms/step - accuracy: 0.3384 - loss: 3.1838 - val_accuracy: 0.4896 - val_loss: 2.4563 - learning_rate: 6.8751e-04
Epoch 6/300
1413/1413 - 94s - 67ms/step - accuracy: 0.3596 - loss: 3.1141 - val_accuracy: 0.4896 - val_loss: 2.5550 - learning_rate: 6.8751e-04
Epoch 7/300
1413/1413 - 95s - 67ms/step - accuracy: 0.3561 - loss: 3.1006 - val_accuracy: 0.5096 - val_loss: 2.3266 - learning_rate: 6.8751e-04
Epoch 8/300
1413/1413 - 94s - 66ms/step - accuracy: 0.3632 - loss: 3.0374 - val_accuracy: 0.5119 - val_loss: 2.2622 - learning_rate: 6.8751e-04
Epoch 9/300
1413/1413 - 95s - 67ms/step - accuracy: 0.3654 - loss: 3.0228 - val_accuracy: 0.5398 - val_loss: 2.2528 - learning_rate: 6.8751e-04
Epoch 10/300
1413/1413 - 92s - 65ms/step - accuracy: 0.3739 - loss: 2.9762 - val_accuracy: 0.5303 - val_loss: 2.1920 - learning_rate: 6.8751e-04
Epoch 11/300
1413/1413 - 95s - 67ms/step - accuracy: 0.3753 - loss: 2.9581 - val_accuracy: 0.5191 - val_loss: 2.2895 - learning_rate: 6.8751e-04
Epoch 12/300
1413/1413 - 92s - 65ms/step - accuracy: 0.3845 - loss: 2.9516 - val_accuracy: 0.5247 - val_loss: 2.2272 - learning_rate: 6.8751e-04
Epoch 13/300
1413/1413 - 93s - 65ms/step - accuracy: 0.3813 - loss: 2.9314 - val_accuracy: 0.5462 - val_loss: 2.1872 - learning_rate: 6.8751e-04
Epoch 14/300
1413/1413 - 93s - 66ms/step - accuracy: 0.3863 - loss: 2.9290 - val_accuracy: 0.5151 - val_loss: 2.2646 - learning_rate: 6.8751e-04
Epoch 15/300
1413/1413 - 94s - 67ms/step - accuracy: 0.3851 - loss: 2.9367 - val_accuracy: 0.5701 - val_loss: 2.1014 - learning_rate: 6.8751e-04
Epoch 16/300
1413/1413 - 93s - 66ms/step - accuracy: 0.3893 - loss: 2.8843 - val_accuracy: 0.5199 - val_loss: 2.1792 - learning_rate: 6.8751e-04
Epoch 17/300
1413/1413 - 93s - 66ms/step - accuracy: 0.3949 - loss: 2.8743 - val_accuracy: 0.5263 - val_loss: 2.1617 - learning_rate: 6.8751e-04
Epoch 18/300
1413/1413 - 93s - 66ms/step - accuracy: 0.3991 - loss: 2.8368 - val_accuracy: 0.5661 - val_loss: 2.0310 - learning_rate: 6.8751e-04
Epoch 19/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4008 - loss: 2.8511 - val_accuracy: 0.5287 - val_loss: 2.2935 - learning_rate: 6.8751e-04
Epoch 20/300
1413/1413 - 94s - 66ms/step - accuracy: 0.4037 - loss: 2.8406 - val_accuracy: 0.5470 - val_loss: 2.1275 - learning_rate: 6.8751e-04
Epoch 21/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4009 - loss: 2.8457 - val_accuracy: 0.5557 - val_loss: 2.0738 - learning_rate: 6.8751e-04
Epoch 22/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4025 - loss: 2.8346 - val_accuracy: 0.5518 - val_loss: 2.0343 - learning_rate: 6.8751e-04
Epoch 23/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4035 - loss: 2.8392 - val_accuracy: 0.5756 - val_loss: 2.0255 - learning_rate: 6.8751e-04
Epoch 24/300
1413/1413 - 97s - 68ms/step - accuracy: 0.4086 - loss: 2.8046 - val_accuracy: 0.5573 - val_loss: 2.0299 - learning_rate: 6.8751e-04
Epoch 25/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4078 - loss: 2.8259 - val_accuracy: 0.5637 - val_loss: 2.0332 - learning_rate: 6.8751e-04
Epoch 26/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4117 - loss: 2.8207 - val_accuracy: 0.5685 - val_loss: 2.1184 - learning_rate: 6.8751e-04
Epoch 27/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4104 - loss: 2.8218 - val_accuracy: 0.5685 - val_loss: 2.1167 - learning_rate: 6.8751e-04
Epoch 28/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4089 - loss: 2.8217 - val_accuracy: 0.5637 - val_loss: 2.0307 - learning_rate: 6.8751e-04
Epoch 29/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4072 - loss: 2.8287 - val_accuracy: 0.5406 - val_loss: 2.0744 - learning_rate: 6.8751e-04
Epoch 30/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4090 - loss: 2.7573 - val_accuracy: 0.5502 - val_loss: 2.0288 - learning_rate: 6.8751e-04
Epoch 31/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4183 - loss: 2.7866 - val_accuracy: 0.5661 - val_loss: 1.9475 - learning_rate: 6.8751e-04
Epoch 32/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4146 - loss: 2.7664 - val_accuracy: 0.5740 - val_loss: 2.0235 - learning_rate: 6.8751e-04
Epoch 33/300
1413/1413 - 97s - 68ms/step - accuracy: 0.4110 - loss: 2.7670 - val_accuracy: 0.5478 - val_loss: 1.9953 - learning_rate: 6.8751e-04
Epoch 34/300
1413/1413 - 95s - 68ms/step - accuracy: 0.4171 - loss: 2.7583 - val_accuracy: 0.5637 - val_loss: 1.9732 - learning_rate: 6.8751e-04
Epoch 35/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4166 - loss: 2.7996 - val_accuracy: 0.5717 - val_loss: 1.9970 - learning_rate: 6.8751e-04
Epoch 36/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4128 - loss: 2.7847 - val_accuracy: 0.5629 - val_loss: 2.0025 - learning_rate: 6.8751e-04
Epoch 37/300
1413/1413 - 95s - 68ms/step - accuracy: 0.4202 - loss: 2.7661 - val_accuracy: 0.5661 - val_loss: 2.0407 - learning_rate: 6.8751e-04
Epoch 38/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4237 - loss: 2.7512 - val_accuracy: 0.5820 - val_loss: 1.9332 - learning_rate: 6.8751e-04
Epoch 39/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4222 - loss: 2.7265 - val_accuracy: 0.5732 - val_loss: 1.9531 - learning_rate: 6.8751e-04
Epoch 40/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4210 - loss: 2.7563 - val_accuracy: 0.5788 - val_loss: 2.0081 - learning_rate: 6.8751e-04
Epoch 41/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4147 - loss: 2.7584 - val_accuracy: 0.5900 - val_loss: 1.9682 - learning_rate: 6.8751e-04
Epoch 42/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4224 - loss: 2.7285 - val_accuracy: 0.5486 - val_loss: 2.1023 - learning_rate: 6.8751e-04
Epoch 43/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4233 - loss: 2.7483 - val_accuracy: 0.5701 - val_loss: 2.0011 - learning_rate: 6.8751e-04
Epoch 44/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4248 - loss: 2.7347 - val_accuracy: 0.5693 - val_loss: 1.9734 - learning_rate: 6.8751e-04
Epoch 45/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4266 - loss: 2.7354 - val_accuracy: 0.5812 - val_loss: 1.9582 - learning_rate: 6.8751e-04
Epoch 46/300

Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0003437538689468056.
1413/1413 - 95s - 67ms/step - accuracy: 0.4278 - loss: 2.7487 - val_accuracy: 0.5955 - val_loss: 1.9370 - learning_rate: 6.8751e-04
Epoch 47/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4408 - loss: 2.6525 - val_accuracy: 0.5995 - val_loss: 1.8623 - learning_rate: 3.4375e-04
Epoch 48/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4452 - loss: 2.6205 - val_accuracy: 0.5939 - val_loss: 1.8880 - learning_rate: 3.4375e-04
Epoch 49/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4453 - loss: 2.6116 - val_accuracy: 0.6027 - val_loss: 1.8494 - learning_rate: 3.4375e-04
Epoch 50/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4435 - loss: 2.6080 - val_accuracy: 0.6027 - val_loss: 1.8409 - learning_rate: 3.4375e-04
Epoch 51/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4448 - loss: 2.6183 - val_accuracy: 0.5796 - val_loss: 1.8719 - learning_rate: 3.4375e-04
Epoch 52/300
1413/1413 - 93s - 65ms/step - accuracy: 0.4446 - loss: 2.5813 - val_accuracy: 0.6210 - val_loss: 1.8119 - learning_rate: 3.4375e-04
Epoch 53/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4509 - loss: 2.5915 - val_accuracy: 0.5916 - val_loss: 1.8159 - learning_rate: 3.4375e-04
Epoch 54/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4471 - loss: 2.5708 - val_accuracy: 0.6131 - val_loss: 1.8052 - learning_rate: 3.4375e-04
Epoch 55/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4463 - loss: 2.5735 - val_accuracy: 0.6146 - val_loss: 1.8642 - learning_rate: 3.4375e-04
Epoch 56/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4579 - loss: 2.5589 - val_accuracy: 0.6107 - val_loss: 1.8196 - learning_rate: 3.4375e-04
Epoch 57/300
1413/1413 - 94s - 66ms/step - accuracy: 0.4574 - loss: 2.5517 - val_accuracy: 0.6043 - val_loss: 1.8075 - learning_rate: 3.4375e-04
Epoch 58/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4477 - loss: 2.5810 - val_accuracy: 0.6067 - val_loss: 1.8415 - learning_rate: 3.4375e-04
Epoch 59/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4524 - loss: 2.5496 - val_accuracy: 0.6011 - val_loss: 1.8735 - learning_rate: 3.4375e-04
Epoch 60/300
1413/1413 - 94s - 66ms/step - accuracy: 0.4558 - loss: 2.5725 - val_accuracy: 0.6194 - val_loss: 1.7915 - learning_rate: 3.4375e-04
Epoch 61/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4567 - loss: 2.5511 - val_accuracy: 0.6115 - val_loss: 1.8271 - learning_rate: 3.4375e-04
Epoch 62/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4504 - loss: 2.5583 - val_accuracy: 0.5971 - val_loss: 1.8202 - learning_rate: 3.4375e-04
Epoch 63/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4557 - loss: 2.5698 - val_accuracy: 0.6162 - val_loss: 1.8125 - learning_rate: 3.4375e-04
Epoch 64/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4585 - loss: 2.5428 - val_accuracy: 0.6099 - val_loss: 1.7778 - learning_rate: 3.4375e-04
Epoch 65/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4581 - loss: 2.5551 - val_accuracy: 0.6051 - val_loss: 1.7992 - learning_rate: 3.4375e-04
Epoch 66/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4516 - loss: 2.5778 - val_accuracy: 0.6043 - val_loss: 1.8505 - learning_rate: 3.4375e-04
Epoch 67/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4591 - loss: 2.5450 - val_accuracy: 0.5995 - val_loss: 1.7881 - learning_rate: 3.4375e-04
Epoch 68/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4627 - loss: 2.5384 - val_accuracy: 0.6115 - val_loss: 1.7977 - learning_rate: 3.4375e-04
Epoch 69/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4612 - loss: 2.5276 - val_accuracy: 0.6059 - val_loss: 1.8215 - learning_rate: 3.4375e-04
Epoch 70/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4559 - loss: 2.5771 - val_accuracy: 0.6027 - val_loss: 1.8098 - learning_rate: 3.4375e-04
Epoch 71/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4593 - loss: 2.5359 - val_accuracy: 0.6051 - val_loss: 1.8006 - learning_rate: 3.4375e-04
Epoch 72/300

Epoch 72: ReduceLROnPlateau reducing learning rate to 0.0001718769344734028.
1413/1413 - 96s - 68ms/step - accuracy: 0.4595 - loss: 2.5263 - val_accuracy: 0.6083 - val_loss: 1.7910 - learning_rate: 3.4375e-04
Epoch 73/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4695 - loss: 2.4645 - val_accuracy: 0.6234 - val_loss: 1.7266 - learning_rate: 1.7188e-04
Epoch 74/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4678 - loss: 2.4613 - val_accuracy: 0.6258 - val_loss: 1.7626 - learning_rate: 1.7188e-04
Epoch 75/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4700 - loss: 2.4751 - val_accuracy: 0.6162 - val_loss: 1.7646 - learning_rate: 1.7188e-04
Epoch 76/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4637 - loss: 2.4915 - val_accuracy: 0.6250 - val_loss: 1.7655 - learning_rate: 1.7188e-04
Epoch 77/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4717 - loss: 2.4480 - val_accuracy: 0.6186 - val_loss: 1.7368 - learning_rate: 1.7188e-04
Epoch 78/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4702 - loss: 2.4431 - val_accuracy: 0.6083 - val_loss: 1.7612 - learning_rate: 1.7188e-04
Epoch 79/300
1413/1413 - 95s - 68ms/step - accuracy: 0.4662 - loss: 2.4661 - val_accuracy: 0.6322 - val_loss: 1.7259 - learning_rate: 1.7188e-04
Epoch 80/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4685 - loss: 2.4634 - val_accuracy: 0.6115 - val_loss: 1.7439 - learning_rate: 1.7188e-04
Epoch 81/300
1413/1413 - 95s - 68ms/step - accuracy: 0.4668 - loss: 2.4771 - val_accuracy: 0.6218 - val_loss: 1.7572 - learning_rate: 1.7188e-04
Epoch 82/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4760 - loss: 2.4766 - val_accuracy: 0.6306 - val_loss: 1.7131 - learning_rate: 1.7188e-04
Epoch 83/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4748 - loss: 2.4508 - val_accuracy: 0.6234 - val_loss: 1.7255 - learning_rate: 1.7188e-04
Epoch 84/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4741 - loss: 2.4542 - val_accuracy: 0.6123 - val_loss: 1.7273 - learning_rate: 1.7188e-04
Epoch 85/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4688 - loss: 2.4462 - val_accuracy: 0.6154 - val_loss: 1.7355 - learning_rate: 1.7188e-04
Epoch 86/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4733 - loss: 2.4651 - val_accuracy: 0.6226 - val_loss: 1.7493 - learning_rate: 1.7188e-04
Epoch 87/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4693 - loss: 2.4444 - val_accuracy: 0.6266 - val_loss: 1.7361 - learning_rate: 1.7188e-04
Epoch 88/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4724 - loss: 2.4461 - val_accuracy: 0.6330 - val_loss: 1.7119 - learning_rate: 1.7188e-04
Epoch 89/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4759 - loss: 2.4460 - val_accuracy: 0.6162 - val_loss: 1.7297 - learning_rate: 1.7188e-04
Epoch 90/300
1413/1413 - 95s - 68ms/step - accuracy: 0.4782 - loss: 2.4069 - val_accuracy: 0.6330 - val_loss: 1.7346 - learning_rate: 1.7188e-04
Epoch 91/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4785 - loss: 2.4655 - val_accuracy: 0.6234 - val_loss: 1.7149 - learning_rate: 1.7188e-04
Epoch 92/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4723 - loss: 2.4506 - val_accuracy: 0.6298 - val_loss: 1.7247 - learning_rate: 1.7188e-04
Epoch 93/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4732 - loss: 2.4616 - val_accuracy: 0.6234 - val_loss: 1.7246 - learning_rate: 1.7188e-04
Epoch 94/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4803 - loss: 2.4314 - val_accuracy: 0.6170 - val_loss: 1.7483 - learning_rate: 1.7188e-04
Epoch 95/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4737 - loss: 2.4149 - val_accuracy: 0.6385 - val_loss: 1.6999 - learning_rate: 1.7188e-04
Epoch 96/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4716 - loss: 2.4512 - val_accuracy: 0.6282 - val_loss: 1.6957 - learning_rate: 1.7188e-04
Epoch 97/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4736 - loss: 2.4241 - val_accuracy: 0.6338 - val_loss: 1.6928 - learning_rate: 1.7188e-04
Epoch 98/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4711 - loss: 2.4483 - val_accuracy: 0.6290 - val_loss: 1.6698 - learning_rate: 1.7188e-04
Epoch 99/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4793 - loss: 2.4276 - val_accuracy: 0.6194 - val_loss: 1.6769 - learning_rate: 1.7188e-04
Epoch 100/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4750 - loss: 2.4441 - val_accuracy: 0.6369 - val_loss: 1.6710 - learning_rate: 1.7188e-04
Epoch 101/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4775 - loss: 2.4187 - val_accuracy: 0.6354 - val_loss: 1.6822 - learning_rate: 1.7188e-04
Epoch 102/300
1413/1413 - 95s - 68ms/step - accuracy: 0.4755 - loss: 2.4340 - val_accuracy: 0.6489 - val_loss: 1.6758 - learning_rate: 1.7188e-04
Epoch 103/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4767 - loss: 2.4324 - val_accuracy: 0.6242 - val_loss: 1.6790 - learning_rate: 1.7188e-04
Epoch 104/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4785 - loss: 2.4417 - val_accuracy: 0.6242 - val_loss: 1.6865 - learning_rate: 1.7188e-04
Epoch 105/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4747 - loss: 2.4305 - val_accuracy: 0.6258 - val_loss: 1.6917 - learning_rate: 1.7188e-04
Epoch 106/300

Epoch 106: ReduceLROnPlateau reducing learning rate to 8.59384672367014e-05.
1413/1413 - 95s - 67ms/step - accuracy: 0.4750 - loss: 2.4112 - val_accuracy: 0.6322 - val_loss: 1.6797 - learning_rate: 1.7188e-04
Epoch 107/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4837 - loss: 2.4136 - val_accuracy: 0.6330 - val_loss: 1.6567 - learning_rate: 8.5938e-05
Epoch 108/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4807 - loss: 2.3990 - val_accuracy: 0.6282 - val_loss: 1.6587 - learning_rate: 8.5938e-05
Epoch 109/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4841 - loss: 2.4018 - val_accuracy: 0.6234 - val_loss: 1.6755 - learning_rate: 8.5938e-05
Epoch 110/300
1413/1413 - 95s - 68ms/step - accuracy: 0.4796 - loss: 2.4007 - val_accuracy: 0.6361 - val_loss: 1.6488 - learning_rate: 8.5938e-05
Epoch 111/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4818 - loss: 2.4165 - val_accuracy: 0.6354 - val_loss: 1.6847 - learning_rate: 8.5938e-05
Epoch 112/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4830 - loss: 2.4055 - val_accuracy: 0.6369 - val_loss: 1.6736 - learning_rate: 8.5938e-05
Epoch 113/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4842 - loss: 2.3860 - val_accuracy: 0.6377 - val_loss: 1.6541 - learning_rate: 8.5938e-05
Epoch 114/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4835 - loss: 2.3787 - val_accuracy: 0.6377 - val_loss: 1.6406 - learning_rate: 8.5938e-05
Epoch 115/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4820 - loss: 2.4066 - val_accuracy: 0.6401 - val_loss: 1.6693 - learning_rate: 8.5938e-05
Epoch 116/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4837 - loss: 2.3911 - val_accuracy: 0.6441 - val_loss: 1.6346 - learning_rate: 8.5938e-05
Epoch 117/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4806 - loss: 2.3961 - val_accuracy: 0.6457 - val_loss: 1.6378 - learning_rate: 8.5938e-05
Epoch 118/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4847 - loss: 2.3986 - val_accuracy: 0.6369 - val_loss: 1.6643 - learning_rate: 8.5938e-05
Epoch 119/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4828 - loss: 2.4065 - val_accuracy: 0.6346 - val_loss: 1.6838 - learning_rate: 8.5938e-05
Epoch 120/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4838 - loss: 2.4107 - val_accuracy: 0.6521 - val_loss: 1.6496 - learning_rate: 8.5938e-05
Epoch 121/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4849 - loss: 2.3939 - val_accuracy: 0.6441 - val_loss: 1.6393 - learning_rate: 8.5938e-05
Epoch 122/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4852 - loss: 2.3805 - val_accuracy: 0.6369 - val_loss: 1.6504 - learning_rate: 8.5938e-05
Epoch 123/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4854 - loss: 2.3790 - val_accuracy: 0.6393 - val_loss: 1.6372 - learning_rate: 8.5938e-05
Epoch 124/300

Epoch 124: ReduceLROnPlateau reducing learning rate to 4.29692336183507e-05.
1413/1413 - 96s - 68ms/step - accuracy: 0.4876 - loss: 2.3855 - val_accuracy: 0.6401 - val_loss: 1.6695 - learning_rate: 8.5938e-05
Epoch 125/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4927 - loss: 2.3612 - val_accuracy: 0.6354 - val_loss: 1.6581 - learning_rate: 4.2969e-05
Epoch 126/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4883 - loss: 2.3452 - val_accuracy: 0.6441 - val_loss: 1.6426 - learning_rate: 4.2969e-05
Epoch 127/300
1413/1413 - 95s - 68ms/step - accuracy: 0.4862 - loss: 2.3680 - val_accuracy: 0.6401 - val_loss: 1.6506 - learning_rate: 4.2969e-05
Epoch 128/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4839 - loss: 2.3838 - val_accuracy: 0.6449 - val_loss: 1.6474 - learning_rate: 4.2969e-05
Epoch 129/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4869 - loss: 2.3478 - val_accuracy: 0.6314 - val_loss: 1.6510 - learning_rate: 4.2969e-05
Epoch 130/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4843 - loss: 2.3592 - val_accuracy: 0.6425 - val_loss: 1.6345 - learning_rate: 4.2969e-05
Epoch 131/300
1413/1413 - 95s - 68ms/step - accuracy: 0.4891 - loss: 2.3511 - val_accuracy: 0.6473 - val_loss: 1.6423 - learning_rate: 4.2969e-05
Epoch 132/300

Epoch 132: ReduceLROnPlateau reducing learning rate to 2.148461680917535e-05.
1413/1413 - 95s - 67ms/step - accuracy: 0.4891 - loss: 2.3627 - val_accuracy: 0.6433 - val_loss: 1.6415 - learning_rate: 4.2969e-05
Epoch 132: early stopping
Restoring model weights from the end of the best epoch: 116.
Fold 3 Evaluation results: [1.6400765180587769, 0.6441082954406738]
              precision    recall  f1-score   support

        1820       0.75      0.77      0.76        62
        1821       0.88      0.88      0.88        57
        1822       0.00      0.00      0.00         1
        1823       0.25      0.50      0.33         2
        1824       0.00      0.00      0.00         1
        1825       0.25      0.50      0.33         2
        1826       0.00      0.00      0.00         3
        1827       0.80      0.64      0.71        25
        1828       0.00      0.00      0.00         2
        1829       0.57      0.80      0.67         5
        1830       0.54      0.71      0.62        56
        1831       0.84      0.85      0.84       134
        1832       0.87      0.79      0.83        68
        1833       0.94      0.89      0.92        19
        1834       0.54      0.67      0.60        30
        1835       0.00      0.00      0.00         2
        1836       0.00      0.00      0.00         3
        1837       0.14      0.29      0.19         7
        1838       0.00      0.00      0.00         4
        1839       0.00      0.00      0.00         1
        1840       0.69      0.72      0.70        43
        1841       0.71      0.78      0.74       108
        1842       0.67      0.40      0.50         5
        1843       0.25      0.17      0.20         6
        1844       0.00      0.00      0.00         0
        1845       0.00      0.00      0.00         1
        1846       0.00      0.00      0.00         5
        1847       0.50      0.50      0.50         2
        1848       1.00      0.17      0.29         6
        1849       0.67      0.40      0.50         5
        1850       0.57      0.79      0.66        47
        1851       0.74      0.73      0.73        77
        1852       0.60      0.43      0.50         7
        1853       0.33      0.17      0.22         6
        1854       0.00      0.00      0.00         2
        1855       0.33      0.17      0.23        23
        1856       0.56      0.42      0.48        12
        1857       0.49      0.58      0.53        31
        1858       0.00      0.00      0.00         2
        1859       0.00      0.00      0.00         3
        1860       0.53      0.38      0.44        64
        1861       0.77      0.82      0.80        85
        1862       0.24      0.21      0.22        19
        1863       0.45      0.50      0.47        18
        1864       0.33      0.47      0.39        17
        1865       0.25      0.17      0.20         6
        1866       0.12      0.17      0.14         6
        1867       0.31      0.40      0.35        10
        1868       0.00      0.00      0.00         8
        1869       0.00      0.00      0.00         5
        1870       0.49      0.57      0.52        30
        1871       0.63      0.68      0.65        50
        1872       0.40      0.29      0.33         7
        1873       0.40      0.18      0.25        11
        1874       0.25      0.40      0.31         5
        1875       0.42      0.36      0.38        14
        1876       0.71      0.50      0.59        10
        1877       0.29      0.33      0.31         6
        1878       0.67      0.67      0.67         9
        1879       0.00      0.00      0.00         1

    accuracy                           0.64      1256
   macro avg       0.38      0.36      0.36      1256
weighted avg       0.63      0.64      0.63      1256

Matthews Correlation Coefficient: 0.626
Macro avg F1: 0.358
Weighted avg F1: 0.633
Micro avg F1: 0.644
Top-3 Accuracy: 0.860
Top-5 Accuracy: 0.921
Micro ROC AUC  = 0.99
Macro ROC AUC (present classes) = 0.98
Classification MAE (in years): 2.80

Fold 3 Misclassification Analysis:
Near misses (within 2 years): 119 out of 447 misclassifications (26.62%)
MAE with outliers: 2.80
MAE without outliers: 1.89 (improvement: 0.91)

5 Worst misclassifications:
Image: data/datasets/public/1870/1873_042_001met.jpg, True: 1876, Predicted: 1820, Error: 56
Image: data/datasets/public/1830/1830_122_001wikimedia2.jpg, True: 1871, Predicted: 1821, Error: 50
Image: data/datasets/private/1870/1871_23etsy.jpg, True: 1870, Predicted: 1820, Error: 50
Image: data/datasets/private/1860/1861_70etsy.jpg, True: 1820, Predicted: 1867, Error: 47
Image: data/datasets/private/1850/1855_87et.jpg, True: 1862, Predicted: 1820, Error: 42

===== Fold 4 =====

===== Fine Tuning 7 layers! =====
Epoch 1/300
1413/1413 - 121s - 86ms/step - accuracy: 0.1987 - loss: 4.0153 - val_accuracy: 0.3240 - val_loss: 3.4367 - learning_rate: 6.8751e-04
Epoch 2/300
1413/1413 - 96s - 68ms/step - accuracy: 0.2769 - loss: 3.4944 - val_accuracy: 0.3973 - val_loss: 2.8302 - learning_rate: 6.8751e-04
Epoch 3/300
1413/1413 - 96s - 68ms/step - accuracy: 0.3092 - loss: 3.3679 - val_accuracy: 0.4188 - val_loss: 2.7848 - learning_rate: 6.8751e-04
Epoch 4/300
1413/1413 - 96s - 68ms/step - accuracy: 0.3328 - loss: 3.2281 - val_accuracy: 0.4761 - val_loss: 2.5347 - learning_rate: 6.8751e-04
Epoch 5/300
1413/1413 - 96s - 68ms/step - accuracy: 0.3413 - loss: 3.1855 - val_accuracy: 0.4809 - val_loss: 2.4471 - learning_rate: 6.8751e-04
Epoch 6/300
1413/1413 - 96s - 68ms/step - accuracy: 0.3511 - loss: 3.1091 - val_accuracy: 0.5135 - val_loss: 2.3594 - learning_rate: 6.8751e-04
Epoch 7/300
1413/1413 - 95s - 67ms/step - accuracy: 0.3585 - loss: 3.0677 - val_accuracy: 0.4865 - val_loss: 2.3721 - learning_rate: 6.8751e-04
Epoch 8/300
1413/1413 - 95s - 67ms/step - accuracy: 0.3674 - loss: 3.0309 - val_accuracy: 0.4841 - val_loss: 2.4044 - learning_rate: 6.8751e-04
Epoch 9/300
1413/1413 - 95s - 68ms/step - accuracy: 0.3667 - loss: 2.9956 - val_accuracy: 0.4889 - val_loss: 2.3145 - learning_rate: 6.8751e-04
Epoch 10/300
1413/1413 - 96s - 68ms/step - accuracy: 0.3611 - loss: 3.0107 - val_accuracy: 0.5279 - val_loss: 2.1869 - learning_rate: 6.8751e-04
Epoch 11/300
1413/1413 - 96s - 68ms/step - accuracy: 0.3729 - loss: 2.9684 - val_accuracy: 0.5016 - val_loss: 2.2314 - learning_rate: 6.8751e-04
Epoch 12/300
1413/1413 - 95s - 67ms/step - accuracy: 0.3766 - loss: 2.9411 - val_accuracy: 0.5119 - val_loss: 2.2256 - learning_rate: 6.8751e-04
Epoch 13/300
1413/1413 - 96s - 68ms/step - accuracy: 0.3882 - loss: 2.9272 - val_accuracy: 0.5263 - val_loss: 2.1586 - learning_rate: 6.8751e-04
Epoch 14/300
1413/1413 - 96s - 68ms/step - accuracy: 0.3829 - loss: 2.9312 - val_accuracy: 0.4968 - val_loss: 2.2455 - learning_rate: 6.8751e-04
Epoch 15/300
1413/1413 - 95s - 67ms/step - accuracy: 0.3841 - loss: 2.8910 - val_accuracy: 0.5191 - val_loss: 2.2520 - learning_rate: 6.8751e-04
Epoch 16/300
1413/1413 - 96s - 68ms/step - accuracy: 0.3851 - loss: 2.8841 - val_accuracy: 0.5175 - val_loss: 2.1941 - learning_rate: 6.8751e-04
Epoch 17/300
1413/1413 - 96s - 68ms/step - accuracy: 0.3957 - loss: 2.8485 - val_accuracy: 0.5470 - val_loss: 2.1469 - learning_rate: 6.8751e-04
Epoch 18/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4036 - loss: 2.8458 - val_accuracy: 0.5287 - val_loss: 2.1990 - learning_rate: 6.8751e-04
Epoch 19/300
1413/1413 - 95s - 68ms/step - accuracy: 0.3995 - loss: 2.8288 - val_accuracy: 0.5191 - val_loss: 2.1950 - learning_rate: 6.8751e-04
Epoch 20/300
1413/1413 - 97s - 68ms/step - accuracy: 0.3979 - loss: 2.8501 - val_accuracy: 0.5502 - val_loss: 2.0353 - learning_rate: 6.8751e-04
Epoch 21/300
1413/1413 - 96s - 68ms/step - accuracy: 0.3977 - loss: 2.8500 - val_accuracy: 0.5231 - val_loss: 2.1883 - learning_rate: 6.8751e-04
Epoch 22/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4114 - loss: 2.8203 - val_accuracy: 0.5430 - val_loss: 2.1210 - learning_rate: 6.8751e-04
Epoch 23/300
1413/1413 - 95s - 68ms/step - accuracy: 0.4084 - loss: 2.8180 - val_accuracy: 0.5565 - val_loss: 2.1059 - learning_rate: 6.8751e-04
Epoch 24/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4070 - loss: 2.8142 - val_accuracy: 0.5342 - val_loss: 2.1540 - learning_rate: 6.8751e-04
Epoch 25/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4048 - loss: 2.8282 - val_accuracy: 0.5311 - val_loss: 2.1191 - learning_rate: 6.8751e-04
Epoch 26/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4095 - loss: 2.8047 - val_accuracy: 0.5677 - val_loss: 2.0069 - learning_rate: 6.8751e-04
Epoch 27/300
1413/1413 - 90s - 64ms/step - accuracy: 0.4110 - loss: 2.7891 - val_accuracy: 0.5470 - val_loss: 2.0628 - learning_rate: 6.8751e-04
Epoch 28/300
1413/1413 - 90s - 64ms/step - accuracy: 0.4124 - loss: 2.7720 - val_accuracy: 0.5613 - val_loss: 2.0152 - learning_rate: 6.8751e-04
Epoch 29/300
1413/1413 - 90s - 64ms/step - accuracy: 0.4107 - loss: 2.7893 - val_accuracy: 0.5637 - val_loss: 2.0126 - learning_rate: 6.8751e-04
Epoch 30/300
1413/1413 - 89s - 63ms/step - accuracy: 0.4119 - loss: 2.7615 - val_accuracy: 0.5502 - val_loss: 2.1726 - learning_rate: 6.8751e-04
Epoch 31/300
1413/1413 - 91s - 64ms/step - accuracy: 0.4166 - loss: 2.7905 - val_accuracy: 0.5581 - val_loss: 1.9824 - learning_rate: 6.8751e-04
Epoch 32/300
1413/1413 - 90s - 64ms/step - accuracy: 0.4133 - loss: 2.7633 - val_accuracy: 0.5709 - val_loss: 2.0134 - learning_rate: 6.8751e-04
Epoch 33/300
1413/1413 - 90s - 64ms/step - accuracy: 0.4180 - loss: 2.7631 - val_accuracy: 0.5605 - val_loss: 2.0260 - learning_rate: 6.8751e-04
Epoch 34/300
1413/1413 - 91s - 64ms/step - accuracy: 0.4113 - loss: 2.7933 - val_accuracy: 0.5828 - val_loss: 1.9585 - learning_rate: 6.8751e-04
Epoch 35/300
1413/1413 - 87s - 62ms/step - accuracy: 0.4189 - loss: 2.7510 - val_accuracy: 0.5780 - val_loss: 1.9871 - learning_rate: 6.8751e-04
Epoch 36/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4187 - loss: 2.7445 - val_accuracy: 0.5430 - val_loss: 2.0531 - learning_rate: 6.8751e-04
Epoch 37/300
1413/1413 - 87s - 62ms/step - accuracy: 0.4270 - loss: 2.7176 - val_accuracy: 0.5780 - val_loss: 1.9657 - learning_rate: 6.8751e-04
Epoch 38/300
1413/1413 - 90s - 63ms/step - accuracy: 0.4146 - loss: 2.7511 - val_accuracy: 0.5764 - val_loss: 1.9970 - learning_rate: 6.8751e-04
Epoch 39/300
1413/1413 - 90s - 64ms/step - accuracy: 0.4223 - loss: 2.7589 - val_accuracy: 0.5494 - val_loss: 1.9819 - learning_rate: 6.8751e-04
Epoch 40/300
1413/1413 - 89s - 63ms/step - accuracy: 0.4157 - loss: 2.7712 - val_accuracy: 0.5677 - val_loss: 2.0264 - learning_rate: 6.8751e-04
Epoch 41/300
1413/1413 - 90s - 64ms/step - accuracy: 0.4156 - loss: 2.7447 - val_accuracy: 0.5788 - val_loss: 1.9561 - learning_rate: 6.8751e-04
Epoch 42/300
1413/1413 - 88s - 63ms/step - accuracy: 0.4200 - loss: 2.7338 - val_accuracy: 0.5764 - val_loss: 1.9786 - learning_rate: 6.8751e-04
Epoch 43/300
1413/1413 - 90s - 63ms/step - accuracy: 0.4243 - loss: 2.7305 - val_accuracy: 0.5661 - val_loss: 2.0336 - learning_rate: 6.8751e-04
Epoch 44/300
1413/1413 - 89s - 63ms/step - accuracy: 0.4139 - loss: 2.7225 - val_accuracy: 0.5804 - val_loss: 1.9639 - learning_rate: 6.8751e-04
Epoch 45/300
1413/1413 - 88s - 62ms/step - accuracy: 0.4248 - loss: 2.7063 - val_accuracy: 0.5780 - val_loss: 2.0119 - learning_rate: 6.8751e-04
Epoch 46/300
1413/1413 - 89s - 63ms/step - accuracy: 0.4285 - loss: 2.7055 - val_accuracy: 0.5621 - val_loss: 2.0231 - learning_rate: 6.8751e-04
Epoch 47/300
1413/1413 - 90s - 63ms/step - accuracy: 0.4179 - loss: 2.7245 - val_accuracy: 0.5828 - val_loss: 1.9428 - learning_rate: 6.8751e-04
Epoch 48/300
1413/1413 - 89s - 63ms/step - accuracy: 0.4339 - loss: 2.6968 - val_accuracy: 0.5884 - val_loss: 1.9637 - learning_rate: 6.8751e-04
Epoch 49/300
1413/1413 - 88s - 63ms/step - accuracy: 0.4270 - loss: 2.7185 - val_accuracy: 0.5868 - val_loss: 1.9178 - learning_rate: 6.8751e-04
Epoch 50/300
1413/1413 - 88s - 62ms/step - accuracy: 0.4194 - loss: 2.7082 - val_accuracy: 0.5518 - val_loss: 2.0850 - learning_rate: 6.8751e-04
Epoch 51/300
1413/1413 - 90s - 63ms/step - accuracy: 0.4241 - loss: 2.7216 - val_accuracy: 0.5637 - val_loss: 2.0379 - learning_rate: 6.8751e-04
Epoch 52/300
1413/1413 - 90s - 63ms/step - accuracy: 0.4220 - loss: 2.7029 - val_accuracy: 0.5995 - val_loss: 1.9296 - learning_rate: 6.8751e-04
Epoch 53/300
1413/1413 - 89s - 63ms/step - accuracy: 0.4256 - loss: 2.6950 - val_accuracy: 0.5637 - val_loss: 1.9899 - learning_rate: 6.8751e-04
Epoch 54/300
1413/1413 - 89s - 63ms/step - accuracy: 0.4226 - loss: 2.6901 - val_accuracy: 0.5621 - val_loss: 1.9592 - learning_rate: 6.8751e-04
Epoch 55/300
1413/1413 - 90s - 63ms/step - accuracy: 0.4338 - loss: 2.7015 - val_accuracy: 0.5812 - val_loss: 1.9368 - learning_rate: 6.8751e-04
Epoch 56/300
1413/1413 - 89s - 63ms/step - accuracy: 0.4225 - loss: 2.7215 - val_accuracy: 0.5780 - val_loss: 1.9917 - learning_rate: 6.8751e-04
Epoch 57/300

Epoch 57: ReduceLROnPlateau reducing learning rate to 0.0003437538689468056.
1413/1413 - 89s - 63ms/step - accuracy: 0.4217 - loss: 2.7145 - val_accuracy: 0.5748 - val_loss: 1.9556 - learning_rate: 6.8751e-04
Epoch 58/300
1413/1413 - 89s - 63ms/step - accuracy: 0.4480 - loss: 2.6272 - val_accuracy: 0.5955 - val_loss: 1.8839 - learning_rate: 3.4375e-04
Epoch 59/300
1413/1413 - 89s - 63ms/step - accuracy: 0.4432 - loss: 2.5932 - val_accuracy: 0.5828 - val_loss: 1.8878 - learning_rate: 3.4375e-04
Epoch 60/300
1413/1413 - 89s - 63ms/step - accuracy: 0.4484 - loss: 2.5910 - val_accuracy: 0.5924 - val_loss: 1.8302 - learning_rate: 3.4375e-04
Epoch 61/300
1413/1413 - 90s - 63ms/step - accuracy: 0.4483 - loss: 2.5862 - val_accuracy: 0.5908 - val_loss: 1.8592 - learning_rate: 3.4375e-04
Epoch 62/300
1413/1413 - 89s - 63ms/step - accuracy: 0.4535 - loss: 2.5453 - val_accuracy: 0.5924 - val_loss: 1.8496 - learning_rate: 3.4375e-04
Epoch 63/300
1413/1413 - 86s - 61ms/step - accuracy: 0.4540 - loss: 2.5617 - val_accuracy: 0.5900 - val_loss: 1.8409 - learning_rate: 3.4375e-04
Epoch 64/300
1413/1413 - 89s - 63ms/step - accuracy: 0.4540 - loss: 2.5542 - val_accuracy: 0.5939 - val_loss: 1.8189 - learning_rate: 3.4375e-04
Epoch 65/300
1413/1413 - 89s - 63ms/step - accuracy: 0.4534 - loss: 2.5488 - val_accuracy: 0.6011 - val_loss: 1.8441 - learning_rate: 3.4375e-04
Epoch 66/300
1413/1413 - 89s - 63ms/step - accuracy: 0.4525 - loss: 2.5420 - val_accuracy: 0.5828 - val_loss: 1.8371 - learning_rate: 3.4375e-04
Epoch 67/300
1413/1413 - 89s - 63ms/step - accuracy: 0.4551 - loss: 2.5605 - val_accuracy: 0.5971 - val_loss: 1.8393 - learning_rate: 3.4375e-04
Epoch 68/300
1413/1413 - 90s - 64ms/step - accuracy: 0.4515 - loss: 2.5391 - val_accuracy: 0.5987 - val_loss: 1.8711 - learning_rate: 3.4375e-04
Epoch 69/300
1413/1413 - 88s - 62ms/step - accuracy: 0.4521 - loss: 2.5521 - val_accuracy: 0.5804 - val_loss: 1.8416 - learning_rate: 3.4375e-04
Epoch 70/300
1413/1413 - 87s - 62ms/step - accuracy: 0.4578 - loss: 2.5539 - val_accuracy: 0.6011 - val_loss: 1.8466 - learning_rate: 3.4375e-04
Epoch 71/300
1413/1413 - 89s - 63ms/step - accuracy: 0.4542 - loss: 2.5464 - val_accuracy: 0.6043 - val_loss: 1.8306 - learning_rate: 3.4375e-04
Epoch 72/300

Epoch 72: ReduceLROnPlateau reducing learning rate to 0.0001718769344734028.
1413/1413 - 88s - 62ms/step - accuracy: 0.4561 - loss: 2.5226 - val_accuracy: 0.5908 - val_loss: 1.8764 - learning_rate: 3.4375e-04
Epoch 73/300
1413/1413 - 88s - 62ms/step - accuracy: 0.4680 - loss: 2.5151 - val_accuracy: 0.6019 - val_loss: 1.7860 - learning_rate: 1.7188e-04
Epoch 74/300
1413/1413 - 87s - 62ms/step - accuracy: 0.4604 - loss: 2.4774 - val_accuracy: 0.6027 - val_loss: 1.7859 - learning_rate: 1.7188e-04
Epoch 75/300
1413/1413 - 90s - 63ms/step - accuracy: 0.4614 - loss: 2.4775 - val_accuracy: 0.6075 - val_loss: 1.7677 - learning_rate: 1.7188e-04
Epoch 76/300
1413/1413 - 85s - 60ms/step - accuracy: 0.4649 - loss: 2.4933 - val_accuracy: 0.6011 - val_loss: 1.7830 - learning_rate: 1.7188e-04
Epoch 77/300
1413/1413 - 90s - 64ms/step - accuracy: 0.4745 - loss: 2.4421 - val_accuracy: 0.5932 - val_loss: 1.7627 - learning_rate: 1.7188e-04
Epoch 78/300
1413/1413 - 89s - 63ms/step - accuracy: 0.4689 - loss: 2.4682 - val_accuracy: 0.6099 - val_loss: 1.7723 - learning_rate: 1.7188e-04
Epoch 79/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4662 - loss: 2.4585 - val_accuracy: 0.6051 - val_loss: 1.7501 - learning_rate: 1.7188e-04
Epoch 80/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4644 - loss: 2.4739 - val_accuracy: 0.5987 - val_loss: 1.7618 - learning_rate: 1.7188e-04
Epoch 81/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4698 - loss: 2.4526 - val_accuracy: 0.6067 - val_loss: 1.7292 - learning_rate: 1.7188e-04
Epoch 82/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4706 - loss: 2.4395 - val_accuracy: 0.6067 - val_loss: 1.7535 - learning_rate: 1.7188e-04
Epoch 83/300
1413/1413 - 97s - 68ms/step - accuracy: 0.4701 - loss: 2.4638 - val_accuracy: 0.6107 - val_loss: 1.7726 - learning_rate: 1.7188e-04
Epoch 84/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4660 - loss: 2.4657 - val_accuracy: 0.6035 - val_loss: 1.7465 - learning_rate: 1.7188e-04
Epoch 85/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4702 - loss: 2.4518 - val_accuracy: 0.6019 - val_loss: 1.7460 - learning_rate: 1.7188e-04
Epoch 86/300
1413/1413 - 97s - 68ms/step - accuracy: 0.4642 - loss: 2.4884 - val_accuracy: 0.6027 - val_loss: 1.7471 - learning_rate: 1.7188e-04
Epoch 87/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4689 - loss: 2.4555 - val_accuracy: 0.6131 - val_loss: 1.7558 - learning_rate: 1.7188e-04
Epoch 88/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4713 - loss: 2.4581 - val_accuracy: 0.6115 - val_loss: 1.7610 - learning_rate: 1.7188e-04
Epoch 89/300

Epoch 89: ReduceLROnPlateau reducing learning rate to 8.59384672367014e-05.
1413/1413 - 96s - 68ms/step - accuracy: 0.4739 - loss: 2.4472 - val_accuracy: 0.6075 - val_loss: 1.7477 - learning_rate: 1.7188e-04
Epoch 90/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4696 - loss: 2.4456 - val_accuracy: 0.6131 - val_loss: 1.7062 - learning_rate: 8.5938e-05
Epoch 91/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4714 - loss: 2.4163 - val_accuracy: 0.6107 - val_loss: 1.7247 - learning_rate: 8.5938e-05
Epoch 92/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4718 - loss: 2.4352 - val_accuracy: 0.6139 - val_loss: 1.6951 - learning_rate: 8.5938e-05
Epoch 93/300
1413/1413 - 91s - 65ms/step - accuracy: 0.4754 - loss: 2.4366 - val_accuracy: 0.6131 - val_loss: 1.7435 - learning_rate: 8.5938e-05
Epoch 94/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4817 - loss: 2.4013 - val_accuracy: 0.6202 - val_loss: 1.7331 - learning_rate: 8.5938e-05
Epoch 95/300
1413/1413 - 91s - 64ms/step - accuracy: 0.4757 - loss: 2.4054 - val_accuracy: 0.6131 - val_loss: 1.7380 - learning_rate: 8.5938e-05
Epoch 96/300
1413/1413 - 94s - 66ms/step - accuracy: 0.4717 - loss: 2.4568 - val_accuracy: 0.6075 - val_loss: 1.7252 - learning_rate: 8.5938e-05
Epoch 97/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4748 - loss: 2.4312 - val_accuracy: 0.6162 - val_loss: 1.7286 - learning_rate: 8.5938e-05
Epoch 98/300
1413/1413 - 90s - 64ms/step - accuracy: 0.4778 - loss: 2.4324 - val_accuracy: 0.6115 - val_loss: 1.7245 - learning_rate: 8.5938e-05
Epoch 99/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4795 - loss: 2.4181 - val_accuracy: 0.6194 - val_loss: 1.7293 - learning_rate: 8.5938e-05
Epoch 100/300

Epoch 100: ReduceLROnPlateau reducing learning rate to 4.29692336183507e-05.
1413/1413 - 94s - 66ms/step - accuracy: 0.4763 - loss: 2.4214 - val_accuracy: 0.6083 - val_loss: 1.7294 - learning_rate: 8.5938e-05
Epoch 101/300
1413/1413 - 97s - 68ms/step - accuracy: 0.4800 - loss: 2.3954 - val_accuracy: 0.6131 - val_loss: 1.7169 - learning_rate: 4.2969e-05
Epoch 102/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4816 - loss: 2.3981 - val_accuracy: 0.6131 - val_loss: 1.7099 - learning_rate: 4.2969e-05
Epoch 103/300
1413/1413 - 94s - 66ms/step - accuracy: 0.4855 - loss: 2.3909 - val_accuracy: 0.6091 - val_loss: 1.7279 - learning_rate: 4.2969e-05
Epoch 104/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4785 - loss: 2.4041 - val_accuracy: 0.6107 - val_loss: 1.7147 - learning_rate: 4.2969e-05
Epoch 105/300
1413/1413 - 89s - 63ms/step - accuracy: 0.4889 - loss: 2.3697 - val_accuracy: 0.6194 - val_loss: 1.7181 - learning_rate: 4.2969e-05
Epoch 106/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4727 - loss: 2.4206 - val_accuracy: 0.6170 - val_loss: 1.7219 - learning_rate: 4.2969e-05
Epoch 107/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4857 - loss: 2.3770 - val_accuracy: 0.6210 - val_loss: 1.7180 - learning_rate: 4.2969e-05
Epoch 108/300

Epoch 108: ReduceLROnPlateau reducing learning rate to 2.148461680917535e-05.
1413/1413 - 93s - 66ms/step - accuracy: 0.4855 - loss: 2.3847 - val_accuracy: 0.6131 - val_loss: 1.7151 - learning_rate: 4.2969e-05
Epoch 108: early stopping
Restoring model weights from the end of the best epoch: 92.
Fold 4 Evaluation results: [1.704345464706421, 0.6138535141944885]
              precision    recall  f1-score   support

        1820       0.72      0.74      0.73        62
        1821       0.96      0.83      0.89        58
        1822       0.00      0.00      0.00         1
        1823       1.00      0.50      0.67         2
        1824       0.00      0.00      0.00         1
        1825       0.33      0.50      0.40         2
        1826       0.00      0.00      0.00         3
        1827       0.67      0.80      0.73        25
        1828       0.50      0.50      0.50         2
        1829       0.67      1.00      0.80         4
        1830       0.68      0.70      0.69        56
        1831       0.73      0.88      0.80       134
        1832       0.79      0.79      0.79        68
        1833       0.90      0.95      0.92        19
        1834       0.52      0.57      0.54        30
        1835       0.00      0.00      0.00         2
        1836       0.00      0.00      0.00         3
        1837       0.50      0.29      0.36         7
        1838       1.00      0.50      0.67         4
        1839       0.00      0.00      0.00         1
        1840       0.51      0.58      0.54        43
        1841       0.64      0.60      0.62       108
        1842       0.50      0.40      0.44         5
        1843       0.75      0.50      0.60         6
        1844       0.00      0.00      0.00         0
        1845       0.00      0.00      0.00         1
        1846       0.50      0.20      0.29         5
        1847       0.00      0.00      0.00         2
        1848       0.14      0.17      0.15         6
        1849       0.00      0.00      0.00         5
        1850       0.41      0.60      0.49        47
        1851       0.71      0.61      0.66        77
        1852       0.44      0.57      0.50         7
        1853       0.00      0.00      0.00         6
        1854       0.50      0.50      0.50         2
        1855       0.30      0.13      0.18        23
        1856       0.92      1.00      0.96        12
        1857       0.46      0.42      0.44        31
        1858       0.00      0.00      0.00         2
        1859       0.00      0.00      0.00         3
        1860       0.33      0.30      0.31        64
        1861       0.77      0.84      0.80        85
        1862       0.22      0.26      0.24        19
        1863       0.44      0.44      0.44        18
        1864       0.38      0.29      0.33        17
        1865       0.40      0.33      0.36         6
        1866       0.00      0.00      0.00         6
        1867       0.17      0.10      0.12        10
        1868       0.50      0.12      0.20         8
        1869       0.00      0.00      0.00         5
        1870       0.38      0.47      0.42        30
        1871       0.71      0.86      0.78        49
        1872       0.33      0.29      0.31         7
        1873       0.29      0.36      0.32        11
        1874       0.20      0.17      0.18         6
        1875       0.25      0.29      0.27        14
        1876       0.91      1.00      0.95        10
        1877       0.20      0.17      0.18         6
        1878       0.62      0.56      0.59         9
        1879       0.00      0.00      0.00         1

    accuracy                           0.61      1256
   macro avg       0.40      0.38      0.38      1256
weighted avg       0.60      0.61      0.60      1256

Matthews Correlation Coefficient: 0.594
Macro avg F1: 0.378
Weighted avg F1: 0.601
Micro avg F1: 0.614
Top-3 Accuracy: 0.857
Top-5 Accuracy: 0.917
Micro ROC AUC  = 0.99
Macro ROC AUC (present classes) = 0.97
Classification MAE (in years): 3.12

Fold 4 Misclassification Analysis:
Near misses (within 2 years): 127 out of 485 misclassifications (26.19%)
MAE with outliers: 3.12
MAE without outliers: 2.19 (improvement: 0.92)

5 Worst misclassifications:
Image: data/datasets/public/1830/1830_111wikimedia2.jpg, True: 1877, Predicted: 1820, Error: 57
Image: data/datasets/private/1830/1831_1116etsy.jpg, True: 1820, Predicted: 1876, Error: 56
Image: data/datasets/public/1850/1850_160wikimedia2.jpg, True: 1820, Predicted: 1871, Error: 51
Image: data/datasets/public/1840/1843_045met.jpg, True: 1870, Predicted: 1820, Error: 50
Image: data/datasets/private/1860/1860_46et.jpg, True: 1862, Predicted: 1820, Error: 42

===== Fold 5 =====

===== Fine Tuning 7 layers! =====
Epoch 1/300
1413/1413 - 115s - 82ms/step - accuracy: 0.1892 - loss: 3.9751 - val_accuracy: 0.3360 - val_loss: 3.2287 - learning_rate: 6.8751e-04
Epoch 2/300
1413/1413 - 92s - 65ms/step - accuracy: 0.2728 - loss: 3.5483 - val_accuracy: 0.4029 - val_loss: 2.8774 - learning_rate: 6.8751e-04
Epoch 3/300
1413/1413 - 92s - 65ms/step - accuracy: 0.3074 - loss: 3.3539 - val_accuracy: 0.4315 - val_loss: 2.8140 - learning_rate: 6.8751e-04
Epoch 4/300
1413/1413 - 95s - 67ms/step - accuracy: 0.3319 - loss: 3.2346 - val_accuracy: 0.4825 - val_loss: 2.4747 - learning_rate: 6.8751e-04
Epoch 5/300
1413/1413 - 98s - 69ms/step - accuracy: 0.3390 - loss: 3.1607 - val_accuracy: 0.4777 - val_loss: 2.3348 - learning_rate: 6.8751e-04
Epoch 6/300
1413/1413 - 99s - 70ms/step - accuracy: 0.3498 - loss: 3.1351 - val_accuracy: 0.4291 - val_loss: 2.5942 - learning_rate: 6.8751e-04
Epoch 7/300
1413/1413 - 97s - 69ms/step - accuracy: 0.3547 - loss: 3.0929 - val_accuracy: 0.4952 - val_loss: 2.2736 - learning_rate: 6.8751e-04
Epoch 8/300
1413/1413 - 95s - 67ms/step - accuracy: 0.3665 - loss: 3.0310 - val_accuracy: 0.5127 - val_loss: 2.4577 - learning_rate: 6.8751e-04
Epoch 9/300
1413/1413 - 96s - 68ms/step - accuracy: 0.3675 - loss: 3.0206 - val_accuracy: 0.5119 - val_loss: 2.3275 - learning_rate: 6.8751e-04
Epoch 10/300
1413/1413 - 97s - 68ms/step - accuracy: 0.3755 - loss: 2.9854 - val_accuracy: 0.5151 - val_loss: 2.2974 - learning_rate: 6.8751e-04
Epoch 11/300
1413/1413 - 97s - 69ms/step - accuracy: 0.3746 - loss: 2.9759 - val_accuracy: 0.5159 - val_loss: 2.1975 - learning_rate: 6.8751e-04
Epoch 12/300
1413/1413 - 97s - 69ms/step - accuracy: 0.3823 - loss: 2.9368 - val_accuracy: 0.5311 - val_loss: 2.2781 - learning_rate: 6.8751e-04
Epoch 13/300
1413/1413 - 98s - 69ms/step - accuracy: 0.3741 - loss: 2.9429 - val_accuracy: 0.5032 - val_loss: 2.2064 - learning_rate: 6.8751e-04
Epoch 14/300
1413/1413 - 98s - 69ms/step - accuracy: 0.3923 - loss: 2.8985 - val_accuracy: 0.5032 - val_loss: 2.2395 - learning_rate: 6.8751e-04
Epoch 15/300
1413/1413 - 99s - 70ms/step - accuracy: 0.3878 - loss: 2.9092 - val_accuracy: 0.5175 - val_loss: 2.1479 - learning_rate: 6.8751e-04
Epoch 16/300
1413/1413 - 96s - 68ms/step - accuracy: 0.3963 - loss: 2.9033 - val_accuracy: 0.5311 - val_loss: 2.1617 - learning_rate: 6.8751e-04
Epoch 17/300
1413/1413 - 99s - 70ms/step - accuracy: 0.3925 - loss: 2.8690 - val_accuracy: 0.5382 - val_loss: 2.0802 - learning_rate: 6.8751e-04
Epoch 18/300
1413/1413 - 98s - 69ms/step - accuracy: 0.4047 - loss: 2.8229 - val_accuracy: 0.5637 - val_loss: 2.0888 - learning_rate: 6.8751e-04
Epoch 19/300
1413/1413 - 97s - 69ms/step - accuracy: 0.3994 - loss: 2.8733 - val_accuracy: 0.5661 - val_loss: 2.0149 - learning_rate: 6.8751e-04
Epoch 20/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4055 - loss: 2.8261 - val_accuracy: 0.5685 - val_loss: 2.0527 - learning_rate: 6.8751e-04
Epoch 21/300
1413/1413 - 98s - 69ms/step - accuracy: 0.3973 - loss: 2.8357 - val_accuracy: 0.5597 - val_loss: 2.0093 - learning_rate: 6.8751e-04
Epoch 22/300
1413/1413 - 98s - 70ms/step - accuracy: 0.4019 - loss: 2.8332 - val_accuracy: 0.5740 - val_loss: 2.0171 - learning_rate: 6.8751e-04
Epoch 23/300
1413/1413 - 98s - 69ms/step - accuracy: 0.4064 - loss: 2.8450 - val_accuracy: 0.5398 - val_loss: 2.1034 - learning_rate: 6.8751e-04
Epoch 24/300
1413/1413 - 98s - 69ms/step - accuracy: 0.4010 - loss: 2.8221 - val_accuracy: 0.5279 - val_loss: 2.1162 - learning_rate: 6.8751e-04
Epoch 25/300
1413/1413 - 97s - 68ms/step - accuracy: 0.4079 - loss: 2.8320 - val_accuracy: 0.5828 - val_loss: 2.0227 - learning_rate: 6.8751e-04
Epoch 26/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4053 - loss: 2.8242 - val_accuracy: 0.5597 - val_loss: 2.0495 - learning_rate: 6.8751e-04
Epoch 27/300
1413/1413 - 99s - 70ms/step - accuracy: 0.4096 - loss: 2.8034 - val_accuracy: 0.5637 - val_loss: 2.0325 - learning_rate: 6.8751e-04
Epoch 28/300
1413/1413 - 98s - 69ms/step - accuracy: 0.4087 - loss: 2.7900 - val_accuracy: 0.5645 - val_loss: 2.0894 - learning_rate: 6.8751e-04
Epoch 29/300

Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0003437538689468056.
1413/1413 - 99s - 70ms/step - accuracy: 0.4078 - loss: 2.7833 - val_accuracy: 0.5621 - val_loss: 2.0456 - learning_rate: 6.8751e-04
Epoch 30/300
1413/1413 - 97s - 68ms/step - accuracy: 0.4292 - loss: 2.7133 - val_accuracy: 0.5812 - val_loss: 1.9542 - learning_rate: 3.4375e-04
Epoch 31/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4364 - loss: 2.6435 - val_accuracy: 0.5804 - val_loss: 1.9268 - learning_rate: 3.4375e-04
Epoch 32/300
1413/1413 - 94s - 66ms/step - accuracy: 0.4341 - loss: 2.6488 - val_accuracy: 0.5924 - val_loss: 1.8793 - learning_rate: 3.4375e-04
Epoch 33/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4409 - loss: 2.6425 - val_accuracy: 0.5820 - val_loss: 1.9131 - learning_rate: 3.4375e-04
Epoch 34/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4349 - loss: 2.6663 - val_accuracy: 0.5844 - val_loss: 1.8841 - learning_rate: 3.4375e-04
Epoch 35/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4371 - loss: 2.6419 - val_accuracy: 0.5963 - val_loss: 1.8802 - learning_rate: 3.4375e-04
Epoch 36/300
1413/1413 - 99s - 70ms/step - accuracy: 0.4438 - loss: 2.6250 - val_accuracy: 0.5812 - val_loss: 1.8689 - learning_rate: 3.4375e-04
Epoch 37/300
1413/1413 - 98s - 69ms/step - accuracy: 0.4383 - loss: 2.6204 - val_accuracy: 0.5939 - val_loss: 1.8542 - learning_rate: 3.4375e-04
Epoch 38/300
1413/1413 - 98s - 69ms/step - accuracy: 0.4450 - loss: 2.6171 - val_accuracy: 0.5892 - val_loss: 1.9401 - learning_rate: 3.4375e-04
Epoch 39/300
1413/1413 - 98s - 69ms/step - accuracy: 0.4394 - loss: 2.6124 - val_accuracy: 0.5963 - val_loss: 1.9039 - learning_rate: 3.4375e-04
Epoch 40/300
1413/1413 - 97s - 68ms/step - accuracy: 0.4471 - loss: 2.5753 - val_accuracy: 0.6035 - val_loss: 1.8728 - learning_rate: 3.4375e-04
Epoch 41/300
1413/1413 - 98s - 69ms/step - accuracy: 0.4489 - loss: 2.5867 - val_accuracy: 0.5748 - val_loss: 1.9082 - learning_rate: 3.4375e-04
Epoch 42/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4429 - loss: 2.6007 - val_accuracy: 0.6011 - val_loss: 1.8113 - learning_rate: 3.4375e-04
Epoch 43/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4397 - loss: 2.5904 - val_accuracy: 0.6027 - val_loss: 1.9015 - learning_rate: 3.4375e-04
Epoch 44/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4506 - loss: 2.5787 - val_accuracy: 0.6139 - val_loss: 1.8969 - learning_rate: 3.4375e-04
Epoch 45/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4487 - loss: 2.5809 - val_accuracy: 0.6242 - val_loss: 1.8429 - learning_rate: 3.4375e-04
Epoch 46/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4550 - loss: 2.5786 - val_accuracy: 0.6091 - val_loss: 1.8429 - learning_rate: 3.4375e-04
Epoch 47/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4579 - loss: 2.5624 - val_accuracy: 0.6059 - val_loss: 1.7907 - learning_rate: 3.4375e-04
Epoch 48/300
1413/1413 - 98s - 70ms/step - accuracy: 0.4513 - loss: 2.5669 - val_accuracy: 0.5963 - val_loss: 1.8980 - learning_rate: 3.4375e-04
Epoch 49/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4532 - loss: 2.5544 - val_accuracy: 0.5876 - val_loss: 1.8394 - learning_rate: 3.4375e-04
Epoch 50/300
1413/1413 - 97s - 68ms/step - accuracy: 0.4517 - loss: 2.5487 - val_accuracy: 0.6115 - val_loss: 1.8114 - learning_rate: 3.4375e-04
Epoch 51/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4478 - loss: 2.5530 - val_accuracy: 0.6011 - val_loss: 1.8580 - learning_rate: 3.4375e-04
Epoch 52/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4520 - loss: 2.5747 - val_accuracy: 0.6051 - val_loss: 1.8284 - learning_rate: 3.4375e-04
Epoch 53/300
1413/1413 - 98s - 69ms/step - accuracy: 0.4503 - loss: 2.5739 - val_accuracy: 0.6035 - val_loss: 1.8444 - learning_rate: 3.4375e-04
Epoch 54/300
1413/1413 - 87s - 62ms/step - accuracy: 0.4540 - loss: 2.5468 - val_accuracy: 0.5955 - val_loss: 1.8314 - learning_rate: 3.4375e-04
Epoch 55/300

Epoch 55: ReduceLROnPlateau reducing learning rate to 0.0001718769344734028.
1413/1413 - 82s - 58ms/step - accuracy: 0.4476 - loss: 2.5864 - val_accuracy: 0.5955 - val_loss: 1.8190 - learning_rate: 3.4375e-04
Epoch 56/300
1413/1413 - 83s - 59ms/step - accuracy: 0.4614 - loss: 2.4878 - val_accuracy: 0.6194 - val_loss: 1.7966 - learning_rate: 1.7188e-04
Epoch 57/300
1413/1413 - 84s - 59ms/step - accuracy: 0.4617 - loss: 2.5121 - val_accuracy: 0.6146 - val_loss: 1.7889 - learning_rate: 1.7188e-04
Epoch 58/300
1413/1413 - 83s - 59ms/step - accuracy: 0.4640 - loss: 2.4975 - val_accuracy: 0.6083 - val_loss: 1.7722 - learning_rate: 1.7188e-04
Epoch 59/300
1413/1413 - 88s - 62ms/step - accuracy: 0.4696 - loss: 2.4626 - val_accuracy: 0.6154 - val_loss: 1.7554 - learning_rate: 1.7188e-04
Epoch 60/300
1413/1413 - 83s - 59ms/step - accuracy: 0.4672 - loss: 2.4928 - val_accuracy: 0.6146 - val_loss: 1.7479 - learning_rate: 1.7188e-04
Epoch 61/300
1413/1413 - 97s - 68ms/step - accuracy: 0.4710 - loss: 2.4424 - val_accuracy: 0.6242 - val_loss: 1.7773 - learning_rate: 1.7188e-04
Epoch 62/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4706 - loss: 2.4679 - val_accuracy: 0.6107 - val_loss: 1.7712 - learning_rate: 1.7188e-04
Epoch 63/300
1413/1413 - 98s - 69ms/step - accuracy: 0.4730 - loss: 2.4533 - val_accuracy: 0.6330 - val_loss: 1.7269 - learning_rate: 1.7188e-04
Epoch 64/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4684 - loss: 2.4686 - val_accuracy: 0.6146 - val_loss: 1.7292 - learning_rate: 1.7188e-04
Epoch 65/300
1413/1413 - 98s - 69ms/step - accuracy: 0.4680 - loss: 2.4416 - val_accuracy: 0.6178 - val_loss: 1.7311 - learning_rate: 1.7188e-04
Epoch 66/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4683 - loss: 2.4834 - val_accuracy: 0.6186 - val_loss: 1.7489 - learning_rate: 1.7188e-04
Epoch 67/300
1413/1413 - 104s - 73ms/step - accuracy: 0.4697 - loss: 2.4644 - val_accuracy: 0.6218 - val_loss: 1.7532 - learning_rate: 1.7188e-04
Epoch 68/300
1413/1413 - 104s - 73ms/step - accuracy: 0.4663 - loss: 2.4956 - val_accuracy: 0.6226 - val_loss: 1.7383 - learning_rate: 1.7188e-04
Epoch 69/300
1413/1413 - 103s - 73ms/step - accuracy: 0.4739 - loss: 2.4695 - val_accuracy: 0.6170 - val_loss: 1.7397 - learning_rate: 1.7188e-04
Epoch 70/300
1413/1413 - 104s - 73ms/step - accuracy: 0.4685 - loss: 2.4605 - val_accuracy: 0.6194 - val_loss: 1.7518 - learning_rate: 1.7188e-04
Epoch 71/300

Epoch 71: ReduceLROnPlateau reducing learning rate to 8.59384672367014e-05.
1413/1413 - 103s - 73ms/step - accuracy: 0.4754 - loss: 2.4552 - val_accuracy: 0.6091 - val_loss: 1.7612 - learning_rate: 1.7188e-04
Epoch 72/300
1413/1413 - 104s - 74ms/step - accuracy: 0.4776 - loss: 2.4397 - val_accuracy: 0.6377 - val_loss: 1.7170 - learning_rate: 8.5938e-05
Epoch 73/300
1413/1413 - 103s - 73ms/step - accuracy: 0.4797 - loss: 2.4033 - val_accuracy: 0.6282 - val_loss: 1.7266 - learning_rate: 8.5938e-05
Epoch 74/300
1413/1413 - 103s - 73ms/step - accuracy: 0.4690 - loss: 2.4476 - val_accuracy: 0.6258 - val_loss: 1.7192 - learning_rate: 8.5938e-05
Epoch 75/300
1413/1413 - 102s - 72ms/step - accuracy: 0.4816 - loss: 2.4199 - val_accuracy: 0.6218 - val_loss: 1.7046 - learning_rate: 8.5938e-05
Epoch 76/300
1413/1413 - 102s - 72ms/step - accuracy: 0.4799 - loss: 2.4134 - val_accuracy: 0.6282 - val_loss: 1.7469 - learning_rate: 8.5938e-05
Epoch 77/300
1413/1413 - 102s - 72ms/step - accuracy: 0.4664 - loss: 2.4387 - val_accuracy: 0.6290 - val_loss: 1.7246 - learning_rate: 8.5938e-05
Epoch 78/300
1413/1413 - 102s - 72ms/step - accuracy: 0.4777 - loss: 2.3955 - val_accuracy: 0.6194 - val_loss: 1.7180 - learning_rate: 8.5938e-05
Epoch 79/300
1413/1413 - 102s - 72ms/step - accuracy: 0.4776 - loss: 2.4271 - val_accuracy: 0.6170 - val_loss: 1.7102 - learning_rate: 8.5938e-05
Epoch 80/300
1413/1413 - 99s - 70ms/step - accuracy: 0.4790 - loss: 2.4195 - val_accuracy: 0.6218 - val_loss: 1.7016 - learning_rate: 8.5938e-05
Epoch 81/300
1413/1413 - 101s - 71ms/step - accuracy: 0.4791 - loss: 2.3889 - val_accuracy: 0.6178 - val_loss: 1.7509 - learning_rate: 8.5938e-05
Epoch 82/300
1413/1413 - 91s - 64ms/step - accuracy: 0.4831 - loss: 2.4207 - val_accuracy: 0.6314 - val_loss: 1.6967 - learning_rate: 8.5938e-05
Epoch 83/300
1413/1413 - 91s - 64ms/step - accuracy: 0.4840 - loss: 2.3691 - val_accuracy: 0.6234 - val_loss: 1.6989 - learning_rate: 8.5938e-05
Epoch 84/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4765 - loss: 2.4086 - val_accuracy: 0.6322 - val_loss: 1.7028 - learning_rate: 8.5938e-05
Epoch 85/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4828 - loss: 2.3956 - val_accuracy: 0.6274 - val_loss: 1.6975 - learning_rate: 8.5938e-05
Epoch 86/300
1413/1413 - 90s - 64ms/step - accuracy: 0.4784 - loss: 2.4165 - val_accuracy: 0.6338 - val_loss: 1.6839 - learning_rate: 8.5938e-05
Epoch 87/300
1413/1413 - 85s - 61ms/step - accuracy: 0.4686 - loss: 2.4267 - val_accuracy: 0.6290 - val_loss: 1.6955 - learning_rate: 8.5938e-05
Epoch 88/300
1413/1413 - 85s - 60ms/step - accuracy: 0.4795 - loss: 2.4064 - val_accuracy: 0.6282 - val_loss: 1.6743 - learning_rate: 8.5938e-05
Epoch 89/300
1413/1413 - 85s - 60ms/step - accuracy: 0.4777 - loss: 2.3909 - val_accuracy: 0.6361 - val_loss: 1.6746 - learning_rate: 8.5938e-05
Epoch 90/300
1413/1413 - 83s - 59ms/step - accuracy: 0.4773 - loss: 2.4186 - val_accuracy: 0.6346 - val_loss: 1.6830 - learning_rate: 8.5938e-05
Epoch 91/300
1413/1413 - 84s - 59ms/step - accuracy: 0.4871 - loss: 2.3696 - val_accuracy: 0.6282 - val_loss: 1.6991 - learning_rate: 8.5938e-05
Epoch 92/300
1413/1413 - 84s - 60ms/step - accuracy: 0.4833 - loss: 2.3981 - val_accuracy: 0.6258 - val_loss: 1.7128 - learning_rate: 8.5938e-05
Epoch 93/300
1413/1413 - 86s - 61ms/step - accuracy: 0.4820 - loss: 2.3886 - val_accuracy: 0.6377 - val_loss: 1.6840 - learning_rate: 8.5938e-05
Epoch 94/300
1413/1413 - 84s - 59ms/step - accuracy: 0.4825 - loss: 2.3821 - val_accuracy: 0.6433 - val_loss: 1.6762 - learning_rate: 8.5938e-05
Epoch 95/300
1413/1413 - 84s - 60ms/step - accuracy: 0.4808 - loss: 2.3865 - val_accuracy: 0.6322 - val_loss: 1.6829 - learning_rate: 8.5938e-05
Epoch 96/300

Epoch 96: ReduceLROnPlateau reducing learning rate to 4.29692336183507e-05.
1413/1413 - 84s - 60ms/step - accuracy: 0.4780 - loss: 2.3911 - val_accuracy: 0.6346 - val_loss: 1.6883 - learning_rate: 8.5938e-05
Epoch 97/300
1413/1413 - 85s - 60ms/step - accuracy: 0.4805 - loss: 2.4048 - val_accuracy: 0.6322 - val_loss: 1.6649 - learning_rate: 4.2969e-05
Epoch 98/300
1413/1413 - 85s - 60ms/step - accuracy: 0.4844 - loss: 2.3804 - val_accuracy: 0.6330 - val_loss: 1.6629 - learning_rate: 4.2969e-05
Epoch 99/300
1413/1413 - 85s - 60ms/step - accuracy: 0.4840 - loss: 2.3962 - val_accuracy: 0.6361 - val_loss: 1.6723 - learning_rate: 4.2969e-05
Epoch 100/300
1413/1413 - 84s - 59ms/step - accuracy: 0.4799 - loss: 2.4066 - val_accuracy: 0.6298 - val_loss: 1.6715 - learning_rate: 4.2969e-05
Epoch 101/300
1413/1413 - 87s - 62ms/step - accuracy: 0.4813 - loss: 2.3816 - val_accuracy: 0.6330 - val_loss: 1.6811 - learning_rate: 4.2969e-05
Epoch 102/300
1413/1413 - 98s - 69ms/step - accuracy: 0.4782 - loss: 2.3882 - val_accuracy: 0.6401 - val_loss: 1.6702 - learning_rate: 4.2969e-05
Epoch 103/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4935 - loss: 2.3514 - val_accuracy: 0.6361 - val_loss: 1.6733 - learning_rate: 4.2969e-05
Epoch 104/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4816 - loss: 2.3595 - val_accuracy: 0.6346 - val_loss: 1.6632 - learning_rate: 4.2969e-05
Epoch 105/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4847 - loss: 2.3798 - val_accuracy: 0.6385 - val_loss: 1.6747 - learning_rate: 4.2969e-05
Epoch 106/300

Epoch 106: ReduceLROnPlateau reducing learning rate to 2.148461680917535e-05.
1413/1413 - 95s - 67ms/step - accuracy: 0.4908 - loss: 2.3631 - val_accuracy: 0.6346 - val_loss: 1.6711 - learning_rate: 4.2969e-05
Epoch 107/300
1413/1413 - 98s - 69ms/step - accuracy: 0.4832 - loss: 2.3675 - val_accuracy: 0.6377 - val_loss: 1.6673 - learning_rate: 2.1485e-05
Epoch 108/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4818 - loss: 2.3833 - val_accuracy: 0.6377 - val_loss: 1.6632 - learning_rate: 2.1485e-05
Epoch 109/300
1413/1413 - 100s - 70ms/step - accuracy: 0.4854 - loss: 2.3803 - val_accuracy: 0.6417 - val_loss: 1.6637 - learning_rate: 2.1485e-05
Epoch 110/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4877 - loss: 2.3615 - val_accuracy: 0.6369 - val_loss: 1.6518 - learning_rate: 2.1485e-05
Epoch 111/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4850 - loss: 2.3765 - val_accuracy: 0.6409 - val_loss: 1.6610 - learning_rate: 2.1485e-05
Epoch 112/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4973 - loss: 2.3412 - val_accuracy: 0.6401 - val_loss: 1.6659 - learning_rate: 2.1485e-05
Epoch 113/300
1413/1413 - 91s - 65ms/step - accuracy: 0.4910 - loss: 2.3732 - val_accuracy: 0.6298 - val_loss: 1.6577 - learning_rate: 2.1485e-05
Epoch 114/300
1413/1413 - 91s - 65ms/step - accuracy: 0.4846 - loss: 2.3720 - val_accuracy: 0.6393 - val_loss: 1.6584 - learning_rate: 2.1485e-05
Epoch 115/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4907 - loss: 2.3710 - val_accuracy: 0.6354 - val_loss: 1.6524 - learning_rate: 2.1485e-05
Epoch 116/300
1413/1413 - 99s - 70ms/step - accuracy: 0.4903 - loss: 2.3728 - val_accuracy: 0.6298 - val_loss: 1.6625 - learning_rate: 2.1485e-05
Epoch 117/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4905 - loss: 2.3689 - val_accuracy: 0.6361 - val_loss: 1.6626 - learning_rate: 2.1485e-05
Epoch 118/300
1413/1413 - 98s - 70ms/step - accuracy: 0.4912 - loss: 2.3689 - val_accuracy: 0.6401 - val_loss: 1.6460 - learning_rate: 2.1485e-05
Epoch 119/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4911 - loss: 2.3685 - val_accuracy: 0.6361 - val_loss: 1.6532 - learning_rate: 2.1485e-05
Epoch 120/300
1413/1413 - 89s - 63ms/step - accuracy: 0.4850 - loss: 2.3679 - val_accuracy: 0.6489 - val_loss: 1.6484 - learning_rate: 2.1485e-05
Epoch 121/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4913 - loss: 2.3584 - val_accuracy: 0.6433 - val_loss: 1.6461 - learning_rate: 2.1485e-05
Epoch 122/300
1413/1413 - 88s - 62ms/step - accuracy: 0.4887 - loss: 2.3723 - val_accuracy: 0.6346 - val_loss: 1.6605 - learning_rate: 2.1485e-05
Epoch 123/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4847 - loss: 2.3742 - val_accuracy: 0.6314 - val_loss: 1.6580 - learning_rate: 2.1485e-05
Epoch 124/300
1413/1413 - 90s - 64ms/step - accuracy: 0.4836 - loss: 2.3590 - val_accuracy: 0.6417 - val_loss: 1.6518 - learning_rate: 2.1485e-05
Epoch 125/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4866 - loss: 2.3699 - val_accuracy: 0.6314 - val_loss: 1.6607 - learning_rate: 2.1485e-05
Epoch 126/300

Epoch 126: ReduceLROnPlateau reducing learning rate to 1.0742308404587675e-05.
1413/1413 - 93s - 66ms/step - accuracy: 0.4931 - loss: 2.3449 - val_accuracy: 0.6369 - val_loss: 1.6512 - learning_rate: 2.1485e-05
Epoch 127/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4867 - loss: 2.3501 - val_accuracy: 0.6385 - val_loss: 1.6497 - learning_rate: 1.0742e-05
Epoch 128/300
1413/1413 - 97s - 68ms/step - accuracy: 0.4850 - loss: 2.3693 - val_accuracy: 0.6377 - val_loss: 1.6481 - learning_rate: 1.0742e-05
Epoch 129/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4932 - loss: 2.3489 - val_accuracy: 0.6401 - val_loss: 1.6522 - learning_rate: 1.0742e-05
Epoch 130/300
1413/1413 - 90s - 64ms/step - accuracy: 0.4883 - loss: 2.3470 - val_accuracy: 0.6409 - val_loss: 1.6564 - learning_rate: 1.0742e-05
Epoch 131/300
1413/1413 - 87s - 61ms/step - accuracy: 0.4875 - loss: 2.3512 - val_accuracy: 0.6417 - val_loss: 1.6561 - learning_rate: 1.0742e-05
Epoch 132/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4910 - loss: 2.3321 - val_accuracy: 0.6393 - val_loss: 1.6671 - learning_rate: 1.0742e-05
Epoch 133/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4846 - loss: 2.3738 - val_accuracy: 0.6346 - val_loss: 1.6552 - learning_rate: 1.0742e-05
Epoch 134/300

Epoch 134: ReduceLROnPlateau reducing learning rate to 5.3711542022938374e-06.
1413/1413 - 97s - 69ms/step - accuracy: 0.4923 - loss: 2.3574 - val_accuracy: 0.6369 - val_loss: 1.6493 - learning_rate: 1.0742e-05
Epoch 134: early stopping
Restoring model weights from the end of the best epoch: 118.
Fold 5 Evaluation results: [1.6420336961746216, 0.6401273608207703]
              precision    recall  f1-score   support

        1820       0.80      0.85      0.83        61
        1821       0.86      0.86      0.86        58
        1822       0.00      0.00      0.00         2
        1823       0.00      0.00      0.00         1
        1824       0.00      0.00      0.00         1
        1825       0.33      0.50      0.40         2
        1826       0.00      0.00      0.00         2
        1827       0.84      0.64      0.73        25
        1828       0.00      0.00      0.00         2
        1829       0.50      1.00      0.67         4
        1830       0.54      0.57      0.56        56
        1831       0.80      0.88      0.84       135
        1832       0.82      0.75      0.78        68
        1833       0.88      0.79      0.83        19
        1834       0.47      0.62      0.54        29
        1835       0.00      0.00      0.00         2
        1836       0.12      0.33      0.18         3
        1837       0.40      0.33      0.36         6
        1838       0.00      0.00      0.00         4
        1839       0.00      0.00      0.00         1
        1840       0.54      0.79      0.64        43
        1841       0.75      0.70      0.72       107
        1842       1.00      0.40      0.57         5
        1843       0.40      0.33      0.36         6
        1844       0.00      0.00      0.00         0
        1845       0.00      0.00      0.00         1
        1846       0.00      0.00      0.00         5
        1847       0.00      0.00      0.00         2
        1848       0.33      0.33      0.33         6
        1849       0.25      0.20      0.22         5
        1850       0.43      0.49      0.46        47
        1851       0.73      0.61      0.67        77
        1852       1.00      0.38      0.55         8
        1853       0.20      0.17      0.18         6
        1854       0.00      0.00      0.00         2
        1855       0.54      0.30      0.39        23
        1856       0.80      0.67      0.73        12
        1857       0.40      0.55      0.47        31
        1858       0.00      0.00      0.00         3
        1859       0.00      0.00      0.00         3
        1860       0.38      0.37      0.37        65
        1861       0.76      0.81      0.78        85
        1862       0.40      0.42      0.41        19
        1863       0.72      0.72      0.72        18
        1864       0.53      0.47      0.50        17
        1865       0.60      0.43      0.50         7
        1866       0.29      0.33      0.31         6
        1867       0.36      0.40      0.38        10
        1868       0.25      0.14      0.18         7
        1869       0.00      0.00      0.00         5
        1870       0.43      0.48      0.45        31
        1871       0.70      0.67      0.69        49
        1872       0.43      0.86      0.57         7
        1873       0.55      0.55      0.55        11
        1874       0.60      0.50      0.55         6
        1875       0.53      0.64      0.58        14
        1876       1.00      0.80      0.89        10
        1877       1.00      0.17      0.29         6
        1878       0.50      0.89      0.64         9
        1879       0.00      0.00      0.00         1

    accuracy                           0.64      1256
   macro avg       0.41      0.40      0.39      1256
weighted avg       0.64      0.64      0.63      1256

Matthews Correlation Coefficient: 0.622
Macro avg F1: 0.387
Weighted avg F1: 0.632
Micro avg F1: 0.640
Top-3 Accuracy: 0.870
Top-5 Accuracy: 0.920
Micro ROC AUC  = 0.99
Macro ROC AUC (present classes) = 0.98
Classification MAE (in years): 2.77

Fold 5 Misclassification Analysis:
Near misses (within 2 years): 123 out of 452 misclassifications (27.21%)
MAE with outliers: 2.77
MAE without outliers: 1.94 (improvement: 0.83)

5 Worst misclassifications:
Image: data/datasets/private/1860/1861_805etsy.jpg, True: 1820, Predicted: 1871, Error: 51
Image: data/datasets/private/1820/1821_260etsy.jpg, True: 1827, Predicted: 1871, Error: 44
Image: data/datasets/private/1840/1841_1200etsy.jpg, True: 1827, Predicted: 1871, Error: 44
Image: data/datasets/private/1830/1831_842etsy.jpg, True: 1862, Predicted: 1820, Error: 42
Image: data/datasets/public/1830/1830_186wikimedia2.jpg, True: 1871, Predicted: 1831, Error: 40

===== Fold 6 =====

===== Fine Tuning 7 layers! =====
Epoch 1/300
1413/1413 - 121s - 85ms/step - accuracy: 0.1889 - loss: 4.0195 - val_accuracy: 0.3575 - val_loss: 3.2511 - learning_rate: 6.8751e-04
Epoch 2/300
1413/1413 - 97s - 69ms/step - accuracy: 0.2621 - loss: 3.5542 - val_accuracy: 0.3917 - val_loss: 2.8653 - learning_rate: 6.8751e-04
Epoch 3/300
1413/1413 - 95s - 67ms/step - accuracy: 0.3030 - loss: 3.3266 - val_accuracy: 0.4260 - val_loss: 2.6557 - learning_rate: 6.8751e-04
Epoch 4/300
1413/1413 - 96s - 68ms/step - accuracy: 0.3245 - loss: 3.2655 - val_accuracy: 0.4689 - val_loss: 2.5535 - learning_rate: 6.8751e-04
Epoch 5/300
1413/1413 - 98s - 69ms/step - accuracy: 0.3445 - loss: 3.1727 - val_accuracy: 0.4737 - val_loss: 2.4615 - learning_rate: 6.8751e-04
Epoch 6/300
1413/1413 - 95s - 67ms/step - accuracy: 0.3441 - loss: 3.1390 - val_accuracy: 0.4936 - val_loss: 2.3478 - learning_rate: 6.8751e-04
Epoch 7/300
1413/1413 - 94s - 67ms/step - accuracy: 0.3627 - loss: 3.0595 - val_accuracy: 0.4904 - val_loss: 2.3118 - learning_rate: 6.8751e-04
Epoch 8/300
1413/1413 - 89s - 63ms/step - accuracy: 0.3610 - loss: 3.0536 - val_accuracy: 0.5024 - val_loss: 2.3632 - learning_rate: 6.8751e-04
Epoch 9/300
1413/1413 - 98s - 69ms/step - accuracy: 0.3565 - loss: 3.0617 - val_accuracy: 0.4912 - val_loss: 2.4270 - learning_rate: 6.8751e-04
Epoch 10/300
1413/1413 - 95s - 67ms/step - accuracy: 0.3703 - loss: 2.9914 - val_accuracy: 0.5111 - val_loss: 2.3067 - learning_rate: 6.8751e-04
Epoch 11/300
1413/1413 - 97s - 68ms/step - accuracy: 0.3784 - loss: 2.9731 - val_accuracy: 0.5215 - val_loss: 2.3133 - learning_rate: 6.8751e-04
Epoch 12/300
1413/1413 - 98s - 69ms/step - accuracy: 0.3761 - loss: 2.9515 - val_accuracy: 0.4674 - val_loss: 2.3432 - learning_rate: 6.8751e-04
Epoch 13/300
1413/1413 - 96s - 68ms/step - accuracy: 0.3812 - loss: 2.9434 - val_accuracy: 0.5159 - val_loss: 2.2673 - learning_rate: 6.8751e-04
Epoch 14/300
1413/1413 - 98s - 69ms/step - accuracy: 0.3855 - loss: 2.9230 - val_accuracy: 0.5318 - val_loss: 2.2425 - learning_rate: 6.8751e-04
Epoch 15/300
1413/1413 - 96s - 68ms/step - accuracy: 0.3858 - loss: 2.8960 - val_accuracy: 0.5096 - val_loss: 2.2328 - learning_rate: 6.8751e-04
Epoch 16/300
1413/1413 - 96s - 68ms/step - accuracy: 0.3828 - loss: 2.9171 - val_accuracy: 0.5199 - val_loss: 2.1983 - learning_rate: 6.8751e-04
Epoch 17/300
1413/1413 - 96s - 68ms/step - accuracy: 0.3875 - loss: 2.8752 - val_accuracy: 0.5589 - val_loss: 2.1574 - learning_rate: 6.8751e-04
Epoch 18/300
1413/1413 - 95s - 67ms/step - accuracy: 0.3881 - loss: 2.9049 - val_accuracy: 0.5287 - val_loss: 2.1118 - learning_rate: 6.8751e-04
Epoch 19/300
1413/1413 - 95s - 67ms/step - accuracy: 0.3933 - loss: 2.8423 - val_accuracy: 0.5533 - val_loss: 2.1533 - learning_rate: 6.8751e-04
Epoch 20/300
1413/1413 - 94s - 67ms/step - accuracy: 0.3987 - loss: 2.8541 - val_accuracy: 0.5334 - val_loss: 2.1544 - learning_rate: 6.8751e-04
Epoch 21/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4010 - loss: 2.8359 - val_accuracy: 0.5533 - val_loss: 2.0761 - learning_rate: 6.8751e-04
Epoch 22/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4076 - loss: 2.8157 - val_accuracy: 0.5446 - val_loss: 2.1764 - learning_rate: 6.8751e-04
Epoch 23/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4015 - loss: 2.8226 - val_accuracy: 0.5494 - val_loss: 2.1338 - learning_rate: 6.8751e-04
Epoch 24/300
1413/1413 - 95s - 67ms/step - accuracy: 0.3945 - loss: 2.8312 - val_accuracy: 0.5191 - val_loss: 2.2772 - learning_rate: 6.8751e-04
Epoch 25/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4001 - loss: 2.8395 - val_accuracy: 0.5693 - val_loss: 2.0570 - learning_rate: 6.8751e-04
Epoch 26/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4010 - loss: 2.8246 - val_accuracy: 0.5406 - val_loss: 2.1769 - learning_rate: 6.8751e-04
Epoch 27/300
1413/1413 - 94s - 66ms/step - accuracy: 0.4024 - loss: 2.8344 - val_accuracy: 0.5358 - val_loss: 2.1382 - learning_rate: 6.8751e-04
Epoch 28/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4046 - loss: 2.8210 - val_accuracy: 0.5295 - val_loss: 2.2525 - learning_rate: 6.8751e-04
Epoch 29/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4094 - loss: 2.8079 - val_accuracy: 0.5518 - val_loss: 2.1381 - learning_rate: 6.8751e-04
Epoch 30/300
1413/1413 - 94s - 66ms/step - accuracy: 0.4064 - loss: 2.7960 - val_accuracy: 0.5406 - val_loss: 2.1197 - learning_rate: 6.8751e-04
Epoch 31/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4091 - loss: 2.8003 - val_accuracy: 0.5756 - val_loss: 2.0905 - learning_rate: 6.8751e-04
Epoch 32/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4098 - loss: 2.7839 - val_accuracy: 0.5740 - val_loss: 2.1052 - learning_rate: 6.8751e-04
Epoch 33/300

Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0003437538689468056.
1413/1413 - 96s - 68ms/step - accuracy: 0.4206 - loss: 2.7738 - val_accuracy: 0.5589 - val_loss: 2.1106 - learning_rate: 6.8751e-04
Epoch 34/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4297 - loss: 2.6616 - val_accuracy: 0.5796 - val_loss: 2.0218 - learning_rate: 3.4375e-04
Epoch 35/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4354 - loss: 2.6391 - val_accuracy: 0.5748 - val_loss: 1.9669 - learning_rate: 3.4375e-04
Epoch 36/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4339 - loss: 2.6399 - val_accuracy: 0.5780 - val_loss: 1.9811 - learning_rate: 3.4375e-04
Epoch 37/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4363 - loss: 2.6476 - val_accuracy: 0.5876 - val_loss: 1.9925 - learning_rate: 3.4375e-04
Epoch 38/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4351 - loss: 2.6266 - val_accuracy: 0.5900 - val_loss: 1.9560 - learning_rate: 3.4375e-04
Epoch 39/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4401 - loss: 2.6104 - val_accuracy: 0.5732 - val_loss: 1.9795 - learning_rate: 3.4375e-04
Epoch 40/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4399 - loss: 2.6352 - val_accuracy: 0.5908 - val_loss: 1.9347 - learning_rate: 3.4375e-04
Epoch 41/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4363 - loss: 2.6200 - val_accuracy: 0.5868 - val_loss: 1.9185 - learning_rate: 3.4375e-04
Epoch 42/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4431 - loss: 2.6086 - val_accuracy: 0.5836 - val_loss: 1.9665 - learning_rate: 3.4375e-04
Epoch 43/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4447 - loss: 2.6031 - val_accuracy: 0.5987 - val_loss: 1.8835 - learning_rate: 3.4375e-04
Epoch 44/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4428 - loss: 2.5952 - val_accuracy: 0.5828 - val_loss: 1.9517 - learning_rate: 3.4375e-04
Epoch 45/300
1413/1413 - 97s - 68ms/step - accuracy: 0.4425 - loss: 2.6107 - val_accuracy: 0.5892 - val_loss: 1.9009 - learning_rate: 3.4375e-04
Epoch 46/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4423 - loss: 2.6024 - val_accuracy: 0.5995 - val_loss: 1.8912 - learning_rate: 3.4375e-04
Epoch 47/300
1413/1413 - 143s - 102ms/step - accuracy: 0.4493 - loss: 2.5644 - val_accuracy: 0.5804 - val_loss: 1.9775 - learning_rate: 3.4375e-04
Epoch 48/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4443 - loss: 2.5959 - val_accuracy: 0.5900 - val_loss: 1.8909 - learning_rate: 3.4375e-04
Epoch 49/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4420 - loss: 2.5975 - val_accuracy: 0.5932 - val_loss: 1.9251 - learning_rate: 3.4375e-04
Epoch 50/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4445 - loss: 2.5961 - val_accuracy: 0.5971 - val_loss: 1.9264 - learning_rate: 3.4375e-04
Epoch 51/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4458 - loss: 2.6021 - val_accuracy: 0.5995 - val_loss: 1.8758 - learning_rate: 3.4375e-04
Epoch 52/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4488 - loss: 2.5825 - val_accuracy: 0.6027 - val_loss: 1.8933 - learning_rate: 3.4375e-04
Epoch 53/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4493 - loss: 2.5640 - val_accuracy: 0.6019 - val_loss: 1.8961 - learning_rate: 3.4375e-04
Epoch 54/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4524 - loss: 2.5654 - val_accuracy: 0.5979 - val_loss: 1.8478 - learning_rate: 3.4375e-04
Epoch 55/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4490 - loss: 2.6003 - val_accuracy: 0.5916 - val_loss: 1.9718 - learning_rate: 3.4375e-04
Epoch 56/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4452 - loss: 2.5821 - val_accuracy: 0.5836 - val_loss: 1.9212 - learning_rate: 3.4375e-04
Epoch 57/300
1413/1413 - 94s - 66ms/step - accuracy: 0.4500 - loss: 2.5726 - val_accuracy: 0.6091 - val_loss: 1.8754 - learning_rate: 3.4375e-04
Epoch 58/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4508 - loss: 2.5546 - val_accuracy: 0.5892 - val_loss: 1.9107 - learning_rate: 3.4375e-04
Epoch 59/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4448 - loss: 2.5711 - val_accuracy: 0.5987 - val_loss: 1.8603 - learning_rate: 3.4375e-04
Epoch 60/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4528 - loss: 2.5796 - val_accuracy: 0.5868 - val_loss: 1.8755 - learning_rate: 3.4375e-04
Epoch 61/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4528 - loss: 2.5427 - val_accuracy: 0.6075 - val_loss: 1.8642 - learning_rate: 3.4375e-04
Epoch 62/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4431 - loss: 2.6047 - val_accuracy: 0.6059 - val_loss: 1.8273 - learning_rate: 3.4375e-04
Epoch 63/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4448 - loss: 2.5772 - val_accuracy: 0.5788 - val_loss: 1.8592 - learning_rate: 3.4375e-04
Epoch 64/300
1413/1413 - 98s - 69ms/step - accuracy: 0.4480 - loss: 2.5800 - val_accuracy: 0.6011 - val_loss: 1.8235 - learning_rate: 3.4375e-04
Epoch 65/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4445 - loss: 2.5691 - val_accuracy: 0.6115 - val_loss: 1.8351 - learning_rate: 3.4375e-04
Epoch 66/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4542 - loss: 2.5742 - val_accuracy: 0.5995 - val_loss: 1.8445 - learning_rate: 3.4375e-04
Epoch 67/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4524 - loss: 2.5520 - val_accuracy: 0.6019 - val_loss: 1.8671 - learning_rate: 3.4375e-04
Epoch 68/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4499 - loss: 2.5404 - val_accuracy: 0.6107 - val_loss: 1.8779 - learning_rate: 3.4375e-04
Epoch 69/300
1413/1413 - 97s - 68ms/step - accuracy: 0.4560 - loss: 2.5389 - val_accuracy: 0.6027 - val_loss: 1.7817 - learning_rate: 3.4375e-04
Epoch 70/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4496 - loss: 2.5418 - val_accuracy: 0.6210 - val_loss: 1.8029 - learning_rate: 3.4375e-04
Epoch 71/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4518 - loss: 2.5523 - val_accuracy: 0.6131 - val_loss: 1.8692 - learning_rate: 3.4375e-04
Epoch 72/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4504 - loss: 2.5653 - val_accuracy: 0.6075 - val_loss: 1.8536 - learning_rate: 3.4375e-04
Epoch 73/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4544 - loss: 2.5259 - val_accuracy: 0.5995 - val_loss: 1.8604 - learning_rate: 3.4375e-04
Epoch 74/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4485 - loss: 2.5587 - val_accuracy: 0.5963 - val_loss: 1.8406 - learning_rate: 3.4375e-04
Epoch 75/300
1413/1413 - 95s - 68ms/step - accuracy: 0.4517 - loss: 2.5594 - val_accuracy: 0.6123 - val_loss: 1.8347 - learning_rate: 3.4375e-04
Epoch 76/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4523 - loss: 2.5299 - val_accuracy: 0.5892 - val_loss: 1.8501 - learning_rate: 3.4375e-04
Epoch 77/300

Epoch 77: ReduceLROnPlateau reducing learning rate to 0.0001718769344734028.
1413/1413 - 96s - 68ms/step - accuracy: 0.4480 - loss: 2.5418 - val_accuracy: 0.5979 - val_loss: 1.8175 - learning_rate: 3.4375e-04
Epoch 78/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4678 - loss: 2.4942 - val_accuracy: 0.6099 - val_loss: 1.7699 - learning_rate: 1.7188e-04
Epoch 79/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4646 - loss: 2.4841 - val_accuracy: 0.6170 - val_loss: 1.7447 - learning_rate: 1.7188e-04
Epoch 80/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4672 - loss: 2.4970 - val_accuracy: 0.6146 - val_loss: 1.7988 - learning_rate: 1.7188e-04
Epoch 81/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4615 - loss: 2.4916 - val_accuracy: 0.6083 - val_loss: 1.7609 - learning_rate: 1.7188e-04
Epoch 82/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4629 - loss: 2.4880 - val_accuracy: 0.6162 - val_loss: 1.7744 - learning_rate: 1.7188e-04
Epoch 83/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4644 - loss: 2.4676 - val_accuracy: 0.6218 - val_loss: 1.7733 - learning_rate: 1.7188e-04
Epoch 84/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4725 - loss: 2.4718 - val_accuracy: 0.6043 - val_loss: 1.7753 - learning_rate: 1.7188e-04
Epoch 85/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4637 - loss: 2.4585 - val_accuracy: 0.6131 - val_loss: 1.7786 - learning_rate: 1.7188e-04
Epoch 86/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4712 - loss: 2.4465 - val_accuracy: 0.6202 - val_loss: 1.7769 - learning_rate: 1.7188e-04
Epoch 87/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4705 - loss: 2.4418 - val_accuracy: 0.6139 - val_loss: 1.7282 - learning_rate: 1.7188e-04
Epoch 88/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4793 - loss: 2.4392 - val_accuracy: 0.6186 - val_loss: 1.7949 - learning_rate: 1.7188e-04
Epoch 89/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4684 - loss: 2.4503 - val_accuracy: 0.6139 - val_loss: 1.7755 - learning_rate: 1.7188e-04
Epoch 90/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4732 - loss: 2.4707 - val_accuracy: 0.6226 - val_loss: 1.7638 - learning_rate: 1.7188e-04
Epoch 91/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4670 - loss: 2.4465 - val_accuracy: 0.6194 - val_loss: 1.7690 - learning_rate: 1.7188e-04
Epoch 92/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4762 - loss: 2.4420 - val_accuracy: 0.6194 - val_loss: 1.7560 - learning_rate: 1.7188e-04
Epoch 93/300
1413/1413 - 98s - 69ms/step - accuracy: 0.4752 - loss: 2.4330 - val_accuracy: 0.6186 - val_loss: 1.7647 - learning_rate: 1.7188e-04
Epoch 94/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4687 - loss: 2.4498 - val_accuracy: 0.6218 - val_loss: 1.7686 - learning_rate: 1.7188e-04
Epoch 95/300

Epoch 95: ReduceLROnPlateau reducing learning rate to 8.59384672367014e-05.
1413/1413 - 97s - 68ms/step - accuracy: 0.4724 - loss: 2.4398 - val_accuracy: 0.6139 - val_loss: 1.7805 - learning_rate: 1.7188e-04
Epoch 96/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4695 - loss: 2.4459 - val_accuracy: 0.6202 - val_loss: 1.7504 - learning_rate: 8.5938e-05
Epoch 97/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4717 - loss: 2.4105 - val_accuracy: 0.6210 - val_loss: 1.7232 - learning_rate: 8.5938e-05
Epoch 98/300
1413/1413 - 98s - 69ms/step - accuracy: 0.4811 - loss: 2.3845 - val_accuracy: 0.6178 - val_loss: 1.7394 - learning_rate: 8.5938e-05
Epoch 99/300
1413/1413 - 95s - 68ms/step - accuracy: 0.4826 - loss: 2.3872 - val_accuracy: 0.6298 - val_loss: 1.7223 - learning_rate: 8.5938e-05
Epoch 100/300
1413/1413 - 102s - 72ms/step - accuracy: 0.4768 - loss: 2.4021 - val_accuracy: 0.6282 - val_loss: 1.7204 - learning_rate: 8.5938e-05
Epoch 101/300
1413/1413 - 102s - 72ms/step - accuracy: 0.4781 - loss: 2.4156 - val_accuracy: 0.6274 - val_loss: 1.7540 - learning_rate: 8.5938e-05
Epoch 102/300
1413/1413 - 103s - 73ms/step - accuracy: 0.4813 - loss: 2.3940 - val_accuracy: 0.6178 - val_loss: 1.7382 - learning_rate: 8.5938e-05
Epoch 103/300
1413/1413 - 103s - 73ms/step - accuracy: 0.4793 - loss: 2.3823 - val_accuracy: 0.6258 - val_loss: 1.7129 - learning_rate: 8.5938e-05
Epoch 104/300
1413/1413 - 102s - 72ms/step - accuracy: 0.4761 - loss: 2.4166 - val_accuracy: 0.6186 - val_loss: 1.7359 - learning_rate: 8.5938e-05
Epoch 105/300
1413/1413 - 103s - 73ms/step - accuracy: 0.4778 - loss: 2.4338 - val_accuracy: 0.6218 - val_loss: 1.7442 - learning_rate: 8.5938e-05
Epoch 106/300
1413/1413 - 102s - 72ms/step - accuracy: 0.4760 - loss: 2.4068 - val_accuracy: 0.6282 - val_loss: 1.7185 - learning_rate: 8.5938e-05
Epoch 107/300
1413/1413 - 106s - 75ms/step - accuracy: 0.4862 - loss: 2.3703 - val_accuracy: 0.6298 - val_loss: 1.7073 - learning_rate: 8.5938e-05
Epoch 108/300
1413/1413 - 102s - 73ms/step - accuracy: 0.4797 - loss: 2.4061 - val_accuracy: 0.6290 - val_loss: 1.7312 - learning_rate: 8.5938e-05
Epoch 109/300
1413/1413 - 105s - 74ms/step - accuracy: 0.4804 - loss: 2.4004 - val_accuracy: 0.6218 - val_loss: 1.7178 - learning_rate: 8.5938e-05
Epoch 110/300
1413/1413 - 103s - 73ms/step - accuracy: 0.4792 - loss: 2.3752 - val_accuracy: 0.6346 - val_loss: 1.7169 - learning_rate: 8.5938e-05
Epoch 111/300
1413/1413 - 105s - 74ms/step - accuracy: 0.4843 - loss: 2.3865 - val_accuracy: 0.6186 - val_loss: 1.7239 - learning_rate: 8.5938e-05
Epoch 112/300
1413/1413 - 97s - 68ms/step - accuracy: 0.4797 - loss: 2.3701 - val_accuracy: 0.6369 - val_loss: 1.6908 - learning_rate: 8.5938e-05
Epoch 113/300
1413/1413 - 97s - 68ms/step - accuracy: 0.4804 - loss: 2.4066 - val_accuracy: 0.6298 - val_loss: 1.7022 - learning_rate: 8.5938e-05
Epoch 114/300
1413/1413 - 103s - 73ms/step - accuracy: 0.4870 - loss: 2.3889 - val_accuracy: 0.6274 - val_loss: 1.6926 - learning_rate: 8.5938e-05
Epoch 115/300
1413/1413 - 100s - 71ms/step - accuracy: 0.4745 - loss: 2.4107 - val_accuracy: 0.6346 - val_loss: 1.7142 - learning_rate: 8.5938e-05
Epoch 116/300
1413/1413 - 101s - 71ms/step - accuracy: 0.4777 - loss: 2.3799 - val_accuracy: 0.6234 - val_loss: 1.7199 - learning_rate: 8.5938e-05
Epoch 117/300
1413/1413 - 100s - 71ms/step - accuracy: 0.4795 - loss: 2.3865 - val_accuracy: 0.6258 - val_loss: 1.7217 - learning_rate: 8.5938e-05
Epoch 118/300
1413/1413 - 100s - 71ms/step - accuracy: 0.4770 - loss: 2.3894 - val_accuracy: 0.6393 - val_loss: 1.7496 - learning_rate: 8.5938e-05
Epoch 119/300
1413/1413 - 101s - 71ms/step - accuracy: 0.4823 - loss: 2.3873 - val_accuracy: 0.6361 - val_loss: 1.7266 - learning_rate: 8.5938e-05
Epoch 120/300

Epoch 120: ReduceLROnPlateau reducing learning rate to 4.29692336183507e-05.
1413/1413 - 101s - 72ms/step - accuracy: 0.4746 - loss: 2.4140 - val_accuracy: 0.6290 - val_loss: 1.7454 - learning_rate: 8.5938e-05
Epoch 121/300
1413/1413 - 100s - 71ms/step - accuracy: 0.4877 - loss: 2.3762 - val_accuracy: 0.6234 - val_loss: 1.7116 - learning_rate: 4.2969e-05
Epoch 122/300
1413/1413 - 100s - 71ms/step - accuracy: 0.4838 - loss: 2.3677 - val_accuracy: 0.6258 - val_loss: 1.7255 - learning_rate: 4.2969e-05
Epoch 123/300
1413/1413 - 100s - 71ms/step - accuracy: 0.4840 - loss: 2.3771 - val_accuracy: 0.6298 - val_loss: 1.7150 - learning_rate: 4.2969e-05
Epoch 124/300
1413/1413 - 100s - 71ms/step - accuracy: 0.4844 - loss: 2.3816 - val_accuracy: 0.6290 - val_loss: 1.7147 - learning_rate: 4.2969e-05
Epoch 125/300
1413/1413 - 98s - 69ms/step - accuracy: 0.4852 - loss: 2.3747 - val_accuracy: 0.6210 - val_loss: 1.7056 - learning_rate: 4.2969e-05
Epoch 126/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4839 - loss: 2.3788 - val_accuracy: 0.6354 - val_loss: 1.7051 - learning_rate: 4.2969e-05
Epoch 127/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4802 - loss: 2.3758 - val_accuracy: 0.6314 - val_loss: 1.7091 - learning_rate: 4.2969e-05
Epoch 128/300

Epoch 128: ReduceLROnPlateau reducing learning rate to 2.148461680917535e-05.
1413/1413 - 97s - 68ms/step - accuracy: 0.4828 - loss: 2.3776 - val_accuracy: 0.6314 - val_loss: 1.7068 - learning_rate: 4.2969e-05
Epoch 128: early stopping
Restoring model weights from the end of the best epoch: 112.
Fold 6 Evaluation results: [1.686699390411377, 0.6369426846504211]
              precision    recall  f1-score   support

        1820       0.82      0.87      0.84        61
        1821       0.94      0.76      0.84        58
        1822       0.00      0.00      0.00         2
        1823       0.00      0.00      0.00         1
        1824       0.00      0.00      0.00         1
        1825       1.00      0.50      0.67         2
        1826       0.50      0.50      0.50         2
        1827       0.69      0.72      0.71        25
        1828       1.00      1.00      1.00         2
        1829       0.60      0.75      0.67         4
        1830       0.60      0.61      0.60        56
        1831       0.78      0.90      0.84       135
        1832       0.84      0.79      0.82        68
        1833       0.90      1.00      0.95        19
        1834       0.57      0.79      0.67        29
        1835       0.00      0.00      0.00         2
        1836       0.00      0.00      0.00         3
        1837       0.20      0.33      0.25         6
        1838       0.25      0.25      0.25         4
        1839       0.00      0.00      0.00         1
        1840       0.45      0.60      0.51        42
        1841       0.78      0.65      0.71       107
        1842       0.33      0.33      0.33         6
        1843       1.00      0.17      0.29         6
        1844       0.00      0.00      0.00         0
        1845       0.00      0.00      0.00         1
        1846       0.20      0.17      0.18         6
        1847       0.00      0.00      0.00         2
        1848       0.20      0.20      0.20         5
        1849       0.17      0.20      0.18         5
        1850       0.44      0.60      0.51        48
        1851       0.69      0.74      0.71        77
        1852       0.50      0.25      0.33         8
        1853       0.60      0.50      0.55         6
        1854       0.00      0.00      0.00         2
        1855       0.54      0.30      0.39        23
        1856       0.70      0.58      0.64        12
        1857       0.46      0.55      0.50        31
        1858       0.00      0.00      0.00         3
        1859       0.00      0.00      0.00         3
        1860       0.35      0.35      0.35        65
        1861       0.82      0.84      0.83        85
        1862       0.31      0.26      0.29        19
        1863       0.48      0.56      0.51        18
        1864       0.35      0.47      0.40        17
        1865       0.67      0.29      0.40         7
        1866       0.67      0.33      0.44         6
        1867       0.33      0.10      0.15        10
        1868       0.00      0.00      0.00         7
        1869       0.00      0.00      0.00         6
        1870       0.43      0.65      0.52        31
        1871       0.84      0.76      0.80        49
        1872       0.50      0.43      0.46         7
        1873       0.20      0.09      0.12        11
        1874       0.00      0.00      0.00         5
        1875       0.29      0.14      0.19        14
        1876       0.83      1.00      0.91        10
        1877       0.43      0.60      0.50         5
        1878       0.33      0.22      0.27         9
        1879       0.00      0.00      0.00         1

    accuracy                           0.64      1256
   macro avg       0.41      0.38      0.38      1256
weighted avg       0.63      0.64      0.63      1256

Matthews Correlation Coefficient: 0.619
Macro avg F1: 0.379
Weighted avg F1: 0.626
Micro avg F1: 0.637
Top-3 Accuracy: 0.854
Top-5 Accuracy: 0.912
Micro ROC AUC  = 0.99
Macro ROC AUC (present classes) = 0.98
Classification MAE (in years): 3.12

Fold 6 Misclassification Analysis:
Near misses (within 2 years): 87 out of 456 misclassifications (19.08%)
MAE with outliers: 3.12
MAE without outliers: 2.13 (improvement: 0.99)

5 Worst misclassifications:
Image: data/datasets/private/1850/1851_185etsy.jpg, True: 1879, Predicted: 1820, Error: 59
Image: data/datasets/public/1820/1827_055met.jpg, True: 1822, Predicted: 1876, Error: 54
Image: data/datasets/private/1860/1861_720etsy.jpg, True: 1832, Predicted: 1878, Error: 46
Image: data/datasets/public/1870/1876_439vna.jpg, True: 1862, Predicted: 1820, Error: 42
Image: data/datasets/private/1820/1820_48etsy.jpg, True: 1860, Predicted: 1820, Error: 40

===== Fold 7 =====

===== Fine Tuning 7 layers! =====
Epoch 1/300
1413/1413 - 123s - 87ms/step - accuracy: 0.1892 - loss: 4.0092 - val_accuracy: 0.3471 - val_loss: 3.3001 - learning_rate: 6.8751e-04
Epoch 2/300
1413/1413 - 97s - 69ms/step - accuracy: 0.2675 - loss: 3.5430 - val_accuracy: 0.3901 - val_loss: 2.8621 - learning_rate: 6.8751e-04
Epoch 3/300
1413/1413 - 97s - 68ms/step - accuracy: 0.2982 - loss: 3.3374 - val_accuracy: 0.4482 - val_loss: 2.5814 - learning_rate: 6.8751e-04
Epoch 4/300
1413/1413 - 97s - 68ms/step - accuracy: 0.3191 - loss: 3.2475 - val_accuracy: 0.4705 - val_loss: 2.4208 - learning_rate: 6.8751e-04
Epoch 5/300
1413/1413 - 98s - 69ms/step - accuracy: 0.3333 - loss: 3.1921 - val_accuracy: 0.4777 - val_loss: 2.4294 - learning_rate: 6.8751e-04
Epoch 6/300
1413/1413 - 98s - 69ms/step - accuracy: 0.3439 - loss: 3.1379 - val_accuracy: 0.4682 - val_loss: 2.5281 - learning_rate: 6.8751e-04
Epoch 7/300
1413/1413 - 98s - 70ms/step - accuracy: 0.3535 - loss: 3.0956 - val_accuracy: 0.4745 - val_loss: 2.3556 - learning_rate: 6.8751e-04
Epoch 8/300
1413/1413 - 97s - 68ms/step - accuracy: 0.3612 - loss: 3.0592 - val_accuracy: 0.5199 - val_loss: 2.2953 - learning_rate: 6.8751e-04
Epoch 9/300
1413/1413 - 97s - 69ms/step - accuracy: 0.3621 - loss: 3.0435 - val_accuracy: 0.5016 - val_loss: 2.4730 - learning_rate: 6.8751e-04
Epoch 10/300
1413/1413 - 97s - 68ms/step - accuracy: 0.3724 - loss: 3.0003 - val_accuracy: 0.5064 - val_loss: 2.3062 - learning_rate: 6.8751e-04
Epoch 11/300
1413/1413 - 98s - 69ms/step - accuracy: 0.3751 - loss: 3.0013 - val_accuracy: 0.5199 - val_loss: 2.2758 - learning_rate: 6.8751e-04
Epoch 12/300
1413/1413 - 97s - 69ms/step - accuracy: 0.3715 - loss: 2.9944 - val_accuracy: 0.5255 - val_loss: 2.2750 - learning_rate: 6.8751e-04
Epoch 13/300
1413/1413 - 98s - 69ms/step - accuracy: 0.3775 - loss: 2.9536 - val_accuracy: 0.5454 - val_loss: 2.2006 - learning_rate: 6.8751e-04
Epoch 14/300
1413/1413 - 93s - 66ms/step - accuracy: 0.3737 - loss: 2.9619 - val_accuracy: 0.5295 - val_loss: 2.2330 - learning_rate: 6.8751e-04
Epoch 15/300
1413/1413 - 91s - 64ms/step - accuracy: 0.3793 - loss: 2.9677 - val_accuracy: 0.5064 - val_loss: 2.3115 - learning_rate: 6.8751e-04
Epoch 16/300
1413/1413 - 97s - 69ms/step - accuracy: 0.3772 - loss: 2.9560 - val_accuracy: 0.5295 - val_loss: 2.1492 - learning_rate: 6.8751e-04
Epoch 17/300
1413/1413 - 98s - 69ms/step - accuracy: 0.3872 - loss: 2.9464 - val_accuracy: 0.5605 - val_loss: 2.1734 - learning_rate: 6.8751e-04
Epoch 18/300
1413/1413 - 97s - 69ms/step - accuracy: 0.3896 - loss: 2.8907 - val_accuracy: 0.5390 - val_loss: 2.1930 - learning_rate: 6.8751e-04
Epoch 19/300
1413/1413 - 97s - 69ms/step - accuracy: 0.3923 - loss: 2.9307 - val_accuracy: 0.5390 - val_loss: 2.1397 - learning_rate: 6.8751e-04
Epoch 20/300
1413/1413 - 96s - 68ms/step - accuracy: 0.3864 - loss: 2.8862 - val_accuracy: 0.5382 - val_loss: 2.1355 - learning_rate: 6.8751e-04
Epoch 21/300
1413/1413 - 97s - 69ms/step - accuracy: 0.3917 - loss: 2.9024 - val_accuracy: 0.5486 - val_loss: 2.1079 - learning_rate: 6.8751e-04
Epoch 22/300
1413/1413 - 97s - 68ms/step - accuracy: 0.3886 - loss: 2.8593 - val_accuracy: 0.5199 - val_loss: 2.1682 - learning_rate: 6.8751e-04
Epoch 23/300
1413/1413 - 97s - 69ms/step - accuracy: 0.3908 - loss: 2.8757 - val_accuracy: 0.5358 - val_loss: 2.1410 - learning_rate: 6.8751e-04
Epoch 24/300
1413/1413 - 95s - 67ms/step - accuracy: 0.3959 - loss: 2.8744 - val_accuracy: 0.5621 - val_loss: 2.0726 - learning_rate: 6.8751e-04
Epoch 25/300
1413/1413 - 96s - 68ms/step - accuracy: 0.3982 - loss: 2.8307 - val_accuracy: 0.5303 - val_loss: 2.2454 - learning_rate: 6.8751e-04
Epoch 26/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4055 - loss: 2.8240 - val_accuracy: 0.5342 - val_loss: 2.1892 - learning_rate: 6.8751e-04
Epoch 27/300
1413/1413 - 98s - 69ms/step - accuracy: 0.4028 - loss: 2.8378 - val_accuracy: 0.5549 - val_loss: 2.1484 - learning_rate: 6.8751e-04
Epoch 28/300
1413/1413 - 98s - 69ms/step - accuracy: 0.4038 - loss: 2.8350 - val_accuracy: 0.5621 - val_loss: 2.1104 - learning_rate: 6.8751e-04
Epoch 29/300
1413/1413 - 97s - 69ms/step - accuracy: 0.3972 - loss: 2.8290 - val_accuracy: 0.5239 - val_loss: 2.1142 - learning_rate: 6.8751e-04
Epoch 30/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4033 - loss: 2.8120 - val_accuracy: 0.5645 - val_loss: 2.0436 - learning_rate: 6.8751e-04
Epoch 31/300
1413/1413 - 96s - 68ms/step - accuracy: 0.3993 - loss: 2.8532 - val_accuracy: 0.5454 - val_loss: 2.0940 - learning_rate: 6.8751e-04
Epoch 32/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4033 - loss: 2.8202 - val_accuracy: 0.5701 - val_loss: 2.0861 - learning_rate: 6.8751e-04
Epoch 33/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4114 - loss: 2.7967 - val_accuracy: 0.5653 - val_loss: 2.0331 - learning_rate: 6.8751e-04
Epoch 34/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4121 - loss: 2.7719 - val_accuracy: 0.5502 - val_loss: 2.0145 - learning_rate: 6.8751e-04
Epoch 35/300
1413/1413 - 95s - 68ms/step - accuracy: 0.4029 - loss: 2.8337 - val_accuracy: 0.5557 - val_loss: 2.0616 - learning_rate: 6.8751e-04
Epoch 36/300
1413/1413 - 98s - 70ms/step - accuracy: 0.4122 - loss: 2.7896 - val_accuracy: 0.5446 - val_loss: 2.0977 - learning_rate: 6.8751e-04
Epoch 37/300
1413/1413 - 98s - 69ms/step - accuracy: 0.4084 - loss: 2.7827 - val_accuracy: 0.5446 - val_loss: 2.0490 - learning_rate: 6.8751e-04
Epoch 38/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4117 - loss: 2.7963 - val_accuracy: 0.5645 - val_loss: 2.0663 - learning_rate: 6.8751e-04
Epoch 39/300
1413/1413 - 99s - 70ms/step - accuracy: 0.4116 - loss: 2.7853 - val_accuracy: 0.5422 - val_loss: 2.1435 - learning_rate: 6.8751e-04
Epoch 40/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4112 - loss: 2.7941 - val_accuracy: 0.5581 - val_loss: 2.0322 - learning_rate: 6.8751e-04
Epoch 41/300
1413/1413 - 98s - 69ms/step - accuracy: 0.4017 - loss: 2.7811 - val_accuracy: 0.5629 - val_loss: 2.0830 - learning_rate: 6.8751e-04
Epoch 42/300

Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0003437538689468056.
1413/1413 - 97s - 68ms/step - accuracy: 0.4117 - loss: 2.7732 - val_accuracy: 0.5414 - val_loss: 2.0833 - learning_rate: 6.8751e-04
Epoch 43/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4282 - loss: 2.6859 - val_accuracy: 0.5836 - val_loss: 1.9275 - learning_rate: 3.4375e-04
Epoch 44/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4331 - loss: 2.6325 - val_accuracy: 0.5852 - val_loss: 1.9295 - learning_rate: 3.4375e-04
Epoch 45/300
1413/1413 - 99s - 70ms/step - accuracy: 0.4334 - loss: 2.6815 - val_accuracy: 0.5677 - val_loss: 1.9701 - learning_rate: 3.4375e-04
Epoch 46/300
1413/1413 - 97s - 68ms/step - accuracy: 0.4329 - loss: 2.6626 - val_accuracy: 0.5788 - val_loss: 1.9498 - learning_rate: 3.4375e-04
Epoch 47/300
1413/1413 - 98s - 69ms/step - accuracy: 0.4362 - loss: 2.6411 - val_accuracy: 0.5955 - val_loss: 1.8701 - learning_rate: 3.4375e-04
Epoch 48/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4325 - loss: 2.6448 - val_accuracy: 0.5979 - val_loss: 1.8752 - learning_rate: 3.4375e-04
Epoch 49/300
1413/1413 - 98s - 70ms/step - accuracy: 0.4364 - loss: 2.6583 - val_accuracy: 0.6003 - val_loss: 1.8615 - learning_rate: 3.4375e-04
Epoch 50/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4394 - loss: 2.6373 - val_accuracy: 0.5804 - val_loss: 1.9580 - learning_rate: 3.4375e-04
Epoch 51/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4397 - loss: 2.6163 - val_accuracy: 0.6011 - val_loss: 1.8820 - learning_rate: 3.4375e-04
Epoch 52/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4303 - loss: 2.6506 - val_accuracy: 0.5804 - val_loss: 1.8705 - learning_rate: 3.4375e-04
Epoch 53/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4390 - loss: 2.6142 - val_accuracy: 0.5932 - val_loss: 1.8678 - learning_rate: 3.4375e-04
Epoch 54/300
<<<<<<< HEAD
1413/1413 - 95s - 67ms/step - accuracy: 0.4407 - loss: 2.6109 - val_accuracy: 0.5939 - val_loss: 1.8872 - learning_rate: 3.4375e-04
Epoch 55/300
1413/1413 - 95s - 68ms/step - accuracy: 0.4362 - loss: 2.6459 - val_accuracy: 0.5900 - val_loss: 1.8947 - learning_rate: 3.4375e-04
Epoch 56/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4467 - loss: 2.6296 - val_accuracy: 0.5987 - val_loss: 1.8723 - learning_rate: 3.4375e-04
Epoch 57/300

Epoch 57: ReduceLROnPlateau reducing learning rate to 0.0001718769344734028.
1413/1413 - 98s - 69ms/step - accuracy: 0.4436 - loss: 2.6055 - val_accuracy: 0.5772 - val_loss: 1.9527 - learning_rate: 3.4375e-04
Epoch 58/300
1413/1413 - 97s - 68ms/step - accuracy: 0.4517 - loss: 2.5506 - val_accuracy: 0.6027 - val_loss: 1.8533 - learning_rate: 1.7188e-04
Epoch 59/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4526 - loss: 2.5615 - val_accuracy: 0.5796 - val_loss: 1.8603 - learning_rate: 1.7188e-04
Epoch 60/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4498 - loss: 2.5403 - val_accuracy: 0.6051 - val_loss: 1.8461 - learning_rate: 1.7188e-04
Epoch 61/300
1413/1413 - 98s - 69ms/step - accuracy: 0.4583 - loss: 2.5440 - val_accuracy: 0.6075 - val_loss: 1.8413 - learning_rate: 1.7188e-04
Epoch 62/300
1413/1413 - 97s - 68ms/step - accuracy: 0.4519 - loss: 2.5446 - val_accuracy: 0.5955 - val_loss: 1.8287 - learning_rate: 1.7188e-04
Epoch 63/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4529 - loss: 2.5357 - val_accuracy: 0.6067 - val_loss: 1.8283 - learning_rate: 1.7188e-04
Epoch 64/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4606 - loss: 2.5372 - val_accuracy: 0.6027 - val_loss: 1.8298 - learning_rate: 1.7188e-04
Epoch 65/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4611 - loss: 2.5365 - val_accuracy: 0.5932 - val_loss: 1.8759 - learning_rate: 1.7188e-04
Epoch 66/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4645 - loss: 2.5095 - val_accuracy: 0.6091 - val_loss: 1.8236 - learning_rate: 1.7188e-04
Epoch 67/300
1413/1413 - 98s - 69ms/step - accuracy: 0.4563 - loss: 2.5435 - val_accuracy: 0.6075 - val_loss: 1.8246 - learning_rate: 1.7188e-04
Epoch 68/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4544 - loss: 2.5355 - val_accuracy: 0.6075 - val_loss: 1.7869 - learning_rate: 1.7188e-04
Epoch 69/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4585 - loss: 2.4991 - val_accuracy: 0.6083 - val_loss: 1.8104 - learning_rate: 1.7188e-04
Epoch 70/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4550 - loss: 2.5132 - val_accuracy: 0.6123 - val_loss: 1.7772 - learning_rate: 1.7188e-04
Epoch 71/300
1413/1413 - 98s - 70ms/step - accuracy: 0.4517 - loss: 2.5308 - val_accuracy: 0.6099 - val_loss: 1.8357 - learning_rate: 1.7188e-04
Epoch 72/300
1413/1413 - 97s - 68ms/step - accuracy: 0.4616 - loss: 2.5144 - val_accuracy: 0.6123 - val_loss: 1.8115 - learning_rate: 1.7188e-04
Epoch 73/300
1413/1413 - 98s - 69ms/step - accuracy: 0.4583 - loss: 2.5430 - val_accuracy: 0.6115 - val_loss: 1.7740 - learning_rate: 1.7188e-04
Epoch 74/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4648 - loss: 2.4913 - val_accuracy: 0.6115 - val_loss: 1.7973 - learning_rate: 1.7188e-04
Epoch 75/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4579 - loss: 2.5245 - val_accuracy: 0.6051 - val_loss: 1.7974 - learning_rate: 1.7188e-04
Epoch 76/300
1413/1413 - 98s - 69ms/step - accuracy: 0.4562 - loss: 2.5195 - val_accuracy: 0.6011 - val_loss: 1.7976 - learning_rate: 1.7188e-04
Epoch 77/300
1413/1413 - 98s - 69ms/step - accuracy: 0.4545 - loss: 2.5413 - val_accuracy: 0.6146 - val_loss: 1.8306 - learning_rate: 1.7188e-04
Epoch 78/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4658 - loss: 2.4719 - val_accuracy: 0.5995 - val_loss: 1.8102 - learning_rate: 1.7188e-04
Epoch 79/300
1413/1413 - 98s - 70ms/step - accuracy: 0.4571 - loss: 2.5086 - val_accuracy: 0.6043 - val_loss: 1.8175 - learning_rate: 1.7188e-04
Epoch 80/300
1413/1413 - 98s - 69ms/step - accuracy: 0.4575 - loss: 2.5309 - val_accuracy: 0.6059 - val_loss: 1.8141 - learning_rate: 1.7188e-04
Epoch 81/300

Epoch 81: ReduceLROnPlateau reducing learning rate to 8.59384672367014e-05.
1413/1413 - 98s - 70ms/step - accuracy: 0.4594 - loss: 2.5378 - val_accuracy: 0.6091 - val_loss: 1.8177 - learning_rate: 1.7188e-04
Epoch 82/300
1413/1413 - 98s - 69ms/step - accuracy: 0.4702 - loss: 2.4708 - val_accuracy: 0.6131 - val_loss: 1.7715 - learning_rate: 8.5938e-05
Epoch 83/300
1413/1413 - 98s - 69ms/step - accuracy: 0.4653 - loss: 2.4880 - val_accuracy: 0.6131 - val_loss: 1.7952 - learning_rate: 8.5938e-05
Epoch 84/300
1413/1413 - 98s - 69ms/step - accuracy: 0.4698 - loss: 2.4440 - val_accuracy: 0.6123 - val_loss: 1.7874 - learning_rate: 8.5938e-05
Epoch 85/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4628 - loss: 2.4931 - val_accuracy: 0.6091 - val_loss: 1.7756 - learning_rate: 8.5938e-05
Epoch 86/300
1413/1413 - 98s - 69ms/step - accuracy: 0.4651 - loss: 2.4950 - val_accuracy: 0.6075 - val_loss: 1.7846 - learning_rate: 8.5938e-05
Epoch 87/300
1413/1413 - 99s - 70ms/step - accuracy: 0.4716 - loss: 2.4348 - val_accuracy: 0.6059 - val_loss: 1.7618 - learning_rate: 8.5938e-05
Epoch 88/300
1413/1413 - 98s - 69ms/step - accuracy: 0.4701 - loss: 2.4758 - val_accuracy: 0.6099 - val_loss: 1.7724 - learning_rate: 8.5938e-05
Epoch 89/300
1413/1413 - 99s - 70ms/step - accuracy: 0.4624 - loss: 2.4818 - val_accuracy: 0.6131 - val_loss: 1.7833 - learning_rate: 8.5938e-05
Epoch 90/300
1413/1413 - 97s - 68ms/step - accuracy: 0.4703 - loss: 2.4425 - val_accuracy: 0.6075 - val_loss: 1.7786 - learning_rate: 8.5938e-05
Epoch 91/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4695 - loss: 2.4541 - val_accuracy: 0.6059 - val_loss: 1.7721 - learning_rate: 8.5938e-05
Epoch 92/300
1413/1413 - 99s - 70ms/step - accuracy: 0.4720 - loss: 2.4386 - val_accuracy: 0.6083 - val_loss: 1.7665 - learning_rate: 8.5938e-05
Epoch 93/300
1413/1413 - 98s - 69ms/step - accuracy: 0.4690 - loss: 2.4701 - val_accuracy: 0.6043 - val_loss: 1.7719 - learning_rate: 8.5938e-05
Epoch 94/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4696 - loss: 2.4794 - val_accuracy: 0.6099 - val_loss: 1.7583 - learning_rate: 8.5938e-05
Epoch 95/300
1413/1413 - 99s - 70ms/step - accuracy: 0.4679 - loss: 2.4361 - val_accuracy: 0.6099 - val_loss: 1.7693 - learning_rate: 8.5938e-05
Epoch 96/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4702 - loss: 2.4633 - val_accuracy: 0.6146 - val_loss: 1.7676 - learning_rate: 8.5938e-05
Epoch 97/300
1413/1413 - 99s - 70ms/step - accuracy: 0.4692 - loss: 2.4676 - val_accuracy: 0.6099 - val_loss: 1.7761 - learning_rate: 8.5938e-05
Epoch 98/300
1413/1413 - 98s - 70ms/step - accuracy: 0.4722 - loss: 2.4521 - val_accuracy: 0.6170 - val_loss: 1.7644 - learning_rate: 8.5938e-05
Epoch 99/300
1413/1413 - 98s - 69ms/step - accuracy: 0.4636 - loss: 2.4861 - val_accuracy: 0.6075 - val_loss: 1.7549 - learning_rate: 8.5938e-05
Epoch 100/300
1413/1413 - 99s - 70ms/step - accuracy: 0.4691 - loss: 2.4569 - val_accuracy: 0.6083 - val_loss: 1.7740 - learning_rate: 8.5938e-05
Epoch 101/300
1413/1413 - 98s - 69ms/step - accuracy: 0.4710 - loss: 2.4497 - val_accuracy: 0.6035 - val_loss: 1.7747 - learning_rate: 8.5938e-05
Epoch 102/300
1413/1413 - 98s - 69ms/step - accuracy: 0.4660 - loss: 2.4817 - val_accuracy: 0.6043 - val_loss: 1.7862 - learning_rate: 8.5938e-05
Epoch 103/300
1413/1413 - 98s - 69ms/step - accuracy: 0.4797 - loss: 2.4275 - val_accuracy: 0.6075 - val_loss: 1.7496 - learning_rate: 8.5938e-05
Epoch 104/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4724 - loss: 2.4412 - val_accuracy: 0.5995 - val_loss: 1.7823 - learning_rate: 8.5938e-05
Epoch 105/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4809 - loss: 2.4111 - val_accuracy: 0.6083 - val_loss: 1.7596 - learning_rate: 8.5938e-05
Epoch 106/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4678 - loss: 2.4476 - val_accuracy: 0.6162 - val_loss: 1.7654 - learning_rate: 8.5938e-05
Epoch 107/300
1413/1413 - 98s - 69ms/step - accuracy: 0.4647 - loss: 2.4746 - val_accuracy: 0.6218 - val_loss: 1.7503 - learning_rate: 8.5938e-05
Epoch 108/300
1413/1413 - 102s - 73ms/step - accuracy: 0.4713 - loss: 2.4463 - val_accuracy: 0.6067 - val_loss: 1.7731 - learning_rate: 8.5938e-05
Epoch 109/300
1413/1413 - 101s - 71ms/step - accuracy: 0.4752 - loss: 2.4563 - val_accuracy: 0.6290 - val_loss: 1.7571 - learning_rate: 8.5938e-05
Epoch 110/300
1413/1413 - 101s - 71ms/step - accuracy: 0.4737 - loss: 2.4407 - val_accuracy: 0.6131 - val_loss: 1.7719 - learning_rate: 8.5938e-05
Epoch 111/300

Epoch 111: ReduceLROnPlateau reducing learning rate to 4.29692336183507e-05.
1413/1413 - 102s - 72ms/step - accuracy: 0.4731 - loss: 2.4465 - val_accuracy: 0.6186 - val_loss: 1.7664 - learning_rate: 8.5938e-05
Epoch 112/300
1413/1413 - 100s - 71ms/step - accuracy: 0.4670 - loss: 2.4729 - val_accuracy: 0.6178 - val_loss: 1.7613 - learning_rate: 4.2969e-05
Epoch 113/300
1413/1413 - 99s - 70ms/step - accuracy: 0.4769 - loss: 2.4339 - val_accuracy: 0.6170 - val_loss: 1.7437 - learning_rate: 4.2969e-05
Epoch 114/300
1413/1413 - 100s - 71ms/step - accuracy: 0.4763 - loss: 2.4248 - val_accuracy: 0.6218 - val_loss: 1.7443 - learning_rate: 4.2969e-05
Epoch 115/300
1413/1413 - 100s - 71ms/step - accuracy: 0.4752 - loss: 2.4346 - val_accuracy: 0.6186 - val_loss: 1.7470 - learning_rate: 4.2969e-05
Epoch 116/300
1413/1413 - 99s - 70ms/step - accuracy: 0.4794 - loss: 2.4043 - val_accuracy: 0.6266 - val_loss: 1.7385 - learning_rate: 4.2969e-05
Epoch 117/300
1413/1413 - 100s - 71ms/step - accuracy: 0.4794 - loss: 2.4182 - val_accuracy: 0.6186 - val_loss: 1.7437 - learning_rate: 4.2969e-05
Epoch 118/300
1413/1413 - 100s - 71ms/step - accuracy: 0.4685 - loss: 2.4416 - val_accuracy: 0.6242 - val_loss: 1.7378 - learning_rate: 4.2969e-05
Epoch 119/300
1413/1413 - 101s - 71ms/step - accuracy: 0.4724 - loss: 2.4301 - val_accuracy: 0.6322 - val_loss: 1.7465 - learning_rate: 4.2969e-05
Epoch 120/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4736 - loss: 2.4202 - val_accuracy: 0.6178 - val_loss: 1.7488 - learning_rate: 4.2969e-05
Epoch 121/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4773 - loss: 2.4305 - val_accuracy: 0.6218 - val_loss: 1.7417 - learning_rate: 4.2969e-05
Epoch 122/300
1413/1413 - 99s - 70ms/step - accuracy: 0.4757 - loss: 2.4257 - val_accuracy: 0.6266 - val_loss: 1.7418 - learning_rate: 4.2969e-05
Epoch 123/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4741 - loss: 2.4246 - val_accuracy: 0.6250 - val_loss: 1.7581 - learning_rate: 4.2969e-05
Epoch 124/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4752 - loss: 2.4358 - val_accuracy: 0.6146 - val_loss: 1.7478 - learning_rate: 4.2969e-05
Epoch 125/300
1413/1413 - 98s - 69ms/step - accuracy: 0.4815 - loss: 2.4295 - val_accuracy: 0.6306 - val_loss: 1.7425 - learning_rate: 4.2969e-05
Epoch 126/300

Epoch 126: ReduceLROnPlateau reducing learning rate to 2.148461680917535e-05.
1413/1413 - 97s - 69ms/step - accuracy: 0.4805 - loss: 2.4159 - val_accuracy: 0.6258 - val_loss: 1.7422 - learning_rate: 4.2969e-05
Epoch 127/300
1413/1413 - 99s - 70ms/step - accuracy: 0.4816 - loss: 2.4245 - val_accuracy: 0.6250 - val_loss: 1.7444 - learning_rate: 2.1485e-05
Epoch 128/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4785 - loss: 2.4126 - val_accuracy: 0.6226 - val_loss: 1.7386 - learning_rate: 2.1485e-05
Epoch 129/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4865 - loss: 2.3812 - val_accuracy: 0.6202 - val_loss: 1.7446 - learning_rate: 2.1485e-05
Epoch 130/300
1413/1413 - 98s - 70ms/step - accuracy: 0.4749 - loss: 2.4391 - val_accuracy: 0.6242 - val_loss: 1.7295 - learning_rate: 2.1485e-05
Epoch 131/300
1413/1413 - 97s - 68ms/step - accuracy: 0.4768 - loss: 2.4174 - val_accuracy: 0.6282 - val_loss: 1.7351 - learning_rate: 2.1485e-05
Epoch 132/300
1413/1413 - 98s - 69ms/step - accuracy: 0.4821 - loss: 2.4044 - val_accuracy: 0.6226 - val_loss: 1.7415 - learning_rate: 2.1485e-05
Epoch 133/300
1413/1413 - 98s - 69ms/step - accuracy: 0.4792 - loss: 2.3955 - val_accuracy: 0.6218 - val_loss: 1.7353 - learning_rate: 2.1485e-05
Epoch 134/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4729 - loss: 2.4248 - val_accuracy: 0.6210 - val_loss: 1.7401 - learning_rate: 2.1485e-05
Epoch 135/300
1413/1413 - 98s - 69ms/step - accuracy: 0.4712 - loss: 2.4259 - val_accuracy: 0.6202 - val_loss: 1.7513 - learning_rate: 2.1485e-05
Epoch 136/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4786 - loss: 2.4206 - val_accuracy: 0.6218 - val_loss: 1.7358 - learning_rate: 2.1485e-05
Epoch 137/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4788 - loss: 2.4079 - val_accuracy: 0.6154 - val_loss: 1.7445 - learning_rate: 2.1485e-05
Epoch 138/300

Epoch 138: ReduceLROnPlateau reducing learning rate to 1.0742308404587675e-05.
1413/1413 - 99s - 70ms/step - accuracy: 0.4796 - loss: 2.4169 - val_accuracy: 0.6250 - val_loss: 1.7339 - learning_rate: 2.1485e-05
Epoch 139/300
1413/1413 - 98s - 69ms/step - accuracy: 0.4771 - loss: 2.4422 - val_accuracy: 0.6218 - val_loss: 1.7352 - learning_rate: 1.0742e-05
Epoch 140/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4795 - loss: 2.4280 - val_accuracy: 0.6226 - val_loss: 1.7290 - learning_rate: 1.0742e-05
Epoch 141/300
1413/1413 - 98s - 70ms/step - accuracy: 0.4682 - loss: 2.4615 - val_accuracy: 0.6186 - val_loss: 1.7316 - learning_rate: 1.0742e-05
Epoch 142/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4737 - loss: 2.4169 - val_accuracy: 0.6170 - val_loss: 1.7333 - learning_rate: 1.0742e-05
Epoch 143/300
1413/1413 - 98s - 69ms/step - accuracy: 0.4794 - loss: 2.3971 - val_accuracy: 0.6282 - val_loss: 1.7209 - learning_rate: 1.0742e-05
Epoch 144/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4762 - loss: 2.4375 - val_accuracy: 0.6298 - val_loss: 1.7377 - learning_rate: 1.0742e-05
Epoch 145/300
1413/1413 - 112s - 79ms/step - accuracy: 0.4739 - loss: 2.4307 - val_accuracy: 0.6242 - val_loss: 1.7461 - learning_rate: 1.0742e-05
Epoch 146/300
1413/1413 - 110s - 78ms/step - accuracy: 0.4818 - loss: 2.4111 - val_accuracy: 0.6250 - val_loss: 1.7338 - learning_rate: 1.0742e-05
Epoch 147/300
1413/1413 - 107s - 76ms/step - accuracy: 0.4766 - loss: 2.4179 - val_accuracy: 0.6306 - val_loss: 1.7364 - learning_rate: 1.0742e-05
Epoch 148/300
1413/1413 - 108s - 76ms/step - accuracy: 0.4800 - loss: 2.4208 - val_accuracy: 0.6250 - val_loss: 1.7317 - learning_rate: 1.0742e-05
Epoch 149/300
1413/1413 - 107s - 76ms/step - accuracy: 0.4773 - loss: 2.4228 - val_accuracy: 0.6274 - val_loss: 1.7282 - learning_rate: 1.0742e-05
Epoch 150/300
1413/1413 - 108s - 76ms/step - accuracy: 0.4775 - loss: 2.3967 - val_accuracy: 0.6274 - val_loss: 1.7402 - learning_rate: 1.0742e-05
Epoch 151/300

Epoch 151: ReduceLROnPlateau reducing learning rate to 5.3711542022938374e-06.
1413/1413 - 106s - 75ms/step - accuracy: 0.4765 - loss: 2.4010 - val_accuracy: 0.6242 - val_loss: 1.7376 - learning_rate: 1.0742e-05
Epoch 152/300
1413/1413 - 108s - 76ms/step - accuracy: 0.4735 - loss: 2.4187 - val_accuracy: 0.6258 - val_loss: 1.7360 - learning_rate: 5.3712e-06
Epoch 153/300
1413/1413 - 110s - 78ms/step - accuracy: 0.4795 - loss: 2.4199 - val_accuracy: 0.6282 - val_loss: 1.7281 - learning_rate: 5.3712e-06
Epoch 154/300
1413/1413 - 107s - 76ms/step - accuracy: 0.4805 - loss: 2.4224 - val_accuracy: 0.6226 - val_loss: 1.7308 - learning_rate: 5.3712e-06
Epoch 155/300
1413/1413 - 105s - 75ms/step - accuracy: 0.4829 - loss: 2.4110 - val_accuracy: 0.6242 - val_loss: 1.7301 - learning_rate: 5.3712e-06
Epoch 156/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4768 - loss: 2.4186 - val_accuracy: 0.6226 - val_loss: 1.7368 - learning_rate: 5.3712e-06
Epoch 157/300
1413/1413 - 142s - 101ms/step - accuracy: 0.4811 - loss: 2.4046 - val_accuracy: 0.6258 - val_loss: 1.7288 - learning_rate: 5.3712e-06
Epoch 158/300
1413/1413 - 98s - 70ms/step - accuracy: 0.4764 - loss: 2.4125 - val_accuracy: 0.6250 - val_loss: 1.7321 - learning_rate: 5.3712e-06
Epoch 159/300

Epoch 159: ReduceLROnPlateau reducing learning rate to 2.6855771011469187e-06.
1413/1413 - 98s - 70ms/step - accuracy: 0.4813 - loss: 2.3994 - val_accuracy: 0.6242 - val_loss: 1.7318 - learning_rate: 5.3712e-06
Epoch 159: early stopping
Restoring model weights from the end of the best epoch: 143.
Fold 7 Evaluation results: [1.7259712219238281, 0.6281847357749939]
              precision    recall  f1-score   support

        1820       0.86      0.79      0.82        61
        1821       0.85      0.79      0.82        58
        1822       0.00      0.00      0.00         2
        1823       0.00      0.00      0.00         1
        1824       0.00      0.00      0.00         1
        1825       0.00      0.00      0.00         2
        1826       0.00      0.00      0.00         2
        1827       0.81      0.84      0.82        25
        1828       1.00      0.50      0.67         2
        1829       0.60      0.75      0.67         4
        1830       0.57      0.68      0.62        56
        1831       0.77      0.87      0.82       135
        1832       0.79      0.79      0.79        68
        1833       0.95      0.95      0.95        19
        1834       0.56      0.66      0.60        29
        1835       0.00      0.00      0.00         2
        1836       0.00      0.00      0.00         4
        1837       0.44      0.67      0.53         6
        1838       1.00      0.25      0.40         4
        1839       0.00      0.00      0.00         1
        1840       0.57      0.67      0.62        42
        1841       0.75      0.59      0.66       107
        1842       1.00      0.17      0.29         6
        1843       0.50      0.17      0.25         6
        1844       0.00      0.00      0.00         0
        1845       0.00      0.00      0.00         1
        1846       1.00      0.50      0.67         6
        1847       0.00      0.00      0.00         2
        1848       0.00      0.00      0.00         5
        1849       0.25      0.60      0.35         5
        1850       0.42      0.50      0.46        48
        1851       0.70      0.74      0.72        77
        1852       0.00      0.00      0.00         8
        1853       0.00      0.00      0.00         6
        1854       0.00      0.00      0.00         2
        1855       0.60      0.26      0.36        23
        1856       0.67      0.50      0.57        12
        1857       0.43      0.48      0.45        31
        1858       0.00      0.00      0.00         3
        1859       0.00      0.00      0.00         2
        1860       0.41      0.45      0.43        65
        1861       0.80      0.87      0.83        85
        1862       0.23      0.16      0.19        19
        1863       0.42      0.72      0.53        18
        1864       0.40      0.35      0.38        17
        1865       1.00      0.14      0.25         7
        1866       0.40      0.33      0.36         6
        1867       0.20      0.20      0.20        10
        1868       0.00      0.00      0.00         7
        1869       0.50      0.17      0.25         6
        1870       0.36      0.58      0.44        31
        1871       0.79      0.78      0.78        49
        1872       0.20      0.29      0.24         7
        1873       0.38      0.27      0.32        11
        1874       0.33      0.20      0.25         5
        1875       0.21      0.21      0.21        14
        1876       1.00      0.90      0.95        10
        1877       0.00      0.00      0.00         5
        1878       0.67      0.67      0.67         9
        1879       0.00      0.00      0.00         1

    accuracy                           0.63      1256
   macro avg       0.41      0.35      0.35      1256
weighted avg       0.63      0.63      0.62      1256

Matthews Correlation Coefficient: 0.609
Macro avg F1: 0.353
Weighted avg F1: 0.618
Micro avg F1: 0.628
Top-3 Accuracy: 0.846
Top-5 Accuracy: 0.904
Micro ROC AUC  = 0.99
Macro ROC AUC (present classes) = 0.98
Classification MAE (in years): 2.96

Fold 7 Misclassification Analysis:
Near misses (within 2 years): 133 out of 467 misclassifications (28.48%)
MAE with outliers: 2.96
MAE without outliers: 1.99 (improvement: 0.98)

5 Worst misclassifications:
Image: data/datasets/public/1870/1876_407vna.jpg, True: 1879, Predicted: 1820, Error: 59
Image: data/datasets/private/1860/1861_375etsy.jpg, True: 1876, Predicted: 1820, Error: 56
Image: data/datasets/private/1860/1861_293etsy.jpg, True: 1820, Predicted: 1863, Error: 43
Image: data/datasets/public/1840/1841_005_001met.jpg, True: 1820, Predicted: 1863, Error: 43
Image: data/datasets/public/1830/1830_103wikimedia2.jpg, True: 1827, Predicted: 1870, Error: 43

===== Fold 8 =====

===== Fine Tuning 7 layers! =====
Epoch 1/300
1413/1413 - 121s - 86ms/step - accuracy: 0.1906 - loss: 4.0470 - val_accuracy: 0.3376 - val_loss: 3.2953 - learning_rate: 6.8751e-04
Epoch 2/300
1413/1413 - 97s - 69ms/step - accuracy: 0.2730 - loss: 3.5436 - val_accuracy: 0.4084 - val_loss: 2.8322 - learning_rate: 6.8751e-04
Epoch 3/300
1413/1413 - 99s - 70ms/step - accuracy: 0.3051 - loss: 3.3734 - val_accuracy: 0.4530 - val_loss: 2.6065 - learning_rate: 6.8751e-04
Epoch 4/300
1413/1413 - 99s - 70ms/step - accuracy: 0.3222 - loss: 3.2508 - val_accuracy: 0.4618 - val_loss: 2.5096 - learning_rate: 6.8751e-04
Epoch 5/300
1413/1413 - 98s - 69ms/step - accuracy: 0.3367 - loss: 3.1844 - val_accuracy: 0.4697 - val_loss: 2.5476 - learning_rate: 6.8751e-04
Epoch 6/300
1413/1413 - 99s - 70ms/step - accuracy: 0.3511 - loss: 3.1359 - val_accuracy: 0.5247 - val_loss: 2.2412 - learning_rate: 6.8751e-04
Epoch 7/300
1413/1413 - 100s - 70ms/step - accuracy: 0.3493 - loss: 3.1105 - val_accuracy: 0.4793 - val_loss: 2.3799 - learning_rate: 6.8751e-04
Epoch 8/300
1413/1413 - 97s - 69ms/step - accuracy: 0.3609 - loss: 3.0627 - val_accuracy: 0.4928 - val_loss: 2.3403 - learning_rate: 6.8751e-04
Epoch 9/300
1413/1413 - 97s - 69ms/step - accuracy: 0.3550 - loss: 3.0334 - val_accuracy: 0.5000 - val_loss: 2.3650 - learning_rate: 6.8751e-04
Epoch 10/300
1413/1413 - 98s - 69ms/step - accuracy: 0.3708 - loss: 3.0196 - val_accuracy: 0.5318 - val_loss: 2.1967 - learning_rate: 6.8751e-04
Epoch 11/300
1413/1413 - 98s - 69ms/step - accuracy: 0.3848 - loss: 2.9738 - val_accuracy: 0.5159 - val_loss: 2.2275 - learning_rate: 6.8751e-04
Epoch 12/300
1413/1413 - 99s - 70ms/step - accuracy: 0.3807 - loss: 2.9786 - val_accuracy: 0.5478 - val_loss: 2.1328 - learning_rate: 6.8751e-04
Epoch 13/300
1413/1413 - 98s - 69ms/step - accuracy: 0.3851 - loss: 2.9628 - val_accuracy: 0.5255 - val_loss: 2.2144 - learning_rate: 6.8751e-04
Epoch 14/300
1413/1413 - 96s - 68ms/step - accuracy: 0.3830 - loss: 2.9353 - val_accuracy: 0.5271 - val_loss: 2.2267 - learning_rate: 6.8751e-04
Epoch 15/300
1413/1413 - 99s - 70ms/step - accuracy: 0.3778 - loss: 2.9679 - val_accuracy: 0.5295 - val_loss: 2.1725 - learning_rate: 6.8751e-04
Epoch 16/300
1413/1413 - 97s - 68ms/step - accuracy: 0.3864 - loss: 2.9250 - val_accuracy: 0.5199 - val_loss: 2.1470 - learning_rate: 6.8751e-04
Epoch 17/300
1413/1413 - 97s - 69ms/step - accuracy: 0.3933 - loss: 2.9043 - val_accuracy: 0.5239 - val_loss: 2.1301 - learning_rate: 6.8751e-04
Epoch 18/300
1413/1413 - 99s - 70ms/step - accuracy: 0.3960 - loss: 2.8883 - val_accuracy: 0.5605 - val_loss: 2.0334 - learning_rate: 6.8751e-04
Epoch 19/300
1413/1413 - 95s - 68ms/step - accuracy: 0.3994 - loss: 2.8839 - val_accuracy: 0.5223 - val_loss: 2.1755 - learning_rate: 6.8751e-04
Epoch 20/300
1413/1413 - 98s - 69ms/step - accuracy: 0.3935 - loss: 2.8746 - val_accuracy: 0.5318 - val_loss: 2.0946 - learning_rate: 6.8751e-04
Epoch 21/300
1413/1413 - 98s - 70ms/step - accuracy: 0.3944 - loss: 2.8934 - val_accuracy: 0.5533 - val_loss: 2.1409 - learning_rate: 6.8751e-04
Epoch 22/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4048 - loss: 2.8403 - val_accuracy: 0.5589 - val_loss: 2.0714 - learning_rate: 6.8751e-04
Epoch 23/300
1413/1413 - 99s - 70ms/step - accuracy: 0.4024 - loss: 2.8485 - val_accuracy: 0.5732 - val_loss: 2.0330 - learning_rate: 6.8751e-04
Epoch 24/300
1413/1413 - 98s - 70ms/step - accuracy: 0.4027 - loss: 2.8268 - val_accuracy: 0.5470 - val_loss: 2.1135 - learning_rate: 6.8751e-04
Epoch 25/300
1413/1413 - 97s - 68ms/step - accuracy: 0.4124 - loss: 2.7945 - val_accuracy: 0.5605 - val_loss: 2.0421 - learning_rate: 6.8751e-04
Epoch 26/300
1413/1413 - 99s - 70ms/step - accuracy: 0.4097 - loss: 2.8272 - val_accuracy: 0.5677 - val_loss: 1.9560 - learning_rate: 6.8751e-04
Epoch 27/300
1413/1413 - 97s - 69ms/step - accuracy: 0.3996 - loss: 2.8150 - val_accuracy: 0.5621 - val_loss: 1.9965 - learning_rate: 6.8751e-04
Epoch 28/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4082 - loss: 2.8062 - val_accuracy: 0.5645 - val_loss: 2.0260 - learning_rate: 6.8751e-04
Epoch 29/300
1413/1413 - 100s - 70ms/step - accuracy: 0.4147 - loss: 2.8128 - val_accuracy: 0.5748 - val_loss: 2.0429 - learning_rate: 6.8751e-04
Epoch 30/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4125 - loss: 2.8133 - val_accuracy: 0.5637 - val_loss: 1.9598 - learning_rate: 6.8751e-04
Epoch 31/300
1413/1413 - 97s - 68ms/step - accuracy: 0.4148 - loss: 2.8012 - val_accuracy: 0.5653 - val_loss: 2.0559 - learning_rate: 6.8751e-04
Epoch 32/300
1413/1413 - 99s - 70ms/step - accuracy: 0.4131 - loss: 2.7894 - val_accuracy: 0.5677 - val_loss: 2.0213 - learning_rate: 6.8751e-04
Epoch 33/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4067 - loss: 2.8018 - val_accuracy: 0.5438 - val_loss: 2.0906 - learning_rate: 6.8751e-04
Epoch 34/300

Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0003437538689468056.
1413/1413 - 99s - 70ms/step - accuracy: 0.4074 - loss: 2.8043 - val_accuracy: 0.5629 - val_loss: 1.9755 - learning_rate: 6.8751e-04
Epoch 35/300
1413/1413 - 99s - 70ms/step - accuracy: 0.4340 - loss: 2.6825 - val_accuracy: 0.5852 - val_loss: 1.8600 - learning_rate: 3.4375e-04
Epoch 36/300
1413/1413 - 97s - 68ms/step - accuracy: 0.4302 - loss: 2.6893 - val_accuracy: 0.5908 - val_loss: 1.8209 - learning_rate: 3.4375e-04
Epoch 37/300
1413/1413 - 98s - 69ms/step - accuracy: 0.4371 - loss: 2.6790 - val_accuracy: 0.5868 - val_loss: 1.8475 - learning_rate: 3.4375e-04
Epoch 38/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4334 - loss: 2.6688 - val_accuracy: 0.6051 - val_loss: 1.8266 - learning_rate: 3.4375e-04
Epoch 39/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4362 - loss: 2.6430 - val_accuracy: 0.6154 - val_loss: 1.8353 - learning_rate: 3.4375e-04
Epoch 40/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4349 - loss: 2.6365 - val_accuracy: 0.5979 - val_loss: 1.8027 - learning_rate: 3.4375e-04
Epoch 41/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4366 - loss: 2.6339 - val_accuracy: 0.5955 - val_loss: 1.8609 - learning_rate: 3.4375e-04
Epoch 42/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4391 - loss: 2.6450 - val_accuracy: 0.5939 - val_loss: 1.8399 - learning_rate: 3.4375e-04
Epoch 43/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4426 - loss: 2.6086 - val_accuracy: 0.6194 - val_loss: 1.8288 - learning_rate: 3.4375e-04
Epoch 44/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4478 - loss: 2.6154 - val_accuracy: 0.5987 - val_loss: 1.8713 - learning_rate: 3.4375e-04
Epoch 45/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4463 - loss: 2.6064 - val_accuracy: 0.6019 - val_loss: 1.8438 - learning_rate: 3.4375e-04
Epoch 46/300
1413/1413 - 98s - 69ms/step - accuracy: 0.4404 - loss: 2.5956 - val_accuracy: 0.6067 - val_loss: 1.8209 - learning_rate: 3.4375e-04
Epoch 47/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4402 - loss: 2.6227 - val_accuracy: 0.5995 - val_loss: 1.8546 - learning_rate: 3.4375e-04
Epoch 48/300

Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0001718769344734028.
1413/1413 - 96s - 68ms/step - accuracy: 0.4391 - loss: 2.6139 - val_accuracy: 0.5963 - val_loss: 1.9112 - learning_rate: 3.4375e-04
Epoch 49/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4461 - loss: 2.5649 - val_accuracy: 0.6234 - val_loss: 1.7712 - learning_rate: 1.7188e-04
Epoch 50/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4499 - loss: 2.5548 - val_accuracy: 0.6115 - val_loss: 1.7658 - learning_rate: 1.7188e-04
Epoch 51/300
1413/1413 - 98s - 69ms/step - accuracy: 0.4515 - loss: 2.5740 - val_accuracy: 0.6218 - val_loss: 1.7638 - learning_rate: 1.7188e-04
Epoch 52/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4555 - loss: 2.5428 - val_accuracy: 0.6123 - val_loss: 1.7715 - learning_rate: 1.7188e-04
Epoch 53/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4532 - loss: 2.5665 - val_accuracy: 0.6178 - val_loss: 1.7326 - learning_rate: 1.7188e-04
Epoch 54/300
1413/1413 - 98s - 69ms/step - accuracy: 0.4555 - loss: 2.5475 - val_accuracy: 0.6178 - val_loss: 1.7580 - learning_rate: 1.7188e-04
Epoch 55/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4571 - loss: 2.5380 - val_accuracy: 0.6298 - val_loss: 1.7492 - learning_rate: 1.7188e-04
Epoch 56/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4688 - loss: 2.4974 - val_accuracy: 0.6202 - val_loss: 1.7478 - learning_rate: 1.7188e-04
Epoch 57/300
1413/1413 - 99s - 70ms/step - accuracy: 0.4540 - loss: 2.5363 - val_accuracy: 0.6091 - val_loss: 1.7467 - learning_rate: 1.7188e-04
Epoch 58/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4585 - loss: 2.5467 - val_accuracy: 0.6266 - val_loss: 1.7304 - learning_rate: 1.7188e-04
Epoch 59/300
1413/1413 - 98s - 69ms/step - accuracy: 0.4572 - loss: 2.5263 - val_accuracy: 0.6107 - val_loss: 1.7336 - learning_rate: 1.7188e-04
Epoch 60/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4627 - loss: 2.5201 - val_accuracy: 0.6274 - val_loss: 1.7270 - learning_rate: 1.7188e-04
Epoch 61/300
1413/1413 - 94s - 66ms/step - accuracy: 0.4616 - loss: 2.5220 - val_accuracy: 0.6346 - val_loss: 1.7419 - learning_rate: 1.7188e-04
Epoch 62/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4640 - loss: 2.5020 - val_accuracy: 0.6266 - val_loss: 1.7295 - learning_rate: 1.7188e-04
Epoch 63/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4558 - loss: 2.5239 - val_accuracy: 0.6123 - val_loss: 1.7314 - learning_rate: 1.7188e-04
Epoch 64/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4632 - loss: 2.5088 - val_accuracy: 0.6131 - val_loss: 1.7798 - learning_rate: 1.7188e-04
Epoch 65/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4636 - loss: 2.5149 - val_accuracy: 0.6361 - val_loss: 1.7321 - learning_rate: 1.7188e-04
Epoch 66/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4651 - loss: 2.5104 - val_accuracy: 0.6266 - val_loss: 1.7315 - learning_rate: 1.7188e-04
Epoch 67/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4651 - loss: 2.4960 - val_accuracy: 0.6139 - val_loss: 1.7414 - learning_rate: 1.7188e-04
Epoch 68/300

Epoch 68: ReduceLROnPlateau reducing learning rate to 8.59384672367014e-05.
1413/1413 - 97s - 68ms/step - accuracy: 0.4539 - loss: 2.5194 - val_accuracy: 0.6290 - val_loss: 1.7380 - learning_rate: 1.7188e-04
Epoch 69/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4685 - loss: 2.4699 - val_accuracy: 0.6322 - val_loss: 1.7085 - learning_rate: 8.5938e-05
Epoch 70/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4784 - loss: 2.4514 - val_accuracy: 0.6338 - val_loss: 1.7125 - learning_rate: 8.5938e-05
Epoch 71/300
1413/1413 - 95s - 68ms/step - accuracy: 0.4715 - loss: 2.4697 - val_accuracy: 0.6401 - val_loss: 1.7089 - learning_rate: 8.5938e-05
Epoch 72/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4731 - loss: 2.4756 - val_accuracy: 0.6282 - val_loss: 1.7051 - learning_rate: 8.5938e-05
Epoch 73/300
1413/1413 - 98s - 69ms/step - accuracy: 0.4678 - loss: 2.4619 - val_accuracy: 0.6354 - val_loss: 1.7025 - learning_rate: 8.5938e-05
Epoch 74/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4708 - loss: 2.4734 - val_accuracy: 0.6354 - val_loss: 1.6856 - learning_rate: 8.5938e-05
Epoch 75/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4653 - loss: 2.4872 - val_accuracy: 0.6282 - val_loss: 1.6979 - learning_rate: 8.5938e-05
Epoch 76/300
1413/1413 - 98s - 69ms/step - accuracy: 0.4685 - loss: 2.4762 - val_accuracy: 0.6298 - val_loss: 1.6796 - learning_rate: 8.5938e-05
Epoch 77/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4739 - loss: 2.4551 - val_accuracy: 0.6354 - val_loss: 1.7016 - learning_rate: 8.5938e-05
Epoch 78/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4639 - loss: 2.4661 - val_accuracy: 0.6369 - val_loss: 1.6925 - learning_rate: 8.5938e-05
Epoch 79/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4740 - loss: 2.4330 - val_accuracy: 0.6385 - val_loss: 1.6693 - learning_rate: 8.5938e-05
Epoch 80/300
1413/1413 - 94s - 66ms/step - accuracy: 0.4647 - loss: 2.4782 - val_accuracy: 0.6393 - val_loss: 1.6945 - learning_rate: 8.5938e-05
Epoch 81/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4695 - loss: 2.4527 - val_accuracy: 0.6338 - val_loss: 1.6882 - learning_rate: 8.5938e-05
Epoch 82/300
1413/1413 - 94s - 66ms/step - accuracy: 0.4704 - loss: 2.4713 - val_accuracy: 0.6433 - val_loss: 1.6934 - learning_rate: 8.5938e-05
Epoch 83/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4712 - loss: 2.4686 - val_accuracy: 0.6298 - val_loss: 1.6743 - learning_rate: 8.5938e-05
Epoch 84/300
1413/1413 - 97s - 68ms/step - accuracy: 0.4679 - loss: 2.4614 - val_accuracy: 0.6322 - val_loss: 1.6762 - learning_rate: 8.5938e-05
Epoch 85/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4735 - loss: 2.4433 - val_accuracy: 0.6330 - val_loss: 1.6804 - learning_rate: 8.5938e-05
Epoch 86/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4794 - loss: 2.4301 - val_accuracy: 0.6306 - val_loss: 1.6921 - learning_rate: 8.5938e-05
Epoch 87/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4712 - loss: 2.4609 - val_accuracy: 0.6306 - val_loss: 1.6663 - learning_rate: 8.5938e-05
Epoch 88/300
1413/1413 - 94s - 66ms/step - accuracy: 0.4749 - loss: 2.4433 - val_accuracy: 0.6354 - val_loss: 1.6646 - learning_rate: 8.5938e-05
Epoch 89/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4713 - loss: 2.4447 - val_accuracy: 0.6282 - val_loss: 1.6709 - learning_rate: 8.5938e-05
Epoch 90/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4648 - loss: 2.4785 - val_accuracy: 0.6354 - val_loss: 1.7010 - learning_rate: 8.5938e-05
Epoch 91/300
1413/1413 - 94s - 66ms/step - accuracy: 0.4776 - loss: 2.4333 - val_accuracy: 0.6346 - val_loss: 1.6703 - learning_rate: 8.5938e-05
Epoch 92/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4785 - loss: 2.4390 - val_accuracy: 0.6401 - val_loss: 1.6736 - learning_rate: 8.5938e-05
Epoch 93/300
1413/1413 - 94s - 66ms/step - accuracy: 0.4765 - loss: 2.4245 - val_accuracy: 0.6457 - val_loss: 1.6700 - learning_rate: 8.5938e-05
Epoch 94/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4731 - loss: 2.4442 - val_accuracy: 0.6481 - val_loss: 1.6673 - learning_rate: 8.5938e-05
Epoch 95/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4762 - loss: 2.4296 - val_accuracy: 0.6385 - val_loss: 1.6647 - learning_rate: 8.5938e-05
Epoch 96/300

Epoch 96: ReduceLROnPlateau reducing learning rate to 4.29692336183507e-05.
1413/1413 - 92s - 65ms/step - accuracy: 0.4843 - loss: 2.4027 - val_accuracy: 0.6417 - val_loss: 1.6760 - learning_rate: 8.5938e-05
Epoch 97/300
1413/1413 - 97s - 68ms/step - accuracy: 0.4646 - loss: 2.4631 - val_accuracy: 0.6377 - val_loss: 1.6662 - learning_rate: 4.2969e-05
Epoch 98/300
1413/1413 - 94s - 66ms/step - accuracy: 0.4810 - loss: 2.4088 - val_accuracy: 0.6354 - val_loss: 1.6580 - learning_rate: 4.2969e-05
Epoch 99/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4797 - loss: 2.4269 - val_accuracy: 0.6361 - val_loss: 1.6433 - learning_rate: 4.2969e-05
Epoch 100/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4799 - loss: 2.4245 - val_accuracy: 0.6449 - val_loss: 1.6452 - learning_rate: 4.2969e-05
Epoch 101/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4863 - loss: 2.4028 - val_accuracy: 0.6354 - val_loss: 1.6507 - learning_rate: 4.2969e-05
Epoch 102/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4762 - loss: 2.4253 - val_accuracy: 0.6465 - val_loss: 1.6453 - learning_rate: 4.2969e-05
Epoch 103/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4831 - loss: 2.4147 - val_accuracy: 0.6354 - val_loss: 1.6353 - learning_rate: 4.2969e-05
Epoch 104/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4797 - loss: 2.4228 - val_accuracy: 0.6409 - val_loss: 1.6605 - learning_rate: 4.2969e-05
Epoch 105/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4754 - loss: 2.4193 - val_accuracy: 0.6393 - val_loss: 1.6595 - learning_rate: 4.2969e-05
Epoch 106/300
1413/1413 - 94s - 66ms/step - accuracy: 0.4835 - loss: 2.4164 - val_accuracy: 0.6330 - val_loss: 1.6502 - learning_rate: 4.2969e-05
Epoch 107/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4751 - loss: 2.4319 - val_accuracy: 0.6330 - val_loss: 1.6616 - learning_rate: 4.2969e-05
Epoch 108/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4830 - loss: 2.4187 - val_accuracy: 0.6393 - val_loss: 1.6623 - learning_rate: 4.2969e-05
Epoch 109/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4767 - loss: 2.4122 - val_accuracy: 0.6417 - val_loss: 1.6420 - learning_rate: 4.2969e-05
Epoch 110/300
1413/1413 - 95s - 68ms/step - accuracy: 0.4762 - loss: 2.4313 - val_accuracy: 0.6417 - val_loss: 1.6352 - learning_rate: 4.2969e-05
Epoch 111/300

Epoch 111: ReduceLROnPlateau reducing learning rate to 2.148461680917535e-05.
1413/1413 - 96s - 68ms/step - accuracy: 0.4755 - loss: 2.3998 - val_accuracy: 0.6417 - val_loss: 1.6448 - learning_rate: 4.2969e-05
Epoch 112/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4721 - loss: 2.4321 - val_accuracy: 0.6409 - val_loss: 1.6417 - learning_rate: 2.1485e-05
Epoch 113/300
1413/1413 - 94s - 66ms/step - accuracy: 0.4797 - loss: 2.4170 - val_accuracy: 0.6361 - val_loss: 1.6392 - learning_rate: 2.1485e-05
Epoch 114/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4808 - loss: 2.3835 - val_accuracy: 0.6338 - val_loss: 1.6393 - learning_rate: 2.1485e-05
Epoch 115/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4766 - loss: 2.4065 - val_accuracy: 0.6425 - val_loss: 1.6389 - learning_rate: 2.1485e-05
Epoch 116/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4713 - loss: 2.4231 - val_accuracy: 0.6354 - val_loss: 1.6372 - learning_rate: 2.1485e-05
Epoch 117/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4881 - loss: 2.3974 - val_accuracy: 0.6409 - val_loss: 1.6316 - learning_rate: 2.1485e-05
Epoch 118/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4819 - loss: 2.3841 - val_accuracy: 0.6385 - val_loss: 1.6353 - learning_rate: 2.1485e-05
Epoch 119/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4848 - loss: 2.4083 - val_accuracy: 0.6369 - val_loss: 1.6489 - learning_rate: 2.1485e-05
Epoch 120/300
1413/1413 - 94s - 66ms/step - accuracy: 0.4780 - loss: 2.4075 - val_accuracy: 0.6393 - val_loss: 1.6376 - learning_rate: 2.1485e-05
Epoch 121/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4816 - loss: 2.4047 - val_accuracy: 0.6393 - val_loss: 1.6359 - learning_rate: 2.1485e-05
Epoch 122/300
1413/1413 - 93s - 65ms/step - accuracy: 0.4795 - loss: 2.3847 - val_accuracy: 0.6417 - val_loss: 1.6334 - learning_rate: 2.1485e-05
Epoch 123/300
1413/1413 - 91s - 64ms/step - accuracy: 0.4929 - loss: 2.3616 - val_accuracy: 0.6433 - val_loss: 1.6370 - learning_rate: 2.1485e-05
Epoch 124/300
1413/1413 - 88s - 62ms/step - accuracy: 0.4771 - loss: 2.4113 - val_accuracy: 0.6425 - val_loss: 1.6321 - learning_rate: 2.1485e-05
Epoch 125/300

Epoch 125: ReduceLROnPlateau reducing learning rate to 1.0742308404587675e-05.
1413/1413 - 91s - 64ms/step - accuracy: 0.4832 - loss: 2.4117 - val_accuracy: 0.6346 - val_loss: 1.6317 - learning_rate: 2.1485e-05
Epoch 126/300
1413/1413 - 91s - 65ms/step - accuracy: 0.4887 - loss: 2.3818 - val_accuracy: 0.6441 - val_loss: 1.6315 - learning_rate: 1.0742e-05
Epoch 127/300
1413/1413 - 85s - 60ms/step - accuracy: 0.4725 - loss: 2.3916 - val_accuracy: 0.6401 - val_loss: 1.6340 - learning_rate: 1.0742e-05
Epoch 128/300
1413/1413 - 86s - 61ms/step - accuracy: 0.4789 - loss: 2.4024 - val_accuracy: 0.6385 - val_loss: 1.6289 - learning_rate: 1.0742e-05
Epoch 129/300
1413/1413 - 90s - 64ms/step - accuracy: 0.4882 - loss: 2.3941 - val_accuracy: 0.6441 - val_loss: 1.6225 - learning_rate: 1.0742e-05
Epoch 130/300
1413/1413 - 90s - 64ms/step - accuracy: 0.4877 - loss: 2.3997 - val_accuracy: 0.6441 - val_loss: 1.6329 - learning_rate: 1.0742e-05
Epoch 131/300
1413/1413 - 91s - 65ms/step - accuracy: 0.4793 - loss: 2.3960 - val_accuracy: 0.6417 - val_loss: 1.6316 - learning_rate: 1.0742e-05
Epoch 132/300
1413/1413 - 88s - 62ms/step - accuracy: 0.4823 - loss: 2.3964 - val_accuracy: 0.6377 - val_loss: 1.6359 - learning_rate: 1.0742e-05
Epoch 133/300
1413/1413 - 91s - 65ms/step - accuracy: 0.4781 - loss: 2.3912 - val_accuracy: 0.6433 - val_loss: 1.6191 - learning_rate: 1.0742e-05
Epoch 134/300
1413/1413 - 91s - 64ms/step - accuracy: 0.4858 - loss: 2.3970 - val_accuracy: 0.6457 - val_loss: 1.6283 - learning_rate: 1.0742e-05
Epoch 135/300
1413/1413 - 85s - 60ms/step - accuracy: 0.4779 - loss: 2.4116 - val_accuracy: 0.6433 - val_loss: 1.6325 - learning_rate: 1.0742e-05
Epoch 136/300
1413/1413 - 89s - 63ms/step - accuracy: 0.4826 - loss: 2.4042 - val_accuracy: 0.6393 - val_loss: 1.6391 - learning_rate: 1.0742e-05
Epoch 137/300
1413/1413 - 91s - 64ms/step - accuracy: 0.4873 - loss: 2.3811 - val_accuracy: 0.6409 - val_loss: 1.6310 - learning_rate: 1.0742e-05
Epoch 138/300
1413/1413 - 90s - 63ms/step - accuracy: 0.4831 - loss: 2.3623 - val_accuracy: 0.6393 - val_loss: 1.6227 - learning_rate: 1.0742e-05
Epoch 139/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4765 - loss: 2.4033 - val_accuracy: 0.6425 - val_loss: 1.6303 - learning_rate: 1.0742e-05
Epoch 140/300
1413/1413 - 89s - 63ms/step - accuracy: 0.4892 - loss: 2.3852 - val_accuracy: 0.6457 - val_loss: 1.6294 - learning_rate: 1.0742e-05
Epoch 141/300

Epoch 141: ReduceLROnPlateau reducing learning rate to 5.3711542022938374e-06.
1413/1413 - 91s - 64ms/step - accuracy: 0.4813 - loss: 2.3875 - val_accuracy: 0.6401 - val_loss: 1.6275 - learning_rate: 1.0742e-05
Epoch 142/300
1413/1413 - 88s - 63ms/step - accuracy: 0.4802 - loss: 2.4046 - val_accuracy: 0.6409 - val_loss: 1.6275 - learning_rate: 5.3712e-06
Epoch 143/300
1413/1413 - 85s - 60ms/step - accuracy: 0.4852 - loss: 2.4158 - val_accuracy: 0.6425 - val_loss: 1.6377 - learning_rate: 5.3712e-06
Epoch 144/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4861 - loss: 2.3768 - val_accuracy: 0.6401 - val_loss: 1.6287 - learning_rate: 5.3712e-06
Epoch 145/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4808 - loss: 2.4025 - val_accuracy: 0.6433 - val_loss: 1.6323 - learning_rate: 5.3712e-06
Epoch 146/300
1413/1413 - 90s - 64ms/step - accuracy: 0.4703 - loss: 2.4103 - val_accuracy: 0.6409 - val_loss: 1.6306 - learning_rate: 5.3712e-06
Epoch 147/300
1413/1413 - 91s - 64ms/step - accuracy: 0.4747 - loss: 2.4204 - val_accuracy: 0.6409 - val_loss: 1.6301 - learning_rate: 5.3712e-06
Epoch 148/300
1413/1413 - 89s - 63ms/step - accuracy: 0.4763 - loss: 2.3932 - val_accuracy: 0.6425 - val_loss: 1.6314 - learning_rate: 5.3712e-06
Epoch 149/300

Epoch 149: ReduceLROnPlateau reducing learning rate to 2.6855771011469187e-06.
1413/1413 - 90s - 64ms/step - accuracy: 0.4826 - loss: 2.3794 - val_accuracy: 0.6441 - val_loss: 1.6285 - learning_rate: 5.3712e-06
Epoch 149: early stopping
Restoring model weights from the end of the best epoch: 133.
Fold 8 Evaluation results: [1.6295232772827148, 0.6433120965957642]
              precision    recall  f1-score   support

        1820       0.82      0.79      0.80        62
        1821       0.90      0.79      0.84        57
        1822       0.50      0.50      0.50         2
        1823       1.00      1.00      1.00         1
        1824       0.00      0.00      0.00         1
        1825       0.25      0.50      0.33         2
        1826       0.00      0.00      0.00         2
        1827       0.91      0.80      0.85        25
        1828       0.50      0.50      0.50         2
        1829       1.00      0.75      0.86         4
        1830       0.71      0.73      0.72        56
        1831       0.73      0.90      0.81       135
        1832       0.90      0.79      0.84        68
        1833       0.95      1.00      0.97        19
        1834       0.55      0.90      0.68        29
        1835       0.00      0.00      0.00         2
        1836       0.00      0.00      0.00         4
        1837       0.56      0.83      0.67         6
        1838       0.00      0.00      0.00         4
        1839       0.00      0.00      0.00         1
        1840       0.53      0.62      0.57        42
        1841       0.70      0.64      0.67       107
        1842       0.25      0.17      0.20         6
        1843       1.00      0.40      0.57         5
        1844       0.00      0.00      0.00         0
        1845       0.00      0.00      0.00         1
        1846       1.00      0.33      0.50         6
        1847       0.50      0.50      0.50         2
        1848       0.14      0.20      0.17         5
        1849       0.18      0.40      0.25         5
        1850       0.39      0.58      0.47        48
        1851       0.76      0.66      0.71        77
        1852       0.50      0.12      0.20         8
        1853       0.00      0.00      0.00         7
        1854       0.00      0.00      0.00         3
        1855       0.70      0.30      0.42        23
        1856       0.83      0.42      0.56        12
        1857       0.51      0.65      0.57        31
        1858       0.00      0.00      0.00         2
        1859       0.00      0.00      0.00         2
        1860       0.41      0.37      0.39        65
        1861       0.72      0.76      0.74        85
        1862       0.12      0.11      0.11        19
        1863       0.38      0.47      0.42        19
        1864       0.53      0.47      0.50        17
        1865       0.71      0.71      0.71         7
        1866       0.40      0.33      0.36         6
        1867       0.27      0.30      0.29        10
        1868       0.00      0.00      0.00         7
        1869       0.00      0.00      0.00         6
        1870       0.48      0.65      0.55        31
        1871       0.70      0.76      0.73        49
        1872       0.00      0.00      0.00         7
        1873       0.50      0.36      0.42        11
        1874       0.40      0.40      0.40         5
        1875       0.47      0.54      0.50        13
        1876       0.89      0.80      0.84        10
        1877       0.67      0.40      0.50         5
        1878       0.86      0.67      0.75         9
        1879       0.00      0.00      0.00         1

    accuracy                           0.64      1256
   macro avg       0.45      0.41      0.42      1256
weighted avg       0.64      0.64      0.63      1256

Matthews Correlation Coefficient: 0.625
Macro avg F1: 0.416
Weighted avg F1: 0.633
Micro avg F1: 0.643
Top-3 Accuracy: 0.872
Top-5 Accuracy: 0.928
Micro ROC AUC  = 0.99
Macro ROC AUC (present classes) = 0.98
Classification MAE (in years): 2.99

Fold 8 Misclassification Analysis:
Near misses (within 2 years): 121 out of 448 misclassifications (27.01%)
MAE with outliers: 2.99
MAE without outliers: 1.97 (improvement: 1.02)

5 Worst misclassifications:
Image: data/datasets/private/1820/1821_34etsy.jpg, True: 1875, Predicted: 1820, Error: 55
Image: data/datasets/private/1840/1841_707etsy.jpg, True: 1820, Predicted: 1871, Error: 51
Image: data/datasets/private/1870/1871_96etsy.jpg, True: 1873, Predicted: 1830, Error: 43
Image: data/datasets/private/1830/1831_210etsy.jpg, True: 1862, Predicted: 1820, Error: 42
Image: data/datasets/public/1860/1868_022met.jpg, True: 1871, Predicted: 1831, Error: 40

===== Fold 9 =====

===== Fine Tuning 7 layers! =====
Epoch 1/300
1413/1413 - 113s - 80ms/step - accuracy: 0.2015 - loss: 4.0143 - val_accuracy: 0.3331 - val_loss: 3.2336 - learning_rate: 6.8751e-04
Epoch 2/300
1413/1413 - 91s - 65ms/step - accuracy: 0.2849 - loss: 3.4911 - val_accuracy: 0.3729 - val_loss: 2.8974 - learning_rate: 6.8751e-04
Epoch 3/300
1413/1413 - 91s - 64ms/step - accuracy: 0.3075 - loss: 3.3501 - val_accuracy: 0.3833 - val_loss: 2.6459 - learning_rate: 6.8751e-04
Epoch 4/300
1413/1413 - 90s - 64ms/step - accuracy: 0.3252 - loss: 3.2476 - val_accuracy: 0.4550 - val_loss: 2.6595 - learning_rate: 6.8751e-04
Epoch 5/300
1413/1413 - 92s - 65ms/step - accuracy: 0.3373 - loss: 3.1572 - val_accuracy: 0.4510 - val_loss: 2.5494 - learning_rate: 6.8751e-04
Epoch 6/300
1413/1413 - 90s - 63ms/step - accuracy: 0.3469 - loss: 3.1169 - val_accuracy: 0.4853 - val_loss: 2.4216 - learning_rate: 6.8751e-04
Epoch 7/300
1413/1413 - 87s - 62ms/step - accuracy: 0.3550 - loss: 3.0975 - val_accuracy: 0.5100 - val_loss: 2.4022 - learning_rate: 6.8751e-04
Epoch 8/300
1413/1413 - 87s - 62ms/step - accuracy: 0.3597 - loss: 3.0270 - val_accuracy: 0.4813 - val_loss: 2.3507 - learning_rate: 6.8751e-04
Epoch 9/300
1413/1413 - 90s - 63ms/step - accuracy: 0.3705 - loss: 3.0100 - val_accuracy: 0.4948 - val_loss: 2.3629 - learning_rate: 6.8751e-04
Epoch 10/300
1413/1413 - 91s - 64ms/step - accuracy: 0.3667 - loss: 3.0041 - val_accuracy: 0.5267 - val_loss: 2.2158 - learning_rate: 6.8751e-04
Epoch 11/300
1413/1413 - 91s - 64ms/step - accuracy: 0.3739 - loss: 2.9773 - val_accuracy: 0.5179 - val_loss: 2.3603 - learning_rate: 6.8751e-04
Epoch 12/300
1413/1413 - 89s - 63ms/step - accuracy: 0.3794 - loss: 2.9594 - val_accuracy: 0.5139 - val_loss: 2.2194 - learning_rate: 6.8751e-04
Epoch 13/300
1413/1413 - 92s - 65ms/step - accuracy: 0.3808 - loss: 2.9386 - val_accuracy: 0.5100 - val_loss: 2.2173 - learning_rate: 6.8751e-04
Epoch 14/300
1413/1413 - 89s - 63ms/step - accuracy: 0.3899 - loss: 2.8987 - val_accuracy: 0.5163 - val_loss: 2.1963 - learning_rate: 6.8751e-04
Epoch 15/300
1413/1413 - 86s - 61ms/step - accuracy: 0.3848 - loss: 2.8936 - val_accuracy: 0.5116 - val_loss: 2.2033 - learning_rate: 6.8751e-04
Epoch 16/300
1413/1413 - 91s - 64ms/step - accuracy: 0.3918 - loss: 2.8621 - val_accuracy: 0.5187 - val_loss: 2.2865 - learning_rate: 6.8751e-04
Epoch 17/300
1413/1413 - 89s - 63ms/step - accuracy: 0.3943 - loss: 2.8878 - val_accuracy: 0.5339 - val_loss: 2.1461 - learning_rate: 6.8751e-04
Epoch 18/300
1413/1413 - 91s - 64ms/step - accuracy: 0.3937 - loss: 2.8717 - val_accuracy: 0.5235 - val_loss: 2.2228 - learning_rate: 6.8751e-04
Epoch 19/300
1413/1413 - 91s - 65ms/step - accuracy: 0.3902 - loss: 2.8624 - val_accuracy: 0.5426 - val_loss: 2.0763 - learning_rate: 6.8751e-04
Epoch 20/300
1413/1413 - 89s - 63ms/step - accuracy: 0.4034 - loss: 2.8343 - val_accuracy: 0.5315 - val_loss: 2.0646 - learning_rate: 6.8751e-04
Epoch 21/300
1413/1413 - 92s - 65ms/step - accuracy: 0.3968 - loss: 2.8326 - val_accuracy: 0.5116 - val_loss: 2.1525 - learning_rate: 6.8751e-04
Epoch 22/300
1413/1413 - 85s - 60ms/step - accuracy: 0.4040 - loss: 2.8206 - val_accuracy: 0.5633 - val_loss: 2.1190 - learning_rate: 6.8751e-04
Epoch 23/300
1413/1413 - 87s - 61ms/step - accuracy: 0.3959 - loss: 2.8215 - val_accuracy: 0.5506 - val_loss: 2.1638 - learning_rate: 6.8751e-04
Epoch 24/300
1413/1413 - 91s - 65ms/step - accuracy: 0.4075 - loss: 2.8016 - val_accuracy: 0.5339 - val_loss: 2.1534 - learning_rate: 6.8751e-04
Epoch 25/300
1413/1413 - 88s - 62ms/step - accuracy: 0.4061 - loss: 2.8317 - val_accuracy: 0.5155 - val_loss: 2.2819 - learning_rate: 6.8751e-04
Epoch 26/300
1413/1413 - 91s - 65ms/step - accuracy: 0.4133 - loss: 2.8278 - val_accuracy: 0.4964 - val_loss: 2.1131 - learning_rate: 6.8751e-04
Epoch 27/300
1413/1413 - 91s - 64ms/step - accuracy: 0.4061 - loss: 2.8018 - val_accuracy: 0.5371 - val_loss: 2.0743 - learning_rate: 6.8751e-04
Epoch 28/300

Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0003437538689468056.
1413/1413 - 90s - 64ms/step - accuracy: 0.4161 - loss: 2.7691 - val_accuracy: 0.5578 - val_loss: 2.0971 - learning_rate: 6.8751e-04
Epoch 29/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4327 - loss: 2.6791 - val_accuracy: 0.5610 - val_loss: 1.9948 - learning_rate: 3.4375e-04
Epoch 30/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4311 - loss: 2.6663 - val_accuracy: 0.5506 - val_loss: 1.9895 - learning_rate: 3.4375e-04
Epoch 31/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4308 - loss: 2.6755 - val_accuracy: 0.5530 - val_loss: 2.0013 - learning_rate: 3.4375e-04
Epoch 32/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4382 - loss: 2.6472 - val_accuracy: 0.5713 - val_loss: 2.0114 - learning_rate: 3.4375e-04
Epoch 33/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4318 - loss: 2.6546 - val_accuracy: 0.5602 - val_loss: 2.0040 - learning_rate: 3.4375e-04
Epoch 34/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4424 - loss: 2.6072 - val_accuracy: 0.5610 - val_loss: 2.0231 - learning_rate: 3.4375e-04
Epoch 35/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4370 - loss: 2.6117 - val_accuracy: 0.5610 - val_loss: 2.0182 - learning_rate: 3.4375e-04
Epoch 36/300
1413/1413 - 91s - 65ms/step - accuracy: 0.4343 - loss: 2.6429 - val_accuracy: 0.5681 - val_loss: 1.9879 - learning_rate: 3.4375e-04
Epoch 37/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4406 - loss: 2.6022 - val_accuracy: 0.5506 - val_loss: 1.9730 - learning_rate: 3.4375e-04
Epoch 38/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4383 - loss: 2.6158 - val_accuracy: 0.5753 - val_loss: 1.9126 - learning_rate: 3.4375e-04
Epoch 39/300
1413/1413 - 94s - 66ms/step - accuracy: 0.4452 - loss: 2.6217 - val_accuracy: 0.5689 - val_loss: 1.9072 - learning_rate: 3.4375e-04
Epoch 40/300
1413/1413 - 95s - 68ms/step - accuracy: 0.4495 - loss: 2.5739 - val_accuracy: 0.5801 - val_loss: 1.8953 - learning_rate: 3.4375e-04
Epoch 41/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4455 - loss: 2.5958 - val_accuracy: 0.5514 - val_loss: 2.0209 - learning_rate: 3.4375e-04
Epoch 42/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4392 - loss: 2.6131 - val_accuracy: 0.5665 - val_loss: 1.9061 - learning_rate: 3.4375e-04
Epoch 43/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4463 - loss: 2.5891 - val_accuracy: 0.5442 - val_loss: 2.0520 - learning_rate: 3.4375e-04
Epoch 44/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4480 - loss: 2.5788 - val_accuracy: 0.5769 - val_loss: 1.9322 - learning_rate: 3.4375e-04
Epoch 45/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4533 - loss: 2.5881 - val_accuracy: 0.5641 - val_loss: 1.9356 - learning_rate: 3.4375e-04
Epoch 46/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4514 - loss: 2.5675 - val_accuracy: 0.5689 - val_loss: 1.8981 - learning_rate: 3.4375e-04
Epoch 47/300
1413/1413 - 94s - 66ms/step - accuracy: 0.4427 - loss: 2.5844 - val_accuracy: 0.5825 - val_loss: 1.9023 - learning_rate: 3.4375e-04
Epoch 48/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4493 - loss: 2.5966 - val_accuracy: 0.5825 - val_loss: 1.8756 - learning_rate: 3.4375e-04
Epoch 49/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4486 - loss: 2.5920 - val_accuracy: 0.5801 - val_loss: 1.8770 - learning_rate: 3.4375e-04
Epoch 50/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4506 - loss: 2.5670 - val_accuracy: 0.5841 - val_loss: 1.9563 - learning_rate: 3.4375e-04
Epoch 51/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4493 - loss: 2.5720 - val_accuracy: 0.5817 - val_loss: 1.9374 - learning_rate: 3.4375e-04
Epoch 52/300
1413/1413 - 90s - 63ms/step - accuracy: 0.4490 - loss: 2.5316 - val_accuracy: 0.5721 - val_loss: 1.8813 - learning_rate: 3.4375e-04
Epoch 53/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4498 - loss: 2.5700 - val_accuracy: 0.5865 - val_loss: 1.8569 - learning_rate: 3.4375e-04
Epoch 54/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4518 - loss: 2.5591 - val_accuracy: 0.5721 - val_loss: 1.8682 - learning_rate: 3.4375e-04
Epoch 55/300
1413/1413 - 88s - 62ms/step - accuracy: 0.4492 - loss: 2.5955 - val_accuracy: 0.5737 - val_loss: 1.8752 - learning_rate: 3.4375e-04
Epoch 56/300
1413/1413 - 90s - 64ms/step - accuracy: 0.4497 - loss: 2.5717 - val_accuracy: 0.5753 - val_loss: 1.8899 - learning_rate: 3.4375e-04
Epoch 57/300
1413/1413 - 89s - 63ms/step - accuracy: 0.4505 - loss: 2.5450 - val_accuracy: 0.5841 - val_loss: 1.8700 - learning_rate: 3.4375e-04
Epoch 58/300
1413/1413 - 88s - 63ms/step - accuracy: 0.4521 - loss: 2.5607 - val_accuracy: 0.5952 - val_loss: 1.8444 - learning_rate: 3.4375e-04
Epoch 59/300
1413/1413 - 90s - 64ms/step - accuracy: 0.4502 - loss: 2.5566 - val_accuracy: 0.5809 - val_loss: 1.8874 - learning_rate: 3.4375e-04
Epoch 60/300
1413/1413 - 90s - 64ms/step - accuracy: 0.4543 - loss: 2.5634 - val_accuracy: 0.5888 - val_loss: 1.8705 - learning_rate: 3.4375e-04
Epoch 61/300
1413/1413 - 95s - 68ms/step - accuracy: 0.4542 - loss: 2.5569 - val_accuracy: 0.5801 - val_loss: 1.8480 - learning_rate: 3.4375e-04
Epoch 62/300
1413/1413 - 94s - 66ms/step - accuracy: 0.4545 - loss: 2.5482 - val_accuracy: 0.5865 - val_loss: 1.8580 - learning_rate: 3.4375e-04
Epoch 63/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4538 - loss: 2.5468 - val_accuracy: 0.5817 - val_loss: 1.9041 - learning_rate: 3.4375e-04
Epoch 64/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4551 - loss: 2.5427 - val_accuracy: 0.5729 - val_loss: 1.8771 - learning_rate: 3.4375e-04
Epoch 65/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4613 - loss: 2.5372 - val_accuracy: 0.5888 - val_loss: 1.8366 - learning_rate: 3.4375e-04
Epoch 66/300
1413/1413 - 99s - 70ms/step - accuracy: 0.4546 - loss: 2.5452 - val_accuracy: 0.5849 - val_loss: 1.8509 - learning_rate: 3.4375e-04
Epoch 67/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4627 - loss: 2.4930 - val_accuracy: 0.5625 - val_loss: 1.9551 - learning_rate: 3.4375e-04
Epoch 68/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4555 - loss: 2.5296 - val_accuracy: 0.5777 - val_loss: 1.8253 - learning_rate: 3.4375e-04
Epoch 69/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4618 - loss: 2.5063 - val_accuracy: 0.5865 - val_loss: 1.8781 - learning_rate: 3.4375e-04
Epoch 70/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4578 - loss: 2.5348 - val_accuracy: 0.5936 - val_loss: 1.8354 - learning_rate: 3.4375e-04
Epoch 71/300
1413/1413 - 91s - 64ms/step - accuracy: 0.4597 - loss: 2.5192 - val_accuracy: 0.5896 - val_loss: 1.8373 - learning_rate: 3.4375e-04
Epoch 72/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4586 - loss: 2.5138 - val_accuracy: 0.5841 - val_loss: 1.8022 - learning_rate: 3.4375e-04
Epoch 73/300
1413/1413 - 94s - 66ms/step - accuracy: 0.4578 - loss: 2.5276 - val_accuracy: 0.5968 - val_loss: 1.8467 - learning_rate: 3.4375e-04
Epoch 74/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4515 - loss: 2.5567 - val_accuracy: 0.5920 - val_loss: 1.8604 - learning_rate: 3.4375e-04
Epoch 75/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4554 - loss: 2.5374 - val_accuracy: 0.5880 - val_loss: 1.8087 - learning_rate: 3.4375e-04
Epoch 76/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4582 - loss: 2.5134 - val_accuracy: 0.5928 - val_loss: 1.8480 - learning_rate: 3.4375e-04
Epoch 77/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4590 - loss: 2.5031 - val_accuracy: 0.5944 - val_loss: 1.8524 - learning_rate: 3.4375e-04
Epoch 78/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4596 - loss: 2.5184 - val_accuracy: 0.5896 - val_loss: 1.8705 - learning_rate: 3.4375e-04
Epoch 79/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4637 - loss: 2.5197 - val_accuracy: 0.5865 - val_loss: 1.8491 - learning_rate: 3.4375e-04
Epoch 80/300

Epoch 80: ReduceLROnPlateau reducing learning rate to 0.0001718769344734028.
1413/1413 - 95s - 67ms/step - accuracy: 0.4609 - loss: 2.4976 - val_accuracy: 0.5665 - val_loss: 1.9329 - learning_rate: 3.4375e-04
Epoch 81/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4705 - loss: 2.4824 - val_accuracy: 0.5968 - val_loss: 1.8119 - learning_rate: 1.7188e-04
Epoch 82/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4738 - loss: 2.4142 - val_accuracy: 0.5992 - val_loss: 1.7943 - learning_rate: 1.7188e-04
Epoch 83/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4747 - loss: 2.4248 - val_accuracy: 0.6112 - val_loss: 1.7942 - learning_rate: 1.7188e-04
Epoch 84/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4726 - loss: 2.4194 - val_accuracy: 0.6064 - val_loss: 1.7769 - learning_rate: 1.7188e-04
Epoch 85/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4725 - loss: 2.4462 - val_accuracy: 0.5976 - val_loss: 1.8030 - learning_rate: 1.7188e-04
Epoch 86/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4780 - loss: 2.4118 - val_accuracy: 0.6096 - val_loss: 1.7982 - learning_rate: 1.7188e-04
Epoch 87/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4812 - loss: 2.4116 - val_accuracy: 0.6040 - val_loss: 1.7900 - learning_rate: 1.7188e-04
Epoch 88/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4752 - loss: 2.4328 - val_accuracy: 0.6024 - val_loss: 1.7819 - learning_rate: 1.7188e-04
Epoch 89/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4731 - loss: 2.4447 - val_accuracy: 0.6064 - val_loss: 1.7849 - learning_rate: 1.7188e-04
Epoch 90/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4719 - loss: 2.4569 - val_accuracy: 0.6048 - val_loss: 1.7732 - learning_rate: 1.7188e-04
Epoch 91/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4767 - loss: 2.4166 - val_accuracy: 0.6120 - val_loss: 1.7507 - learning_rate: 1.7188e-04
Epoch 92/300
1413/1413 - 95s - 68ms/step - accuracy: 0.4794 - loss: 2.4353 - val_accuracy: 0.6040 - val_loss: 1.7962 - learning_rate: 1.7188e-04
Epoch 93/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4636 - loss: 2.4495 - val_accuracy: 0.6143 - val_loss: 1.7572 - learning_rate: 1.7188e-04
Epoch 94/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4733 - loss: 2.4352 - val_accuracy: 0.6000 - val_loss: 1.7623 - learning_rate: 1.7188e-04
Epoch 95/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4784 - loss: 2.4121 - val_accuracy: 0.6048 - val_loss: 1.8043 - learning_rate: 1.7188e-04
Epoch 96/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4851 - loss: 2.3908 - val_accuracy: 0.5992 - val_loss: 1.7966 - learning_rate: 1.7188e-04
Epoch 97/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4837 - loss: 2.3917 - val_accuracy: 0.6080 - val_loss: 1.7537 - learning_rate: 1.7188e-04
Epoch 98/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4773 - loss: 2.4043 - val_accuracy: 0.6167 - val_loss: 1.7851 - learning_rate: 1.7188e-04
Epoch 99/300

Epoch 99: ReduceLROnPlateau reducing learning rate to 8.59384672367014e-05.
1413/1413 - 95s - 68ms/step - accuracy: 0.4779 - loss: 2.4069 - val_accuracy: 0.6104 - val_loss: 1.8327 - learning_rate: 1.7188e-04
Epoch 100/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4837 - loss: 2.4039 - val_accuracy: 0.6056 - val_loss: 1.7526 - learning_rate: 8.5938e-05
Epoch 101/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4826 - loss: 2.3833 - val_accuracy: 0.6024 - val_loss: 1.7436 - learning_rate: 8.5938e-05
Epoch 102/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4913 - loss: 2.3748 - val_accuracy: 0.6064 - val_loss: 1.7434 - learning_rate: 8.5938e-05
Epoch 103/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4909 - loss: 2.3635 - val_accuracy: 0.6096 - val_loss: 1.7503 - learning_rate: 8.5938e-05
Epoch 104/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4860 - loss: 2.3711 - val_accuracy: 0.6040 - val_loss: 1.7532 - learning_rate: 8.5938e-05
Epoch 105/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4901 - loss: 2.3440 - val_accuracy: 0.6088 - val_loss: 1.7382 - learning_rate: 8.5938e-05
Epoch 106/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4885 - loss: 2.3844 - val_accuracy: 0.6135 - val_loss: 1.7308 - learning_rate: 8.5938e-05
Epoch 107/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4881 - loss: 2.3696 - val_accuracy: 0.6096 - val_loss: 1.7405 - learning_rate: 8.5938e-05
Epoch 108/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4889 - loss: 2.3606 - val_accuracy: 0.6104 - val_loss: 1.7502 - learning_rate: 8.5938e-05
Epoch 109/300
1413/1413 - 95s - 68ms/step - accuracy: 0.4941 - loss: 2.3626 - val_accuracy: 0.6080 - val_loss: 1.7254 - learning_rate: 8.5938e-05
Epoch 110/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4850 - loss: 2.3629 - val_accuracy: 0.6032 - val_loss: 1.7534 - learning_rate: 8.5938e-05
Epoch 111/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4965 - loss: 2.3552 - val_accuracy: 0.6104 - val_loss: 1.7297 - learning_rate: 8.5938e-05
Epoch 112/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4840 - loss: 2.3736 - val_accuracy: 0.6104 - val_loss: 1.7050 - learning_rate: 8.5938e-05
Epoch 113/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4866 - loss: 2.3560 - val_accuracy: 0.6159 - val_loss: 1.7235 - learning_rate: 8.5938e-05
Epoch 114/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4834 - loss: 2.3581 - val_accuracy: 0.6143 - val_loss: 1.7205 - learning_rate: 8.5938e-05
Epoch 115/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4910 - loss: 2.3594 - val_accuracy: 0.6199 - val_loss: 1.7361 - learning_rate: 8.5938e-05
Epoch 116/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4913 - loss: 2.3261 - val_accuracy: 0.6223 - val_loss: 1.7282 - learning_rate: 8.5938e-05
Epoch 117/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4885 - loss: 2.3602 - val_accuracy: 0.6127 - val_loss: 1.7310 - learning_rate: 8.5938e-05
Epoch 118/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4881 - loss: 2.3623 - val_accuracy: 0.6279 - val_loss: 1.7068 - learning_rate: 8.5938e-05
Epoch 119/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4865 - loss: 2.3369 - val_accuracy: 0.6143 - val_loss: 1.7290 - learning_rate: 8.5938e-05
Epoch 120/300

Epoch 120: ReduceLROnPlateau reducing learning rate to 4.29692336183507e-05.
1413/1413 - 95s - 67ms/step - accuracy: 0.4832 - loss: 2.3491 - val_accuracy: 0.6223 - val_loss: 1.7183 - learning_rate: 8.5938e-05
Epoch 121/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4986 - loss: 2.3157 - val_accuracy: 0.6215 - val_loss: 1.7102 - learning_rate: 4.2969e-05
Epoch 122/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4864 - loss: 2.3460 - val_accuracy: 0.6175 - val_loss: 1.7056 - learning_rate: 4.2969e-05
Epoch 123/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4873 - loss: 2.3312 - val_accuracy: 0.6335 - val_loss: 1.6900 - learning_rate: 4.2969e-05
Epoch 124/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4937 - loss: 2.3248 - val_accuracy: 0.6207 - val_loss: 1.7124 - learning_rate: 4.2969e-05
Epoch 125/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4863 - loss: 2.3468 - val_accuracy: 0.6239 - val_loss: 1.7025 - learning_rate: 4.2969e-05
Epoch 126/300
1413/1413 - 95s - 68ms/step - accuracy: 0.4990 - loss: 2.3242 - val_accuracy: 0.6271 - val_loss: 1.6932 - learning_rate: 4.2969e-05
Epoch 127/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4965 - loss: 2.3379 - val_accuracy: 0.6295 - val_loss: 1.6919 - learning_rate: 4.2969e-05
Epoch 128/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4928 - loss: 2.3228 - val_accuracy: 0.6295 - val_loss: 1.6919 - learning_rate: 4.2969e-05
Epoch 129/300
1413/1413 - 95s - 68ms/step - accuracy: 0.4919 - loss: 2.3247 - val_accuracy: 0.6231 - val_loss: 1.6851 - learning_rate: 4.2969e-05
Epoch 130/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4938 - loss: 2.3432 - val_accuracy: 0.6183 - val_loss: 1.7085 - learning_rate: 4.2969e-05
Epoch 131/300
1413/1413 - 95s - 67ms/step - accuracy: 0.5006 - loss: 2.2998 - val_accuracy: 0.6199 - val_loss: 1.6907 - learning_rate: 4.2969e-05
Epoch 132/300
1413/1413 - 95s - 67ms/step - accuracy: 0.5016 - loss: 2.3180 - val_accuracy: 0.6191 - val_loss: 1.6870 - learning_rate: 4.2969e-05
Epoch 133/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4932 - loss: 2.3333 - val_accuracy: 0.6175 - val_loss: 1.6871 - learning_rate: 4.2969e-05
Epoch 134/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4904 - loss: 2.3222 - val_accuracy: 0.6143 - val_loss: 1.7177 - learning_rate: 4.2969e-05
Epoch 135/300
1413/1413 - 95s - 67ms/step - accuracy: 0.5035 - loss: 2.3070 - val_accuracy: 0.6223 - val_loss: 1.7141 - learning_rate: 4.2969e-05
Epoch 136/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4988 - loss: 2.2960 - val_accuracy: 0.6239 - val_loss: 1.6976 - learning_rate: 4.2969e-05
Epoch 137/300

Epoch 137: ReduceLROnPlateau reducing learning rate to 2.148461680917535e-05.
1413/1413 - 95s - 67ms/step - accuracy: 0.4949 - loss: 2.3187 - val_accuracy: 0.6191 - val_loss: 1.6924 - learning_rate: 4.2969e-05
Epoch 138/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4923 - loss: 2.3279 - val_accuracy: 0.6231 - val_loss: 1.6859 - learning_rate: 2.1485e-05
Epoch 139/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4919 - loss: 2.3172 - val_accuracy: 0.6279 - val_loss: 1.6762 - learning_rate: 2.1485e-05
Epoch 140/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4925 - loss: 2.3191 - val_accuracy: 0.6191 - val_loss: 1.7083 - learning_rate: 2.1485e-05
Epoch 141/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4913 - loss: 2.3345 - val_accuracy: 0.6143 - val_loss: 1.6943 - learning_rate: 2.1485e-05
Epoch 142/300
1413/1413 - 96s - 68ms/step - accuracy: 0.5038 - loss: 2.3119 - val_accuracy: 0.6231 - val_loss: 1.6938 - learning_rate: 2.1485e-05
Epoch 143/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4996 - loss: 2.3116 - val_accuracy: 0.6287 - val_loss: 1.6804 - learning_rate: 2.1485e-05
Epoch 144/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4974 - loss: 2.3214 - val_accuracy: 0.6231 - val_loss: 1.6949 - learning_rate: 2.1485e-05
Epoch 145/300
1413/1413 - 95s - 67ms/step - accuracy: 0.5052 - loss: 2.2752 - val_accuracy: 0.6255 - val_loss: 1.6796 - learning_rate: 2.1485e-05
Epoch 146/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4927 - loss: 2.3363 - val_accuracy: 0.6183 - val_loss: 1.6819 - learning_rate: 2.1485e-05
Epoch 147/300

Epoch 147: ReduceLROnPlateau reducing learning rate to 1.0742308404587675e-05.
1413/1413 - 95s - 67ms/step - accuracy: 0.4974 - loss: 2.3199 - val_accuracy: 0.6239 - val_loss: 1.6832 - learning_rate: 2.1485e-05
Epoch 148/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4948 - loss: 2.3170 - val_accuracy: 0.6271 - val_loss: 1.6832 - learning_rate: 1.0742e-05
Epoch 149/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4946 - loss: 2.3452 - val_accuracy: 0.6215 - val_loss: 1.6906 - learning_rate: 1.0742e-05
Epoch 150/300
1413/1413 - 95s - 68ms/step - accuracy: 0.5027 - loss: 2.3088 - val_accuracy: 0.6279 - val_loss: 1.6901 - learning_rate: 1.0742e-05
Epoch 151/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4962 - loss: 2.2760 - val_accuracy: 0.6279 - val_loss: 1.6848 - learning_rate: 1.0742e-05
Epoch 152/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4956 - loss: 2.2674 - val_accuracy: 0.6287 - val_loss: 1.6821 - learning_rate: 1.0742e-05
Epoch 153/300
1413/1413 - 95s - 67ms/step - accuracy: 0.5044 - loss: 2.2933 - val_accuracy: 0.6175 - val_loss: 1.6793 - learning_rate: 1.0742e-05
Epoch 154/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4943 - loss: 2.3046 - val_accuracy: 0.6271 - val_loss: 1.6793 - learning_rate: 1.0742e-05
Epoch 155/300

Epoch 155: ReduceLROnPlateau reducing learning rate to 5.3711542022938374e-06.
1413/1413 - 95s - 67ms/step - accuracy: 0.4953 - loss: 2.3100 - val_accuracy: 0.6239 - val_loss: 1.6875 - learning_rate: 1.0742e-05
Epoch 155: early stopping
Restoring model weights from the end of the best epoch: 139.
Fold 9 Evaluation results: [1.6761915683746338, 0.6278884410858154]
              precision    recall  f1-score   support

        1820       0.72      0.82      0.77        62
        1821       0.91      0.89      0.90        57
        1822       0.00      0.00      0.00         1
        1823       0.00      0.00      0.00         1
        1824       0.00      0.00      0.00         1
        1825       0.00      0.00      0.00         2
        1826       0.00      0.00      0.00         2
        1827       0.89      0.68      0.77        25
        1828       0.00      0.00      0.00         2
        1829       0.75      0.75      0.75         4
        1830       0.56      0.57      0.57        56
        1831       0.80      0.90      0.85       134
        1832       0.73      0.78      0.75        68
        1833       1.00      0.95      0.97        19
        1834       0.68      0.72      0.70        29
        1835       0.00      0.00      0.00         2
        1836       0.00      0.00      0.00         4
        1837       0.18      0.33      0.24         6
        1838       0.50      0.25      0.33         4
        1839       0.00      0.00      0.00         1
        1840       0.50      0.58      0.54        43
        1841       0.70      0.64      0.67       107
        1842       0.33      0.17      0.22         6
        1843       0.50      0.60      0.55         5
        1844       0.00      0.00      0.00         0
        1845       0.00      0.00      0.00         1
        1846       0.67      0.33      0.44         6
        1847       0.00      0.00      0.00         2
        1848       0.43      0.60      0.50         5
        1849       0.50      0.33      0.40         6
        1850       0.53      0.77      0.63        48
        1851       0.73      0.60      0.66        77
        1852       0.29      0.29      0.29         7
        1853       0.25      0.14      0.18         7
        1854       0.00      0.00      0.00         3
        1855       0.46      0.26      0.33        23
        1856       0.70      0.58      0.64        12
        1857       0.53      0.63      0.58        30
        1858       1.00      0.50      0.67         2
        1859       0.00      0.00      0.00         2
        1860       0.43      0.35      0.39        65
        1861       0.73      0.82      0.77        85
        1862       0.39      0.37      0.38        19
        1863       0.31      0.47      0.38        19
        1864       0.26      0.29      0.28        17
        1865       0.33      0.29      0.31         7
        1866       0.25      0.17      0.20         6
        1867       0.29      0.18      0.22        11
        1868       0.00      0.00      0.00         7
        1869       0.00      0.00      0.00         5
        1870       0.46      0.58      0.51        31
        1871       0.80      0.71      0.75        49
        1872       0.40      0.57      0.47         7
        1873       0.25      0.30      0.27        10
        1874       0.00      0.00      0.00         5
        1875       0.38      0.21      0.27        14
        1876       1.00      0.80      0.89        10
        1877       0.50      0.20      0.29         5
        1878       0.33      0.44      0.38         9
        1879       0.00      0.00      0.00         2

    accuracy                           0.63      1255
   macro avg       0.38      0.36      0.36      1255
weighted avg       0.62      0.63      0.62      1255

Matthews Correlation Coefficient: 0.609
Macro avg F1: 0.361
Weighted avg F1: 0.618
Micro avg F1: 0.628
Top-3 Accuracy: 0.864
Top-5 Accuracy: 0.919
Micro ROC AUC  = 0.99
Macro ROC AUC (present classes) = 0.98
Classification MAE (in years): 2.99

Fold 9 Misclassification Analysis:
Near misses (within 2 years): 128 out of 467 misclassifications (27.41%)
MAE with outliers: 2.99
MAE without outliers: 2.00 (improvement: 0.99)

5 Worst misclassifications:
Image: data/datasets/public/1820/1827_084met.jpg, True: 1879, Predicted: 1820, Error: 59
Image: data/datasets/public/1860/1869_034met.jpg, True: 1820, Predicted: 1867, Error: 47
Image: data/datasets/public/1860/1860_27wikimedia2.jpg, True: 1875, Predicted: 1830, Error: 45
Image: data/datasets/private/1860/1861_809etsy.jpg, True: 1875, Predicted: 1830, Error: 45
Image: data/datasets/private/1830/1830_24etsy.jpg, True: 1876, Predicted: 1832, Error: 44

Mean MAE over 10 folds: 3.0346

Mean accuracy over 10 folds: 0.6287

Mean Matthews Correlation Coefficient over 10 folds: 0.6100

=== Total running time: 35 hours, 53 minutes, 56 seconds ===

=======
>>>>>>> 0bbc263646c36694c8f849d7abb22150418546af
