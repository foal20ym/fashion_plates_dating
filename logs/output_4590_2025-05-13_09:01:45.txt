TensorFlow Version: 2.20.0-dev20250508
Num GPUs Available: 1
Using GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')

=== Using model: NASNetMobile. ===
RUN ID: 2025-05-13_09:01:50
Test fold: 0

===== Fine Tuning 7 layers! =====
Epoch 1/300
1413/1413 - 156s - 110ms/step - accuracy: 0.1530 - loss: 4.2502 - val_accuracy: 0.2675 - val_loss: 3.9264 - learning_rate: 2.0479e-04
Epoch 2/300
1413/1413 - 87s - 62ms/step - accuracy: 0.2465 - loss: 3.8111 - val_accuracy: 0.3639 - val_loss: 3.3870 - learning_rate: 2.0479e-04
Epoch 3/300
1413/1413 - 87s - 61ms/step - accuracy: 0.2814 - loss: 3.5805 - val_accuracy: 0.3822 - val_loss: 3.1274 - learning_rate: 2.0479e-04
Epoch 4/300
1413/1413 - 87s - 61ms/step - accuracy: 0.2961 - loss: 3.4724 - val_accuracy: 0.4092 - val_loss: 2.9702 - learning_rate: 2.0479e-04
Epoch 5/300
1413/1413 - 87s - 61ms/step - accuracy: 0.3180 - loss: 3.3543 - val_accuracy: 0.4291 - val_loss: 2.8353 - learning_rate: 2.0479e-04
Epoch 6/300
1413/1413 - 85s - 60ms/step - accuracy: 0.3267 - loss: 3.3061 - val_accuracy: 0.4475 - val_loss: 2.8483 - learning_rate: 2.0479e-04
Epoch 7/300
1413/1413 - 87s - 62ms/step - accuracy: 0.3369 - loss: 3.2509 - val_accuracy: 0.4689 - val_loss: 2.7950 - learning_rate: 2.0479e-04
Epoch 8/300
1413/1413 - 87s - 62ms/step - accuracy: 0.3407 - loss: 3.2332 - val_accuracy: 0.4371 - val_loss: 2.8206 - learning_rate: 2.0479e-04
Epoch 9/300
1413/1413 - 87s - 61ms/step - accuracy: 0.3492 - loss: 3.1778 - val_accuracy: 0.4658 - val_loss: 2.6713 - learning_rate: 2.0479e-04
Epoch 10/300
1413/1413 - 89s - 63ms/step - accuracy: 0.3515 - loss: 3.1378 - val_accuracy: 0.4546 - val_loss: 2.6404 - learning_rate: 2.0479e-04
Epoch 11/300
1413/1413 - 87s - 61ms/step - accuracy: 0.3565 - loss: 3.1180 - val_accuracy: 0.4626 - val_loss: 2.6148 - learning_rate: 2.0479e-04
Epoch 12/300
1413/1413 - 88s - 63ms/step - accuracy: 0.3668 - loss: 3.0746 - val_accuracy: 0.4737 - val_loss: 2.5406 - learning_rate: 2.0479e-04
Epoch 13/300
1413/1413 - 88s - 62ms/step - accuracy: 0.3643 - loss: 3.0648 - val_accuracy: 0.4721 - val_loss: 2.5220 - learning_rate: 2.0479e-04
Epoch 14/300
1413/1413 - 86s - 61ms/step - accuracy: 0.3694 - loss: 3.0542 - val_accuracy: 0.5000 - val_loss: 2.5055 - learning_rate: 2.0479e-04
Epoch 15/300
1413/1413 - 85s - 60ms/step - accuracy: 0.3732 - loss: 3.0259 - val_accuracy: 0.4769 - val_loss: 2.5085 - learning_rate: 2.0479e-04
Epoch 16/300
1413/1413 - 85s - 60ms/step - accuracy: 0.3799 - loss: 2.9946 - val_accuracy: 0.4976 - val_loss: 2.4666 - learning_rate: 2.0479e-04
Epoch 17/300
1413/1413 - 85s - 60ms/step - accuracy: 0.3718 - loss: 2.9796 - val_accuracy: 0.4889 - val_loss: 2.4257 - learning_rate: 2.0479e-04
Epoch 18/300
1413/1413 - 82s - 58ms/step - accuracy: 0.3814 - loss: 2.9696 - val_accuracy: 0.4904 - val_loss: 2.4104 - learning_rate: 2.0479e-04
Epoch 19/300
1413/1413 - 84s - 59ms/step - accuracy: 0.3862 - loss: 2.9610 - val_accuracy: 0.4960 - val_loss: 2.4189 - learning_rate: 2.0479e-04
Epoch 20/300
1413/1413 - 85s - 60ms/step - accuracy: 0.3821 - loss: 2.9559 - val_accuracy: 0.5048 - val_loss: 2.3968 - learning_rate: 2.0479e-04
Epoch 21/300
1413/1413 - 84s - 60ms/step - accuracy: 0.3835 - loss: 2.9478 - val_accuracy: 0.5000 - val_loss: 2.3764 - learning_rate: 2.0479e-04
Epoch 22/300
1413/1413 - 86s - 61ms/step - accuracy: 0.3843 - loss: 2.9551 - val_accuracy: 0.4912 - val_loss: 2.2981 - learning_rate: 2.0479e-04
Epoch 23/300
1413/1413 - 89s - 63ms/step - accuracy: 0.3932 - loss: 2.9081 - val_accuracy: 0.5167 - val_loss: 2.3389 - learning_rate: 2.0479e-04
Epoch 24/300
1413/1413 - 90s - 64ms/step - accuracy: 0.3898 - loss: 2.8837 - val_accuracy: 0.5334 - val_loss: 2.2153 - learning_rate: 2.0479e-04
Epoch 25/300
1413/1413 - 87s - 62ms/step - accuracy: 0.3935 - loss: 2.8676 - val_accuracy: 0.5056 - val_loss: 2.3229 - learning_rate: 2.0479e-04
Epoch 26/300
1413/1413 - 87s - 62ms/step - accuracy: 0.3853 - loss: 2.8852 - val_accuracy: 0.5215 - val_loss: 2.2607 - learning_rate: 2.0479e-04
Epoch 27/300
1413/1413 - 88s - 62ms/step - accuracy: 0.3916 - loss: 2.8727 - val_accuracy: 0.5350 - val_loss: 2.3180 - learning_rate: 2.0479e-04
Epoch 28/300
1413/1413 - 89s - 63ms/step - accuracy: 0.3950 - loss: 2.8939 - val_accuracy: 0.5382 - val_loss: 2.2693 - learning_rate: 2.0479e-04
Epoch 29/300
1413/1413 - 91s - 64ms/step - accuracy: 0.3986 - loss: 2.8532 - val_accuracy: 0.5199 - val_loss: 2.2383 - learning_rate: 2.0479e-04
Epoch 30/300
1413/1413 - 88s - 63ms/step - accuracy: 0.4024 - loss: 2.8451 - val_accuracy: 0.5271 - val_loss: 2.2332 - learning_rate: 2.0479e-04
Epoch 31/300
1413/1413 - 88s - 63ms/step - accuracy: 0.4028 - loss: 2.8194 - val_accuracy: 0.5247 - val_loss: 2.2345 - learning_rate: 2.0479e-04
Epoch 32/300

Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00010239420953439549.
1413/1413 - 90s - 64ms/step - accuracy: 0.4033 - loss: 2.8327 - val_accuracy: 0.5223 - val_loss: 2.2257 - learning_rate: 2.0479e-04
Epoch 33/300
1413/1413 - 89s - 63ms/step - accuracy: 0.4120 - loss: 2.7906 - val_accuracy: 0.5454 - val_loss: 2.1616 - learning_rate: 1.0239e-04
Epoch 34/300
1413/1413 - 91s - 64ms/step - accuracy: 0.4194 - loss: 2.7649 - val_accuracy: 0.5470 - val_loss: 2.1601 - learning_rate: 1.0239e-04
Epoch 35/300
1413/1413 - 88s - 63ms/step - accuracy: 0.4222 - loss: 2.7639 - val_accuracy: 0.5406 - val_loss: 2.1651 - learning_rate: 1.0239e-04
Epoch 36/300
1413/1413 - 91s - 65ms/step - accuracy: 0.4140 - loss: 2.7683 - val_accuracy: 0.5406 - val_loss: 2.1702 - learning_rate: 1.0239e-04
Epoch 37/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4193 - loss: 2.7642 - val_accuracy: 0.5374 - val_loss: 2.1826 - learning_rate: 1.0239e-04
Epoch 38/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4231 - loss: 2.7485 - val_accuracy: 0.5326 - val_loss: 2.1685 - learning_rate: 1.0239e-04
Epoch 39/300
1413/1413 - 88s - 62ms/step - accuracy: 0.4179 - loss: 2.7356 - val_accuracy: 0.5430 - val_loss: 2.1373 - learning_rate: 1.0239e-04
Epoch 40/300
1413/1413 - 90s - 63ms/step - accuracy: 0.4240 - loss: 2.7580 - val_accuracy: 0.5382 - val_loss: 2.1750 - learning_rate: 1.0239e-04
Epoch 41/300
1413/1413 - 88s - 62ms/step - accuracy: 0.4144 - loss: 2.7520 - val_accuracy: 0.5478 - val_loss: 2.1425 - learning_rate: 1.0239e-04
Epoch 42/300
1413/1413 - 90s - 64ms/step - accuracy: 0.4210 - loss: 2.7661 - val_accuracy: 0.5374 - val_loss: 2.1715 - learning_rate: 1.0239e-04
Epoch 43/300
1413/1413 - 89s - 63ms/step - accuracy: 0.4220 - loss: 2.7342 - val_accuracy: 0.5533 - val_loss: 2.1567 - learning_rate: 1.0239e-04
Epoch 44/300
1413/1413 - 90s - 64ms/step - accuracy: 0.4143 - loss: 2.7485 - val_accuracy: 0.5510 - val_loss: 2.1276 - learning_rate: 1.0239e-04
Epoch 45/300
1413/1413 - 89s - 63ms/step - accuracy: 0.4244 - loss: 2.7326 - val_accuracy: 0.5438 - val_loss: 2.1320 - learning_rate: 1.0239e-04
Epoch 46/300
1413/1413 - 88s - 62ms/step - accuracy: 0.4237 - loss: 2.7383 - val_accuracy: 0.5502 - val_loss: 2.1198 - learning_rate: 1.0239e-04
Epoch 47/300
1413/1413 - 90s - 64ms/step - accuracy: 0.4301 - loss: 2.7506 - val_accuracy: 0.5669 - val_loss: 2.0773 - learning_rate: 1.0239e-04
Epoch 48/300
1413/1413 - 90s - 64ms/step - accuracy: 0.4190 - loss: 2.7285 - val_accuracy: 0.5661 - val_loss: 2.0907 - learning_rate: 1.0239e-04
Epoch 49/300
1413/1413 - 89s - 63ms/step - accuracy: 0.4263 - loss: 2.6969 - val_accuracy: 0.5438 - val_loss: 2.1095 - learning_rate: 1.0239e-04
Epoch 50/300
1413/1413 - 89s - 63ms/step - accuracy: 0.4247 - loss: 2.7351 - val_accuracy: 0.5525 - val_loss: 2.1138 - learning_rate: 1.0239e-04
Epoch 51/300
1413/1413 - 87s - 62ms/step - accuracy: 0.4206 - loss: 2.7365 - val_accuracy: 0.5462 - val_loss: 2.1339 - learning_rate: 1.0239e-04
Epoch 52/300
1413/1413 - 87s - 61ms/step - accuracy: 0.4247 - loss: 2.7192 - val_accuracy: 0.5629 - val_loss: 2.0911 - learning_rate: 1.0239e-04
Epoch 53/300
1413/1413 - 87s - 62ms/step - accuracy: 0.4335 - loss: 2.7049 - val_accuracy: 0.5597 - val_loss: 2.1034 - learning_rate: 1.0239e-04
Epoch 54/300
1413/1413 - 88s - 62ms/step - accuracy: 0.4303 - loss: 2.6897 - val_accuracy: 0.5613 - val_loss: 2.1066 - learning_rate: 1.0239e-04
Epoch 55/300
1413/1413 - 89s - 63ms/step - accuracy: 0.4192 - loss: 2.7024 - val_accuracy: 0.5637 - val_loss: 2.0759 - learning_rate: 1.0239e-04
Epoch 56/300
1413/1413 - 89s - 63ms/step - accuracy: 0.4236 - loss: 2.7060 - val_accuracy: 0.5541 - val_loss: 2.0706 - learning_rate: 1.0239e-04
Epoch 57/300
1413/1413 - 91s - 64ms/step - accuracy: 0.4224 - loss: 2.7302 - val_accuracy: 0.5669 - val_loss: 2.0589 - learning_rate: 1.0239e-04
Epoch 58/300
1413/1413 - 89s - 63ms/step - accuracy: 0.4270 - loss: 2.6893 - val_accuracy: 0.5597 - val_loss: 2.0426 - learning_rate: 1.0239e-04
Epoch 59/300
1413/1413 - 89s - 63ms/step - accuracy: 0.4301 - loss: 2.6849 - val_accuracy: 0.5565 - val_loss: 2.0459 - learning_rate: 1.0239e-04
Epoch 60/300
1413/1413 - 90s - 64ms/step - accuracy: 0.4274 - loss: 2.6867 - val_accuracy: 0.5637 - val_loss: 2.0770 - learning_rate: 1.0239e-04
Epoch 61/300
1413/1413 - 89s - 63ms/step - accuracy: 0.4281 - loss: 2.6641 - val_accuracy: 0.5709 - val_loss: 2.0663 - learning_rate: 1.0239e-04
Epoch 62/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4319 - loss: 2.6719 - val_accuracy: 0.5597 - val_loss: 2.0634 - learning_rate: 1.0239e-04
Epoch 63/300
1413/1413 - 89s - 63ms/step - accuracy: 0.4242 - loss: 2.6782 - val_accuracy: 0.5669 - val_loss: 2.0568 - learning_rate: 1.0239e-04
Epoch 64/300
1413/1413 - 90s - 63ms/step - accuracy: 0.4293 - loss: 2.6963 - val_accuracy: 0.5629 - val_loss: 2.0648 - learning_rate: 1.0239e-04
Epoch 65/300
1413/1413 - 88s - 62ms/step - accuracy: 0.4241 - loss: 2.6949 - val_accuracy: 0.5653 - val_loss: 2.1121 - learning_rate: 1.0239e-04
Epoch 66/300

Epoch 66: ReduceLROnPlateau reducing learning rate to 5.119710476719774e-05.
1413/1413 - 87s - 62ms/step - accuracy: 0.4335 - loss: 2.6755 - val_accuracy: 0.5533 - val_loss: 2.0994 - learning_rate: 1.0239e-04
Epoch 67/300
1413/1413 - 89s - 63ms/step - accuracy: 0.4341 - loss: 2.6705 - val_accuracy: 0.5764 - val_loss: 2.0711 - learning_rate: 5.1197e-05
Epoch 68/300
1413/1413 - 87s - 61ms/step - accuracy: 0.4334 - loss: 2.6383 - val_accuracy: 0.5772 - val_loss: 2.0207 - learning_rate: 5.1197e-05
Epoch 69/300
1413/1413 - 87s - 62ms/step - accuracy: 0.4315 - loss: 2.6493 - val_accuracy: 0.5621 - val_loss: 2.0194 - learning_rate: 5.1197e-05
Epoch 70/300
1413/1413 - 90s - 63ms/step - accuracy: 0.4360 - loss: 2.6449 - val_accuracy: 0.5637 - val_loss: 2.0530 - learning_rate: 5.1197e-05
Epoch 71/300
1413/1413 - 86s - 61ms/step - accuracy: 0.4401 - loss: 2.6408 - val_accuracy: 0.5756 - val_loss: 2.0047 - learning_rate: 5.1197e-05
Epoch 72/300
1413/1413 - 88s - 62ms/step - accuracy: 0.4417 - loss: 2.6268 - val_accuracy: 0.5637 - val_loss: 2.0216 - learning_rate: 5.1197e-05
Epoch 73/300
1413/1413 - 89s - 63ms/step - accuracy: 0.4406 - loss: 2.6306 - val_accuracy: 0.5717 - val_loss: 2.0297 - learning_rate: 5.1197e-05
Epoch 74/300
1413/1413 - 87s - 61ms/step - accuracy: 0.4372 - loss: 2.6289 - val_accuracy: 0.5661 - val_loss: 2.0491 - learning_rate: 5.1197e-05
Epoch 75/300
1413/1413 - 89s - 63ms/step - accuracy: 0.4408 - loss: 2.6256 - val_accuracy: 0.5629 - val_loss: 2.0148 - learning_rate: 5.1197e-05
Epoch 76/300
1413/1413 - 88s - 62ms/step - accuracy: 0.4463 - loss: 2.6141 - val_accuracy: 0.5701 - val_loss: 2.0068 - learning_rate: 5.1197e-05
Epoch 77/300
1413/1413 - 72s - 51ms/step - accuracy: 0.4404 - loss: 2.6378 - val_accuracy: 0.5725 - val_loss: 2.0567 - learning_rate: 5.1197e-05
Epoch 78/300
1413/1413 - 74s - 52ms/step - accuracy: 0.4393 - loss: 2.6245 - val_accuracy: 0.5693 - val_loss: 2.0248 - learning_rate: 5.1197e-05
Epoch 79/300

Epoch 79: ReduceLROnPlateau reducing learning rate to 2.559855238359887e-05.
1413/1413 - 76s - 54ms/step - accuracy: 0.4404 - loss: 2.6420 - val_accuracy: 0.5685 - val_loss: 2.0299 - learning_rate: 5.1197e-05
Epoch 80/300
1413/1413 - 76s - 53ms/step - accuracy: 0.4370 - loss: 2.6436 - val_accuracy: 0.5756 - val_loss: 1.9892 - learning_rate: 2.5599e-05
Epoch 81/300
1413/1413 - 74s - 52ms/step - accuracy: 0.4371 - loss: 2.6375 - val_accuracy: 0.5701 - val_loss: 2.0013 - learning_rate: 2.5599e-05
Epoch 82/300
1413/1413 - 78s - 55ms/step - accuracy: 0.4461 - loss: 2.6288 - val_accuracy: 0.5740 - val_loss: 1.9902 - learning_rate: 2.5599e-05
Epoch 83/300
1413/1413 - 78s - 55ms/step - accuracy: 0.4494 - loss: 2.5958 - val_accuracy: 0.5788 - val_loss: 1.9818 - learning_rate: 2.5599e-05
Epoch 84/300
1413/1413 - 78s - 55ms/step - accuracy: 0.4362 - loss: 2.6495 - val_accuracy: 0.5796 - val_loss: 1.9820 - learning_rate: 2.5599e-05
Epoch 85/300
1413/1413 - 85s - 60ms/step - accuracy: 0.4399 - loss: 2.6158 - val_accuracy: 0.5756 - val_loss: 1.9897 - learning_rate: 2.5599e-05
Epoch 86/300
1413/1413 - 89s - 63ms/step - accuracy: 0.4438 - loss: 2.6246 - val_accuracy: 0.5748 - val_loss: 1.9937 - learning_rate: 2.5599e-05
Epoch 87/300
1413/1413 - 87s - 61ms/step - accuracy: 0.4423 - loss: 2.6240 - val_accuracy: 0.5788 - val_loss: 2.0136 - learning_rate: 2.5599e-05
Epoch 88/300
1413/1413 - 89s - 63ms/step - accuracy: 0.4355 - loss: 2.6571 - val_accuracy: 0.5796 - val_loss: 1.9737 - learning_rate: 2.5599e-05
Epoch 89/300
1413/1413 - 88s - 62ms/step - accuracy: 0.4510 - loss: 2.6057 - val_accuracy: 0.5709 - val_loss: 2.0230 - learning_rate: 2.5599e-05
Epoch 90/300
1413/1413 - 88s - 62ms/step - accuracy: 0.4478 - loss: 2.5913 - val_accuracy: 0.5828 - val_loss: 1.9808 - learning_rate: 2.5599e-05
Epoch 91/300
1413/1413 - 99s - 70ms/step - accuracy: 0.4425 - loss: 2.6058 - val_accuracy: 0.5756 - val_loss: 1.9867 - learning_rate: 2.5599e-05
Epoch 92/300
1413/1413 - 98s - 70ms/step - accuracy: 0.4424 - loss: 2.6078 - val_accuracy: 0.5772 - val_loss: 2.0102 - learning_rate: 2.5599e-05
Epoch 93/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4467 - loss: 2.6002 - val_accuracy: 0.5693 - val_loss: 2.0080 - learning_rate: 2.5599e-05
Epoch 94/300
1413/1413 - 98s - 69ms/step - accuracy: 0.4418 - loss: 2.6167 - val_accuracy: 0.5820 - val_loss: 1.9949 - learning_rate: 2.5599e-05
Epoch 95/300
1413/1413 - 100s - 71ms/step - accuracy: 0.4391 - loss: 2.6203 - val_accuracy: 0.5717 - val_loss: 1.9853 - learning_rate: 2.5599e-05
Epoch 96/300

Epoch 96: ReduceLROnPlateau reducing learning rate to 1.2799276191799436e-05.
1413/1413 - 97s - 69ms/step - accuracy: 0.4461 - loss: 2.6140 - val_accuracy: 0.5740 - val_loss: 1.9926 - learning_rate: 2.5599e-05
Epoch 97/300
1413/1413 - 99s - 70ms/step - accuracy: 0.4444 - loss: 2.6028 - val_accuracy: 0.5740 - val_loss: 1.9982 - learning_rate: 1.2799e-05
Epoch 98/300
1413/1413 - 101s - 71ms/step - accuracy: 0.4442 - loss: 2.6052 - val_accuracy: 0.5788 - val_loss: 1.9825 - learning_rate: 1.2799e-05
Epoch 99/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4428 - loss: 2.6037 - val_accuracy: 0.5788 - val_loss: 1.9928 - learning_rate: 1.2799e-05
Epoch 100/300
1413/1413 - 98s - 70ms/step - accuracy: 0.4444 - loss: 2.6084 - val_accuracy: 0.5756 - val_loss: 1.9927 - learning_rate: 1.2799e-05
Epoch 101/300
1413/1413 - 98s - 69ms/step - accuracy: 0.4425 - loss: 2.6226 - val_accuracy: 0.5732 - val_loss: 1.9972 - learning_rate: 1.2799e-05
Epoch 102/300
1413/1413 - 97s - 69ms/step - accuracy: 0.4433 - loss: 2.6098 - val_accuracy: 0.5780 - val_loss: 1.9928 - learning_rate: 1.2799e-05
Epoch 103/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4448 - loss: 2.5941 - val_accuracy: 0.5780 - val_loss: 1.9789 - learning_rate: 1.2799e-05
Epoch 104/300

Epoch 104: ReduceLROnPlateau reducing learning rate to 6.399638095899718e-06.
1413/1413 - 95s - 67ms/step - accuracy: 0.4390 - loss: 2.6079 - val_accuracy: 0.5732 - val_loss: 1.9892 - learning_rate: 1.2799e-05
Epoch 104: early stopping
Restoring model weights from the end of the best epoch: 88.
Fold 0 Evaluation results: [1.9791518449783325, 0.5796178579330444]
              precision    recall  f1-score   support

        1820       0.67      0.81      0.73        62
        1821       0.96      0.75      0.84        57
        1822       0.00      0.00      0.00         1
        1823       0.00      0.00      0.00         1
        1824       0.00      0.00      0.00         1
        1825       0.00      0.00      0.00         3
        1826       0.00      0.00      0.00         2
        1827       0.80      0.80      0.80        25
        1828       0.00      0.00      0.00         1
        1829       1.00      0.80      0.89         5
        1830       0.52      0.57      0.55        56
        1831       0.76      0.90      0.83       134
        1832       0.80      0.82      0.81        67
        1833       0.80      0.84      0.82        19
        1834       0.37      0.62      0.46        29
        1835       0.00      0.00      0.00         2
        1836       0.00      0.00      0.00         4
        1837       0.50      0.17      0.25         6
        1838       0.50      0.67      0.57         3
        1839       0.00      0.00      0.00         1
        1840       0.57      0.47      0.51        43
        1841       0.63      0.57      0.60       108
        1842       1.00      0.67      0.80         6
        1843       0.25      0.17      0.20         6
        1844       0.00      0.00      0.00         1
        1845       0.00      0.00      0.00         1
        1846       0.00      0.00      0.00         6
        1847       0.00      0.00      0.00         2
        1848       0.25      0.40      0.31         5
        1849       0.20      0.17      0.18         6
        1850       0.40      0.44      0.42        48
        1851       0.59      0.71      0.64        77
        1852       1.00      0.14      0.25         7
        1853       0.00      0.00      0.00         7
        1854       0.00      0.00      0.00         3
        1855       0.43      0.52      0.47        23
        1856       0.80      0.67      0.73        12
        1857       0.50      0.50      0.50        30
        1858       0.00      0.00      0.00         2
        1859       0.00      0.00      0.00         2
        1860       0.31      0.25      0.27        65
        1861       0.70      0.69      0.70        85
        1862       0.29      0.32      0.30        19
        1863       0.26      0.26      0.26        19
        1864       0.38      0.35      0.36        17
        1865       0.00      0.00      0.00         7
        1866       0.00      0.00      0.00         5
        1867       0.38      0.27      0.32        11
        1868       0.00      0.00      0.00         7
        1869       0.00      0.00      0.00         5
        1870       0.36      0.42      0.39        31
        1871       0.61      0.71      0.66        49
        1872       0.22      0.29      0.25         7
        1873       0.33      0.10      0.15        10
        1874       0.00      0.00      0.00         5
        1875       0.29      0.36      0.32        14
        1876       0.73      0.80      0.76        10
        1877       0.33      0.40      0.36         5
        1878       0.23      0.33      0.27         9
        1879       0.00      0.00      0.00         2

    accuracy                           0.58      1256
   macro avg       0.33      0.31      0.31      1256
weighted avg       0.56      0.58      0.56      1256

Matthews Correlation Coefficient: 0.558
Macro avg F1: 0.309
Weighted avg F1: 0.564
Micro avg F1: 0.580
Top-3 Accuracy: 0.810
Top-5 Accuracy: 0.884
Micro ROC AUC  = 0.98
Macro ROC AUC (present classes) = 0.97
Classification MAE (in years): 3.85

Fold 0 Misclassification Analysis:
Near misses (within 2 years): 125 out of 528 misclassifications (23.67%)
MAE with outliers: 3.85
MAE without outliers: 2.37 (improvement: 1.48)

5 Worst misclassifications:
Image: data/datasets/private/1820/1820_117etsy.jpg, True: 1820, Predicted: 1875, Error: 55
Image: data/datasets/public/1830/1832_2153vna.jpg, True: 1874, Predicted: 1820, Error: 54
Image: data/datasets/public/1860/1863_078met.jpg, True: 1873, Predicted: 1820, Error: 53
Image: data/datasets/public/1860/1860_109wikimedia2.jpg, True: 1820, Predicted: 1872, Error: 52
Image: data/datasets/private/1820/1820_164etsy.jpg, True: 1871, Predicted: 1820, Error: 51
Metrics: {'accuracy': 0.5796178579330444, 'mae_years': np.float64(3.8495222929936306), 'mcc': np.float64(0.5579476749664961)}

=== Total running time: 2 hours, 35 minutes, 49 seconds ===

