TensorFlow Version: 2.20.0-dev20250508
Num GPUs Available: 1
Physical devices cannot be modified after being initialized

=== Using model: InceptionV3. ===
RUN ID: 2025-05-23_05:40:00
Task: Classification

===== Fold 0 =====
=== Running on Public Data ===

===== Fine Tuning 9 layers! =====
Epoch 1/300
657/657 - 126s - 192ms/step - accuracy: 0.0972 - loss: 4.6462 - val_accuracy: 0.1729 - val_loss: 4.8503 - learning_rate: 2.5974e-04
Epoch 2/300
657/657 - 69s - 105ms/step - accuracy: 0.1595 - loss: 4.4132 - val_accuracy: 0.2432 - val_loss: 3.8584 - learning_rate: 2.5974e-04
Epoch 3/300
657/657 - 65s - 100ms/step - accuracy: 0.1907 - loss: 4.2914 - val_accuracy: 0.2860 - val_loss: 3.9239 - learning_rate: 2.5974e-04
Epoch 4/300
657/657 - 66s - 101ms/step - accuracy: 0.2105 - loss: 4.2240 - val_accuracy: 0.3082 - val_loss: 3.8377 - learning_rate: 2.5974e-04
Epoch 5/300
657/657 - 65s - 99ms/step - accuracy: 0.2297 - loss: 4.1682 - val_accuracy: 0.2894 - val_loss: 3.7630 - learning_rate: 2.5974e-04
Epoch 6/300
657/657 - 66s - 100ms/step - accuracy: 0.2409 - loss: 4.1031 - val_accuracy: 0.3373 - val_loss: 3.6702 - learning_rate: 2.5974e-04
Epoch 7/300
657/657 - 64s - 97ms/step - accuracy: 0.2464 - loss: 4.0607 - val_accuracy: 0.3630 - val_loss: 3.6594 - learning_rate: 2.5974e-04
Epoch 8/300
657/657 - 64s - 98ms/step - accuracy: 0.2565 - loss: 4.0314 - val_accuracy: 0.3527 - val_loss: 3.5054 - learning_rate: 2.5974e-04
Epoch 9/300
657/657 - 65s - 100ms/step - accuracy: 0.2695 - loss: 3.9829 - val_accuracy: 0.3818 - val_loss: 3.4643 - learning_rate: 2.5974e-04
Epoch 10/300
657/657 - 65s - 98ms/step - accuracy: 0.2706 - loss: 3.9377 - val_accuracy: 0.3870 - val_loss: 3.4267 - learning_rate: 2.5974e-04
Epoch 11/300
657/657 - 65s - 99ms/step - accuracy: 0.2750 - loss: 3.9451 - val_accuracy: 0.3921 - val_loss: 3.3999 - learning_rate: 2.5974e-04
Epoch 12/300
657/657 - 67s - 102ms/step - accuracy: 0.2759 - loss: 3.8637 - val_accuracy: 0.3733 - val_loss: 3.2772 - learning_rate: 2.5974e-04
Epoch 13/300
657/657 - 65s - 100ms/step - accuracy: 0.2801 - loss: 3.8989 - val_accuracy: 0.4041 - val_loss: 3.2306 - learning_rate: 2.5974e-04
Epoch 14/300
657/657 - 66s - 101ms/step - accuracy: 0.2877 - loss: 3.8509 - val_accuracy: 0.4058 - val_loss: 3.2269 - learning_rate: 2.5974e-04
Epoch 15/300
657/657 - 65s - 99ms/step - accuracy: 0.2936 - loss: 3.8191 - val_accuracy: 0.3853 - val_loss: 3.1257 - learning_rate: 2.5974e-04
Epoch 16/300
657/657 - 65s - 99ms/step - accuracy: 0.2913 - loss: 3.8202 - val_accuracy: 0.3921 - val_loss: 3.2087 - learning_rate: 2.5974e-04
Epoch 17/300
657/657 - 67s - 102ms/step - accuracy: 0.3010 - loss: 3.7914 - val_accuracy: 0.3921 - val_loss: 3.0702 - learning_rate: 2.5974e-04
Epoch 18/300
657/657 - 62s - 95ms/step - accuracy: 0.3022 - loss: 3.7488 - val_accuracy: 0.4195 - val_loss: 3.0033 - learning_rate: 2.5974e-04
Epoch 19/300
657/657 - 65s - 99ms/step - accuracy: 0.2993 - loss: 3.7467 - val_accuracy: 0.4247 - val_loss: 3.0327 - learning_rate: 2.5974e-04
Epoch 20/300
657/657 - 66s - 100ms/step - accuracy: 0.3132 - loss: 3.7260 - val_accuracy: 0.4366 - val_loss: 2.9554 - learning_rate: 2.5974e-04
Epoch 21/300
657/657 - 65s - 99ms/step - accuracy: 0.3157 - loss: 3.6848 - val_accuracy: 0.4435 - val_loss: 2.9762 - learning_rate: 2.5974e-04
Epoch 22/300
657/657 - 66s - 100ms/step - accuracy: 0.3146 - loss: 3.6888 - val_accuracy: 0.4281 - val_loss: 2.9242 - learning_rate: 2.5974e-04
Epoch 23/300
657/657 - 66s - 101ms/step - accuracy: 0.3161 - loss: 3.6671 - val_accuracy: 0.4469 - val_loss: 2.9709 - learning_rate: 2.5974e-04
Epoch 24/300
657/657 - 65s - 99ms/step - accuracy: 0.3256 - loss: 3.6390 - val_accuracy: 0.4298 - val_loss: 2.8953 - learning_rate: 2.5974e-04
Epoch 25/300
657/657 - 64s - 97ms/step - accuracy: 0.3182 - loss: 3.6667 - val_accuracy: 0.4315 - val_loss: 2.8553 - learning_rate: 2.5974e-04
Epoch 26/300
657/657 - 66s - 101ms/step - accuracy: 0.3206 - loss: 3.5988 - val_accuracy: 0.4366 - val_loss: 2.8770 - learning_rate: 2.5974e-04
Epoch 27/300
657/657 - 67s - 102ms/step - accuracy: 0.3220 - loss: 3.6038 - val_accuracy: 0.4281 - val_loss: 2.8145 - learning_rate: 2.5974e-04
Epoch 28/300
657/657 - 63s - 95ms/step - accuracy: 0.3338 - loss: 3.5693 - val_accuracy: 0.4418 - val_loss: 2.8278 - learning_rate: 2.5974e-04
Epoch 29/300
657/657 - 65s - 99ms/step - accuracy: 0.3167 - loss: 3.5929 - val_accuracy: 0.4195 - val_loss: 2.8806 - learning_rate: 2.5974e-04
Epoch 30/300
657/657 - 64s - 98ms/step - accuracy: 0.3235 - loss: 3.5854 - val_accuracy: 0.4452 - val_loss: 2.8028 - learning_rate: 2.5974e-04
Epoch 31/300
657/657 - 66s - 100ms/step - accuracy: 0.3328 - loss: 3.5577 - val_accuracy: 0.4538 - val_loss: 2.7329 - learning_rate: 2.5974e-04
Epoch 32/300
657/657 - 66s - 100ms/step - accuracy: 0.3300 - loss: 3.5506 - val_accuracy: 0.4503 - val_loss: 2.8133 - learning_rate: 2.5974e-04
Epoch 33/300
657/657 - 64s - 98ms/step - accuracy: 0.3273 - loss: 3.5626 - val_accuracy: 0.4315 - val_loss: 2.8187 - learning_rate: 2.5974e-04
Epoch 34/300
657/657 - 64s - 98ms/step - accuracy: 0.3231 - loss: 3.5420 - val_accuracy: 0.4418 - val_loss: 2.8175 - learning_rate: 2.5974e-04
Epoch 35/300
657/657 - 65s - 99ms/step - accuracy: 0.3260 - loss: 3.5633 - val_accuracy: 0.4538 - val_loss: 2.7635 - learning_rate: 2.5974e-04
Epoch 36/300
657/657 - 65s - 99ms/step - accuracy: 0.3370 - loss: 3.5165 - val_accuracy: 0.4452 - val_loss: 2.7191 - learning_rate: 2.5974e-04
Epoch 37/300
657/657 - 65s - 99ms/step - accuracy: 0.3378 - loss: 3.5347 - val_accuracy: 0.4315 - val_loss: 2.7770 - learning_rate: 2.5974e-04
Epoch 38/300
657/657 - 62s - 94ms/step - accuracy: 0.3353 - loss: 3.5279 - val_accuracy: 0.4469 - val_loss: 2.7475 - learning_rate: 2.5974e-04
Epoch 39/300
657/657 - 66s - 101ms/step - accuracy: 0.3298 - loss: 3.5110 - val_accuracy: 0.4349 - val_loss: 2.7236 - learning_rate: 2.5974e-04
Epoch 40/300
657/657 - 65s - 99ms/step - accuracy: 0.3395 - loss: 3.4820 - val_accuracy: 0.4572 - val_loss: 2.7300 - learning_rate: 2.5974e-04
Epoch 41/300
657/657 - 63s - 95ms/step - accuracy: 0.3488 - loss: 3.4771 - val_accuracy: 0.4640 - val_loss: 2.7502 - learning_rate: 2.5974e-04
Epoch 42/300
657/657 - 67s - 101ms/step - accuracy: 0.3441 - loss: 3.4561 - val_accuracy: 0.4572 - val_loss: 2.6684 - learning_rate: 2.5974e-04
Epoch 43/300
657/657 - 64s - 98ms/step - accuracy: 0.3364 - loss: 3.4820 - val_accuracy: 0.4589 - val_loss: 2.6700 - learning_rate: 2.5974e-04
Epoch 44/300
657/657 - 65s - 99ms/step - accuracy: 0.3338 - loss: 3.4873 - val_accuracy: 0.4469 - val_loss: 2.7227 - learning_rate: 2.5974e-04
Epoch 45/300
657/657 - 65s - 99ms/step - accuracy: 0.3363 - loss: 3.4543 - val_accuracy: 0.4589 - val_loss: 2.7144 - learning_rate: 2.5974e-04
Epoch 46/300
657/657 - 65s - 99ms/step - accuracy: 0.3383 - loss: 3.4443 - val_accuracy: 0.4555 - val_loss: 2.6287 - learning_rate: 2.5974e-04
Epoch 47/300
657/657 - 65s - 98ms/step - accuracy: 0.3422 - loss: 3.4360 - val_accuracy: 0.4606 - val_loss: 2.6771 - learning_rate: 2.5974e-04
Epoch 48/300
657/657 - 63s - 96ms/step - accuracy: 0.3452 - loss: 3.4493 - val_accuracy: 0.4606 - val_loss: 2.6640 - learning_rate: 2.5974e-04
Epoch 49/300
657/657 - 83s - 126ms/step - accuracy: 0.3412 - loss: 3.4360 - val_accuracy: 0.4469 - val_loss: 2.6536 - learning_rate: 2.5974e-04
Epoch 50/300
657/657 - 64s - 97ms/step - accuracy: 0.3423 - loss: 3.4208 - val_accuracy: 0.4795 - val_loss: 2.6772 - learning_rate: 2.5974e-04
Epoch 51/300
657/657 - 65s - 99ms/step - accuracy: 0.3475 - loss: 3.4082 - val_accuracy: 0.4640 - val_loss: 2.6664 - learning_rate: 2.5974e-04
Epoch 52/300
657/657 - 65s - 99ms/step - accuracy: 0.3473 - loss: 3.4109 - val_accuracy: 0.4777 - val_loss: 2.6459 - learning_rate: 2.5974e-04
Epoch 53/300
657/657 - 64s - 97ms/step - accuracy: 0.3467 - loss: 3.4456 - val_accuracy: 0.4760 - val_loss: 2.6402 - learning_rate: 2.5974e-04
Epoch 54/300
657/657 - 65s - 99ms/step - accuracy: 0.3458 - loss: 3.4024 - val_accuracy: 0.4555 - val_loss: 2.6062 - learning_rate: 2.5974e-04
Epoch 55/300
657/657 - 65s - 99ms/step - accuracy: 0.3475 - loss: 3.4112 - val_accuracy: 0.4658 - val_loss: 2.6005 - learning_rate: 2.5974e-04
Epoch 56/300
657/657 - 64s - 97ms/step - accuracy: 0.3513 - loss: 3.3949 - val_accuracy: 0.4555 - val_loss: 2.6110 - learning_rate: 2.5974e-04
Epoch 57/300
657/657 - 63s - 95ms/step - accuracy: 0.3452 - loss: 3.4056 - val_accuracy: 0.4606 - val_loss: 2.5793 - learning_rate: 2.5974e-04
Epoch 58/300
657/657 - 65s - 100ms/step - accuracy: 0.3442 - loss: 3.4320 - val_accuracy: 0.4760 - val_loss: 2.6222 - learning_rate: 2.5974e-04
Epoch 59/300
657/657 - 65s - 99ms/step - accuracy: 0.3501 - loss: 3.3633 - val_accuracy: 0.4795 - val_loss: 2.6192 - learning_rate: 2.5974e-04
Epoch 60/300
657/657 - 65s - 99ms/step - accuracy: 0.3486 - loss: 3.4017 - val_accuracy: 0.4829 - val_loss: 2.6189 - learning_rate: 2.5974e-04
Epoch 61/300
657/657 - 66s - 100ms/step - accuracy: 0.3477 - loss: 3.3930 - val_accuracy: 0.4606 - val_loss: 2.7001 - learning_rate: 2.5974e-04
Epoch 62/300
657/657 - 62s - 95ms/step - accuracy: 0.3536 - loss: 3.3820 - val_accuracy: 0.4658 - val_loss: 2.5831 - learning_rate: 2.5974e-04
Epoch 63/300
657/657 - 63s - 96ms/step - accuracy: 0.3484 - loss: 3.3900 - val_accuracy: 0.4760 - val_loss: 2.6162 - learning_rate: 2.5974e-04
Epoch 64/300
657/657 - 65s - 99ms/step - accuracy: 0.3486 - loss: 3.3631 - val_accuracy: 0.4606 - val_loss: 2.5558 - learning_rate: 2.5974e-04
Epoch 65/300
657/657 - 66s - 101ms/step - accuracy: 0.3520 - loss: 3.3700 - val_accuracy: 0.4623 - val_loss: 2.6144 - learning_rate: 2.5974e-04
Epoch 66/300
657/657 - 64s - 97ms/step - accuracy: 0.3598 - loss: 3.3559 - val_accuracy: 0.4966 - val_loss: 2.5945 - learning_rate: 2.5974e-04
Epoch 67/300
657/657 - 65s - 99ms/step - accuracy: 0.3520 - loss: 3.3486 - val_accuracy: 0.4863 - val_loss: 2.6547 - learning_rate: 2.5974e-04
Epoch 68/300
657/657 - 66s - 101ms/step - accuracy: 0.3496 - loss: 3.3957 - val_accuracy: 0.4743 - val_loss: 2.5579 - learning_rate: 2.5974e-04
Epoch 69/300
657/657 - 65s - 99ms/step - accuracy: 0.3517 - loss: 3.3367 - val_accuracy: 0.4966 - val_loss: 2.6035 - learning_rate: 2.5974e-04
Epoch 70/300
657/657 - 66s - 101ms/step - accuracy: 0.3612 - loss: 3.3476 - val_accuracy: 0.4743 - val_loss: 2.5711 - learning_rate: 2.5974e-04
Epoch 71/300
657/657 - 66s - 100ms/step - accuracy: 0.3593 - loss: 3.3981 - val_accuracy: 0.4914 - val_loss: 2.5885 - learning_rate: 2.5974e-04
Epoch 72/300
657/657 - 65s - 100ms/step - accuracy: 0.3652 - loss: 3.3191 - val_accuracy: 0.4846 - val_loss: 2.5408 - learning_rate: 2.5974e-04
Epoch 73/300
657/657 - 65s - 100ms/step - accuracy: 0.3606 - loss: 3.3519 - val_accuracy: 0.4743 - val_loss: 2.5536 - learning_rate: 2.5974e-04
Epoch 74/300
657/657 - 68s - 103ms/step - accuracy: 0.3663 - loss: 3.3258 - val_accuracy: 0.4846 - val_loss: 2.5237 - learning_rate: 2.5974e-04
Epoch 75/300
657/657 - 68s - 103ms/step - accuracy: 0.3604 - loss: 3.3308 - val_accuracy: 0.4486 - val_loss: 2.5553 - learning_rate: 2.5974e-04
Epoch 76/300
657/657 - 68s - 103ms/step - accuracy: 0.3604 - loss: 3.3434 - val_accuracy: 0.4863 - val_loss: 2.5426 - learning_rate: 2.5974e-04
Epoch 77/300
657/657 - 69s - 105ms/step - accuracy: 0.3581 - loss: 3.3507 - val_accuracy: 0.4880 - val_loss: 2.5865 - learning_rate: 2.5974e-04
Epoch 78/300
657/657 - 68s - 104ms/step - accuracy: 0.3600 - loss: 3.3329 - val_accuracy: 0.4829 - val_loss: 2.6047 - learning_rate: 2.5974e-04
Epoch 79/300
657/657 - 68s - 103ms/step - accuracy: 0.3659 - loss: 3.2964 - val_accuracy: 0.4726 - val_loss: 2.5344 - learning_rate: 2.5974e-04
Epoch 80/300
657/657 - 67s - 102ms/step - accuracy: 0.3578 - loss: 3.3295 - val_accuracy: 0.4829 - val_loss: 2.5588 - learning_rate: 2.5974e-04
Epoch 81/300
657/657 - 69s - 104ms/step - accuracy: 0.3522 - loss: 3.3215 - val_accuracy: 0.4829 - val_loss: 2.5491 - learning_rate: 2.5974e-04
Epoch 82/300

Epoch 82: ReduceLROnPlateau reducing learning rate to 0.0001298690476687625.
657/657 - 68s - 104ms/step - accuracy: 0.3612 - loss: 3.3190 - val_accuracy: 0.4914 - val_loss: 2.5784 - learning_rate: 2.5974e-04
Epoch 83/300
657/657 - 69s - 105ms/step - accuracy: 0.3829 - loss: 3.2018 - val_accuracy: 0.5068 - val_loss: 2.4767 - learning_rate: 1.2987e-04
Epoch 84/300
657/657 - 67s - 101ms/step - accuracy: 0.3785 - loss: 3.2610 - val_accuracy: 0.5051 - val_loss: 2.4901 - learning_rate: 1.2987e-04
Epoch 85/300
657/657 - 67s - 102ms/step - accuracy: 0.3755 - loss: 3.2642 - val_accuracy: 0.5068 - val_loss: 2.4475 - learning_rate: 1.2987e-04
Epoch 86/300
657/657 - 67s - 102ms/step - accuracy: 0.3705 - loss: 3.2240 - val_accuracy: 0.4846 - val_loss: 2.4873 - learning_rate: 1.2987e-04
Epoch 87/300
657/657 - 68s - 103ms/step - accuracy: 0.3720 - loss: 3.1988 - val_accuracy: 0.4932 - val_loss: 2.4773 - learning_rate: 1.2987e-04
Epoch 88/300
657/657 - 68s - 103ms/step - accuracy: 0.3747 - loss: 3.2431 - val_accuracy: 0.4863 - val_loss: 2.4787 - learning_rate: 1.2987e-04
Epoch 89/300
657/657 - 66s - 100ms/step - accuracy: 0.3747 - loss: 3.2332 - val_accuracy: 0.4880 - val_loss: 2.4594 - learning_rate: 1.2987e-04
Epoch 90/300
657/657 - 63s - 95ms/step - accuracy: 0.3705 - loss: 3.2371 - val_accuracy: 0.4897 - val_loss: 2.4926 - learning_rate: 1.2987e-04
Epoch 91/300
657/657 - 61s - 93ms/step - accuracy: 0.3734 - loss: 3.2729 - val_accuracy: 0.4983 - val_loss: 2.4774 - learning_rate: 1.2987e-04
Epoch 92/300
657/657 - 62s - 94ms/step - accuracy: 0.3758 - loss: 3.2272 - val_accuracy: 0.4966 - val_loss: 2.4320 - learning_rate: 1.2987e-04
Epoch 93/300
657/657 - 59s - 90ms/step - accuracy: 0.3739 - loss: 3.2134 - val_accuracy: 0.4983 - val_loss: 2.4620 - learning_rate: 1.2987e-04
Epoch 94/300
657/657 - 60s - 91ms/step - accuracy: 0.3654 - loss: 3.2391 - val_accuracy: 0.4914 - val_loss: 2.4595 - learning_rate: 1.2987e-04
Epoch 95/300
657/657 - 63s - 96ms/step - accuracy: 0.3758 - loss: 3.1907 - val_accuracy: 0.4914 - val_loss: 2.4778 - learning_rate: 1.2987e-04
Epoch 96/300
657/657 - 62s - 94ms/step - accuracy: 0.3785 - loss: 3.2107 - val_accuracy: 0.4914 - val_loss: 2.4764 - learning_rate: 1.2987e-04
Epoch 97/300
657/657 - 60s - 92ms/step - accuracy: 0.3869 - loss: 3.2085 - val_accuracy: 0.5034 - val_loss: 2.4296 - learning_rate: 1.2987e-04
Epoch 98/300
657/657 - 62s - 95ms/step - accuracy: 0.3764 - loss: 3.2349 - val_accuracy: 0.4966 - val_loss: 2.4580 - learning_rate: 1.2987e-04
Epoch 99/300
657/657 - 63s - 95ms/step - accuracy: 0.3732 - loss: 3.2386 - val_accuracy: 0.5171 - val_loss: 2.4500 - learning_rate: 1.2987e-04
Epoch 100/300
657/657 - 61s - 94ms/step - accuracy: 0.3768 - loss: 3.2196 - val_accuracy: 0.5068 - val_loss: 2.4352 - learning_rate: 1.2987e-04
Epoch 101/300
657/657 - 62s - 95ms/step - accuracy: 0.3775 - loss: 3.2082 - val_accuracy: 0.4897 - val_loss: 2.4042 - learning_rate: 1.2987e-04
Epoch 102/300
657/657 - 61s - 93ms/step - accuracy: 0.3749 - loss: 3.2185 - val_accuracy: 0.5086 - val_loss: 2.4450 - learning_rate: 1.2987e-04
Epoch 103/300
657/657 - 62s - 95ms/step - accuracy: 0.3718 - loss: 3.2269 - val_accuracy: 0.5000 - val_loss: 2.4148 - learning_rate: 1.2987e-04
Epoch 104/300
657/657 - 65s - 98ms/step - accuracy: 0.3871 - loss: 3.1873 - val_accuracy: 0.4914 - val_loss: 2.4533 - learning_rate: 1.2987e-04
Epoch 105/300
657/657 - 64s - 98ms/step - accuracy: 0.3678 - loss: 3.2211 - val_accuracy: 0.4966 - val_loss: 2.4613 - learning_rate: 1.2987e-04
Epoch 106/300
657/657 - 63s - 95ms/step - accuracy: 0.3779 - loss: 3.1887 - val_accuracy: 0.4983 - val_loss: 2.4529 - learning_rate: 1.2987e-04
Epoch 107/300
657/657 - 62s - 95ms/step - accuracy: 0.3711 - loss: 3.2294 - val_accuracy: 0.4966 - val_loss: 2.4638 - learning_rate: 1.2987e-04
Epoch 108/300
657/657 - 61s - 93ms/step - accuracy: 0.3755 - loss: 3.1980 - val_accuracy: 0.5034 - val_loss: 2.4227 - learning_rate: 1.2987e-04
Epoch 109/300

Epoch 109: ReduceLROnPlateau reducing learning rate to 6.493452383438125e-05.
657/657 - 64s - 97ms/step - accuracy: 0.3821 - loss: 3.1744 - val_accuracy: 0.4983 - val_loss: 2.4531 - learning_rate: 1.2987e-04
Epoch 110/300
657/657 - 63s - 96ms/step - accuracy: 0.3855 - loss: 3.1696 - val_accuracy: 0.5017 - val_loss: 2.4060 - learning_rate: 6.4935e-05
Epoch 111/300
657/657 - 65s - 98ms/step - accuracy: 0.3798 - loss: 3.1571 - val_accuracy: 0.4949 - val_loss: 2.3966 - learning_rate: 6.4935e-05
Epoch 112/300
657/657 - 61s - 93ms/step - accuracy: 0.3804 - loss: 3.1176 - val_accuracy: 0.4949 - val_loss: 2.3977 - learning_rate: 6.4935e-05
Epoch 113/300
657/657 - 63s - 95ms/step - accuracy: 0.3734 - loss: 3.2086 - val_accuracy: 0.5000 - val_loss: 2.4109 - learning_rate: 6.4935e-05
Epoch 114/300
657/657 - 63s - 96ms/step - accuracy: 0.3893 - loss: 3.1391 - val_accuracy: 0.5051 - val_loss: 2.3748 - learning_rate: 6.4935e-05
Epoch 115/300
657/657 - 64s - 98ms/step - accuracy: 0.3873 - loss: 3.1597 - val_accuracy: 0.5000 - val_loss: 2.3929 - learning_rate: 6.4935e-05
Epoch 116/300
657/657 - 64s - 97ms/step - accuracy: 0.3873 - loss: 3.1243 - val_accuracy: 0.5034 - val_loss: 2.4110 - learning_rate: 6.4935e-05
Epoch 117/300
657/657 - 62s - 94ms/step - accuracy: 0.3882 - loss: 3.1577 - val_accuracy: 0.5086 - val_loss: 2.3983 - learning_rate: 6.4935e-05
Epoch 118/300
657/657 - 61s - 93ms/step - accuracy: 0.3781 - loss: 3.1534 - val_accuracy: 0.5103 - val_loss: 2.3865 - learning_rate: 6.4935e-05
Epoch 119/300
657/657 - 62s - 94ms/step - accuracy: 0.3834 - loss: 3.1944 - val_accuracy: 0.4966 - val_loss: 2.4083 - learning_rate: 6.4935e-05
Epoch 120/300
657/657 - 63s - 96ms/step - accuracy: 0.3930 - loss: 3.1531 - val_accuracy: 0.5068 - val_loss: 2.4051 - learning_rate: 6.4935e-05
Epoch 121/300
657/657 - 62s - 95ms/step - accuracy: 0.3935 - loss: 3.1631 - val_accuracy: 0.4966 - val_loss: 2.3861 - learning_rate: 6.4935e-05
Epoch 122/300

Epoch 122: ReduceLROnPlateau reducing learning rate to 3.2467261917190626e-05.
657/657 - 61s - 93ms/step - accuracy: 0.3863 - loss: 3.1255 - val_accuracy: 0.4966 - val_loss: 2.4017 - learning_rate: 6.4935e-05
Epoch 123/300
657/657 - 63s - 96ms/step - accuracy: 0.3880 - loss: 3.1380 - val_accuracy: 0.5086 - val_loss: 2.3904 - learning_rate: 3.2467e-05
Epoch 124/300
657/657 - 63s - 96ms/step - accuracy: 0.3960 - loss: 3.1179 - val_accuracy: 0.5017 - val_loss: 2.3897 - learning_rate: 3.2467e-05
Epoch 125/300
657/657 - 63s - 96ms/step - accuracy: 0.3937 - loss: 3.1038 - val_accuracy: 0.5017 - val_loss: 2.3939 - learning_rate: 3.2467e-05
Epoch 126/300
657/657 - 63s - 96ms/step - accuracy: 0.3834 - loss: 3.1146 - val_accuracy: 0.5068 - val_loss: 2.3806 - learning_rate: 3.2467e-05
Epoch 127/300
657/657 - 62s - 95ms/step - accuracy: 0.3897 - loss: 3.1193 - val_accuracy: 0.5068 - val_loss: 2.3901 - learning_rate: 3.2467e-05
Epoch 128/300
657/657 - 62s - 95ms/step - accuracy: 0.3876 - loss: 3.1341 - val_accuracy: 0.5120 - val_loss: 2.3777 - learning_rate: 3.2467e-05
Epoch 129/300
657/657 - 64s - 98ms/step - accuracy: 0.3901 - loss: 3.1311 - val_accuracy: 0.5017 - val_loss: 2.3766 - learning_rate: 3.2467e-05
Epoch 130/300
657/657 - 64s - 97ms/step - accuracy: 0.3926 - loss: 3.1211 - val_accuracy: 0.5051 - val_loss: 2.3682 - learning_rate: 3.2467e-05
Epoch 131/300
657/657 - 63s - 95ms/step - accuracy: 0.3821 - loss: 3.1280 - val_accuracy: 0.5120 - val_loss: 2.3799 - learning_rate: 3.2467e-05
Epoch 132/300
657/657 - 61s - 93ms/step - accuracy: 0.3981 - loss: 3.0965 - val_accuracy: 0.5103 - val_loss: 2.3830 - learning_rate: 3.2467e-05
Epoch 133/300
657/657 - 63s - 96ms/step - accuracy: 0.3836 - loss: 3.1518 - val_accuracy: 0.5103 - val_loss: 2.3935 - learning_rate: 3.2467e-05
Epoch 134/300
657/657 - 65s - 99ms/step - accuracy: 0.3914 - loss: 3.0868 - val_accuracy: 0.5068 - val_loss: 2.3825 - learning_rate: 3.2467e-05
Epoch 135/300
657/657 - 60s - 91ms/step - accuracy: 0.3907 - loss: 3.0956 - val_accuracy: 0.5154 - val_loss: 2.3667 - learning_rate: 3.2467e-05
Epoch 136/300
657/657 - 63s - 97ms/step - accuracy: 0.3897 - loss: 3.1130 - val_accuracy: 0.5051 - val_loss: 2.3653 - learning_rate: 3.2467e-05
Epoch 137/300
657/657 - 63s - 95ms/step - accuracy: 0.3810 - loss: 3.0926 - val_accuracy: 0.5103 - val_loss: 2.3714 - learning_rate: 3.2467e-05
Epoch 138/300
657/657 - 61s - 93ms/step - accuracy: 0.3867 - loss: 3.1249 - val_accuracy: 0.5068 - val_loss: 2.3784 - learning_rate: 3.2467e-05
Epoch 139/300
657/657 - 61s - 94ms/step - accuracy: 0.3819 - loss: 3.1700 - val_accuracy: 0.5154 - val_loss: 2.4024 - learning_rate: 3.2467e-05
Epoch 140/300
657/657 - 62s - 95ms/step - accuracy: 0.3888 - loss: 3.1062 - val_accuracy: 0.5034 - val_loss: 2.3657 - learning_rate: 3.2467e-05
Epoch 141/300
657/657 - 62s - 94ms/step - accuracy: 0.3926 - loss: 3.0955 - val_accuracy: 0.5103 - val_loss: 2.3997 - learning_rate: 3.2467e-05
Epoch 142/300
657/657 - 63s - 96ms/step - accuracy: 0.3903 - loss: 3.1269 - val_accuracy: 0.5120 - val_loss: 2.3697 - learning_rate: 3.2467e-05
Epoch 143/300
657/657 - 61s - 93ms/step - accuracy: 0.3981 - loss: 3.0780 - val_accuracy: 0.5051 - val_loss: 2.3766 - learning_rate: 3.2467e-05
Epoch 144/300

Epoch 144: ReduceLROnPlateau reducing learning rate to 1.6233630958595313e-05.
657/657 - 61s - 93ms/step - accuracy: 0.3916 - loss: 3.1224 - val_accuracy: 0.5137 - val_loss: 2.3670 - learning_rate: 3.2467e-05
Epoch 145/300
657/657 - 64s - 97ms/step - accuracy: 0.3935 - loss: 3.0980 - val_accuracy: 0.5120 - val_loss: 2.3820 - learning_rate: 1.6234e-05
Epoch 146/300
657/657 - 62s - 94ms/step - accuracy: 0.3947 - loss: 3.0780 - val_accuracy: 0.5188 - val_loss: 2.3895 - learning_rate: 1.6234e-05
Epoch 147/300
657/657 - 64s - 97ms/step - accuracy: 0.3903 - loss: 3.1003 - val_accuracy: 0.5171 - val_loss: 2.3691 - learning_rate: 1.6234e-05
Epoch 148/300
657/657 - 62s - 95ms/step - accuracy: 0.3968 - loss: 3.1111 - val_accuracy: 0.5137 - val_loss: 2.3504 - learning_rate: 1.6234e-05
Epoch 149/300
657/657 - 62s - 95ms/step - accuracy: 0.3920 - loss: 3.0842 - val_accuracy: 0.5051 - val_loss: 2.3900 - learning_rate: 1.6234e-05
Epoch 150/300
657/657 - 63s - 96ms/step - accuracy: 0.3930 - loss: 3.0737 - val_accuracy: 0.5017 - val_loss: 2.3720 - learning_rate: 1.6234e-05
Epoch 151/300
657/657 - 61s - 93ms/step - accuracy: 0.3983 - loss: 3.0799 - val_accuracy: 0.5068 - val_loss: 2.3690 - learning_rate: 1.6234e-05
Epoch 152/300
657/657 - 64s - 97ms/step - accuracy: 0.3962 - loss: 3.0803 - val_accuracy: 0.5154 - val_loss: 2.3700 - learning_rate: 1.6234e-05
Epoch 153/300
657/657 - 63s - 95ms/step - accuracy: 0.3931 - loss: 3.1148 - val_accuracy: 0.5120 - val_loss: 2.3777 - learning_rate: 1.6234e-05
Epoch 154/300
657/657 - 60s - 92ms/step - accuracy: 0.3952 - loss: 3.0968 - val_accuracy: 0.5068 - val_loss: 2.3618 - learning_rate: 1.6234e-05
Epoch 155/300
657/657 - 63s - 96ms/step - accuracy: 0.3928 - loss: 3.1427 - val_accuracy: 0.5103 - val_loss: 2.3659 - learning_rate: 1.6234e-05
Epoch 156/300

Epoch 156: ReduceLROnPlateau reducing learning rate to 8.116815479297657e-06.
657/657 - 62s - 94ms/step - accuracy: 0.3863 - loss: 3.1081 - val_accuracy: 0.5086 - val_loss: 2.3867 - learning_rate: 1.6234e-05
Epoch 157/300
657/657 - 63s - 96ms/step - accuracy: 0.3964 - loss: 3.0870 - val_accuracy: 0.5051 - val_loss: 2.3730 - learning_rate: 8.1168e-06
Epoch 158/300
657/657 - 64s - 98ms/step - accuracy: 0.4008 - loss: 3.0793 - val_accuracy: 0.5051 - val_loss: 2.3659 - learning_rate: 8.1168e-06
Epoch 159/300
657/657 - 63s - 95ms/step - accuracy: 0.3947 - loss: 3.0703 - val_accuracy: 0.5068 - val_loss: 2.3728 - learning_rate: 8.1168e-06
Epoch 160/300
657/657 - 63s - 97ms/step - accuracy: 0.3901 - loss: 3.1049 - val_accuracy: 0.5103 - val_loss: 2.3592 - learning_rate: 8.1168e-06
Epoch 161/300
657/657 - 62s - 94ms/step - accuracy: 0.4169 - loss: 3.0287 - val_accuracy: 0.5034 - val_loss: 2.3606 - learning_rate: 8.1168e-06
Epoch 162/300
657/657 - 61s - 94ms/step - accuracy: 0.3945 - loss: 3.0876 - val_accuracy: 0.5034 - val_loss: 2.3640 - learning_rate: 8.1168e-06
Epoch 163/300
657/657 - 63s - 95ms/step - accuracy: 0.4019 - loss: 3.1265 - val_accuracy: 0.5086 - val_loss: 2.3527 - learning_rate: 8.1168e-06
Epoch 164/300

Epoch 164: ReduceLROnPlateau reducing learning rate to 4.058407739648828e-06.
657/657 - 60s - 92ms/step - accuracy: 0.3916 - loss: 3.0932 - val_accuracy: 0.5120 - val_loss: 2.3723 - learning_rate: 8.1168e-06
Epoch 164: early stopping
Restoring model weights from the end of the best epoch: 148.
Fold 0 Evaluation results: [2.378129005432129, 0.5136986374855042]
              precision    recall  f1-score   support

        1820       0.66      0.88      0.75        43
        1821       0.00      0.00      0.00         1
        1822       0.00      0.00      0.00         0
        1823       0.00      0.00      0.00         1
        1824       0.00      0.00      0.00         0
        1825       0.00      0.00      0.00         1
        1826       0.00      0.00      0.00         1
        1827       0.00      0.00      0.00         8
        1828       0.00      0.00      0.00         1
        1829       0.33      0.75      0.46         4
        1830       0.55      0.76      0.64        45
        1831       0.00      0.00      0.00         1
        1832       0.96      0.87      0.91        52
        1833       0.82      0.95      0.88        19
        1834       0.60      0.43      0.50         7
        1835       0.00      0.00      0.00         3
        1836       0.00      0.00      0.00         3
        1837       0.45      0.83      0.59         6
        1838       1.00      0.25      0.40         4
        1839       0.00      0.00      0.00         1
        1840       0.52      0.52      0.52        42
        1841       0.56      0.45      0.50        11
        1842       1.00      0.17      0.29         6
        1843       0.00      0.00      0.00         6
        1844       0.00      0.00      0.00         1
        1845       0.00      0.00      0.00         2
        1846       0.33      0.20      0.25         5
        1847       0.00      0.00      0.00         2
        1848       0.40      0.40      0.40         5
        1849       0.50      0.40      0.44         5
        1850       0.37      0.67      0.47        48
        1851       0.67      0.29      0.40         7
        1852       0.00      0.00      0.00         8
        1853       0.00      0.00      0.00         6
        1854       0.00      0.00      0.00         2
        1855       0.31      0.40      0.35        10
        1856       0.64      0.58      0.61        12
        1857       0.00      0.00      0.00         7
        1858       0.00      0.00      0.00         2
        1859       0.00      0.00      0.00         3
        1860       0.36      0.42      0.39        48
        1861       0.00      0.00      0.00         1
        1862       0.00      0.00      0.00         7
        1863       0.36      0.67      0.47         6
        1864       1.00      0.20      0.33         5
        1865       0.33      0.17      0.22         6
        1866       0.00      0.00      0.00         6
        1867       0.28      0.50      0.36        10
        1868       0.00      0.00      0.00         7
        1869       0.00      0.00      0.00         5
        1870       0.38      0.58      0.46        31
        1871       0.00      0.00      0.00         5
        1872       1.00      0.43      0.60         7
        1873       0.14      0.09      0.11        11
        1874       1.00      0.17      0.29         6
        1875       0.33      0.50      0.40         6
        1876       0.83      1.00      0.91        10
        1877       0.50      0.40      0.44         5
        1878       0.60      0.67      0.63         9
        1879       0.00      0.00      0.00         2

    accuracy                           0.51       584
   macro avg       0.30      0.26      0.25       584
weighted avg       0.48      0.51      0.47       584

Matthews Correlation Coefficient: 0.487
Macro avg F1: 0.250
Weighted avg F1: 0.471
Micro avg F1: 0.514
Top-3 Accuracy: 0.784
Top-5 Accuracy: 0.868
Micro ROC AUC  = 0.97
Macro ROC AUC (present classes) = 0.96
Classification MAE (in years): 3.58

Fold 0 Misclassification Analysis:
Near misses (within 2 years): 68 out of 284 misclassifications (23.94%)
Big misses (greater than 10 years): 96
MAE with outliers: 3.58
MAE without outliers: 2.68 (improvement: 0.90)

10 Worst misclassifications:
Image: data/datasets/public/1870/1879_39wikimedia2.jpg, True: 1879, Predicted: 1820, Error: 59
Image: data/datasets/public/1830/1832_1548vna.jpg, True: 1832, Predicted: 1876, Error: 44
Image: data/datasets/public/1860/1864_006met.jpg, True: 1864, Predicted: 1820, Error: 44
Image: data/datasets/public/1820/1820_046met.jpg, True: 1820, Predicted: 1860, Error: 40
Image: data/datasets/public/1870/1871_068met.jpg, True: 1871, Predicted: 1840, Error: 31
Image: data/datasets/public/1860/1860_67wikimedia2.jpg, True: 1860, Predicted: 1830, Error: 30
Image: data/datasets/public/1820/1820_037met.jpg, True: 1820, Predicted: 1850, Error: 30
Image: data/datasets/public/1840/1841_043met.jpg, True: 1841, Predicted: 1867, Error: 26
Image: data/datasets/public/1850/1856_2363vna.jpg, True: 1856, Predicted: 1833, Error: 23
Image: data/datasets/public/1870/1878_479vna.jpg, True: 1878, Predicted: 1856, Error: 22

===== Fold 1 =====
=== Running on Public Data ===

===== Fine Tuning 9 layers! =====
Epoch 1/300
657/657 - 89s - 135ms/step - accuracy: 0.0959 - loss: 4.6785 - val_accuracy: 0.2380 - val_loss: 4.1546 - learning_rate: 2.5974e-04
Epoch 2/300
657/657 - 63s - 95ms/step - accuracy: 0.1547 - loss: 4.3284 - val_accuracy: 0.2500 - val_loss: 3.8188 - learning_rate: 2.5974e-04
Epoch 3/300
657/657 - 64s - 97ms/step - accuracy: 0.1933 - loss: 4.2489 - val_accuracy: 0.2637 - val_loss: 3.7510 - learning_rate: 2.5974e-04
Epoch 4/300
657/657 - 63s - 96ms/step - accuracy: 0.2069 - loss: 4.2188 - val_accuracy: 0.2705 - val_loss: 3.6794 - learning_rate: 2.5974e-04
Epoch 5/300
657/657 - 64s - 97ms/step - accuracy: 0.2166 - loss: 4.1827 - val_accuracy: 0.3134 - val_loss: 3.6017 - learning_rate: 2.5974e-04
Epoch 6/300
657/657 - 61s - 93ms/step - accuracy: 0.2284 - loss: 4.1388 - val_accuracy: 0.3253 - val_loss: 3.5788 - learning_rate: 2.5974e-04
Epoch 7/300
657/657 - 63s - 96ms/step - accuracy: 0.2371 - loss: 4.1256 - val_accuracy: 0.3647 - val_loss: 3.6347 - learning_rate: 2.5974e-04
Epoch 8/300
657/657 - 60s - 92ms/step - accuracy: 0.2459 - loss: 4.0812 - val_accuracy: 0.3630 - val_loss: 3.5413 - learning_rate: 2.5974e-04
Epoch 9/300
657/657 - 63s - 97ms/step - accuracy: 0.2588 - loss: 4.0082 - val_accuracy: 0.3682 - val_loss: 3.4812 - learning_rate: 2.5974e-04
Epoch 10/300
657/657 - 62s - 94ms/step - accuracy: 0.2681 - loss: 3.9990 - val_accuracy: 0.3682 - val_loss: 3.3160 - learning_rate: 2.5974e-04
Epoch 11/300
657/657 - 64s - 97ms/step - accuracy: 0.2700 - loss: 3.9382 - val_accuracy: 0.3750 - val_loss: 3.3620 - learning_rate: 2.5974e-04
Epoch 12/300
657/657 - 62s - 95ms/step - accuracy: 0.2790 - loss: 3.9178 - val_accuracy: 0.3955 - val_loss: 3.3265 - learning_rate: 2.5974e-04
Epoch 13/300
657/657 - 63s - 96ms/step - accuracy: 0.2872 - loss: 3.8538 - val_accuracy: 0.4195 - val_loss: 3.2000 - learning_rate: 2.5974e-04
Epoch 14/300
657/657 - 62s - 95ms/step - accuracy: 0.2872 - loss: 3.8518 - val_accuracy: 0.3853 - val_loss: 3.1233 - learning_rate: 2.5974e-04
Epoch 15/300
657/657 - 62s - 94ms/step - accuracy: 0.2913 - loss: 3.8180 - val_accuracy: 0.4075 - val_loss: 3.2400 - learning_rate: 2.5974e-04
Epoch 16/300
657/657 - 62s - 95ms/step - accuracy: 0.2984 - loss: 3.7799 - val_accuracy: 0.4092 - val_loss: 3.0915 - learning_rate: 2.5974e-04
Epoch 17/300
657/657 - 62s - 94ms/step - accuracy: 0.2982 - loss: 3.7618 - val_accuracy: 0.4298 - val_loss: 3.1673 - learning_rate: 2.5974e-04
Epoch 18/300
657/657 - 61s - 93ms/step - accuracy: 0.3045 - loss: 3.7628 - val_accuracy: 0.4110 - val_loss: 2.9888 - learning_rate: 2.5974e-04
Epoch 19/300
657/657 - 65s - 98ms/step - accuracy: 0.3073 - loss: 3.7267 - val_accuracy: 0.4298 - val_loss: 3.0449 - learning_rate: 2.5974e-04
Epoch 20/300
657/657 - 68s - 104ms/step - accuracy: 0.3003 - loss: 3.7285 - val_accuracy: 0.4315 - val_loss: 3.0001 - learning_rate: 2.5974e-04
Epoch 21/300
657/657 - 69s - 104ms/step - accuracy: 0.3165 - loss: 3.6644 - val_accuracy: 0.4366 - val_loss: 2.9774 - learning_rate: 2.5974e-04
Epoch 22/300
657/657 - 68s - 103ms/step - accuracy: 0.3049 - loss: 3.6763 - val_accuracy: 0.4452 - val_loss: 3.0514 - learning_rate: 2.5974e-04
Epoch 23/300
657/657 - 68s - 104ms/step - accuracy: 0.3119 - loss: 3.6558 - val_accuracy: 0.4469 - val_loss: 2.8961 - learning_rate: 2.5974e-04
Epoch 24/300
657/657 - 69s - 105ms/step - accuracy: 0.3189 - loss: 3.6379 - val_accuracy: 0.3904 - val_loss: 2.8849 - learning_rate: 2.5974e-04
Epoch 25/300
657/657 - 69s - 105ms/step - accuracy: 0.3205 - loss: 3.6095 - val_accuracy: 0.4332 - val_loss: 2.8420 - learning_rate: 2.5974e-04
Epoch 26/300
657/657 - 70s - 106ms/step - accuracy: 0.3077 - loss: 3.6484 - val_accuracy: 0.4469 - val_loss: 2.8936 - learning_rate: 2.5974e-04
Epoch 27/300
657/657 - 66s - 101ms/step - accuracy: 0.3157 - loss: 3.6044 - val_accuracy: 0.4435 - val_loss: 2.8672 - learning_rate: 2.5974e-04
Epoch 28/300
657/657 - 69s - 104ms/step - accuracy: 0.3174 - loss: 3.5688 - val_accuracy: 0.4555 - val_loss: 2.8466 - learning_rate: 2.5974e-04
Epoch 29/300
657/657 - 70s - 106ms/step - accuracy: 0.3233 - loss: 3.5913 - val_accuracy: 0.4366 - val_loss: 2.8150 - learning_rate: 2.5974e-04
Epoch 30/300
657/657 - 69s - 104ms/step - accuracy: 0.3193 - loss: 3.6372 - val_accuracy: 0.4623 - val_loss: 2.7688 - learning_rate: 2.5974e-04
Epoch 31/300
657/657 - 69s - 104ms/step - accuracy: 0.3252 - loss: 3.5680 - val_accuracy: 0.4623 - val_loss: 2.8100 - learning_rate: 2.5974e-04
Epoch 32/300
657/657 - 69s - 105ms/step - accuracy: 0.3284 - loss: 3.5600 - val_accuracy: 0.4401 - val_loss: 2.7620 - learning_rate: 2.5974e-04
Epoch 33/300
657/657 - 70s - 106ms/step - accuracy: 0.3254 - loss: 3.5444 - val_accuracy: 0.4692 - val_loss: 2.7254 - learning_rate: 2.5974e-04
Epoch 34/300
657/657 - 68s - 104ms/step - accuracy: 0.3243 - loss: 3.5536 - val_accuracy: 0.4486 - val_loss: 2.7453 - learning_rate: 2.5974e-04
Epoch 35/300
657/657 - 67s - 101ms/step - accuracy: 0.3324 - loss: 3.5290 - val_accuracy: 0.4572 - val_loss: 2.8040 - learning_rate: 2.5974e-04
Epoch 36/300
657/657 - 67s - 102ms/step - accuracy: 0.3294 - loss: 3.5334 - val_accuracy: 0.4709 - val_loss: 2.7650 - learning_rate: 2.5974e-04
Epoch 37/300
657/657 - 70s - 106ms/step - accuracy: 0.3370 - loss: 3.5021 - val_accuracy: 0.4675 - val_loss: 2.6606 - learning_rate: 2.5974e-04
Epoch 38/300
657/657 - 68s - 103ms/step - accuracy: 0.3317 - loss: 3.5167 - val_accuracy: 0.4572 - val_loss: 2.7420 - learning_rate: 2.5974e-04
Epoch 39/300
657/657 - 69s - 105ms/step - accuracy: 0.3401 - loss: 3.4685 - val_accuracy: 0.4966 - val_loss: 2.6933 - learning_rate: 2.5974e-04
Epoch 40/300
657/657 - 69s - 105ms/step - accuracy: 0.3372 - loss: 3.4553 - val_accuracy: 0.4726 - val_loss: 2.7369 - learning_rate: 2.5974e-04
Epoch 41/300
657/657 - 69s - 106ms/step - accuracy: 0.3477 - loss: 3.4753 - val_accuracy: 0.4623 - val_loss: 2.6742 - learning_rate: 2.5974e-04
Epoch 42/300
657/657 - 69s - 105ms/step - accuracy: 0.3359 - loss: 3.4955 - val_accuracy: 0.4640 - val_loss: 2.6779 - learning_rate: 2.5974e-04
Epoch 43/300
657/657 - 69s - 105ms/step - accuracy: 0.3458 - loss: 3.4778 - val_accuracy: 0.4897 - val_loss: 2.6029 - learning_rate: 2.5974e-04
Epoch 44/300
657/657 - 68s - 104ms/step - accuracy: 0.3294 - loss: 3.4831 - val_accuracy: 0.4863 - val_loss: 2.6679 - learning_rate: 2.5974e-04
Epoch 45/300
657/657 - 68s - 103ms/step - accuracy: 0.3399 - loss: 3.4849 - val_accuracy: 0.4795 - val_loss: 2.6694 - learning_rate: 2.5974e-04
Epoch 46/300
657/657 - 69s - 105ms/step - accuracy: 0.3324 - loss: 3.4716 - val_accuracy: 0.4932 - val_loss: 2.6378 - learning_rate: 2.5974e-04
Epoch 47/300
657/657 - 68s - 104ms/step - accuracy: 0.3452 - loss: 3.4580 - val_accuracy: 0.4743 - val_loss: 2.6585 - learning_rate: 2.5974e-04
Epoch 48/300
657/657 - 67s - 102ms/step - accuracy: 0.3427 - loss: 3.4617 - val_accuracy: 0.4863 - val_loss: 2.6509 - learning_rate: 2.5974e-04
Epoch 49/300
657/657 - 69s - 105ms/step - accuracy: 0.3456 - loss: 3.4448 - val_accuracy: 0.4897 - val_loss: 2.6147 - learning_rate: 2.5974e-04
Epoch 50/300
657/657 - 69s - 105ms/step - accuracy: 0.3482 - loss: 3.4204 - val_accuracy: 0.5120 - val_loss: 2.5488 - learning_rate: 2.5974e-04
Epoch 51/300
657/657 - 69s - 105ms/step - accuracy: 0.3441 - loss: 3.4094 - val_accuracy: 0.4880 - val_loss: 2.5713 - learning_rate: 2.5974e-04
Epoch 52/300
657/657 - 68s - 103ms/step - accuracy: 0.3469 - loss: 3.4095 - val_accuracy: 0.4932 - val_loss: 2.5754 - learning_rate: 2.5974e-04
Epoch 53/300
657/657 - 69s - 106ms/step - accuracy: 0.3355 - loss: 3.4808 - val_accuracy: 0.4709 - val_loss: 2.6493 - learning_rate: 2.5974e-04
Epoch 54/300
657/657 - 67s - 102ms/step - accuracy: 0.3351 - loss: 3.4507 - val_accuracy: 0.5086 - val_loss: 2.5915 - learning_rate: 2.5974e-04
Epoch 55/300
657/657 - 67s - 103ms/step - accuracy: 0.3467 - loss: 3.4277 - val_accuracy: 0.4863 - val_loss: 2.5738 - learning_rate: 2.5974e-04
Epoch 56/300
657/657 - 69s - 105ms/step - accuracy: 0.3511 - loss: 3.4025 - val_accuracy: 0.5034 - val_loss: 2.5389 - learning_rate: 2.5974e-04
Epoch 57/300
657/657 - 69s - 105ms/step - accuracy: 0.3498 - loss: 3.4224 - val_accuracy: 0.4777 - val_loss: 2.5935 - learning_rate: 2.5974e-04
Epoch 58/300
657/657 - 70s - 107ms/step - accuracy: 0.3539 - loss: 3.3922 - val_accuracy: 0.4863 - val_loss: 2.4992 - learning_rate: 2.5974e-04
Epoch 59/300
657/657 - 69s - 104ms/step - accuracy: 0.3425 - loss: 3.4367 - val_accuracy: 0.5017 - val_loss: 2.5231 - learning_rate: 2.5974e-04
Epoch 60/300
657/657 - 70s - 107ms/step - accuracy: 0.3414 - loss: 3.4099 - val_accuracy: 0.5274 - val_loss: 2.5746 - learning_rate: 2.5974e-04
Epoch 61/300
657/657 - 67s - 103ms/step - accuracy: 0.3448 - loss: 3.3927 - val_accuracy: 0.5034 - val_loss: 2.5644 - learning_rate: 2.5974e-04
Epoch 62/300
657/657 - 67s - 102ms/step - accuracy: 0.3526 - loss: 3.3797 - val_accuracy: 0.5051 - val_loss: 2.5914 - learning_rate: 2.5974e-04
Epoch 63/300
657/657 - 68s - 104ms/step - accuracy: 0.3458 - loss: 3.4125 - val_accuracy: 0.5034 - val_loss: 2.5655 - learning_rate: 2.5974e-04
Epoch 64/300
657/657 - 68s - 103ms/step - accuracy: 0.3568 - loss: 3.4055 - val_accuracy: 0.4880 - val_loss: 2.5756 - learning_rate: 2.5974e-04
Epoch 65/300
657/657 - 68s - 104ms/step - accuracy: 0.3473 - loss: 3.3694 - val_accuracy: 0.5223 - val_loss: 2.5499 - learning_rate: 2.5974e-04
Epoch 66/300

Epoch 66: ReduceLROnPlateau reducing learning rate to 0.0001298690476687625.
657/657 - 69s - 105ms/step - accuracy: 0.3549 - loss: 3.3626 - val_accuracy: 0.5171 - val_loss: 2.5506 - learning_rate: 2.5974e-04
Epoch 67/300
657/657 - 67s - 102ms/step - accuracy: 0.3604 - loss: 3.3405 - val_accuracy: 0.5017 - val_loss: 2.4676 - learning_rate: 1.2987e-04
Epoch 68/300
657/657 - 69s - 106ms/step - accuracy: 0.3635 - loss: 3.3339 - val_accuracy: 0.5240 - val_loss: 2.4980 - learning_rate: 1.2987e-04
Epoch 69/300
657/657 - 69s - 105ms/step - accuracy: 0.3539 - loss: 3.3413 - val_accuracy: 0.5000 - val_loss: 2.4663 - learning_rate: 1.2987e-04
Epoch 70/300
657/657 - 70s - 106ms/step - accuracy: 0.3654 - loss: 3.2972 - val_accuracy: 0.5171 - val_loss: 2.4405 - learning_rate: 1.2987e-04
Epoch 71/300
657/657 - 67s - 101ms/step - accuracy: 0.3581 - loss: 3.2967 - val_accuracy: 0.5171 - val_loss: 2.4786 - learning_rate: 1.2987e-04
Epoch 72/300
657/657 - 70s - 106ms/step - accuracy: 0.3669 - loss: 3.2800 - val_accuracy: 0.5120 - val_loss: 2.4721 - learning_rate: 1.2987e-04
Epoch 73/300
657/657 - 69s - 105ms/step - accuracy: 0.3591 - loss: 3.3122 - val_accuracy: 0.5223 - val_loss: 2.4721 - learning_rate: 1.2987e-04
Epoch 74/300
657/657 - 67s - 102ms/step - accuracy: 0.3697 - loss: 3.3000 - val_accuracy: 0.5120 - val_loss: 2.4620 - learning_rate: 1.2987e-04
Epoch 75/300
657/657 - 68s - 104ms/step - accuracy: 0.3587 - loss: 3.2827 - val_accuracy: 0.5308 - val_loss: 2.4321 - learning_rate: 1.2987e-04
Epoch 76/300
657/657 - 68s - 104ms/step - accuracy: 0.3676 - loss: 3.2794 - val_accuracy: 0.5223 - val_loss: 2.4514 - learning_rate: 1.2987e-04
Epoch 77/300
657/657 - 69s - 104ms/step - accuracy: 0.3637 - loss: 3.2708 - val_accuracy: 0.5171 - val_loss: 2.4446 - learning_rate: 1.2987e-04
Epoch 78/300
657/657 - 70s - 107ms/step - accuracy: 0.3621 - loss: 3.2711 - val_accuracy: 0.5257 - val_loss: 2.4260 - learning_rate: 1.2987e-04
Epoch 79/300
657/657 - 67s - 102ms/step - accuracy: 0.3772 - loss: 3.2446 - val_accuracy: 0.5171 - val_loss: 2.4189 - learning_rate: 1.2987e-04
Epoch 80/300
657/657 - 68s - 103ms/step - accuracy: 0.3657 - loss: 3.2902 - val_accuracy: 0.5171 - val_loss: 2.4272 - learning_rate: 1.2987e-04
Epoch 81/300
657/657 - 71s - 109ms/step - accuracy: 0.3646 - loss: 3.2767 - val_accuracy: 0.5240 - val_loss: 2.4322 - learning_rate: 1.2987e-04
Epoch 82/300
657/657 - 69s - 105ms/step - accuracy: 0.3663 - loss: 3.2991 - val_accuracy: 0.5188 - val_loss: 2.4345 - learning_rate: 1.2987e-04
Epoch 83/300
657/657 - 68s - 103ms/step - accuracy: 0.3718 - loss: 3.2426 - val_accuracy: 0.5274 - val_loss: 2.4331 - learning_rate: 1.2987e-04
Epoch 84/300
657/657 - 70s - 106ms/step - accuracy: 0.3659 - loss: 3.2535 - val_accuracy: 0.5188 - val_loss: 2.4264 - learning_rate: 1.2987e-04
Epoch 85/300
657/657 - 70s - 106ms/step - accuracy: 0.3686 - loss: 3.2533 - val_accuracy: 0.5325 - val_loss: 2.3823 - learning_rate: 1.2987e-04
Epoch 86/300
657/657 - 67s - 102ms/step - accuracy: 0.3772 - loss: 3.2523 - val_accuracy: 0.5086 - val_loss: 2.4183 - learning_rate: 1.2987e-04
Epoch 87/300
657/657 - 68s - 104ms/step - accuracy: 0.3791 - loss: 3.2167 - val_accuracy: 0.5205 - val_loss: 2.4149 - learning_rate: 1.2987e-04
Epoch 88/300
657/657 - 67s - 102ms/step - accuracy: 0.3777 - loss: 3.2658 - val_accuracy: 0.5257 - val_loss: 2.4175 - learning_rate: 1.2987e-04
Epoch 89/300
657/657 - 67s - 103ms/step - accuracy: 0.3794 - loss: 3.2317 - val_accuracy: 0.5086 - val_loss: 2.4199 - learning_rate: 1.2987e-04
Epoch 90/300
657/657 - 67s - 102ms/step - accuracy: 0.3762 - loss: 3.2472 - val_accuracy: 0.5171 - val_loss: 2.4450 - learning_rate: 1.2987e-04
Epoch 91/300
657/657 - 70s - 106ms/step - accuracy: 0.3737 - loss: 3.2680 - val_accuracy: 0.5240 - val_loss: 2.4222 - learning_rate: 1.2987e-04
Epoch 92/300
657/657 - 68s - 103ms/step - accuracy: 0.3720 - loss: 3.2472 - val_accuracy: 0.5068 - val_loss: 2.3789 - learning_rate: 1.2987e-04
Epoch 93/300
657/657 - 68s - 103ms/step - accuracy: 0.3728 - loss: 3.2736 - val_accuracy: 0.5171 - val_loss: 2.3944 - learning_rate: 1.2987e-04
Epoch 94/300
657/657 - 69s - 105ms/step - accuracy: 0.3696 - loss: 3.2454 - val_accuracy: 0.5291 - val_loss: 2.4101 - learning_rate: 1.2987e-04
Epoch 95/300
657/657 - 67s - 102ms/step - accuracy: 0.3764 - loss: 3.2415 - val_accuracy: 0.5205 - val_loss: 2.4097 - learning_rate: 1.2987e-04
Epoch 96/300
657/657 - 67s - 102ms/step - accuracy: 0.3724 - loss: 3.2492 - val_accuracy: 0.5325 - val_loss: 2.3948 - learning_rate: 1.2987e-04
Epoch 97/300
657/657 - 67s - 102ms/step - accuracy: 0.3694 - loss: 3.2470 - val_accuracy: 0.5342 - val_loss: 2.3957 - learning_rate: 1.2987e-04
Epoch 98/300
657/657 - 70s - 107ms/step - accuracy: 0.3713 - loss: 3.2365 - val_accuracy: 0.5274 - val_loss: 2.4198 - learning_rate: 1.2987e-04
Epoch 99/300
657/657 - 69s - 105ms/step - accuracy: 0.3728 - loss: 3.2397 - val_accuracy: 0.5342 - val_loss: 2.3741 - learning_rate: 1.2987e-04
Epoch 100/300
657/657 - 69s - 105ms/step - accuracy: 0.3642 - loss: 3.2378 - val_accuracy: 0.5462 - val_loss: 2.4199 - learning_rate: 1.2987e-04
Epoch 101/300
657/657 - 68s - 103ms/step - accuracy: 0.3709 - loss: 3.2710 - val_accuracy: 0.5120 - val_loss: 2.3873 - learning_rate: 1.2987e-04
Epoch 102/300
657/657 - 69s - 105ms/step - accuracy: 0.3732 - loss: 3.2056 - val_accuracy: 0.5257 - val_loss: 2.3986 - learning_rate: 1.2987e-04
Epoch 103/300
657/657 - 67s - 101ms/step - accuracy: 0.3794 - loss: 3.2250 - val_accuracy: 0.5377 - val_loss: 2.3691 - learning_rate: 1.2987e-04
Epoch 104/300
657/657 - 69s - 106ms/step - accuracy: 0.3735 - loss: 3.2285 - val_accuracy: 0.5548 - val_loss: 2.3765 - learning_rate: 1.2987e-04
Epoch 105/300
657/657 - 67s - 102ms/step - accuracy: 0.3730 - loss: 3.2379 - val_accuracy: 0.5394 - val_loss: 2.3777 - learning_rate: 1.2987e-04
Epoch 106/300
657/657 - 69s - 106ms/step - accuracy: 0.3705 - loss: 3.2442 - val_accuracy: 0.5291 - val_loss: 2.3914 - learning_rate: 1.2987e-04
Epoch 107/300
657/657 - 69s - 105ms/step - accuracy: 0.3770 - loss: 3.2057 - val_accuracy: 0.5325 - val_loss: 2.3873 - learning_rate: 1.2987e-04
Epoch 108/300
657/657 - 67s - 102ms/step - accuracy: 0.3713 - loss: 3.1854 - val_accuracy: 0.5360 - val_loss: 2.3626 - learning_rate: 1.2987e-04
Epoch 109/300
657/657 - 83s - 126ms/step - accuracy: 0.3686 - loss: 3.2080 - val_accuracy: 0.5462 - val_loss: 2.3741 - learning_rate: 1.2987e-04
Epoch 110/300
657/657 - 68s - 104ms/step - accuracy: 0.3800 - loss: 3.2022 - val_accuracy: 0.5445 - val_loss: 2.4136 - learning_rate: 1.2987e-04
Epoch 111/300
657/657 - 66s - 101ms/step - accuracy: 0.3787 - loss: 3.2281 - val_accuracy: 0.5445 - val_loss: 2.3951 - learning_rate: 1.2987e-04
Epoch 112/300
657/657 - 68s - 104ms/step - accuracy: 0.3715 - loss: 3.2018 - val_accuracy: 0.5291 - val_loss: 2.3581 - learning_rate: 1.2987e-04
Epoch 113/300
657/657 - 68s - 103ms/step - accuracy: 0.3737 - loss: 3.1973 - val_accuracy: 0.5548 - val_loss: 2.3674 - learning_rate: 1.2987e-04
Epoch 114/300
657/657 - 67s - 102ms/step - accuracy: 0.3749 - loss: 3.2029 - val_accuracy: 0.5360 - val_loss: 2.4083 - learning_rate: 1.2987e-04
Epoch 115/300
657/657 - 71s - 107ms/step - accuracy: 0.3789 - loss: 3.1751 - val_accuracy: 0.5445 - val_loss: 2.3768 - learning_rate: 1.2987e-04
Epoch 116/300
657/657 - 68s - 103ms/step - accuracy: 0.3831 - loss: 3.1994 - val_accuracy: 0.5394 - val_loss: 2.3676 - learning_rate: 1.2987e-04
Epoch 117/300
657/657 - 69s - 105ms/step - accuracy: 0.3781 - loss: 3.2106 - val_accuracy: 0.5531 - val_loss: 2.3843 - learning_rate: 1.2987e-04
Epoch 118/300
657/657 - 69s - 105ms/step - accuracy: 0.3726 - loss: 3.1737 - val_accuracy: 0.5479 - val_loss: 2.3510 - learning_rate: 1.2987e-04
Epoch 119/300
657/657 - 70s - 107ms/step - accuracy: 0.3804 - loss: 3.2222 - val_accuracy: 0.5514 - val_loss: 2.3571 - learning_rate: 1.2987e-04
Epoch 120/300
657/657 - 68s - 104ms/step - accuracy: 0.3785 - loss: 3.1688 - val_accuracy: 0.5291 - val_loss: 2.3687 - learning_rate: 1.2987e-04
Epoch 121/300
657/657 - 67s - 102ms/step - accuracy: 0.3724 - loss: 3.1913 - val_accuracy: 0.5428 - val_loss: 2.3504 - learning_rate: 1.2987e-04
Epoch 122/300
657/657 - 69s - 105ms/step - accuracy: 0.3766 - loss: 3.1811 - val_accuracy: 0.5445 - val_loss: 2.3343 - learning_rate: 1.2987e-04
Epoch 123/300
657/657 - 67s - 103ms/step - accuracy: 0.3806 - loss: 3.2112 - val_accuracy: 0.5377 - val_loss: 2.3622 - learning_rate: 1.2987e-04
Epoch 124/300
657/657 - 69s - 105ms/step - accuracy: 0.3855 - loss: 3.1829 - val_accuracy: 0.5377 - val_loss: 2.3476 - learning_rate: 1.2987e-04
Epoch 125/300
657/657 - 67s - 102ms/step - accuracy: 0.3766 - loss: 3.2001 - val_accuracy: 0.5445 - val_loss: 2.3159 - learning_rate: 1.2987e-04
Epoch 126/300
657/657 - 69s - 106ms/step - accuracy: 0.3705 - loss: 3.2286 - val_accuracy: 0.5428 - val_loss: 2.3654 - learning_rate: 1.2987e-04
Epoch 127/300
657/657 - 68s - 104ms/step - accuracy: 0.3751 - loss: 3.2308 - val_accuracy: 0.5377 - val_loss: 2.3520 - learning_rate: 1.2987e-04
Epoch 128/300
657/657 - 68s - 103ms/step - accuracy: 0.3817 - loss: 3.1904 - val_accuracy: 0.5291 - val_loss: 2.3510 - learning_rate: 1.2987e-04
Epoch 129/300
657/657 - 68s - 103ms/step - accuracy: 0.3831 - loss: 3.1849 - val_accuracy: 0.5479 - val_loss: 2.3389 - learning_rate: 1.2987e-04
Epoch 130/300
657/657 - 69s - 104ms/step - accuracy: 0.3718 - loss: 3.1959 - val_accuracy: 0.5462 - val_loss: 2.3094 - learning_rate: 1.2987e-04
Epoch 131/300
657/657 - 68s - 104ms/step - accuracy: 0.3730 - loss: 3.1897 - val_accuracy: 0.5479 - val_loss: 2.3699 - learning_rate: 1.2987e-04
Epoch 132/300
657/657 - 70s - 107ms/step - accuracy: 0.3739 - loss: 3.2070 - val_accuracy: 0.5497 - val_loss: 2.3336 - learning_rate: 1.2987e-04
Epoch 133/300
657/657 - 67s - 102ms/step - accuracy: 0.3863 - loss: 3.1360 - val_accuracy: 0.5548 - val_loss: 2.3289 - learning_rate: 1.2987e-04
Epoch 134/300
657/657 - 68s - 104ms/step - accuracy: 0.3802 - loss: 3.1726 - val_accuracy: 0.5462 - val_loss: 2.3548 - learning_rate: 1.2987e-04
Epoch 135/300
657/657 - 69s - 105ms/step - accuracy: 0.3823 - loss: 3.1615 - val_accuracy: 0.5497 - val_loss: 2.3175 - learning_rate: 1.2987e-04
Epoch 136/300
657/657 - 68s - 104ms/step - accuracy: 0.3774 - loss: 3.1780 - val_accuracy: 0.5531 - val_loss: 2.3291 - learning_rate: 1.2987e-04
Epoch 137/300
657/657 - 68s - 104ms/step - accuracy: 0.3735 - loss: 3.1839 - val_accuracy: 0.5548 - val_loss: 2.3278 - learning_rate: 1.2987e-04
Epoch 138/300

Epoch 138: ReduceLROnPlateau reducing learning rate to 6.493452383438125e-05.
657/657 - 68s - 103ms/step - accuracy: 0.3892 - loss: 3.1704 - val_accuracy: 0.5479 - val_loss: 2.3123 - learning_rate: 1.2987e-04
Epoch 139/300
657/657 - 83s - 126ms/step - accuracy: 0.3842 - loss: 3.1245 - val_accuracy: 0.5634 - val_loss: 2.3186 - learning_rate: 6.4935e-05
Epoch 140/300
657/657 - 69s - 105ms/step - accuracy: 0.3857 - loss: 3.1209 - val_accuracy: 0.5651 - val_loss: 2.3243 - learning_rate: 6.4935e-05
Epoch 141/300
657/657 - 70s - 106ms/step - accuracy: 0.3871 - loss: 3.1320 - val_accuracy: 0.5565 - val_loss: 2.3011 - learning_rate: 6.4935e-05
Epoch 142/300
657/657 - 69s - 105ms/step - accuracy: 0.3874 - loss: 3.1049 - val_accuracy: 0.5497 - val_loss: 2.2871 - learning_rate: 6.4935e-05
Epoch 143/300
657/657 - 68s - 104ms/step - accuracy: 0.3958 - loss: 3.1272 - val_accuracy: 0.5411 - val_loss: 2.3184 - learning_rate: 6.4935e-05
Epoch 144/300
657/657 - 70s - 106ms/step - accuracy: 0.3787 - loss: 3.1599 - val_accuracy: 0.5445 - val_loss: 2.3363 - learning_rate: 6.4935e-05
Epoch 145/300
657/657 - 69s - 105ms/step - accuracy: 0.3855 - loss: 3.1538 - val_accuracy: 0.5411 - val_loss: 2.3136 - learning_rate: 6.4935e-05
Epoch 146/300
657/657 - 66s - 100ms/step - accuracy: 0.3838 - loss: 3.1500 - val_accuracy: 0.5685 - val_loss: 2.3025 - learning_rate: 6.4935e-05
Epoch 147/300
657/657 - 66s - 100ms/step - accuracy: 0.3886 - loss: 3.1376 - val_accuracy: 0.5531 - val_loss: 2.3102 - learning_rate: 6.4935e-05
Epoch 148/300
657/657 - 70s - 106ms/step - accuracy: 0.3926 - loss: 3.1482 - val_accuracy: 0.5582 - val_loss: 2.3175 - learning_rate: 6.4935e-05
Epoch 149/300
657/657 - 69s - 105ms/step - accuracy: 0.3800 - loss: 3.1413 - val_accuracy: 0.5565 - val_loss: 2.3270 - learning_rate: 6.4935e-05
Epoch 150/300
657/657 - 67s - 101ms/step - accuracy: 0.3852 - loss: 3.1307 - val_accuracy: 0.5514 - val_loss: 2.2852 - learning_rate: 6.4935e-05
Epoch 151/300
657/657 - 70s - 106ms/step - accuracy: 0.3886 - loss: 3.1307 - val_accuracy: 0.5582 - val_loss: 2.2867 - learning_rate: 6.4935e-05
Epoch 152/300
657/657 - 69s - 105ms/step - accuracy: 0.3876 - loss: 3.1161 - val_accuracy: 0.5497 - val_loss: 2.2934 - learning_rate: 6.4935e-05
Epoch 153/300
657/657 - 70s - 106ms/step - accuracy: 0.3920 - loss: 3.0882 - val_accuracy: 0.5582 - val_loss: 2.3057 - learning_rate: 6.4935e-05
Epoch 154/300
657/657 - 68s - 104ms/step - accuracy: 0.3937 - loss: 3.0956 - val_accuracy: 0.5531 - val_loss: 2.3008 - learning_rate: 6.4935e-05
Epoch 155/300
657/657 - 68s - 103ms/step - accuracy: 0.3912 - loss: 3.1207 - val_accuracy: 0.5462 - val_loss: 2.3406 - learning_rate: 6.4935e-05
Epoch 156/300
657/657 - 67s - 103ms/step - accuracy: 0.3892 - loss: 3.1175 - val_accuracy: 0.5479 - val_loss: 2.3203 - learning_rate: 6.4935e-05
Epoch 157/300
657/657 - 69s - 105ms/step - accuracy: 0.3968 - loss: 3.0924 - val_accuracy: 0.5599 - val_loss: 2.3309 - learning_rate: 6.4935e-05
Epoch 158/300

Epoch 158: ReduceLROnPlateau reducing learning rate to 3.2467261917190626e-05.
657/657 - 69s - 105ms/step - accuracy: 0.3874 - loss: 3.0996 - val_accuracy: 0.5634 - val_loss: 2.2872 - learning_rate: 6.4935e-05
Epoch 159/300
657/657 - 67s - 102ms/step - accuracy: 0.3852 - loss: 3.1355 - val_accuracy: 0.5514 - val_loss: 2.2750 - learning_rate: 3.2467e-05
Epoch 160/300
657/657 - 68s - 104ms/step - accuracy: 0.3855 - loss: 3.1147 - val_accuracy: 0.5582 - val_loss: 2.2795 - learning_rate: 3.2467e-05
Epoch 161/300
657/657 - 69s - 106ms/step - accuracy: 0.3893 - loss: 3.1055 - val_accuracy: 0.5616 - val_loss: 2.2715 - learning_rate: 3.2467e-05
Epoch 162/300
657/657 - 69s - 105ms/step - accuracy: 0.3992 - loss: 3.0653 - val_accuracy: 0.5634 - val_loss: 2.2809 - learning_rate: 3.2467e-05
Epoch 163/300
657/657 - 66s - 100ms/step - accuracy: 0.3859 - loss: 3.1244 - val_accuracy: 0.5565 - val_loss: 2.2903 - learning_rate: 3.2467e-05
Epoch 164/300
657/657 - 69s - 106ms/step - accuracy: 0.3996 - loss: 3.0785 - val_accuracy: 0.5565 - val_loss: 2.2746 - learning_rate: 3.2467e-05
Epoch 165/300
657/657 - 69s - 105ms/step - accuracy: 0.4114 - loss: 3.0713 - val_accuracy: 0.5685 - val_loss: 2.2864 - learning_rate: 3.2467e-05
Epoch 166/300
657/657 - 67s - 103ms/step - accuracy: 0.3914 - loss: 3.1040 - val_accuracy: 0.5548 - val_loss: 2.2698 - learning_rate: 3.2467e-05
Epoch 167/300
657/657 - 68s - 104ms/step - accuracy: 0.4040 - loss: 3.0760 - val_accuracy: 0.5565 - val_loss: 2.2676 - learning_rate: 3.2467e-05
Epoch 168/300
657/657 - 68s - 104ms/step - accuracy: 0.3907 - loss: 3.0894 - val_accuracy: 0.5565 - val_loss: 2.2783 - learning_rate: 3.2467e-05
Epoch 169/300
657/657 - 66s - 101ms/step - accuracy: 0.3968 - loss: 3.0852 - val_accuracy: 0.5599 - val_loss: 2.2734 - learning_rate: 3.2467e-05
Epoch 170/300
657/657 - 67s - 102ms/step - accuracy: 0.3935 - loss: 3.1095 - val_accuracy: 0.5634 - val_loss: 2.2570 - learning_rate: 3.2467e-05
Epoch 171/300
657/657 - 67s - 102ms/step - accuracy: 0.3979 - loss: 3.0753 - val_accuracy: 0.5582 - val_loss: 2.2618 - learning_rate: 3.2467e-05
Epoch 172/300
657/657 - 66s - 100ms/step - accuracy: 0.3996 - loss: 3.0985 - val_accuracy: 0.5616 - val_loss: 2.2640 - learning_rate: 3.2467e-05
Epoch 173/300
657/657 - 68s - 103ms/step - accuracy: 0.4013 - loss: 3.0592 - val_accuracy: 0.5599 - val_loss: 2.2683 - learning_rate: 3.2467e-05
Epoch 174/300
657/657 - 69s - 105ms/step - accuracy: 0.3918 - loss: 3.1235 - val_accuracy: 0.5668 - val_loss: 2.2717 - learning_rate: 3.2467e-05
Epoch 175/300
657/657 - 69s - 105ms/step - accuracy: 0.4040 - loss: 3.0810 - val_accuracy: 0.5616 - val_loss: 2.2669 - learning_rate: 3.2467e-05
Epoch 176/300
657/657 - 68s - 103ms/step - accuracy: 0.3869 - loss: 3.1184 - val_accuracy: 0.5616 - val_loss: 2.2688 - learning_rate: 3.2467e-05
Epoch 177/300
657/657 - 69s - 104ms/step - accuracy: 0.3844 - loss: 3.1368 - val_accuracy: 0.5497 - val_loss: 2.2602 - learning_rate: 3.2467e-05
Epoch 178/300

Epoch 178: ReduceLROnPlateau reducing learning rate to 1.6233630958595313e-05.
657/657 - 68s - 104ms/step - accuracy: 0.3945 - loss: 3.1266 - val_accuracy: 0.5514 - val_loss: 2.3004 - learning_rate: 3.2467e-05
Epoch 179/300
657/657 - 69s - 105ms/step - accuracy: 0.3937 - loss: 3.1258 - val_accuracy: 0.5634 - val_loss: 2.2712 - learning_rate: 1.6234e-05
Epoch 180/300
657/657 - 66s - 101ms/step - accuracy: 0.3912 - loss: 3.0982 - val_accuracy: 0.5668 - val_loss: 2.2775 - learning_rate: 1.6234e-05
Epoch 181/300
657/657 - 67s - 102ms/step - accuracy: 0.3954 - loss: 3.0698 - val_accuracy: 0.5634 - val_loss: 2.2649 - learning_rate: 1.6234e-05
Epoch 182/300
657/657 - 68s - 103ms/step - accuracy: 0.3985 - loss: 3.0908 - val_accuracy: 0.5582 - val_loss: 2.2615 - learning_rate: 1.6234e-05
Epoch 183/300
657/657 - 68s - 103ms/step - accuracy: 0.3987 - loss: 3.0676 - val_accuracy: 0.5582 - val_loss: 2.2513 - learning_rate: 1.6234e-05
Epoch 184/300
657/657 - 66s - 101ms/step - accuracy: 0.3914 - loss: 3.1085 - val_accuracy: 0.5702 - val_loss: 2.2695 - learning_rate: 1.6234e-05
Epoch 185/300
657/657 - 67s - 102ms/step - accuracy: 0.3977 - loss: 3.0793 - val_accuracy: 0.5582 - val_loss: 2.2704 - learning_rate: 1.6234e-05
Epoch 186/300
657/657 - 69s - 105ms/step - accuracy: 0.3960 - loss: 3.1048 - val_accuracy: 0.5565 - val_loss: 2.2687 - learning_rate: 1.6234e-05
Epoch 187/300
657/657 - 68s - 104ms/step - accuracy: 0.3971 - loss: 3.0860 - val_accuracy: 0.5599 - val_loss: 2.2763 - learning_rate: 1.6234e-05
Epoch 188/300
657/657 - 68s - 104ms/step - accuracy: 0.3931 - loss: 3.0707 - val_accuracy: 0.5616 - val_loss: 2.2455 - learning_rate: 1.6234e-05
Epoch 189/300
657/657 - 66s - 100ms/step - accuracy: 0.3871 - loss: 3.0893 - val_accuracy: 0.5719 - val_loss: 2.2558 - learning_rate: 1.6234e-05
Epoch 190/300
657/657 - 69s - 105ms/step - accuracy: 0.4008 - loss: 3.0642 - val_accuracy: 0.5651 - val_loss: 2.2543 - learning_rate: 1.6234e-05
Epoch 191/300
657/657 - 67s - 102ms/step - accuracy: 0.3951 - loss: 3.0798 - val_accuracy: 0.5565 - val_loss: 2.2678 - learning_rate: 1.6234e-05
Epoch 192/300
657/657 - 68s - 104ms/step - accuracy: 0.4008 - loss: 3.0817 - val_accuracy: 0.5634 - val_loss: 2.2500 - learning_rate: 1.6234e-05
Epoch 193/300
657/657 - 68s - 103ms/step - accuracy: 0.3914 - loss: 3.1046 - val_accuracy: 0.5565 - val_loss: 2.2506 - learning_rate: 1.6234e-05
Epoch 194/300
657/657 - 68s - 103ms/step - accuracy: 0.3949 - loss: 3.0688 - val_accuracy: 0.5634 - val_loss: 2.2466 - learning_rate: 1.6234e-05
Epoch 195/300
657/657 - 68s - 104ms/step - accuracy: 0.3983 - loss: 3.0761 - val_accuracy: 0.5599 - val_loss: 2.2582 - learning_rate: 1.6234e-05
Epoch 196/300

Epoch 196: ReduceLROnPlateau reducing learning rate to 8.116815479297657e-06.
657/657 - 68s - 104ms/step - accuracy: 0.3973 - loss: 3.1141 - val_accuracy: 0.5651 - val_loss: 2.2626 - learning_rate: 1.6234e-05
Epoch 197/300
657/657 - 69s - 104ms/step - accuracy: 0.3964 - loss: 3.0921 - val_accuracy: 0.5651 - val_loss: 2.2592 - learning_rate: 8.1168e-06
Epoch 198/300
657/657 - 67s - 101ms/step - accuracy: 0.3888 - loss: 3.1047 - val_accuracy: 0.5668 - val_loss: 2.2557 - learning_rate: 8.1168e-06
Epoch 199/300
657/657 - 69s - 105ms/step - accuracy: 0.4042 - loss: 3.0630 - val_accuracy: 0.5599 - val_loss: 2.2414 - learning_rate: 8.1168e-06
Epoch 200/300
657/657 - 70s - 106ms/step - accuracy: 0.3907 - loss: 3.0975 - val_accuracy: 0.5685 - val_loss: 2.2487 - learning_rate: 8.1168e-06
Epoch 201/300
657/657 - 67s - 102ms/step - accuracy: 0.4048 - loss: 3.0519 - val_accuracy: 0.5651 - val_loss: 2.2522 - learning_rate: 8.1168e-06
Epoch 202/300
657/657 - 70s - 106ms/step - accuracy: 0.4049 - loss: 3.0450 - val_accuracy: 0.5634 - val_loss: 2.2612 - learning_rate: 8.1168e-06
Epoch 203/300
657/657 - 68s - 104ms/step - accuracy: 0.3918 - loss: 3.1220 - val_accuracy: 0.5634 - val_loss: 2.2566 - learning_rate: 8.1168e-06
Epoch 204/300
657/657 - 67s - 102ms/step - accuracy: 0.4063 - loss: 3.0961 - val_accuracy: 0.5616 - val_loss: 2.2606 - learning_rate: 8.1168e-06
Epoch 205/300
657/657 - 69s - 105ms/step - accuracy: 0.3954 - loss: 3.1077 - val_accuracy: 0.5668 - val_loss: 2.2671 - learning_rate: 8.1168e-06
Epoch 206/300
657/657 - 67s - 102ms/step - accuracy: 0.3970 - loss: 3.0463 - val_accuracy: 0.5634 - val_loss: 2.2489 - learning_rate: 8.1168e-06
Epoch 207/300

Epoch 207: ReduceLROnPlateau reducing learning rate to 4.058407739648828e-06.
657/657 - 68s - 103ms/step - accuracy: 0.3926 - loss: 3.1145 - val_accuracy: 0.5651 - val_loss: 2.2624 - learning_rate: 8.1168e-06
Epoch 208/300
657/657 - 65s - 99ms/step - accuracy: 0.4002 - loss: 3.0692 - val_accuracy: 0.5651 - val_loss: 2.2537 - learning_rate: 4.0584e-06
Epoch 209/300
657/657 - 69s - 105ms/step - accuracy: 0.4038 - loss: 3.0703 - val_accuracy: 0.5668 - val_loss: 2.2563 - learning_rate: 4.0584e-06
Epoch 210/300
657/657 - 68s - 104ms/step - accuracy: 0.3987 - loss: 3.0700 - val_accuracy: 0.5634 - val_loss: 2.2518 - learning_rate: 4.0584e-06
Epoch 211/300
657/657 - 69s - 105ms/step - accuracy: 0.3973 - loss: 3.0943 - val_accuracy: 0.5685 - val_loss: 2.2575 - learning_rate: 4.0584e-06
Epoch 212/300
657/657 - 70s - 106ms/step - accuracy: 0.4049 - loss: 3.0520 - val_accuracy: 0.5668 - val_loss: 2.2568 - learning_rate: 4.0584e-06
Epoch 213/300
657/657 - 70s - 106ms/step - accuracy: 0.4004 - loss: 3.0455 - val_accuracy: 0.5685 - val_loss: 2.2616 - learning_rate: 4.0584e-06
Epoch 214/300
657/657 - 69s - 104ms/step - accuracy: 0.3895 - loss: 3.0891 - val_accuracy: 0.5668 - val_loss: 2.2422 - learning_rate: 4.0584e-06
Epoch 215/300

Epoch 215: ReduceLROnPlateau reducing learning rate to 2.029203869824414e-06.
657/657 - 68s - 104ms/step - accuracy: 0.3998 - loss: 3.1065 - val_accuracy: 0.5651 - val_loss: 2.2545 - learning_rate: 4.0584e-06
Epoch 215: early stopping
Restoring model weights from the end of the best epoch: 199.
Fold 1 Evaluation results: [2.2577590942382812, 0.5599315166473389]
              precision    recall  f1-score   support

        1820       0.70      0.93      0.80        43
        1821       0.00      0.00      0.00         0
        1822       0.00      0.00      0.00         1
        1823       0.00      0.00      0.00         1
        1824       0.00      0.00      0.00         0
        1825       0.00      0.00      0.00         1
        1826       0.00      0.00      0.00         1
        1827       0.00      0.00      0.00         8
        1828       0.00      0.00      0.00         1
        1829       0.80      1.00      0.89         4
        1830       0.58      0.69      0.63        45
        1831       0.00      0.00      0.00         1
        1832       0.90      0.90      0.90        52
        1833       0.95      0.95      0.95        19
        1834       0.33      0.29      0.31         7
        1835       0.00      0.00      0.00         2
        1836       0.00      0.00      0.00         3
        1837       0.21      0.67      0.32         6
        1838       1.00      0.50      0.67         4
        1839       0.00      0.00      0.00         1
        1840       0.62      0.69      0.65        42
        1841       1.00      0.55      0.71        11
        1842       1.00      0.50      0.67         6
        1843       1.00      0.50      0.67         6
        1844       0.00      0.00      0.00         1
        1845       0.00      0.00      0.00         1
        1846       0.67      0.40      0.50         5
        1847       0.00      0.00      0.00         2
        1848       0.25      0.20      0.22         5
        1849       1.00      0.40      0.57         5
        1850       0.43      0.74      0.54        47
        1851       0.00      0.00      0.00         7
        1852       0.00      0.00      0.00         8
        1853       0.67      0.33      0.44         6
        1854       0.00      0.00      0.00         2
        1855       0.33      0.30      0.32        10
        1856       0.77      0.83      0.80        12
        1857       0.00      0.00      0.00         7
        1858       0.00      0.00      0.00         3
        1859       0.00      0.00      0.00         3
        1860       0.39      0.53      0.45        49
        1861       0.00      0.00      0.00         2
        1862       0.00      0.00      0.00         7
        1863       0.50      0.60      0.55         5
        1864       0.00      0.00      0.00         6
        1865       0.25      0.17      0.20         6
        1866       0.50      0.50      0.50         6
        1867       0.18      0.20      0.19        10
        1868       0.00      0.00      0.00         7
        1869       0.00      0.00      0.00         5
        1870       0.43      0.71      0.54        31
        1871       0.00      0.00      0.00         6
        1872       0.75      0.43      0.55         7
        1873       0.17      0.09      0.12        11
        1874       0.00      0.00      0.00         5
        1875       0.75      0.50      0.60         6
        1876       1.00      0.70      0.82        10
        1877       0.40      0.80      0.53         5
        1878       0.57      0.89      0.70         9
        1879       0.00      0.00      0.00         2

    accuracy                           0.56       584
   macro avg       0.32      0.29      0.29       584
weighted avg       0.51      0.56      0.52       584

Matthews Correlation Coefficient: 0.535
Macro avg F1: 0.288
Weighted avg F1: 0.517
Micro avg F1: 0.560
Top-3 Accuracy: 0.786
Top-5 Accuracy: 0.863
Micro ROC AUC  = 0.98
Macro ROC AUC (present classes) = 0.96
Classification MAE (in years): 3.30

Fold 1 Misclassification Analysis:
Near misses (within 2 years): 66 out of 257 misclassifications (25.68%)
Big misses (greater than 10 years): 80
MAE with outliers: 3.30
MAE without outliers: 2.22 (improvement: 1.08)

10 Worst misclassifications:
Image: data/datasets/public/1870/1876_1953vna.jpg, True: 1876, Predicted: 1832, Error: 44
Image: data/datasets/public/1870/1876_401vna.jpg, True: 1876, Predicted: 1832, Error: 44
Image: data/datasets/public/1850/1859_3076vna.jpg, True: 1859, Predicted: 1820, Error: 39
Image: data/datasets/public/1830/1832_1885vna.jpg, True: 1832, Predicted: 1870, Error: 38
Image: data/datasets/public/1820/1823_53vna.jpg, True: 1823, Predicted: 1860, Error: 37
Image: data/datasets/public/1850/1857_041met.jpg, True: 1857, Predicted: 1820, Error: 37
Image: data/datasets/public/1820/1820_048met.jpg, True: 1820, Predicted: 1855, Error: 35
Image: data/datasets/public/1870/1870_043met.jpg, True: 1870, Predicted: 1840, Error: 30
Image: data/datasets/public/1860/1860_48wikimedia2.jpg, True: 1860, Predicted: 1830, Error: 30
Image: data/datasets/public/1860/1860_13wikimedia2.jpg, True: 1860, Predicted: 1830, Error: 30

===== Fold 2 =====
=== Running on Public Data ===

===== Fine Tuning 9 layers! =====
Epoch 1/300
657/657 - 89s - 136ms/step - accuracy: 0.1071 - loss: 4.6495 - val_accuracy: 0.2363 - val_loss: 4.1842 - learning_rate: 2.5974e-04
Epoch 2/300
657/657 - 69s - 106ms/step - accuracy: 0.1618 - loss: 4.4433 - val_accuracy: 0.2534 - val_loss: 3.9552 - learning_rate: 2.5974e-04
Epoch 3/300
657/657 - 67s - 102ms/step - accuracy: 0.1893 - loss: 4.2971 - val_accuracy: 0.2688 - val_loss: 3.8742 - learning_rate: 2.5974e-04
Epoch 4/300
657/657 - 68s - 104ms/step - accuracy: 0.2063 - loss: 4.2178 - val_accuracy: 0.2911 - val_loss: 3.8490 - learning_rate: 2.5974e-04
Epoch 5/300
657/657 - 70s - 106ms/step - accuracy: 0.2236 - loss: 4.1534 - val_accuracy: 0.3219 - val_loss: 3.7964 - learning_rate: 2.5974e-04
Epoch 6/300
657/657 - 69s - 106ms/step - accuracy: 0.2421 - loss: 4.1206 - val_accuracy: 0.3099 - val_loss: 3.5972 - learning_rate: 2.5974e-04
Epoch 7/300
657/657 - 67s - 101ms/step - accuracy: 0.2392 - loss: 4.0675 - val_accuracy: 0.3356 - val_loss: 3.6969 - learning_rate: 2.5974e-04
Epoch 8/300
657/657 - 68s - 104ms/step - accuracy: 0.2578 - loss: 3.9992 - val_accuracy: 0.3664 - val_loss: 3.5166 - learning_rate: 2.5974e-04
Epoch 9/300
657/657 - 69s - 105ms/step - accuracy: 0.2641 - loss: 4.0208 - val_accuracy: 0.3767 - val_loss: 3.3807 - learning_rate: 2.5974e-04
Epoch 10/300
657/657 - 64s - 98ms/step - accuracy: 0.2773 - loss: 3.9468 - val_accuracy: 0.3682 - val_loss: 3.4396 - learning_rate: 2.5974e-04
Epoch 11/300
657/657 - 69s - 104ms/step - accuracy: 0.2754 - loss: 3.9472 - val_accuracy: 0.3990 - val_loss: 3.4272 - learning_rate: 2.5974e-04
Epoch 12/300
657/657 - 69s - 105ms/step - accuracy: 0.2799 - loss: 3.9124 - val_accuracy: 0.4144 - val_loss: 3.4151 - learning_rate: 2.5974e-04
Epoch 13/300
657/657 - 67s - 102ms/step - accuracy: 0.2870 - loss: 3.8613 - val_accuracy: 0.3750 - val_loss: 3.2526 - learning_rate: 2.5974e-04
Epoch 14/300
657/657 - 69s - 104ms/step - accuracy: 0.2957 - loss: 3.8473 - val_accuracy: 0.3921 - val_loss: 3.2478 - learning_rate: 2.5974e-04
Epoch 15/300
657/657 - 68s - 104ms/step - accuracy: 0.2892 - loss: 3.8315 - val_accuracy: 0.4144 - val_loss: 3.1998 - learning_rate: 2.5974e-04
Epoch 16/300
657/657 - 68s - 103ms/step - accuracy: 0.2953 - loss: 3.7656 - val_accuracy: 0.3955 - val_loss: 3.1902 - learning_rate: 2.5974e-04
Epoch 17/300
657/657 - 68s - 103ms/step - accuracy: 0.3060 - loss: 3.7606 - val_accuracy: 0.4075 - val_loss: 3.2297 - learning_rate: 2.5974e-04
Epoch 18/300
657/657 - 68s - 104ms/step - accuracy: 0.3010 - loss: 3.7364 - val_accuracy: 0.4127 - val_loss: 3.0580 - learning_rate: 2.5974e-04
Epoch 19/300
657/657 - 66s - 100ms/step - accuracy: 0.3041 - loss: 3.7453 - val_accuracy: 0.4075 - val_loss: 3.0696 - learning_rate: 2.5974e-04
Epoch 20/300
657/657 - 68s - 104ms/step - accuracy: 0.3052 - loss: 3.7217 - val_accuracy: 0.4264 - val_loss: 3.0797 - learning_rate: 2.5974e-04
Epoch 21/300
657/657 - 69s - 105ms/step - accuracy: 0.3125 - loss: 3.6642 - val_accuracy: 0.4212 - val_loss: 2.9519 - learning_rate: 2.5974e-04
Epoch 22/300
657/657 - 68s - 103ms/step - accuracy: 0.3121 - loss: 3.6653 - val_accuracy: 0.4298 - val_loss: 3.0282 - learning_rate: 2.5974e-04
Epoch 23/300
657/657 - 67s - 102ms/step - accuracy: 0.3149 - loss: 3.6693 - val_accuracy: 0.4349 - val_loss: 3.0114 - learning_rate: 2.5974e-04
Epoch 24/300
657/657 - 68s - 104ms/step - accuracy: 0.3111 - loss: 3.6839 - val_accuracy: 0.4418 - val_loss: 3.0159 - learning_rate: 2.5974e-04
Epoch 25/300
657/657 - 69s - 104ms/step - accuracy: 0.3224 - loss: 3.6428 - val_accuracy: 0.4572 - val_loss: 2.9755 - learning_rate: 2.5974e-04
Epoch 26/300
657/657 - 67s - 103ms/step - accuracy: 0.3210 - loss: 3.6232 - val_accuracy: 0.4264 - val_loss: 2.9744 - learning_rate: 2.5974e-04
Epoch 27/300
657/657 - 66s - 100ms/step - accuracy: 0.3208 - loss: 3.5827 - val_accuracy: 0.4538 - val_loss: 2.9394 - learning_rate: 2.5974e-04
Epoch 28/300
657/657 - 69s - 105ms/step - accuracy: 0.3239 - loss: 3.6037 - val_accuracy: 0.4281 - val_loss: 2.8977 - learning_rate: 2.5974e-04
Epoch 29/300
657/657 - 69s - 105ms/step - accuracy: 0.3248 - loss: 3.5840 - val_accuracy: 0.4435 - val_loss: 2.8965 - learning_rate: 2.5974e-04
Epoch 30/300
657/657 - 69s - 105ms/step - accuracy: 0.3260 - loss: 3.5781 - val_accuracy: 0.4658 - val_loss: 2.9226 - learning_rate: 2.5974e-04
Epoch 31/300
657/657 - 68s - 103ms/step - accuracy: 0.3298 - loss: 3.5658 - val_accuracy: 0.4589 - val_loss: 2.8986 - learning_rate: 2.5974e-04
Epoch 32/300
657/657 - 68s - 103ms/step - accuracy: 0.3243 - loss: 3.5355 - val_accuracy: 0.4469 - val_loss: 2.8602 - learning_rate: 2.5974e-04
Epoch 33/300
657/657 - 66s - 101ms/step - accuracy: 0.3239 - loss: 3.5175 - val_accuracy: 0.4555 - val_loss: 2.8810 - learning_rate: 2.5974e-04
Epoch 34/300
657/657 - 68s - 104ms/step - accuracy: 0.3269 - loss: 3.5564 - val_accuracy: 0.4281 - val_loss: 2.8169 - learning_rate: 2.5974e-04
Epoch 35/300
657/657 - 67s - 102ms/step - accuracy: 0.3399 - loss: 3.5088 - val_accuracy: 0.4452 - val_loss: 2.7895 - learning_rate: 2.5974e-04
Epoch 36/300
657/657 - 64s - 97ms/step - accuracy: 0.3313 - loss: 3.5115 - val_accuracy: 0.4675 - val_loss: 2.7924 - learning_rate: 2.5974e-04
Epoch 37/300
657/657 - 67s - 102ms/step - accuracy: 0.3313 - loss: 3.5079 - val_accuracy: 0.4418 - val_loss: 2.7753 - learning_rate: 2.5974e-04
Epoch 38/300
657/657 - 63s - 95ms/step - accuracy: 0.3397 - loss: 3.4905 - val_accuracy: 0.4658 - val_loss: 2.7966 - learning_rate: 2.5974e-04
Epoch 39/300
657/657 - 60s - 91ms/step - accuracy: 0.3351 - loss: 3.4907 - val_accuracy: 0.4572 - val_loss: 2.8186 - learning_rate: 2.5974e-04
Epoch 40/300
657/657 - 62s - 94ms/step - accuracy: 0.3336 - loss: 3.4546 - val_accuracy: 0.4640 - val_loss: 2.8176 - learning_rate: 2.5974e-04
Epoch 41/300
657/657 - 62s - 94ms/step - accuracy: 0.3351 - loss: 3.4779 - val_accuracy: 0.4658 - val_loss: 2.7904 - learning_rate: 2.5974e-04
Epoch 42/300
657/657 - 80s - 121ms/step - accuracy: 0.3383 - loss: 3.4996 - val_accuracy: 0.4692 - val_loss: 2.7755 - learning_rate: 2.5974e-04
Epoch 43/300
657/657 - 62s - 95ms/step - accuracy: 0.3355 - loss: 3.4465 - val_accuracy: 0.4846 - val_loss: 2.7571 - learning_rate: 2.5974e-04
Epoch 44/300
657/657 - 61s - 94ms/step - accuracy: 0.3498 - loss: 3.4395 - val_accuracy: 0.4829 - val_loss: 2.7383 - learning_rate: 2.5974e-04
Epoch 45/300
657/657 - 60s - 91ms/step - accuracy: 0.3321 - loss: 3.4776 - val_accuracy: 0.4846 - val_loss: 2.6822 - learning_rate: 2.5974e-04
Epoch 46/300
657/657 - 62s - 94ms/step - accuracy: 0.3420 - loss: 3.4521 - val_accuracy: 0.4812 - val_loss: 2.7115 - learning_rate: 2.5974e-04
Epoch 47/300
657/657 - 64s - 97ms/step - accuracy: 0.3427 - loss: 3.4508 - val_accuracy: 0.4846 - val_loss: 2.7251 - learning_rate: 2.5974e-04
Epoch 48/300
657/657 - 61s - 94ms/step - accuracy: 0.3536 - loss: 3.4399 - val_accuracy: 0.4538 - val_loss: 2.6990 - learning_rate: 2.5974e-04
Epoch 49/300
657/657 - 63s - 96ms/step - accuracy: 0.3441 - loss: 3.4390 - val_accuracy: 0.4795 - val_loss: 2.7232 - learning_rate: 2.5974e-04
Epoch 50/300
657/657 - 62s - 94ms/step - accuracy: 0.3519 - loss: 3.3992 - val_accuracy: 0.4726 - val_loss: 2.7507 - learning_rate: 2.5974e-04
Epoch 51/300
657/657 - 61s - 93ms/step - accuracy: 0.3530 - loss: 3.4110 - val_accuracy: 0.4623 - val_loss: 2.6754 - learning_rate: 2.5974e-04
Epoch 52/300
657/657 - 63s - 95ms/step - accuracy: 0.3376 - loss: 3.4283 - val_accuracy: 0.4795 - val_loss: 2.6793 - learning_rate: 2.5974e-04
Epoch 53/300
657/657 - 61s - 93ms/step - accuracy: 0.3562 - loss: 3.4035 - val_accuracy: 0.4949 - val_loss: 2.6574 - learning_rate: 2.5974e-04
Epoch 54/300
657/657 - 62s - 94ms/step - accuracy: 0.3482 - loss: 3.4185 - val_accuracy: 0.4897 - val_loss: 2.6812 - learning_rate: 2.5974e-04
Epoch 55/300
657/657 - 62s - 94ms/step - accuracy: 0.3503 - loss: 3.4007 - val_accuracy: 0.4692 - val_loss: 2.6830 - learning_rate: 2.5974e-04
Epoch 56/300
657/657 - 62s - 94ms/step - accuracy: 0.3604 - loss: 3.3922 - val_accuracy: 0.5171 - val_loss: 2.7647 - learning_rate: 2.5974e-04
Epoch 57/300
657/657 - 62s - 95ms/step - accuracy: 0.3482 - loss: 3.3926 - val_accuracy: 0.5051 - val_loss: 2.6760 - learning_rate: 2.5974e-04
Epoch 58/300
657/657 - 62s - 94ms/step - accuracy: 0.3488 - loss: 3.3600 - val_accuracy: 0.4863 - val_loss: 2.6379 - learning_rate: 2.5974e-04
Epoch 59/300
657/657 - 63s - 96ms/step - accuracy: 0.3391 - loss: 3.3989 - val_accuracy: 0.4692 - val_loss: 2.6510 - learning_rate: 2.5974e-04
Epoch 60/300
657/657 - 63s - 95ms/step - accuracy: 0.3532 - loss: 3.3655 - val_accuracy: 0.4914 - val_loss: 2.6719 - learning_rate: 2.5974e-04
Epoch 61/300
657/657 - 62s - 94ms/step - accuracy: 0.3509 - loss: 3.3869 - val_accuracy: 0.4983 - val_loss: 2.6110 - learning_rate: 2.5974e-04
Epoch 62/300
657/657 - 60s - 92ms/step - accuracy: 0.3492 - loss: 3.3709 - val_accuracy: 0.4829 - val_loss: 2.6200 - learning_rate: 2.5974e-04
Epoch 63/300
657/657 - 61s - 94ms/step - accuracy: 0.3555 - loss: 3.3759 - val_accuracy: 0.5034 - val_loss: 2.6355 - learning_rate: 2.5974e-04
Epoch 64/300
657/657 - 61s - 93ms/step - accuracy: 0.3456 - loss: 3.3555 - val_accuracy: 0.4846 - val_loss: 2.6270 - learning_rate: 2.5974e-04
Epoch 65/300
657/657 - 63s - 96ms/step - accuracy: 0.3494 - loss: 3.3812 - val_accuracy: 0.5000 - val_loss: 2.6611 - learning_rate: 2.5974e-04
Epoch 66/300
657/657 - 82s - 125ms/step - accuracy: 0.3467 - loss: 3.3518 - val_accuracy: 0.4760 - val_loss: 2.5997 - learning_rate: 2.5974e-04
Epoch 67/300
657/657 - 62s - 94ms/step - accuracy: 0.3562 - loss: 3.3606 - val_accuracy: 0.5068 - val_loss: 2.6234 - learning_rate: 2.5974e-04
Epoch 68/300
657/657 - 64s - 98ms/step - accuracy: 0.3539 - loss: 3.3717 - val_accuracy: 0.4932 - val_loss: 2.6168 - learning_rate: 2.5974e-04
Epoch 69/300
657/657 - 62s - 94ms/step - accuracy: 0.3610 - loss: 3.3562 - val_accuracy: 0.5205 - val_loss: 2.6209 - learning_rate: 2.5974e-04
Epoch 70/300
657/657 - 62s - 95ms/step - accuracy: 0.3612 - loss: 3.3373 - val_accuracy: 0.4949 - val_loss: 2.5847 - learning_rate: 2.5974e-04
Epoch 71/300
657/657 - 60s - 91ms/step - accuracy: 0.3559 - loss: 3.3380 - val_accuracy: 0.5188 - val_loss: 2.5477 - learning_rate: 2.5974e-04
Epoch 72/300
657/657 - 62s - 95ms/step - accuracy: 0.3640 - loss: 3.3217 - val_accuracy: 0.5188 - val_loss: 2.5686 - learning_rate: 2.5974e-04
Epoch 73/300
657/657 - 62s - 94ms/step - accuracy: 0.3562 - loss: 3.3332 - val_accuracy: 0.5103 - val_loss: 2.5409 - learning_rate: 2.5974e-04
Epoch 74/300
657/657 - 62s - 95ms/step - accuracy: 0.3509 - loss: 3.3604 - val_accuracy: 0.5171 - val_loss: 2.5949 - learning_rate: 2.5974e-04
Epoch 75/300
657/657 - 64s - 97ms/step - accuracy: 0.3581 - loss: 3.2988 - val_accuracy: 0.5188 - val_loss: 2.6423 - learning_rate: 2.5974e-04
Epoch 76/300
657/657 - 63s - 95ms/step - accuracy: 0.3593 - loss: 3.3602 - val_accuracy: 0.5223 - val_loss: 2.5671 - learning_rate: 2.5974e-04
Epoch 77/300
657/657 - 63s - 95ms/step - accuracy: 0.3581 - loss: 3.3447 - val_accuracy: 0.4983 - val_loss: 2.6004 - learning_rate: 2.5974e-04
Epoch 78/300
657/657 - 63s - 95ms/step - accuracy: 0.3604 - loss: 3.3189 - val_accuracy: 0.4829 - val_loss: 2.5697 - learning_rate: 2.5974e-04
Epoch 79/300
657/657 - 63s - 96ms/step - accuracy: 0.3646 - loss: 3.3014 - val_accuracy: 0.5017 - val_loss: 2.5962 - learning_rate: 2.5974e-04
Epoch 80/300
657/657 - 61s - 92ms/step - accuracy: 0.3644 - loss: 3.3394 - val_accuracy: 0.5154 - val_loss: 2.5482 - learning_rate: 2.5974e-04
Epoch 81/300

Epoch 81: ReduceLROnPlateau reducing learning rate to 0.0001298690476687625.
657/657 - 62s - 95ms/step - accuracy: 0.3669 - loss: 3.3018 - val_accuracy: 0.4966 - val_loss: 2.6028 - learning_rate: 2.5974e-04
Epoch 82/300
657/657 - 63s - 95ms/step - accuracy: 0.3762 - loss: 3.2640 - val_accuracy: 0.5086 - val_loss: 2.5087 - learning_rate: 1.2987e-04
Epoch 83/300
657/657 - 64s - 97ms/step - accuracy: 0.3749 - loss: 3.2424 - val_accuracy: 0.5137 - val_loss: 2.5222 - learning_rate: 1.2987e-04
Epoch 84/300
657/657 - 63s - 95ms/step - accuracy: 0.3686 - loss: 3.2605 - val_accuracy: 0.5154 - val_loss: 2.4778 - learning_rate: 1.2987e-04
Epoch 85/300
657/657 - 62s - 94ms/step - accuracy: 0.3758 - loss: 3.2320 - val_accuracy: 0.5154 - val_loss: 2.5290 - learning_rate: 1.2987e-04
Epoch 86/300
657/657 - 63s - 96ms/step - accuracy: 0.3707 - loss: 3.2297 - val_accuracy: 0.5205 - val_loss: 2.4834 - learning_rate: 1.2987e-04
Epoch 87/300
657/657 - 62s - 94ms/step - accuracy: 0.3716 - loss: 3.2614 - val_accuracy: 0.5188 - val_loss: 2.5109 - learning_rate: 1.2987e-04
Epoch 88/300
657/657 - 62s - 95ms/step - accuracy: 0.3730 - loss: 3.1923 - val_accuracy: 0.5291 - val_loss: 2.5268 - learning_rate: 1.2987e-04
Epoch 89/300
657/657 - 61s - 92ms/step - accuracy: 0.3730 - loss: 3.1914 - val_accuracy: 0.5308 - val_loss: 2.5087 - learning_rate: 1.2987e-04
Epoch 90/300
657/657 - 62s - 94ms/step - accuracy: 0.3806 - loss: 3.1981 - val_accuracy: 0.5103 - val_loss: 2.4829 - learning_rate: 1.2987e-04
Epoch 91/300
657/657 - 82s - 124ms/step - accuracy: 0.3616 - loss: 3.2609 - val_accuracy: 0.5171 - val_loss: 2.4648 - learning_rate: 1.2987e-04
Epoch 92/300
657/657 - 62s - 94ms/step - accuracy: 0.3838 - loss: 3.1907 - val_accuracy: 0.5188 - val_loss: 2.4850 - learning_rate: 1.2987e-04
Epoch 93/300
657/657 - 63s - 96ms/step - accuracy: 0.3781 - loss: 3.1909 - val_accuracy: 0.5223 - val_loss: 2.4689 - learning_rate: 1.2987e-04
Epoch 94/300
657/657 - 81s - 123ms/step - accuracy: 0.3739 - loss: 3.1690 - val_accuracy: 0.5205 - val_loss: 2.4873 - learning_rate: 1.2987e-04
Epoch 95/300
657/657 - 61s - 93ms/step - accuracy: 0.3739 - loss: 3.1995 - val_accuracy: 0.5086 - val_loss: 2.4641 - learning_rate: 1.2987e-04
Epoch 96/300
657/657 - 63s - 96ms/step - accuracy: 0.3783 - loss: 3.2103 - val_accuracy: 0.5240 - val_loss: 2.4865 - learning_rate: 1.2987e-04
Epoch 97/300
657/657 - 61s - 93ms/step - accuracy: 0.3907 - loss: 3.1660 - val_accuracy: 0.5188 - val_loss: 2.4734 - learning_rate: 1.2987e-04
Epoch 98/300
657/657 - 62s - 95ms/step - accuracy: 0.3716 - loss: 3.2390 - val_accuracy: 0.5257 - val_loss: 2.4375 - learning_rate: 1.2987e-04
Epoch 99/300
657/657 - 63s - 96ms/step - accuracy: 0.3758 - loss: 3.2270 - val_accuracy: 0.5240 - val_loss: 2.4470 - learning_rate: 1.2987e-04
Epoch 100/300
657/657 - 62s - 94ms/step - accuracy: 0.3808 - loss: 3.2139 - val_accuracy: 0.5360 - val_loss: 2.4693 - learning_rate: 1.2987e-04
Epoch 101/300
657/657 - 61s - 93ms/step - accuracy: 0.3753 - loss: 3.2169 - val_accuracy: 0.5325 - val_loss: 2.4789 - learning_rate: 1.2987e-04
Epoch 102/300
657/657 - 63s - 96ms/step - accuracy: 0.3836 - loss: 3.1821 - val_accuracy: 0.5223 - val_loss: 2.4567 - learning_rate: 1.2987e-04
Epoch 103/300
657/657 - 63s - 96ms/step - accuracy: 0.3785 - loss: 3.2021 - val_accuracy: 0.5360 - val_loss: 2.4596 - learning_rate: 1.2987e-04
Epoch 104/300
657/657 - 61s - 92ms/step - accuracy: 0.3787 - loss: 3.1796 - val_accuracy: 0.5240 - val_loss: 2.4624 - learning_rate: 1.2987e-04
Epoch 105/300
657/657 - 62s - 95ms/step - accuracy: 0.3800 - loss: 3.1884 - val_accuracy: 0.5274 - val_loss: 2.4535 - learning_rate: 1.2987e-04
Epoch 106/300

Epoch 106: ReduceLROnPlateau reducing learning rate to 6.493452383438125e-05.
657/657 - 60s - 91ms/step - accuracy: 0.3893 - loss: 3.2069 - val_accuracy: 0.5325 - val_loss: 2.4479 - learning_rate: 1.2987e-04
Epoch 107/300
657/657 - 62s - 94ms/step - accuracy: 0.3842 - loss: 3.1513 - val_accuracy: 0.5274 - val_loss: 2.4566 - learning_rate: 6.4935e-05
Epoch 108/300
657/657 - 62s - 94ms/step - accuracy: 0.3833 - loss: 3.1520 - val_accuracy: 0.5291 - val_loss: 2.4303 - learning_rate: 6.4935e-05
Epoch 109/300
657/657 - 61s - 93ms/step - accuracy: 0.3918 - loss: 3.1259 - val_accuracy: 0.5308 - val_loss: 2.4255 - learning_rate: 6.4935e-05
Epoch 110/300
657/657 - 61s - 93ms/step - accuracy: 0.3781 - loss: 3.1456 - val_accuracy: 0.5274 - val_loss: 2.4352 - learning_rate: 6.4935e-05
Epoch 111/300
657/657 - 62s - 95ms/step - accuracy: 0.3829 - loss: 3.1292 - val_accuracy: 0.5240 - val_loss: 2.4322 - learning_rate: 6.4935e-05
Epoch 112/300
657/657 - 62s - 94ms/step - accuracy: 0.3823 - loss: 3.1629 - val_accuracy: 0.5325 - val_loss: 2.4324 - learning_rate: 6.4935e-05
Epoch 113/300
657/657 - 60s - 92ms/step - accuracy: 0.3785 - loss: 3.2049 - val_accuracy: 0.5342 - val_loss: 2.4267 - learning_rate: 6.4935e-05
Epoch 114/300
657/657 - 63s - 96ms/step - accuracy: 0.3855 - loss: 3.1639 - val_accuracy: 0.5103 - val_loss: 2.4168 - learning_rate: 6.4935e-05
Epoch 115/300
657/657 - 62s - 94ms/step - accuracy: 0.3774 - loss: 3.1181 - val_accuracy: 0.5240 - val_loss: 2.4286 - learning_rate: 6.4935e-05
Epoch 116/300
657/657 - 61s - 92ms/step - accuracy: 0.3945 - loss: 3.1070 - val_accuracy: 0.5291 - val_loss: 2.4309 - learning_rate: 6.4935e-05
Epoch 117/300
657/657 - 62s - 94ms/step - accuracy: 0.3853 - loss: 3.1309 - val_accuracy: 0.5308 - val_loss: 2.4406 - learning_rate: 6.4935e-05
Epoch 118/300
657/657 - 64s - 97ms/step - accuracy: 0.3863 - loss: 3.1608 - val_accuracy: 0.5325 - val_loss: 2.4053 - learning_rate: 6.4935e-05
Epoch 119/300
657/657 - 62s - 94ms/step - accuracy: 0.3783 - loss: 3.1469 - val_accuracy: 0.5291 - val_loss: 2.3885 - learning_rate: 6.4935e-05
Epoch 120/300
657/657 - 62s - 95ms/step - accuracy: 0.3922 - loss: 3.0968 - val_accuracy: 0.5325 - val_loss: 2.4294 - learning_rate: 6.4935e-05
Epoch 121/300
657/657 - 63s - 96ms/step - accuracy: 0.3774 - loss: 3.1427 - val_accuracy: 0.5103 - val_loss: 2.4091 - learning_rate: 6.4935e-05
Epoch 122/300
657/657 - 61s - 93ms/step - accuracy: 0.3842 - loss: 3.1470 - val_accuracy: 0.5462 - val_loss: 2.4101 - learning_rate: 6.4935e-05
Epoch 123/300
657/657 - 63s - 96ms/step - accuracy: 0.3939 - loss: 3.1332 - val_accuracy: 0.5223 - val_loss: 2.3844 - learning_rate: 6.4935e-05
Epoch 124/300
657/657 - 61s - 93ms/step - accuracy: 0.3819 - loss: 3.1673 - val_accuracy: 0.5223 - val_loss: 2.4180 - learning_rate: 6.4935e-05
Epoch 125/300
657/657 - 62s - 94ms/step - accuracy: 0.3952 - loss: 3.1153 - val_accuracy: 0.5308 - val_loss: 2.4177 - learning_rate: 6.4935e-05
Epoch 126/300
657/657 - 62s - 94ms/step - accuracy: 0.3892 - loss: 3.1440 - val_accuracy: 0.5342 - val_loss: 2.4037 - learning_rate: 6.4935e-05
Epoch 127/300
657/657 - 62s - 95ms/step - accuracy: 0.3878 - loss: 3.0989 - val_accuracy: 0.5360 - val_loss: 2.4032 - learning_rate: 6.4935e-05
Epoch 128/300
657/657 - 62s - 95ms/step - accuracy: 0.3869 - loss: 3.1607 - val_accuracy: 0.5394 - val_loss: 2.3908 - learning_rate: 6.4935e-05
Epoch 129/300
657/657 - 61s - 93ms/step - accuracy: 0.3874 - loss: 3.1683 - val_accuracy: 0.5205 - val_loss: 2.3996 - learning_rate: 6.4935e-05
Epoch 130/300
657/657 - 63s - 96ms/step - accuracy: 0.3916 - loss: 3.1192 - val_accuracy: 0.5497 - val_loss: 2.3880 - learning_rate: 6.4935e-05
Epoch 131/300

Epoch 131: ReduceLROnPlateau reducing learning rate to 3.2467261917190626e-05.
657/657 - 62s - 94ms/step - accuracy: 0.3914 - loss: 3.1065 - val_accuracy: 0.5462 - val_loss: 2.4059 - learning_rate: 6.4935e-05
Epoch 132/300
657/657 - 61s - 93ms/step - accuracy: 0.3920 - loss: 3.1176 - val_accuracy: 0.5325 - val_loss: 2.3785 - learning_rate: 3.2467e-05
Epoch 133/300
657/657 - 62s - 95ms/step - accuracy: 0.3888 - loss: 3.1423 - val_accuracy: 0.5257 - val_loss: 2.3917 - learning_rate: 3.2467e-05
Epoch 134/300
657/657 - 60s - 91ms/step - accuracy: 0.3933 - loss: 3.0934 - val_accuracy: 0.5377 - val_loss: 2.3956 - learning_rate: 3.2467e-05
Epoch 135/300
657/657 - 60s - 92ms/step - accuracy: 0.3882 - loss: 3.0760 - val_accuracy: 0.5257 - val_loss: 2.3814 - learning_rate: 3.2467e-05
Epoch 136/300
657/657 - 62s - 95ms/step - accuracy: 0.3895 - loss: 3.1002 - val_accuracy: 0.5377 - val_loss: 2.3847 - learning_rate: 3.2467e-05
Epoch 137/300
657/657 - 81s - 124ms/step - accuracy: 0.3926 - loss: 3.0912 - val_accuracy: 0.5240 - val_loss: 2.3852 - learning_rate: 3.2467e-05
Epoch 138/300
657/657 - 62s - 94ms/step - accuracy: 0.3956 - loss: 3.0847 - val_accuracy: 0.5394 - val_loss: 2.3774 - learning_rate: 3.2467e-05
Epoch 139/300
657/657 - 64s - 98ms/step - accuracy: 0.3970 - loss: 3.0897 - val_accuracy: 0.5360 - val_loss: 2.3732 - learning_rate: 3.2467e-05
Epoch 140/300
657/657 - 63s - 95ms/step - accuracy: 0.3893 - loss: 3.0954 - val_accuracy: 0.5462 - val_loss: 2.3839 - learning_rate: 3.2467e-05
Epoch 141/300
657/657 - 61s - 93ms/step - accuracy: 0.3979 - loss: 3.1028 - val_accuracy: 0.5325 - val_loss: 2.3848 - learning_rate: 3.2467e-05
Epoch 142/300
657/657 - 60s - 91ms/step - accuracy: 0.4006 - loss: 3.1044 - val_accuracy: 0.5411 - val_loss: 2.3765 - learning_rate: 3.2467e-05
Epoch 143/300
657/657 - 63s - 96ms/step - accuracy: 0.3964 - loss: 3.0972 - val_accuracy: 0.5274 - val_loss: 2.3782 - learning_rate: 3.2467e-05
Epoch 144/300
657/657 - 62s - 94ms/step - accuracy: 0.3859 - loss: 3.0940 - val_accuracy: 0.5377 - val_loss: 2.3694 - learning_rate: 3.2467e-05
Epoch 145/300
657/657 - 63s - 96ms/step - accuracy: 0.3880 - loss: 3.1025 - val_accuracy: 0.5325 - val_loss: 2.3746 - learning_rate: 3.2467e-05
Epoch 146/300
657/657 - 61s - 93ms/step - accuracy: 0.3861 - loss: 3.1216 - val_accuracy: 0.5342 - val_loss: 2.3835 - learning_rate: 3.2467e-05
Epoch 147/300
657/657 - 62s - 94ms/step - accuracy: 0.3893 - loss: 3.0994 - val_accuracy: 0.5342 - val_loss: 2.3815 - learning_rate: 3.2467e-05
Epoch 148/300
657/657 - 61s - 93ms/step - accuracy: 0.3951 - loss: 3.0632 - val_accuracy: 0.5325 - val_loss: 2.3926 - learning_rate: 3.2467e-05
Epoch 149/300
657/657 - 63s - 95ms/step - accuracy: 0.3985 - loss: 3.0879 - val_accuracy: 0.5342 - val_loss: 2.3685 - learning_rate: 3.2467e-05
Epoch 150/300
657/657 - 61s - 93ms/step - accuracy: 0.3975 - loss: 3.0848 - val_accuracy: 0.5342 - val_loss: 2.3708 - learning_rate: 3.2467e-05
Epoch 151/300
657/657 - 60s - 92ms/step - accuracy: 0.3836 - loss: 3.0935 - val_accuracy: 0.5325 - val_loss: 2.3722 - learning_rate: 3.2467e-05
Epoch 152/300
657/657 - 61s - 93ms/step - accuracy: 0.4008 - loss: 3.1008 - val_accuracy: 0.5342 - val_loss: 2.3697 - learning_rate: 3.2467e-05
Epoch 153/300
657/657 - 62s - 94ms/step - accuracy: 0.3979 - loss: 3.0749 - val_accuracy: 0.5428 - val_loss: 2.3921 - learning_rate: 3.2467e-05
Epoch 154/300
657/657 - 63s - 96ms/step - accuracy: 0.3930 - loss: 3.0899 - val_accuracy: 0.5223 - val_loss: 2.3709 - learning_rate: 3.2467e-05
Epoch 155/300
657/657 - 61s - 93ms/step - accuracy: 0.3834 - loss: 3.1158 - val_accuracy: 0.5377 - val_loss: 2.3822 - learning_rate: 3.2467e-05
Epoch 156/300
657/657 - 61s - 93ms/step - accuracy: 0.3989 - loss: 3.1093 - val_accuracy: 0.5445 - val_loss: 2.3910 - learning_rate: 3.2467e-05
Epoch 157/300

Epoch 157: ReduceLROnPlateau reducing learning rate to 1.6233630958595313e-05.
657/657 - 62s - 95ms/step - accuracy: 0.4000 - loss: 3.0767 - val_accuracy: 0.5462 - val_loss: 2.3762 - learning_rate: 3.2467e-05
Epoch 158/300
657/657 - 63s - 95ms/step - accuracy: 0.3987 - loss: 3.0857 - val_accuracy: 0.5428 - val_loss: 2.3608 - learning_rate: 1.6234e-05
Epoch 159/300
657/657 - 64s - 97ms/step - accuracy: 0.3975 - loss: 3.0548 - val_accuracy: 0.5360 - val_loss: 2.3535 - learning_rate: 1.6234e-05
Epoch 160/300
657/657 - 60s - 91ms/step - accuracy: 0.3966 - loss: 3.0884 - val_accuracy: 0.5445 - val_loss: 2.3768 - learning_rate: 1.6234e-05
Epoch 161/300
657/657 - 63s - 95ms/step - accuracy: 0.3966 - loss: 3.0755 - val_accuracy: 0.5325 - val_loss: 2.3691 - learning_rate: 1.6234e-05
Epoch 162/300
657/657 - 62s - 94ms/step - accuracy: 0.3888 - loss: 3.1423 - val_accuracy: 0.5377 - val_loss: 2.3678 - learning_rate: 1.6234e-05
Epoch 163/300
657/657 - 61s - 93ms/step - accuracy: 0.3874 - loss: 3.1010 - val_accuracy: 0.5325 - val_loss: 2.3681 - learning_rate: 1.6234e-05
Epoch 164/300
657/657 - 63s - 96ms/step - accuracy: 0.4023 - loss: 3.0494 - val_accuracy: 0.5308 - val_loss: 2.3698 - learning_rate: 1.6234e-05
Epoch 165/300
657/657 - 63s - 95ms/step - accuracy: 0.4046 - loss: 3.0376 - val_accuracy: 0.5308 - val_loss: 2.3588 - learning_rate: 1.6234e-05
Epoch 166/300
657/657 - 60s - 92ms/step - accuracy: 0.3964 - loss: 3.0702 - val_accuracy: 0.5479 - val_loss: 2.3534 - learning_rate: 1.6234e-05
Epoch 167/300

Epoch 167: ReduceLROnPlateau reducing learning rate to 8.116815479297657e-06.
657/657 - 64s - 98ms/step - accuracy: 0.4021 - loss: 3.0815 - val_accuracy: 0.5445 - val_loss: 2.3682 - learning_rate: 1.6234e-05
Epoch 168/300
657/657 - 62s - 94ms/step - accuracy: 0.4021 - loss: 3.1149 - val_accuracy: 0.5428 - val_loss: 2.3554 - learning_rate: 8.1168e-06
Epoch 169/300
657/657 - 60s - 92ms/step - accuracy: 0.4029 - loss: 3.0582 - val_accuracy: 0.5360 - val_loss: 2.3533 - learning_rate: 8.1168e-06
Epoch 170/300
657/657 - 63s - 96ms/step - accuracy: 0.3941 - loss: 3.0831 - val_accuracy: 0.5394 - val_loss: 2.3500 - learning_rate: 8.1168e-06
Epoch 171/300
657/657 - 62s - 95ms/step - accuracy: 0.4023 - loss: 3.0828 - val_accuracy: 0.5342 - val_loss: 2.3495 - learning_rate: 8.1168e-06
Epoch 172/300
657/657 - 62s - 95ms/step - accuracy: 0.3962 - loss: 3.1071 - val_accuracy: 0.5360 - val_loss: 2.3555 - learning_rate: 8.1168e-06
Epoch 173/300
657/657 - 64s - 97ms/step - accuracy: 0.3996 - loss: 3.0720 - val_accuracy: 0.5342 - val_loss: 2.3516 - learning_rate: 8.1168e-06
Epoch 174/300
657/657 - 63s - 96ms/step - accuracy: 0.3949 - loss: 3.0893 - val_accuracy: 0.5411 - val_loss: 2.3660 - learning_rate: 8.1168e-06
Epoch 175/300
657/657 - 61s - 93ms/step - accuracy: 0.3979 - loss: 3.0726 - val_accuracy: 0.5325 - val_loss: 2.3778 - learning_rate: 8.1168e-06
Epoch 176/300
657/657 - 62s - 95ms/step - accuracy: 0.3962 - loss: 3.0799 - val_accuracy: 0.5377 - val_loss: 2.3617 - learning_rate: 8.1168e-06
Epoch 177/300
657/657 - 62s - 95ms/step - accuracy: 0.3952 - loss: 3.1089 - val_accuracy: 0.5360 - val_loss: 2.3615 - learning_rate: 8.1168e-06
Epoch 178/300
657/657 - 62s - 94ms/step - accuracy: 0.4011 - loss: 3.0839 - val_accuracy: 0.5377 - val_loss: 2.3570 - learning_rate: 8.1168e-06
Epoch 179/300

Epoch 179: ReduceLROnPlateau reducing learning rate to 4.058407739648828e-06.
657/657 - 62s - 95ms/step - accuracy: 0.3909 - loss: 3.0833 - val_accuracy: 0.5411 - val_loss: 2.3674 - learning_rate: 8.1168e-06
Epoch 180/300
657/657 - 62s - 94ms/step - accuracy: 0.3926 - loss: 3.0841 - val_accuracy: 0.5394 - val_loss: 2.3594 - learning_rate: 4.0584e-06
Epoch 181/300
657/657 - 63s - 96ms/step - accuracy: 0.3960 - loss: 3.0908 - val_accuracy: 0.5394 - val_loss: 2.3501 - learning_rate: 4.0584e-06
Epoch 182/300
657/657 - 62s - 94ms/step - accuracy: 0.3973 - loss: 3.0970 - val_accuracy: 0.5428 - val_loss: 2.3482 - learning_rate: 4.0584e-06
Epoch 183/300
657/657 - 62s - 95ms/step - accuracy: 0.4042 - loss: 3.0546 - val_accuracy: 0.5377 - val_loss: 2.3536 - learning_rate: 4.0584e-06
Epoch 184/300
657/657 - 60s - 92ms/step - accuracy: 0.4038 - loss: 3.0472 - val_accuracy: 0.5411 - val_loss: 2.3500 - learning_rate: 4.0584e-06
Epoch 185/300
657/657 - 62s - 95ms/step - accuracy: 0.3924 - loss: 3.0732 - val_accuracy: 0.5360 - val_loss: 2.3426 - learning_rate: 4.0584e-06
Epoch 186/300
657/657 - 64s - 97ms/step - accuracy: 0.4006 - loss: 3.0628 - val_accuracy: 0.5428 - val_loss: 2.3602 - learning_rate: 4.0584e-06
Epoch 187/300
657/657 - 60s - 92ms/step - accuracy: 0.3924 - loss: 3.0739 - val_accuracy: 0.5462 - val_loss: 2.3507 - learning_rate: 4.0584e-06
Epoch 188/300
657/657 - 61s - 93ms/step - accuracy: 0.3874 - loss: 3.1200 - val_accuracy: 0.5411 - val_loss: 2.3614 - learning_rate: 4.0584e-06
Epoch 189/300
657/657 - 61s - 93ms/step - accuracy: 0.4004 - loss: 3.0522 - val_accuracy: 0.5411 - val_loss: 2.3516 - learning_rate: 4.0584e-06
Epoch 190/300
657/657 - 63s - 96ms/step - accuracy: 0.3939 - loss: 3.0768 - val_accuracy: 0.5411 - val_loss: 2.3520 - learning_rate: 4.0584e-06
Epoch 191/300
657/657 - 60s - 91ms/step - accuracy: 0.3951 - loss: 3.0754 - val_accuracy: 0.5411 - val_loss: 2.3529 - learning_rate: 4.0584e-06
Epoch 192/300
657/657 - 62s - 95ms/step - accuracy: 0.3888 - loss: 3.0849 - val_accuracy: 0.5479 - val_loss: 2.3550 - learning_rate: 4.0584e-06
Epoch 193/300

Epoch 193: ReduceLROnPlateau reducing learning rate to 2.029203869824414e-06.
657/657 - 64s - 98ms/step - accuracy: 0.3994 - loss: 3.0868 - val_accuracy: 0.5360 - val_loss: 2.3686 - learning_rate: 4.0584e-06
Epoch 194/300
657/657 - 80s - 122ms/step - accuracy: 0.4011 - loss: 3.0411 - val_accuracy: 0.5360 - val_loss: 2.3531 - learning_rate: 2.0292e-06
Epoch 195/300
657/657 - 62s - 95ms/step - accuracy: 0.3907 - loss: 3.0684 - val_accuracy: 0.5411 - val_loss: 2.3657 - learning_rate: 2.0292e-06
Epoch 196/300
657/657 - 60s - 92ms/step - accuracy: 0.3983 - loss: 3.0289 - val_accuracy: 0.5497 - val_loss: 2.3476 - learning_rate: 2.0292e-06
Epoch 197/300
657/657 - 61s - 93ms/step - accuracy: 0.3897 - loss: 3.0857 - val_accuracy: 0.5479 - val_loss: 2.3604 - learning_rate: 2.0292e-06
Epoch 198/300
657/657 - 62s - 95ms/step - accuracy: 0.3935 - loss: 3.0728 - val_accuracy: 0.5342 - val_loss: 2.3555 - learning_rate: 2.0292e-06
Epoch 199/300
657/657 - 63s - 95ms/step - accuracy: 0.3899 - loss: 3.0925 - val_accuracy: 0.5479 - val_loss: 2.3512 - learning_rate: 2.0292e-06
Epoch 200/300
657/657 - 61s - 92ms/step - accuracy: 0.3998 - loss: 3.0697 - val_accuracy: 0.5445 - val_loss: 2.3558 - learning_rate: 2.0292e-06
Epoch 201/300

Epoch 201: ReduceLROnPlateau reducing learning rate to 1.014601934912207e-06.
657/657 - 62s - 95ms/step - accuracy: 0.4000 - loss: 3.0467 - val_accuracy: 0.5428 - val_loss: 2.3574 - learning_rate: 2.0292e-06
Epoch 201: early stopping
Restoring model weights from the end of the best epoch: 185.
Fold 2 Evaluation results: [2.3497259616851807, 0.5359588861465454]
              precision    recall  f1-score   support

        1820       0.71      0.84      0.77        43
        1821       0.00      0.00      0.00         0
        1822       0.00      0.00      0.00         1
        1823       1.00      1.00      1.00         1
        1824       0.00      0.00      0.00         0
        1825       0.00      0.00      0.00         1
        1826       0.00      0.00      0.00         1
        1827       1.00      0.25      0.40         8
        1828       0.00      0.00      0.00         1
        1829       0.60      0.75      0.67         4
        1830       0.64      0.82      0.72        45
        1831       0.00      0.00      0.00         1
        1832       0.96      0.94      0.95        53
        1833       0.82      0.95      0.88        19
        1834       1.00      0.14      0.25         7
        1835       0.00      0.00      0.00         2
        1836       0.00      0.00      0.00         3
        1837       0.25      0.67      0.36         6
        1838       0.50      0.25      0.33         4
        1839       0.00      0.00      0.00         1
        1840       0.51      0.60      0.55        43
        1841       1.00      0.45      0.62        11
        1842       0.83      0.83      0.83         6
        1843       0.67      0.33      0.44         6
        1844       0.00      0.00      0.00         1
        1845       0.00      0.00      0.00         1
        1846       1.00      0.17      0.29         6
        1847       0.00      0.00      0.00         2
        1848       0.17      0.20      0.18         5
        1849       0.25      0.17      0.20         6
        1850       0.36      0.66      0.47        47
        1851       0.00      0.00      0.00         7
        1852       0.00      0.00      0.00         8
        1853       0.50      0.17      0.25         6
        1854       0.00      0.00      0.00         2
        1855       0.25      0.20      0.22        10
        1856       0.75      0.75      0.75        12
        1857       0.67      0.29      0.40         7
        1858       0.00      0.00      0.00         3
        1859       0.00      0.00      0.00         3
        1860       0.36      0.44      0.40        48
        1861       0.00      0.00      0.00         2
        1862       0.00      0.00      0.00         7
        1863       0.38      0.60      0.46         5
        1864       1.00      0.50      0.67         6
        1865       1.00      0.17      0.29         6
        1866       0.14      0.20      0.17         5
        1867       0.27      0.30      0.29        10
        1868       0.00      0.00      0.00         7
        1869       0.00      0.00      0.00         5
        1870       0.32      0.53      0.40        30
        1871       1.00      0.20      0.33         5
        1872       0.20      0.29      0.24         7
        1873       0.00      0.00      0.00        11
        1874       0.50      0.40      0.44         5
        1875       0.62      0.83      0.71         6
        1876       0.90      0.90      0.90        10
        1877       0.50      0.60      0.55         5
        1878       0.67      0.44      0.53         9
        1879       0.00      0.00      0.00         2

    accuracy                           0.54       584
   macro avg       0.37      0.30      0.30       584
weighted avg       0.53      0.54      0.50       584

Matthews Correlation Coefficient: 0.510
Macro avg F1: 0.298
Weighted avg F1: 0.502
Micro avg F1: 0.536
Top-3 Accuracy: 0.786
Top-5 Accuracy: 0.849
Micro ROC AUC  = 0.97
Macro ROC AUC (present classes) = 0.95
Classification MAE (in years): 3.79

Fold 2 Misclassification Analysis:
Near misses (within 2 years): 72 out of 271 misclassifications (26.57%)
Big misses (greater than 10 years): 88
MAE with outliers: 3.79
MAE without outliers: 2.46 (improvement: 1.33)

10 Worst misclassifications:
Image: data/datasets/public/1870/1877_033met.jpg, True: 1877, Predicted: 1820, Error: 57
Image: data/datasets/public/1820/1820_10wikimedia2.jpg, True: 1820, Predicted: 1876, Error: 56
Image: data/datasets/public/1870/1870_035met.jpg, True: 1870, Predicted: 1820, Error: 50
Image: data/datasets/public/1870/1879_9wikimedia2.jpg, True: 1879, Predicted: 1830, Error: 49
Image: data/datasets/public/1820/1820_044met.jpg, True: 1820, Predicted: 1867, Error: 47
Image: data/datasets/public/1820/1827_39wikimedia2.jpg, True: 1827, Predicted: 1870, Error: 43
Image: data/datasets/public/1870/1870_73wikimedia2.jpg, True: 1870, Predicted: 1830, Error: 40
Image: data/datasets/public/1820/1820_028met.jpg, True: 1820, Predicted: 1860, Error: 40
Image: data/datasets/public/1860/1860_055met.jpg, True: 1860, Predicted: 1820, Error: 40
Image: data/datasets/public/1840/1840_13_001wikimedia2.jpg, True: 1840, Predicted: 1870, Error: 30

===== Fold 3 =====
=== Running on Public Data ===

===== Fine Tuning 9 layers! =====
Epoch 1/300
657/657 - 87s - 133ms/step - accuracy: 0.1018 - loss: 4.6381 - val_accuracy: 0.1490 - val_loss: 3.8844 - learning_rate: 2.5974e-04
Epoch 2/300
657/657 - 63s - 96ms/step - accuracy: 0.1625 - loss: 4.4025 - val_accuracy: 0.2534 - val_loss: 4.3236 - learning_rate: 2.5974e-04
Epoch 3/300
657/657 - 60s - 91ms/step - accuracy: 0.1878 - loss: 4.2773 - val_accuracy: 0.2774 - val_loss: 3.7282 - learning_rate: 2.5974e-04
Epoch 4/300
657/657 - 62s - 94ms/step - accuracy: 0.2063 - loss: 4.2055 - val_accuracy: 0.3065 - val_loss: 3.7238 - learning_rate: 2.5974e-04
Epoch 5/300
657/657 - 60s - 91ms/step - accuracy: 0.2232 - loss: 4.1100 - val_accuracy: 0.3476 - val_loss: 3.8343 - learning_rate: 2.5974e-04
Epoch 6/300
657/657 - 65s - 99ms/step - accuracy: 0.2284 - loss: 4.1414 - val_accuracy: 0.3562 - val_loss: 3.5988 - learning_rate: 2.5974e-04
Epoch 7/300
657/657 - 62s - 95ms/step - accuracy: 0.2495 - loss: 4.0846 - val_accuracy: 0.3408 - val_loss: 3.4401 - learning_rate: 2.5974e-04
Epoch 8/300
657/657 - 62s - 94ms/step - accuracy: 0.2485 - loss: 4.0543 - val_accuracy: 0.3767 - val_loss: 3.5662 - learning_rate: 2.5974e-04
Epoch 9/300
657/657 - 62s - 94ms/step - accuracy: 0.2645 - loss: 3.9980 - val_accuracy: 0.3613 - val_loss: 3.3273 - learning_rate: 2.5974e-04
Epoch 10/300
657/657 - 64s - 97ms/step - accuracy: 0.2636 - loss: 3.9935 - val_accuracy: 0.3938 - val_loss: 3.3871 - learning_rate: 2.5974e-04
Epoch 11/300
657/657 - 62s - 95ms/step - accuracy: 0.2636 - loss: 3.9456 - val_accuracy: 0.3853 - val_loss: 3.3127 - learning_rate: 2.5974e-04
Epoch 12/300
657/657 - 61s - 93ms/step - accuracy: 0.2761 - loss: 3.9404 - val_accuracy: 0.3750 - val_loss: 3.2445 - learning_rate: 2.5974e-04
Epoch 13/300
657/657 - 63s - 96ms/step - accuracy: 0.2771 - loss: 3.9178 - val_accuracy: 0.4161 - val_loss: 3.2912 - learning_rate: 2.5974e-04
Epoch 14/300
657/657 - 62s - 95ms/step - accuracy: 0.2898 - loss: 3.8440 - val_accuracy: 0.3801 - val_loss: 3.2611 - learning_rate: 2.5974e-04
Epoch 15/300
657/657 - 62s - 94ms/step - accuracy: 0.2921 - loss: 3.8267 - val_accuracy: 0.4007 - val_loss: 3.2080 - learning_rate: 2.5974e-04
Epoch 16/300
657/657 - 63s - 96ms/step - accuracy: 0.2913 - loss: 3.8072 - val_accuracy: 0.4110 - val_loss: 3.1145 - learning_rate: 2.5974e-04
Epoch 17/300
657/657 - 81s - 124ms/step - accuracy: 0.3016 - loss: 3.7910 - val_accuracy: 0.4075 - val_loss: 3.0691 - learning_rate: 2.5974e-04
Epoch 18/300
657/657 - 62s - 95ms/step - accuracy: 0.2940 - loss: 3.7841 - val_accuracy: 0.3973 - val_loss: 3.0887 - learning_rate: 2.5974e-04
Epoch 19/300
657/657 - 62s - 95ms/step - accuracy: 0.3022 - loss: 3.7510 - val_accuracy: 0.4178 - val_loss: 3.1056 - learning_rate: 2.5974e-04
Epoch 20/300
657/657 - 63s - 96ms/step - accuracy: 0.3029 - loss: 3.6925 - val_accuracy: 0.4247 - val_loss: 2.9705 - learning_rate: 2.5974e-04
Epoch 21/300
657/657 - 59s - 90ms/step - accuracy: 0.3047 - loss: 3.6876 - val_accuracy: 0.4161 - val_loss: 2.9586 - learning_rate: 2.5974e-04
Epoch 22/300
657/657 - 64s - 97ms/step - accuracy: 0.3151 - loss: 3.6394 - val_accuracy: 0.4247 - val_loss: 2.9643 - learning_rate: 2.5974e-04
Epoch 23/300
657/657 - 63s - 96ms/step - accuracy: 0.3069 - loss: 3.7050 - val_accuracy: 0.4229 - val_loss: 3.0113 - learning_rate: 2.5974e-04
Epoch 24/300
657/657 - 61s - 93ms/step - accuracy: 0.3134 - loss: 3.6449 - val_accuracy: 0.4349 - val_loss: 2.9766 - learning_rate: 2.5974e-04
Epoch 25/300
657/657 - 64s - 97ms/step - accuracy: 0.3178 - loss: 3.6401 - val_accuracy: 0.4469 - val_loss: 2.9914 - learning_rate: 2.5974e-04
Epoch 26/300
657/657 - 62s - 95ms/step - accuracy: 0.3189 - loss: 3.6163 - val_accuracy: 0.4161 - val_loss: 2.9348 - learning_rate: 2.5974e-04
Epoch 27/300
657/657 - 63s - 96ms/step - accuracy: 0.3277 - loss: 3.6382 - val_accuracy: 0.4521 - val_loss: 2.9629 - learning_rate: 2.5974e-04
Epoch 28/300
657/657 - 62s - 94ms/step - accuracy: 0.3140 - loss: 3.6389 - val_accuracy: 0.4469 - val_loss: 2.8629 - learning_rate: 2.5974e-04
Epoch 29/300
657/657 - 64s - 97ms/step - accuracy: 0.3138 - loss: 3.6305 - val_accuracy: 0.4332 - val_loss: 2.8847 - learning_rate: 2.5974e-04
Epoch 30/300
657/657 - 61s - 93ms/step - accuracy: 0.3260 - loss: 3.6025 - val_accuracy: 0.4435 - val_loss: 2.8580 - learning_rate: 2.5974e-04
Epoch 31/300
657/657 - 62s - 95ms/step - accuracy: 0.3246 - loss: 3.5651 - val_accuracy: 0.4486 - val_loss: 2.8177 - learning_rate: 2.5974e-04
Epoch 32/300
657/657 - 63s - 96ms/step - accuracy: 0.3290 - loss: 3.5489 - val_accuracy: 0.4247 - val_loss: 2.8851 - learning_rate: 2.5974e-04
Epoch 33/300
657/657 - 63s - 96ms/step - accuracy: 0.3302 - loss: 3.5306 - val_accuracy: 0.4384 - val_loss: 2.8071 - learning_rate: 2.5974e-04
Epoch 34/300
657/657 - 63s - 96ms/step - accuracy: 0.3277 - loss: 3.5277 - val_accuracy: 0.4709 - val_loss: 2.8203 - learning_rate: 2.5974e-04
Epoch 35/300
657/657 - 61s - 93ms/step - accuracy: 0.3273 - loss: 3.5269 - val_accuracy: 0.4555 - val_loss: 2.8160 - learning_rate: 2.5974e-04
Epoch 36/300
657/657 - 64s - 98ms/step - accuracy: 0.3300 - loss: 3.5271 - val_accuracy: 0.4675 - val_loss: 2.7610 - learning_rate: 2.5974e-04
Epoch 37/300
657/657 - 64s - 97ms/step - accuracy: 0.3304 - loss: 3.5108 - val_accuracy: 0.4589 - val_loss: 2.7205 - learning_rate: 2.5974e-04
Epoch 38/300
657/657 - 61s - 93ms/step - accuracy: 0.3302 - loss: 3.5263 - val_accuracy: 0.4366 - val_loss: 2.7817 - learning_rate: 2.5974e-04
Epoch 39/300
657/657 - 62s - 95ms/step - accuracy: 0.3372 - loss: 3.4515 - val_accuracy: 0.4623 - val_loss: 2.7529 - learning_rate: 2.5974e-04
Epoch 40/300
657/657 - 62s - 94ms/step - accuracy: 0.3343 - loss: 3.4809 - val_accuracy: 0.4692 - val_loss: 2.7212 - learning_rate: 2.5974e-04
Epoch 41/300
657/657 - 62s - 95ms/step - accuracy: 0.3382 - loss: 3.4523 - val_accuracy: 0.4435 - val_loss: 2.8232 - learning_rate: 2.5974e-04
Epoch 42/300
657/657 - 63s - 96ms/step - accuracy: 0.3399 - loss: 3.4677 - val_accuracy: 0.4486 - val_loss: 2.7565 - learning_rate: 2.5974e-04
Epoch 43/300
657/657 - 62s - 94ms/step - accuracy: 0.3366 - loss: 3.4920 - val_accuracy: 0.4658 - val_loss: 2.7401 - learning_rate: 2.5974e-04
Epoch 44/300
657/657 - 63s - 96ms/step - accuracy: 0.3410 - loss: 3.4481 - val_accuracy: 0.4538 - val_loss: 2.7431 - learning_rate: 2.5974e-04
Epoch 45/300

Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0001298690476687625.
657/657 - 63s - 96ms/step - accuracy: 0.3393 - loss: 3.4595 - val_accuracy: 0.4521 - val_loss: 2.7666 - learning_rate: 2.5974e-04
Epoch 46/300
657/657 - 63s - 95ms/step - accuracy: 0.3490 - loss: 3.4043 - val_accuracy: 0.4658 - val_loss: 2.6722 - learning_rate: 1.2987e-04
Epoch 47/300
657/657 - 62s - 94ms/step - accuracy: 0.3488 - loss: 3.4232 - val_accuracy: 0.4726 - val_loss: 2.6572 - learning_rate: 1.2987e-04
Epoch 48/300
657/657 - 61s - 93ms/step - accuracy: 0.3500 - loss: 3.3707 - val_accuracy: 0.4675 - val_loss: 2.6959 - learning_rate: 1.2987e-04
Epoch 49/300
657/657 - 63s - 95ms/step - accuracy: 0.3538 - loss: 3.3675 - val_accuracy: 0.4675 - val_loss: 2.6247 - learning_rate: 1.2987e-04
Epoch 50/300
657/657 - 64s - 97ms/step - accuracy: 0.3423 - loss: 3.3959 - val_accuracy: 0.4640 - val_loss: 2.6478 - learning_rate: 1.2987e-04
Epoch 51/300
657/657 - 63s - 95ms/step - accuracy: 0.3498 - loss: 3.3926 - val_accuracy: 0.4675 - val_loss: 2.6469 - learning_rate: 1.2987e-04
Epoch 52/300
657/657 - 62s - 94ms/step - accuracy: 0.3530 - loss: 3.3617 - val_accuracy: 0.4709 - val_loss: 2.6316 - learning_rate: 1.2987e-04
Epoch 53/300
657/657 - 63s - 96ms/step - accuracy: 0.3604 - loss: 3.3650 - val_accuracy: 0.4709 - val_loss: 2.6494 - learning_rate: 1.2987e-04
Epoch 54/300
657/657 - 62s - 94ms/step - accuracy: 0.3560 - loss: 3.3354 - val_accuracy: 0.4760 - val_loss: 2.6619 - learning_rate: 1.2987e-04
Epoch 55/300
657/657 - 63s - 96ms/step - accuracy: 0.3595 - loss: 3.3768 - val_accuracy: 0.4777 - val_loss: 2.5905 - learning_rate: 1.2987e-04
Epoch 56/300
657/657 - 62s - 94ms/step - accuracy: 0.3458 - loss: 3.3710 - val_accuracy: 0.4760 - val_loss: 2.6165 - learning_rate: 1.2987e-04
Epoch 57/300
657/657 - 62s - 94ms/step - accuracy: 0.3604 - loss: 3.3357 - val_accuracy: 0.4692 - val_loss: 2.6133 - learning_rate: 1.2987e-04
Epoch 58/300
657/657 - 63s - 96ms/step - accuracy: 0.3517 - loss: 3.3505 - val_accuracy: 0.4795 - val_loss: 2.5758 - learning_rate: 1.2987e-04
Epoch 59/300
657/657 - 63s - 95ms/step - accuracy: 0.3484 - loss: 3.3815 - val_accuracy: 0.4880 - val_loss: 2.5987 - learning_rate: 1.2987e-04
Epoch 60/300
657/657 - 62s - 94ms/step - accuracy: 0.3536 - loss: 3.3659 - val_accuracy: 0.4897 - val_loss: 2.5968 - learning_rate: 1.2987e-04
Epoch 61/300
657/657 - 63s - 95ms/step - accuracy: 0.3597 - loss: 3.3222 - val_accuracy: 0.4897 - val_loss: 2.5796 - learning_rate: 1.2987e-04
Epoch 62/300
657/657 - 64s - 98ms/step - accuracy: 0.3676 - loss: 3.2922 - val_accuracy: 0.4897 - val_loss: 2.5769 - learning_rate: 1.2987e-04
Epoch 63/300
657/657 - 62s - 95ms/step - accuracy: 0.3562 - loss: 3.3738 - val_accuracy: 0.4914 - val_loss: 2.5975 - learning_rate: 1.2987e-04
Epoch 64/300
657/657 - 63s - 96ms/step - accuracy: 0.3637 - loss: 3.3341 - val_accuracy: 0.4829 - val_loss: 2.5731 - learning_rate: 1.2987e-04
Epoch 65/300
657/657 - 60s - 91ms/step - accuracy: 0.3690 - loss: 3.3027 - val_accuracy: 0.4932 - val_loss: 2.5655 - learning_rate: 1.2987e-04
Epoch 66/300
657/657 - 63s - 95ms/step - accuracy: 0.3553 - loss: 3.3138 - val_accuracy: 0.4795 - val_loss: 2.5730 - learning_rate: 1.2987e-04
Epoch 67/300
657/657 - 62s - 95ms/step - accuracy: 0.3503 - loss: 3.3243 - val_accuracy: 0.4897 - val_loss: 2.5701 - learning_rate: 1.2987e-04
Epoch 68/300
657/657 - 63s - 96ms/step - accuracy: 0.3640 - loss: 3.3089 - val_accuracy: 0.5000 - val_loss: 2.5514 - learning_rate: 1.2987e-04
Epoch 69/300
657/657 - 63s - 96ms/step - accuracy: 0.3673 - loss: 3.2738 - val_accuracy: 0.4812 - val_loss: 2.5764 - learning_rate: 1.2987e-04
Epoch 70/300
657/657 - 63s - 95ms/step - accuracy: 0.3724 - loss: 3.2679 - val_accuracy: 0.4897 - val_loss: 2.5413 - learning_rate: 1.2987e-04
Epoch 71/300
657/657 - 60s - 92ms/step - accuracy: 0.3568 - loss: 3.3207 - val_accuracy: 0.4932 - val_loss: 2.5726 - learning_rate: 1.2987e-04
Epoch 72/300
657/657 - 62s - 95ms/step - accuracy: 0.3635 - loss: 3.3068 - val_accuracy: 0.4880 - val_loss: 2.5576 - learning_rate: 1.2987e-04
Epoch 73/300
657/657 - 62s - 94ms/step - accuracy: 0.3610 - loss: 3.3087 - val_accuracy: 0.4760 - val_loss: 2.4998 - learning_rate: 1.2987e-04
Epoch 74/300
657/657 - 61s - 93ms/step - accuracy: 0.3648 - loss: 3.3184 - val_accuracy: 0.4829 - val_loss: 2.5413 - learning_rate: 1.2987e-04
Epoch 75/300
657/657 - 63s - 97ms/step - accuracy: 0.3650 - loss: 3.2969 - val_accuracy: 0.4880 - val_loss: 2.5493 - learning_rate: 1.2987e-04
Epoch 76/300
657/657 - 63s - 96ms/step - accuracy: 0.3656 - loss: 3.2880 - val_accuracy: 0.4983 - val_loss: 2.5293 - learning_rate: 1.2987e-04
Epoch 77/300
657/657 - 62s - 95ms/step - accuracy: 0.3619 - loss: 3.2892 - val_accuracy: 0.4846 - val_loss: 2.5539 - learning_rate: 1.2987e-04
Epoch 78/300
657/657 - 64s - 97ms/step - accuracy: 0.3608 - loss: 3.2327 - val_accuracy: 0.4760 - val_loss: 2.5316 - learning_rate: 1.2987e-04
Epoch 79/300
657/657 - 63s - 95ms/step - accuracy: 0.3627 - loss: 3.3089 - val_accuracy: 0.4777 - val_loss: 2.5490 - learning_rate: 1.2987e-04
Epoch 80/300
657/657 - 63s - 96ms/step - accuracy: 0.3675 - loss: 3.2662 - val_accuracy: 0.4760 - val_loss: 2.5686 - learning_rate: 1.2987e-04
Epoch 81/300

Epoch 81: ReduceLROnPlateau reducing learning rate to 6.493452383438125e-05.
657/657 - 63s - 95ms/step - accuracy: 0.3699 - loss: 3.2719 - val_accuracy: 0.4846 - val_loss: 2.5009 - learning_rate: 1.2987e-04
Epoch 82/300
657/657 - 63s - 96ms/step - accuracy: 0.3633 - loss: 3.2651 - val_accuracy: 0.4914 - val_loss: 2.5536 - learning_rate: 6.4935e-05
Epoch 83/300
657/657 - 61s - 93ms/step - accuracy: 0.3730 - loss: 3.2511 - val_accuracy: 0.4914 - val_loss: 2.5010 - learning_rate: 6.4935e-05
Epoch 84/300
657/657 - 63s - 95ms/step - accuracy: 0.3775 - loss: 3.2356 - val_accuracy: 0.4829 - val_loss: 2.5162 - learning_rate: 6.4935e-05
Epoch 85/300
657/657 - 64s - 98ms/step - accuracy: 0.3684 - loss: 3.2596 - val_accuracy: 0.4880 - val_loss: 2.5132 - learning_rate: 6.4935e-05
Epoch 86/300
657/657 - 63s - 96ms/step - accuracy: 0.3692 - loss: 3.2339 - val_accuracy: 0.4932 - val_loss: 2.4800 - learning_rate: 6.4935e-05
Epoch 87/300
657/657 - 63s - 96ms/step - accuracy: 0.3709 - loss: 3.2331 - val_accuracy: 0.4812 - val_loss: 2.5026 - learning_rate: 6.4935e-05
Epoch 88/300
657/657 - 61s - 93ms/step - accuracy: 0.3768 - loss: 3.2360 - val_accuracy: 0.4846 - val_loss: 2.4817 - learning_rate: 6.4935e-05
Epoch 89/300
657/657 - 63s - 96ms/step - accuracy: 0.3734 - loss: 3.2581 - val_accuracy: 0.4846 - val_loss: 2.4938 - learning_rate: 6.4935e-05
Epoch 90/300
657/657 - 63s - 96ms/step - accuracy: 0.3863 - loss: 3.2151 - val_accuracy: 0.4914 - val_loss: 2.5026 - learning_rate: 6.4935e-05
Epoch 91/300
657/657 - 62s - 94ms/step - accuracy: 0.3764 - loss: 3.2208 - val_accuracy: 0.4897 - val_loss: 2.5094 - learning_rate: 6.4935e-05
Epoch 92/300
657/657 - 60s - 92ms/step - accuracy: 0.3787 - loss: 3.2239 - val_accuracy: 0.4846 - val_loss: 2.5186 - learning_rate: 6.4935e-05
Epoch 93/300
657/657 - 63s - 96ms/step - accuracy: 0.3770 - loss: 3.2128 - val_accuracy: 0.4880 - val_loss: 2.5076 - learning_rate: 6.4935e-05
Epoch 94/300
657/657 - 63s - 96ms/step - accuracy: 0.3646 - loss: 3.2484 - val_accuracy: 0.4932 - val_loss: 2.4710 - learning_rate: 6.4935e-05
Epoch 95/300
657/657 - 62s - 94ms/step - accuracy: 0.3682 - loss: 3.2117 - val_accuracy: 0.4914 - val_loss: 2.4837 - learning_rate: 6.4935e-05
Epoch 96/300
657/657 - 63s - 96ms/step - accuracy: 0.3726 - loss: 3.2466 - val_accuracy: 0.4932 - val_loss: 2.4879 - learning_rate: 6.4935e-05
Epoch 97/300
657/657 - 63s - 96ms/step - accuracy: 0.3656 - loss: 3.2845 - val_accuracy: 0.5103 - val_loss: 2.5178 - learning_rate: 6.4935e-05
Epoch 98/300
657/657 - 61s - 94ms/step - accuracy: 0.3659 - loss: 3.2586 - val_accuracy: 0.4795 - val_loss: 2.4658 - learning_rate: 6.4935e-05
Epoch 99/300
657/657 - 62s - 94ms/step - accuracy: 0.3755 - loss: 3.2217 - val_accuracy: 0.4983 - val_loss: 2.4737 - learning_rate: 6.4935e-05
Epoch 100/300
657/657 - 63s - 95ms/step - accuracy: 0.3753 - loss: 3.2471 - val_accuracy: 0.4966 - val_loss: 2.4954 - learning_rate: 6.4935e-05
Epoch 101/300
657/657 - 60s - 91ms/step - accuracy: 0.3821 - loss: 3.2223 - val_accuracy: 0.5000 - val_loss: 2.4706 - learning_rate: 6.4935e-05
Epoch 102/300
657/657 - 62s - 94ms/step - accuracy: 0.3741 - loss: 3.2127 - val_accuracy: 0.4949 - val_loss: 2.4447 - learning_rate: 6.4935e-05
Epoch 103/300
657/657 - 63s - 97ms/step - accuracy: 0.3808 - loss: 3.2516 - val_accuracy: 0.4966 - val_loss: 2.5049 - learning_rate: 6.4935e-05
Epoch 104/300
657/657 - 62s - 95ms/step - accuracy: 0.3709 - loss: 3.2396 - val_accuracy: 0.4932 - val_loss: 2.4629 - learning_rate: 6.4935e-05
Epoch 105/300
657/657 - 62s - 94ms/step - accuracy: 0.3791 - loss: 3.2130 - val_accuracy: 0.4897 - val_loss: 2.4613 - learning_rate: 6.4935e-05
Epoch 106/300
657/657 - 63s - 95ms/step - accuracy: 0.3669 - loss: 3.2396 - val_accuracy: 0.4983 - val_loss: 2.4646 - learning_rate: 6.4935e-05
Epoch 107/300
657/657 - 62s - 94ms/step - accuracy: 0.3728 - loss: 3.2191 - val_accuracy: 0.5103 - val_loss: 2.4892 - learning_rate: 6.4935e-05
Epoch 108/300
657/657 - 63s - 95ms/step - accuracy: 0.3783 - loss: 3.2099 - val_accuracy: 0.5103 - val_loss: 2.4714 - learning_rate: 6.4935e-05
Epoch 109/300
657/657 - 63s - 96ms/step - accuracy: 0.3768 - loss: 3.2110 - val_accuracy: 0.5051 - val_loss: 2.4997 - learning_rate: 6.4935e-05
Epoch 110/300

Epoch 110: ReduceLROnPlateau reducing learning rate to 3.2467261917190626e-05.
657/657 - 59s - 90ms/step - accuracy: 0.3720 - loss: 3.2249 - val_accuracy: 0.4897 - val_loss: 2.4500 - learning_rate: 6.4935e-05
Epoch 111/300
657/657 - 82s - 124ms/step - accuracy: 0.3779 - loss: 3.1694 - val_accuracy: 0.4966 - val_loss: 2.4694 - learning_rate: 3.2467e-05
Epoch 112/300
657/657 - 63s - 97ms/step - accuracy: 0.3768 - loss: 3.2095 - val_accuracy: 0.4966 - val_loss: 2.4709 - learning_rate: 3.2467e-05
Epoch 113/300
657/657 - 62s - 94ms/step - accuracy: 0.3791 - loss: 3.1894 - val_accuracy: 0.4949 - val_loss: 2.4490 - learning_rate: 3.2467e-05
Epoch 114/300
657/657 - 63s - 96ms/step - accuracy: 0.3800 - loss: 3.1873 - val_accuracy: 0.4966 - val_loss: 2.4920 - learning_rate: 3.2467e-05
Epoch 115/300
657/657 - 63s - 96ms/step - accuracy: 0.3781 - loss: 3.1865 - val_accuracy: 0.4949 - val_loss: 2.4636 - learning_rate: 3.2467e-05
Epoch 116/300
657/657 - 63s - 95ms/step - accuracy: 0.3756 - loss: 3.2202 - val_accuracy: 0.4966 - val_loss: 2.4755 - learning_rate: 3.2467e-05
Epoch 117/300
657/657 - 63s - 95ms/step - accuracy: 0.3812 - loss: 3.1850 - val_accuracy: 0.4914 - val_loss: 2.4369 - learning_rate: 3.2467e-05
Epoch 118/300
657/657 - 63s - 95ms/step - accuracy: 0.3722 - loss: 3.1927 - val_accuracy: 0.4880 - val_loss: 2.4642 - learning_rate: 3.2467e-05
Epoch 119/300
657/657 - 61s - 93ms/step - accuracy: 0.3766 - loss: 3.1755 - val_accuracy: 0.5000 - val_loss: 2.4240 - learning_rate: 3.2467e-05
Epoch 120/300
657/657 - 62s - 94ms/step - accuracy: 0.3924 - loss: 3.1305 - val_accuracy: 0.5000 - val_loss: 2.4300 - learning_rate: 3.2467e-05
Epoch 121/300
657/657 - 63s - 95ms/step - accuracy: 0.3831 - loss: 3.1790 - val_accuracy: 0.4897 - val_loss: 2.4352 - learning_rate: 3.2467e-05
Epoch 122/300
657/657 - 63s - 96ms/step - accuracy: 0.3718 - loss: 3.2018 - val_accuracy: 0.4983 - val_loss: 2.4475 - learning_rate: 3.2467e-05
Epoch 123/300
657/657 - 62s - 95ms/step - accuracy: 0.3823 - loss: 3.1519 - val_accuracy: 0.4932 - val_loss: 2.4440 - learning_rate: 3.2467e-05
Epoch 124/300
657/657 - 63s - 96ms/step - accuracy: 0.3777 - loss: 3.1755 - val_accuracy: 0.4914 - val_loss: 2.4361 - learning_rate: 3.2467e-05
Epoch 125/300
657/657 - 61s - 93ms/step - accuracy: 0.3873 - loss: 3.1397 - val_accuracy: 0.4949 - val_loss: 2.4442 - learning_rate: 3.2467e-05
Epoch 126/300
657/657 - 64s - 97ms/step - accuracy: 0.3823 - loss: 3.1990 - val_accuracy: 0.5000 - val_loss: 2.4290 - learning_rate: 3.2467e-05
Epoch 127/300
657/657 - 61s - 92ms/step - accuracy: 0.3842 - loss: 3.1442 - val_accuracy: 0.4880 - val_loss: 2.3969 - learning_rate: 3.2467e-05
Epoch 128/300
657/657 - 64s - 97ms/step - accuracy: 0.3844 - loss: 3.1759 - val_accuracy: 0.5000 - val_loss: 2.4465 - learning_rate: 3.2467e-05
Epoch 129/300
657/657 - 64s - 97ms/step - accuracy: 0.3793 - loss: 3.1769 - val_accuracy: 0.4914 - val_loss: 2.4660 - learning_rate: 3.2467e-05
Epoch 130/300
657/657 - 61s - 93ms/step - accuracy: 0.3745 - loss: 3.1916 - val_accuracy: 0.4897 - val_loss: 2.4206 - learning_rate: 3.2467e-05
Epoch 131/300
657/657 - 64s - 97ms/step - accuracy: 0.3911 - loss: 3.1723 - val_accuracy: 0.4983 - val_loss: 2.4217 - learning_rate: 3.2467e-05
Epoch 132/300
657/657 - 62s - 95ms/step - accuracy: 0.3831 - loss: 3.1272 - val_accuracy: 0.4914 - val_loss: 2.4194 - learning_rate: 3.2467e-05
Epoch 133/300
657/657 - 61s - 93ms/step - accuracy: 0.3865 - loss: 3.1709 - val_accuracy: 0.5017 - val_loss: 2.4270 - learning_rate: 3.2467e-05
Epoch 134/300
657/657 - 61s - 94ms/step - accuracy: 0.3802 - loss: 3.1923 - val_accuracy: 0.4914 - val_loss: 2.4357 - learning_rate: 3.2467e-05
Epoch 135/300

Epoch 135: ReduceLROnPlateau reducing learning rate to 1.6233630958595313e-05.
657/657 - 83s - 127ms/step - accuracy: 0.3804 - loss: 3.2018 - val_accuracy: 0.5068 - val_loss: 2.4450 - learning_rate: 3.2467e-05
Epoch 136/300
657/657 - 60s - 92ms/step - accuracy: 0.3852 - loss: 3.1216 - val_accuracy: 0.5000 - val_loss: 2.4111 - learning_rate: 1.6234e-05
Epoch 137/300
657/657 - 63s - 96ms/step - accuracy: 0.3873 - loss: 3.1345 - val_accuracy: 0.4983 - val_loss: 2.4078 - learning_rate: 1.6234e-05
Epoch 138/300
657/657 - 61s - 92ms/step - accuracy: 0.3751 - loss: 3.1694 - val_accuracy: 0.5000 - val_loss: 2.4404 - learning_rate: 1.6234e-05
Epoch 139/300
657/657 - 62s - 95ms/step - accuracy: 0.3855 - loss: 3.1710 - val_accuracy: 0.5051 - val_loss: 2.4167 - learning_rate: 1.6234e-05
Epoch 140/300
657/657 - 63s - 95ms/step - accuracy: 0.3914 - loss: 3.1072 - val_accuracy: 0.5051 - val_loss: 2.4225 - learning_rate: 1.6234e-05
Epoch 141/300
657/657 - 62s - 95ms/step - accuracy: 0.3901 - loss: 3.1469 - val_accuracy: 0.4932 - val_loss: 2.4250 - learning_rate: 1.6234e-05
Epoch 142/300
657/657 - 61s - 92ms/step - accuracy: 0.3916 - loss: 3.1672 - val_accuracy: 0.5000 - val_loss: 2.4327 - learning_rate: 1.6234e-05
Epoch 143/300

Epoch 143: ReduceLROnPlateau reducing learning rate to 8.116815479297657e-06.
657/657 - 63s - 96ms/step - accuracy: 0.3865 - loss: 3.1572 - val_accuracy: 0.5000 - val_loss: 2.4244 - learning_rate: 1.6234e-05
Epoch 143: early stopping
Restoring model weights from the end of the best epoch: 127.
Fold 3 Evaluation results: [2.4103455543518066, 0.48801368474960327]
              precision    recall  f1-score   support

        1820       0.65      0.84      0.73        43
        1821       0.00      0.00      0.00         1
        1822       0.00      0.00      0.00         1
        1823       0.00      0.00      0.00         2
        1824       0.00      0.00      0.00         1
        1825       0.00      0.00      0.00         1
        1826       0.00      0.00      0.00         1
        1827       0.00      0.00      0.00         8
        1828       0.00      0.00      0.00         2
        1829       0.50      0.75      0.60         4
        1830       0.49      0.76      0.59        45
        1831       0.00      0.00      0.00         1
        1832       0.89      0.91      0.90        53
        1833       0.92      0.63      0.75        19
        1834       0.00      0.00      0.00         6
        1835       0.00      0.00      0.00         2
        1836       0.00      0.00      0.00         4
        1837       0.27      0.50      0.35         6
        1838       0.00      0.00      0.00         4
        1839       0.00      0.00      0.00         0
        1840       0.56      0.65      0.60        43
        1841       0.44      0.36      0.40        11
        1842       1.00      0.17      0.29         6
        1843       0.00      0.00      0.00         6
        1844       0.00      0.00      0.00         0
        1845       0.00      0.00      0.00         1
        1846       0.50      0.33      0.40         6
        1847       0.00      0.00      0.00         2
        1848       0.20      0.40      0.27         5
        1849       0.33      0.17      0.22         6
        1850       0.36      0.77      0.49        47
        1851       0.00      0.00      0.00         7
        1852       0.00      0.00      0.00         8
        1853       0.00      0.00      0.00         6
        1854       0.00      0.00      0.00         2
        1855       0.00      0.00      0.00        10
        1856       0.89      0.67      0.76        12
        1857       0.00      0.00      0.00         7
        1858       0.00      0.00      0.00         3
        1859       0.00      0.00      0.00         2
        1860       0.36      0.44      0.39        48
        1861       0.00      0.00      0.00         1
        1862       0.00      0.00      0.00         7
        1863       0.00      0.00      0.00         5
        1864       1.00      0.17      0.29         6
        1865       0.75      0.43      0.55         7
        1866       0.50      0.20      0.29         5
        1867       0.42      0.50      0.45        10
        1868       0.00      0.00      0.00         7
        1869       0.00      0.00      0.00         5
        1870       0.25      0.50      0.34        30
        1871       0.00      0.00      0.00         5
        1872       0.25      0.14      0.18         7
        1873       0.00      0.00      0.00        11
        1874       0.00      0.00      0.00         5
        1875       0.33      0.33      0.33         6
        1876       1.00      0.70      0.82        10
        1877       0.38      0.60      0.46         5
        1878       0.80      0.89      0.84         9
        1879       0.00      0.00      0.00         1

    accuracy                           0.49       584
   macro avg       0.23      0.21      0.20       584
weighted avg       0.43      0.49      0.44       584

Matthews Correlation Coefficient: 0.458
Macro avg F1: 0.205
Weighted avg F1: 0.437
Micro avg F1: 0.488
Top-3 Accuracy: 0.755
Top-5 Accuracy: 0.842
Micro ROC AUC  = 0.97
Macro ROC AUC (present classes) = 0.96
Classification MAE (in years): 3.95

Fold 3 Misclassification Analysis:
Near misses (within 2 years): 67 out of 299 misclassifications (22.41%)
Big misses (greater than 10 years): 96
MAE with outliers: 3.95
MAE without outliers: 2.83 (improvement: 1.12)

10 Worst misclassifications:
Image: data/datasets/public/1870/1876_70washington.jpg, True: 1876, Predicted: 1820, Error: 56
Image: data/datasets/public/1870/1870_82wikimedia2.jpg, True: 1870, Predicted: 1820, Error: 50
Image: data/datasets/public/1870/1870_79wikimedia2.jpg, True: 1870, Predicted: 1820, Error: 50
Image: data/datasets/public/1870/1876_71washington.jpg, True: 1876, Predicted: 1830, Error: 46
Image: data/datasets/public/1860/1868_41washington.jpg, True: 1868, Predicted: 1830, Error: 38
Image: data/datasets/public/1860/1867_130met.jpg, True: 1867, Predicted: 1830, Error: 37
Image: data/datasets/public/1870/1875_38washington.jpg, True: 1875, Predicted: 1840, Error: 35
Image: data/datasets/public/1870/1870_62wikimedia2.jpg, True: 1870, Predicted: 1840, Error: 30
Image: data/datasets/public/1840/1848_48washington.jpg, True: 1848, Predicted: 1878, Error: 30
Image: data/datasets/public/1820/1820_027met.jpg, True: 1820, Predicted: 1850, Error: 30

===== Fold 4 =====
=== Running on Public Data ===

===== Fine Tuning 9 layers! =====
Epoch 1/300
657/657 - 85s - 129ms/step - accuracy: 0.1081 - loss: 4.6520 - val_accuracy: 0.2346 - val_loss: 4.4963 - learning_rate: 2.5974e-04
Epoch 2/300
657/657 - 62s - 95ms/step - accuracy: 0.1642 - loss: 4.4005 - val_accuracy: 0.2380 - val_loss: 4.1701 - learning_rate: 2.5974e-04
Epoch 3/300
657/657 - 64s - 97ms/step - accuracy: 0.1943 - loss: 4.3125 - val_accuracy: 0.2432 - val_loss: 3.9372 - learning_rate: 2.5974e-04
Epoch 4/300
657/657 - 63s - 96ms/step - accuracy: 0.2166 - loss: 4.2132 - val_accuracy: 0.2945 - val_loss: 3.8437 - learning_rate: 2.5974e-04
Epoch 5/300
657/657 - 62s - 94ms/step - accuracy: 0.2365 - loss: 4.1406 - val_accuracy: 0.3065 - val_loss: 3.8224 - learning_rate: 2.5974e-04
Epoch 6/300
657/657 - 63s - 97ms/step - accuracy: 0.2426 - loss: 4.1122 - val_accuracy: 0.3099 - val_loss: 3.9102 - learning_rate: 2.5974e-04
Epoch 7/300
657/657 - 63s - 95ms/step - accuracy: 0.2480 - loss: 4.0866 - val_accuracy: 0.3253 - val_loss: 3.6705 - learning_rate: 2.5974e-04
Epoch 8/300
657/657 - 63s - 96ms/step - accuracy: 0.2567 - loss: 4.0199 - val_accuracy: 0.3271 - val_loss: 3.6092 - learning_rate: 2.5974e-04
Epoch 9/300
657/657 - 63s - 95ms/step - accuracy: 0.2706 - loss: 3.9752 - val_accuracy: 0.3425 - val_loss: 3.4875 - learning_rate: 2.5974e-04
Epoch 10/300
657/657 - 59s - 90ms/step - accuracy: 0.2714 - loss: 3.9319 - val_accuracy: 0.3647 - val_loss: 3.3999 - learning_rate: 2.5974e-04
Epoch 11/300
657/657 - 63s - 96ms/step - accuracy: 0.2771 - loss: 3.8963 - val_accuracy: 0.3442 - val_loss: 3.3946 - learning_rate: 2.5974e-04
Epoch 12/300
657/657 - 63s - 97ms/step - accuracy: 0.2826 - loss: 3.8836 - val_accuracy: 0.3596 - val_loss: 3.2190 - learning_rate: 2.5974e-04
Epoch 13/300
657/657 - 61s - 93ms/step - accuracy: 0.2849 - loss: 3.8406 - val_accuracy: 0.3647 - val_loss: 3.2480 - learning_rate: 2.5974e-04
Epoch 14/300
657/657 - 62s - 95ms/step - accuracy: 0.2839 - loss: 3.8071 - val_accuracy: 0.3750 - val_loss: 3.2596 - learning_rate: 2.5974e-04
Epoch 15/300
657/657 - 63s - 96ms/step - accuracy: 0.2891 - loss: 3.8134 - val_accuracy: 0.3818 - val_loss: 3.1169 - learning_rate: 2.5974e-04
Epoch 16/300
657/657 - 82s - 124ms/step - accuracy: 0.2936 - loss: 3.7875 - val_accuracy: 0.3613 - val_loss: 3.1525 - learning_rate: 2.5974e-04
Epoch 17/300
657/657 - 63s - 96ms/step - accuracy: 0.2944 - loss: 3.7450 - val_accuracy: 0.3836 - val_loss: 3.1906 - learning_rate: 2.5974e-04
Epoch 18/300
657/657 - 64s - 97ms/step - accuracy: 0.3047 - loss: 3.7485 - val_accuracy: 0.4058 - val_loss: 3.1271 - learning_rate: 2.5974e-04
Epoch 19/300
657/657 - 62s - 94ms/step - accuracy: 0.2990 - loss: 3.7146 - val_accuracy: 0.3870 - val_loss: 3.0299 - learning_rate: 2.5974e-04
Epoch 20/300
657/657 - 63s - 96ms/step - accuracy: 0.3153 - loss: 3.6895 - val_accuracy: 0.3870 - val_loss: 3.1146 - learning_rate: 2.5974e-04
Epoch 21/300
657/657 - 62s - 95ms/step - accuracy: 0.3075 - loss: 3.6793 - val_accuracy: 0.3904 - val_loss: 3.0200 - learning_rate: 2.5974e-04
Epoch 22/300
657/657 - 63s - 96ms/step - accuracy: 0.3153 - loss: 3.6624 - val_accuracy: 0.4075 - val_loss: 3.0526 - learning_rate: 2.5974e-04
Epoch 23/300
657/657 - 63s - 95ms/step - accuracy: 0.3109 - loss: 3.6722 - val_accuracy: 0.3784 - val_loss: 2.9489 - learning_rate: 2.5974e-04
Epoch 24/300
657/657 - 63s - 96ms/step - accuracy: 0.3277 - loss: 3.5913 - val_accuracy: 0.4007 - val_loss: 3.0557 - learning_rate: 2.5974e-04
Epoch 25/300
657/657 - 63s - 95ms/step - accuracy: 0.3262 - loss: 3.6129 - val_accuracy: 0.4007 - val_loss: 2.9948 - learning_rate: 2.5974e-04
Epoch 26/300
657/657 - 62s - 95ms/step - accuracy: 0.3262 - loss: 3.5999 - val_accuracy: 0.4092 - val_loss: 2.9854 - learning_rate: 2.5974e-04
Epoch 27/300
657/657 - 62s - 95ms/step - accuracy: 0.3315 - loss: 3.5924 - val_accuracy: 0.4110 - val_loss: 2.9301 - learning_rate: 2.5974e-04
Epoch 28/300
657/657 - 60s - 92ms/step - accuracy: 0.3279 - loss: 3.6128 - val_accuracy: 0.4264 - val_loss: 2.9412 - learning_rate: 2.5974e-04
Epoch 29/300
657/657 - 62s - 94ms/step - accuracy: 0.3256 - loss: 3.5533 - val_accuracy: 0.4195 - val_loss: 2.9520 - learning_rate: 2.5974e-04
Epoch 30/300
657/657 - 62s - 94ms/step - accuracy: 0.3410 - loss: 3.5552 - val_accuracy: 0.4092 - val_loss: 2.9223 - learning_rate: 2.5974e-04
Epoch 31/300
657/657 - 63s - 96ms/step - accuracy: 0.3283 - loss: 3.5384 - val_accuracy: 0.4281 - val_loss: 2.9373 - learning_rate: 2.5974e-04
Epoch 32/300
657/657 - 61s - 94ms/step - accuracy: 0.3363 - loss: 3.4966 - val_accuracy: 0.4247 - val_loss: 2.9152 - learning_rate: 2.5974e-04
Epoch 33/300
657/657 - 62s - 95ms/step - accuracy: 0.3340 - loss: 3.5219 - val_accuracy: 0.4229 - val_loss: 2.9438 - learning_rate: 2.5974e-04
Epoch 34/300
657/657 - 63s - 96ms/step - accuracy: 0.3277 - loss: 3.5302 - val_accuracy: 0.4247 - val_loss: 2.9074 - learning_rate: 2.5974e-04
Epoch 35/300
657/657 - 61s - 93ms/step - accuracy: 0.3302 - loss: 3.5128 - val_accuracy: 0.4229 - val_loss: 2.8161 - learning_rate: 2.5974e-04
Epoch 36/300
657/657 - 62s - 94ms/step - accuracy: 0.3340 - loss: 3.5259 - val_accuracy: 0.4332 - val_loss: 2.8164 - learning_rate: 2.5974e-04
Epoch 37/300
657/657 - 62s - 94ms/step - accuracy: 0.3385 - loss: 3.4779 - val_accuracy: 0.4315 - val_loss: 2.8178 - learning_rate: 2.5974e-04
Epoch 38/300
657/657 - 62s - 94ms/step - accuracy: 0.3467 - loss: 3.4514 - val_accuracy: 0.4486 - val_loss: 2.8674 - learning_rate: 2.5974e-04
Epoch 39/300
657/657 - 63s - 96ms/step - accuracy: 0.3323 - loss: 3.4818 - val_accuracy: 0.4366 - val_loss: 2.7968 - learning_rate: 2.5974e-04
Epoch 40/300
657/657 - 62s - 94ms/step - accuracy: 0.3469 - loss: 3.4538 - val_accuracy: 0.4452 - val_loss: 2.7604 - learning_rate: 2.5974e-04
Epoch 41/300
657/657 - 62s - 94ms/step - accuracy: 0.3422 - loss: 3.4877 - val_accuracy: 0.4401 - val_loss: 2.7920 - learning_rate: 2.5974e-04
Epoch 42/300
657/657 - 63s - 95ms/step - accuracy: 0.3469 - loss: 3.4396 - val_accuracy: 0.4315 - val_loss: 2.8003 - learning_rate: 2.5974e-04
Epoch 43/300
657/657 - 62s - 95ms/step - accuracy: 0.3422 - loss: 3.4385 - val_accuracy: 0.4401 - val_loss: 2.7472 - learning_rate: 2.5974e-04
Epoch 44/300
657/657 - 64s - 98ms/step - accuracy: 0.3448 - loss: 3.4348 - val_accuracy: 0.4486 - val_loss: 2.7881 - learning_rate: 2.5974e-04
Epoch 45/300
657/657 - 59s - 89ms/step - accuracy: 0.3378 - loss: 3.4428 - val_accuracy: 0.4452 - val_loss: 2.7803 - learning_rate: 2.5974e-04
Epoch 46/300
657/657 - 64s - 97ms/step - accuracy: 0.3488 - loss: 3.4492 - val_accuracy: 0.4640 - val_loss: 2.7266 - learning_rate: 2.5974e-04
Epoch 47/300
657/657 - 62s - 94ms/step - accuracy: 0.3397 - loss: 3.4336 - val_accuracy: 0.4349 - val_loss: 2.8308 - learning_rate: 2.5974e-04
Epoch 48/300
657/657 - 63s - 96ms/step - accuracy: 0.3361 - loss: 3.4458 - val_accuracy: 0.4469 - val_loss: 2.7262 - learning_rate: 2.5974e-04
Epoch 49/300
657/657 - 64s - 97ms/step - accuracy: 0.3368 - loss: 3.4196 - val_accuracy: 0.4418 - val_loss: 2.7626 - learning_rate: 2.5974e-04
Epoch 50/300
657/657 - 63s - 96ms/step - accuracy: 0.3486 - loss: 3.4021 - val_accuracy: 0.4486 - val_loss: 2.7162 - learning_rate: 2.5974e-04
Epoch 51/300
657/657 - 62s - 94ms/step - accuracy: 0.3473 - loss: 3.4057 - val_accuracy: 0.4589 - val_loss: 2.6956 - learning_rate: 2.5974e-04
Epoch 52/300
657/657 - 61s - 93ms/step - accuracy: 0.3463 - loss: 3.4381 - val_accuracy: 0.4692 - val_loss: 2.6865 - learning_rate: 2.5974e-04
Epoch 53/300
657/657 - 63s - 96ms/step - accuracy: 0.3532 - loss: 3.4620 - val_accuracy: 0.4589 - val_loss: 2.7119 - learning_rate: 2.5974e-04
Epoch 54/300
657/657 - 60s - 91ms/step - accuracy: 0.3503 - loss: 3.3783 - val_accuracy: 0.4640 - val_loss: 2.6816 - learning_rate: 2.5974e-04
Epoch 55/300
657/657 - 64s - 97ms/step - accuracy: 0.3549 - loss: 3.3824 - val_accuracy: 0.4469 - val_loss: 2.6851 - learning_rate: 2.5974e-04
Epoch 56/300
657/657 - 62s - 94ms/step - accuracy: 0.3572 - loss: 3.3631 - val_accuracy: 0.4726 - val_loss: 2.6892 - learning_rate: 2.5974e-04
Epoch 57/300
657/657 - 61s - 93ms/step - accuracy: 0.3547 - loss: 3.3521 - val_accuracy: 0.4658 - val_loss: 2.6636 - learning_rate: 2.5974e-04
Epoch 58/300
657/657 - 63s - 96ms/step - accuracy: 0.3517 - loss: 3.3687 - val_accuracy: 0.4726 - val_loss: 2.6852 - learning_rate: 2.5974e-04
Epoch 59/300
657/657 - 62s - 94ms/step - accuracy: 0.3574 - loss: 3.3894 - val_accuracy: 0.4658 - val_loss: 2.6356 - learning_rate: 2.5974e-04
Epoch 60/300
657/657 - 61s - 93ms/step - accuracy: 0.3528 - loss: 3.3541 - val_accuracy: 0.4623 - val_loss: 2.6741 - learning_rate: 2.5974e-04
Epoch 61/300
657/657 - 63s - 96ms/step - accuracy: 0.3500 - loss: 3.3641 - val_accuracy: 0.4658 - val_loss: 2.6507 - learning_rate: 2.5974e-04
Epoch 62/300
657/657 - 62s - 94ms/step - accuracy: 0.3602 - loss: 3.3301 - val_accuracy: 0.4452 - val_loss: 2.6570 - learning_rate: 2.5974e-04
Epoch 63/300
657/657 - 61s - 93ms/step - accuracy: 0.3536 - loss: 3.3484 - val_accuracy: 0.4589 - val_loss: 2.6712 - learning_rate: 2.5974e-04
Epoch 64/300
657/657 - 61s - 93ms/step - accuracy: 0.3635 - loss: 3.3420 - val_accuracy: 0.4795 - val_loss: 2.6479 - learning_rate: 2.5974e-04
Epoch 65/300
657/657 - 63s - 96ms/step - accuracy: 0.3551 - loss: 3.3332 - val_accuracy: 0.4760 - val_loss: 2.6077 - learning_rate: 2.5974e-04
Epoch 66/300
657/657 - 62s - 95ms/step - accuracy: 0.3597 - loss: 3.3315 - val_accuracy: 0.4658 - val_loss: 2.6941 - learning_rate: 2.5974e-04
Epoch 67/300
657/657 - 63s - 96ms/step - accuracy: 0.3618 - loss: 3.3601 - val_accuracy: 0.4623 - val_loss: 2.6154 - learning_rate: 2.5974e-04
Epoch 68/300
657/657 - 62s - 94ms/step - accuracy: 0.3610 - loss: 3.3802 - val_accuracy: 0.4726 - val_loss: 2.6479 - learning_rate: 2.5974e-04
Epoch 69/300
657/657 - 63s - 96ms/step - accuracy: 0.3562 - loss: 3.3633 - val_accuracy: 0.4555 - val_loss: 2.5870 - learning_rate: 2.5974e-04
Epoch 70/300
657/657 - 62s - 95ms/step - accuracy: 0.3534 - loss: 3.3537 - val_accuracy: 0.4675 - val_loss: 2.6017 - learning_rate: 2.5974e-04
Epoch 71/300
657/657 - 63s - 95ms/step - accuracy: 0.3570 - loss: 3.3167 - val_accuracy: 0.4846 - val_loss: 2.5968 - learning_rate: 2.5974e-04
Epoch 72/300
657/657 - 60s - 92ms/step - accuracy: 0.3656 - loss: 3.3066 - val_accuracy: 0.4812 - val_loss: 2.6134 - learning_rate: 2.5974e-04
Epoch 73/300
657/657 - 63s - 95ms/step - accuracy: 0.3500 - loss: 3.3668 - val_accuracy: 0.4726 - val_loss: 2.6162 - learning_rate: 2.5974e-04
Epoch 74/300
657/657 - 63s - 95ms/step - accuracy: 0.3553 - loss: 3.3308 - val_accuracy: 0.4795 - val_loss: 2.5785 - learning_rate: 2.5974e-04
Epoch 75/300
657/657 - 61s - 92ms/step - accuracy: 0.3616 - loss: 3.2675 - val_accuracy: 0.4726 - val_loss: 2.5785 - learning_rate: 2.5974e-04
Epoch 76/300
657/657 - 62s - 95ms/step - accuracy: 0.3616 - loss: 3.3200 - val_accuracy: 0.4726 - val_loss: 2.5289 - learning_rate: 2.5974e-04
Epoch 77/300
657/657 - 63s - 97ms/step - accuracy: 0.3646 - loss: 3.3216 - val_accuracy: 0.4606 - val_loss: 2.5638 - learning_rate: 2.5974e-04
Epoch 78/300
657/657 - 61s - 92ms/step - accuracy: 0.3663 - loss: 3.3416 - val_accuracy: 0.4589 - val_loss: 2.5823 - learning_rate: 2.5974e-04
Epoch 79/300
657/657 - 62s - 94ms/step - accuracy: 0.3665 - loss: 3.2931 - val_accuracy: 0.4812 - val_loss: 2.5201 - learning_rate: 2.5974e-04
Epoch 80/300
657/657 - 62s - 94ms/step - accuracy: 0.3701 - loss: 3.2963 - val_accuracy: 0.5000 - val_loss: 2.5970 - learning_rate: 2.5974e-04
Epoch 81/300
657/657 - 61s - 92ms/step - accuracy: 0.3682 - loss: 3.3116 - val_accuracy: 0.4486 - val_loss: 2.5736 - learning_rate: 2.5974e-04
Epoch 82/300
657/657 - 61s - 93ms/step - accuracy: 0.3734 - loss: 3.2709 - val_accuracy: 0.4572 - val_loss: 2.5839 - learning_rate: 2.5974e-04
Epoch 83/300
657/657 - 63s - 96ms/step - accuracy: 0.3779 - loss: 3.3004 - val_accuracy: 0.4709 - val_loss: 2.5746 - learning_rate: 2.5974e-04
Epoch 84/300
657/657 - 62s - 94ms/step - accuracy: 0.3703 - loss: 3.2792 - val_accuracy: 0.4846 - val_loss: 2.6433 - learning_rate: 2.5974e-04
Epoch 85/300
657/657 - 61s - 93ms/step - accuracy: 0.3690 - loss: 3.2820 - val_accuracy: 0.4932 - val_loss: 2.5645 - learning_rate: 2.5974e-04
Epoch 86/300
657/657 - 62s - 94ms/step - accuracy: 0.3600 - loss: 3.3307 - val_accuracy: 0.4897 - val_loss: 2.5353 - learning_rate: 2.5974e-04
Epoch 87/300

Epoch 87: ReduceLROnPlateau reducing learning rate to 0.0001298690476687625.
657/657 - 62s - 95ms/step - accuracy: 0.3604 - loss: 3.3025 - val_accuracy: 0.4795 - val_loss: 2.5866 - learning_rate: 2.5974e-04
Epoch 88/300
657/657 - 61s - 92ms/step - accuracy: 0.3753 - loss: 3.2385 - val_accuracy: 0.4846 - val_loss: 2.5314 - learning_rate: 1.2987e-04
Epoch 89/300
657/657 - 63s - 96ms/step - accuracy: 0.3884 - loss: 3.1915 - val_accuracy: 0.4897 - val_loss: 2.4991 - learning_rate: 1.2987e-04
Epoch 90/300
657/657 - 60s - 91ms/step - accuracy: 0.3781 - loss: 3.1975 - val_accuracy: 0.4846 - val_loss: 2.5183 - learning_rate: 1.2987e-04
Epoch 91/300
657/657 - 61s - 93ms/step - accuracy: 0.3831 - loss: 3.1891 - val_accuracy: 0.4863 - val_loss: 2.4786 - learning_rate: 1.2987e-04
Epoch 92/300
657/657 - 61s - 93ms/step - accuracy: 0.3873 - loss: 3.1808 - val_accuracy: 0.4777 - val_loss: 2.5087 - learning_rate: 1.2987e-04
Epoch 93/300
657/657 - 62s - 94ms/step - accuracy: 0.3688 - loss: 3.2048 - val_accuracy: 0.4846 - val_loss: 2.4953 - learning_rate: 1.2987e-04
Epoch 94/300
657/657 - 62s - 95ms/step - accuracy: 0.3852 - loss: 3.1949 - val_accuracy: 0.4897 - val_loss: 2.5049 - learning_rate: 1.2987e-04
Epoch 95/300
657/657 - 63s - 95ms/step - accuracy: 0.3791 - loss: 3.2048 - val_accuracy: 0.4966 - val_loss: 2.5141 - learning_rate: 1.2987e-04
Epoch 96/300
657/657 - 63s - 96ms/step - accuracy: 0.3850 - loss: 3.1868 - val_accuracy: 0.4983 - val_loss: 2.5167 - learning_rate: 1.2987e-04
Epoch 97/300
657/657 - 62s - 94ms/step - accuracy: 0.3810 - loss: 3.1970 - val_accuracy: 0.4829 - val_loss: 2.4654 - learning_rate: 1.2987e-04
Epoch 98/300
657/657 - 63s - 96ms/step - accuracy: 0.3768 - loss: 3.1955 - val_accuracy: 0.4914 - val_loss: 2.4481 - learning_rate: 1.2987e-04
Epoch 99/300
657/657 - 60s - 92ms/step - accuracy: 0.3861 - loss: 3.1917 - val_accuracy: 0.4966 - val_loss: 2.5048 - learning_rate: 1.2987e-04
Epoch 100/300
657/657 - 62s - 94ms/step - accuracy: 0.3808 - loss: 3.2068 - val_accuracy: 0.4966 - val_loss: 2.4960 - learning_rate: 1.2987e-04
Epoch 101/300
657/657 - 61s - 93ms/step - accuracy: 0.3735 - loss: 3.2116 - val_accuracy: 0.4949 - val_loss: 2.4625 - learning_rate: 1.2987e-04
Epoch 102/300
657/657 - 68s - 104ms/step - accuracy: 0.3907 - loss: 3.1677 - val_accuracy: 0.4640 - val_loss: 2.4465 - learning_rate: 1.2987e-04
Epoch 103/300
657/657 - 68s - 104ms/step - accuracy: 0.3865 - loss: 3.1846 - val_accuracy: 0.4966 - val_loss: 2.4857 - learning_rate: 1.2987e-04
Epoch 104/300
657/657 - 67s - 102ms/step - accuracy: 0.3867 - loss: 3.1362 - val_accuracy: 0.5000 - val_loss: 2.4834 - learning_rate: 1.2987e-04
Epoch 105/300
657/657 - 68s - 103ms/step - accuracy: 0.3764 - loss: 3.2034 - val_accuracy: 0.4795 - val_loss: 2.4525 - learning_rate: 1.2987e-04
Epoch 106/300
657/657 - 68s - 103ms/step - accuracy: 0.3810 - loss: 3.2082 - val_accuracy: 0.4760 - val_loss: 2.4348 - learning_rate: 1.2987e-04
Epoch 107/300
657/657 - 69s - 104ms/step - accuracy: 0.3812 - loss: 3.1916 - val_accuracy: 0.4897 - val_loss: 2.4541 - learning_rate: 1.2987e-04
Epoch 108/300
657/657 - 67s - 102ms/step - accuracy: 0.3920 - loss: 3.1752 - val_accuracy: 0.4949 - val_loss: 2.4696 - learning_rate: 1.2987e-04
Epoch 109/300
657/657 - 69s - 105ms/step - accuracy: 0.3756 - loss: 3.1880 - val_accuracy: 0.4863 - val_loss: 2.4618 - learning_rate: 1.2987e-04
Epoch 110/300
657/657 - 66s - 101ms/step - accuracy: 0.3890 - loss: 3.1648 - val_accuracy: 0.4949 - val_loss: 2.4522 - learning_rate: 1.2987e-04
Epoch 111/300
657/657 - 68s - 104ms/step - accuracy: 0.3916 - loss: 3.1364 - val_accuracy: 0.4983 - val_loss: 2.4740 - learning_rate: 1.2987e-04
Epoch 112/300
657/657 - 69s - 105ms/step - accuracy: 0.3901 - loss: 3.1119 - val_accuracy: 0.5000 - val_loss: 2.4151 - learning_rate: 1.2987e-04
Epoch 113/300
657/657 - 67s - 102ms/step - accuracy: 0.3855 - loss: 3.2112 - val_accuracy: 0.5000 - val_loss: 2.4781 - learning_rate: 1.2987e-04
Epoch 114/300
657/657 - 68s - 103ms/step - accuracy: 0.3842 - loss: 3.1682 - val_accuracy: 0.5017 - val_loss: 2.4336 - learning_rate: 1.2987e-04
Epoch 115/300
657/657 - 68s - 104ms/step - accuracy: 0.3960 - loss: 3.1610 - val_accuracy: 0.4949 - val_loss: 2.4600 - learning_rate: 1.2987e-04
Epoch 116/300
657/657 - 69s - 104ms/step - accuracy: 0.3802 - loss: 3.1360 - val_accuracy: 0.4846 - val_loss: 2.4234 - learning_rate: 1.2987e-04
Epoch 117/300
657/657 - 67s - 101ms/step - accuracy: 0.3924 - loss: 3.1544 - val_accuracy: 0.5086 - val_loss: 2.4629 - learning_rate: 1.2987e-04
Epoch 118/300
657/657 - 68s - 104ms/step - accuracy: 0.3863 - loss: 3.1784 - val_accuracy: 0.5034 - val_loss: 2.4267 - learning_rate: 1.2987e-04
Epoch 119/300
657/657 - 68s - 104ms/step - accuracy: 0.3817 - loss: 3.1450 - val_accuracy: 0.4846 - val_loss: 2.4309 - learning_rate: 1.2987e-04
Epoch 120/300

Epoch 120: ReduceLROnPlateau reducing learning rate to 6.493452383438125e-05.
657/657 - 65s - 99ms/step - accuracy: 0.3909 - loss: 3.1259 - val_accuracy: 0.5034 - val_loss: 2.4424 - learning_rate: 1.2987e-04
Epoch 121/300
657/657 - 69s - 106ms/step - accuracy: 0.3952 - loss: 3.1094 - val_accuracy: 0.5137 - val_loss: 2.3992 - learning_rate: 6.4935e-05
Epoch 122/300
657/657 - 69s - 104ms/step - accuracy: 0.3911 - loss: 3.1186 - val_accuracy: 0.5154 - val_loss: 2.4215 - learning_rate: 6.4935e-05
Epoch 123/300
657/657 - 68s - 103ms/step - accuracy: 0.3956 - loss: 3.1419 - val_accuracy: 0.5086 - val_loss: 2.4059 - learning_rate: 6.4935e-05
Epoch 124/300
657/657 - 68s - 104ms/step - accuracy: 0.3886 - loss: 3.1147 - val_accuracy: 0.5086 - val_loss: 2.4041 - learning_rate: 6.4935e-05
Epoch 125/300
657/657 - 68s - 103ms/step - accuracy: 0.4011 - loss: 3.0864 - val_accuracy: 0.5103 - val_loss: 2.4124 - learning_rate: 6.4935e-05
Epoch 126/300
657/657 - 68s - 104ms/step - accuracy: 0.4030 - loss: 3.0760 - val_accuracy: 0.5034 - val_loss: 2.4062 - learning_rate: 6.4935e-05
Epoch 127/300
657/657 - 68s - 103ms/step - accuracy: 0.3992 - loss: 3.1013 - val_accuracy: 0.5137 - val_loss: 2.4009 - learning_rate: 6.4935e-05
Epoch 128/300
657/657 - 68s - 104ms/step - accuracy: 0.3909 - loss: 3.1249 - val_accuracy: 0.5120 - val_loss: 2.4134 - learning_rate: 6.4935e-05
Epoch 129/300

Epoch 129: ReduceLROnPlateau reducing learning rate to 3.2467261917190626e-05.
657/657 - 68s - 104ms/step - accuracy: 0.3928 - loss: 3.1085 - val_accuracy: 0.5000 - val_loss: 2.3993 - learning_rate: 6.4935e-05
Epoch 130/300
657/657 - 67s - 102ms/step - accuracy: 0.4042 - loss: 3.1005 - val_accuracy: 0.5034 - val_loss: 2.3980 - learning_rate: 3.2467e-05
Epoch 131/300
657/657 - 69s - 105ms/step - accuracy: 0.4032 - loss: 3.0890 - val_accuracy: 0.5154 - val_loss: 2.4115 - learning_rate: 3.2467e-05
Epoch 132/300
657/657 - 67s - 103ms/step - accuracy: 0.3874 - loss: 3.1277 - val_accuracy: 0.5068 - val_loss: 2.4122 - learning_rate: 3.2467e-05
Epoch 133/300
657/657 - 68s - 104ms/step - accuracy: 0.3973 - loss: 3.0710 - val_accuracy: 0.5171 - val_loss: 2.3998 - learning_rate: 3.2467e-05
Epoch 134/300
657/657 - 66s - 101ms/step - accuracy: 0.3968 - loss: 3.1047 - val_accuracy: 0.5068 - val_loss: 2.4063 - learning_rate: 3.2467e-05
Epoch 135/300
657/657 - 69s - 105ms/step - accuracy: 0.3987 - loss: 3.0775 - val_accuracy: 0.5103 - val_loss: 2.3960 - learning_rate: 3.2467e-05
Epoch 136/300
657/657 - 69s - 105ms/step - accuracy: 0.3892 - loss: 3.0965 - val_accuracy: 0.5051 - val_loss: 2.4045 - learning_rate: 3.2467e-05
Epoch 137/300
657/657 - 68s - 103ms/step - accuracy: 0.3973 - loss: 3.1122 - val_accuracy: 0.5068 - val_loss: 2.3978 - learning_rate: 3.2467e-05
Epoch 138/300
657/657 - 68s - 103ms/step - accuracy: 0.3994 - loss: 3.1233 - val_accuracy: 0.5000 - val_loss: 2.4169 - learning_rate: 3.2467e-05
Epoch 139/300
657/657 - 67s - 103ms/step - accuracy: 0.3996 - loss: 3.0688 - val_accuracy: 0.5120 - val_loss: 2.3885 - learning_rate: 3.2467e-05
Epoch 140/300
657/657 - 68s - 104ms/step - accuracy: 0.4015 - loss: 3.0627 - val_accuracy: 0.5103 - val_loss: 2.4153 - learning_rate: 3.2467e-05
Epoch 141/300
657/657 - 67s - 102ms/step - accuracy: 0.3987 - loss: 3.0556 - val_accuracy: 0.5068 - val_loss: 2.3787 - learning_rate: 3.2467e-05
Epoch 142/300
657/657 - 67s - 102ms/step - accuracy: 0.3983 - loss: 3.0901 - val_accuracy: 0.5103 - val_loss: 2.4022 - learning_rate: 3.2467e-05
Epoch 143/300
657/657 - 66s - 101ms/step - accuracy: 0.4032 - loss: 3.0736 - val_accuracy: 0.5051 - val_loss: 2.3965 - learning_rate: 3.2467e-05
Epoch 144/300
657/657 - 67s - 101ms/step - accuracy: 0.4048 - loss: 3.0619 - val_accuracy: 0.5103 - val_loss: 2.4034 - learning_rate: 3.2467e-05
Epoch 145/300
657/657 - 69s - 105ms/step - accuracy: 0.3970 - loss: 3.0787 - val_accuracy: 0.5103 - val_loss: 2.3939 - learning_rate: 3.2467e-05
Epoch 146/300
657/657 - 68s - 103ms/step - accuracy: 0.3939 - loss: 3.0949 - val_accuracy: 0.4983 - val_loss: 2.4059 - learning_rate: 3.2467e-05
Epoch 147/300
657/657 - 67s - 102ms/step - accuracy: 0.3922 - loss: 3.1011 - val_accuracy: 0.5103 - val_loss: 2.3798 - learning_rate: 3.2467e-05
Epoch 148/300
657/657 - 69s - 105ms/step - accuracy: 0.3933 - loss: 3.0840 - val_accuracy: 0.5103 - val_loss: 2.3903 - learning_rate: 3.2467e-05
Epoch 149/300

Epoch 149: ReduceLROnPlateau reducing learning rate to 1.6233630958595313e-05.
657/657 - 68s - 103ms/step - accuracy: 0.3867 - loss: 3.1388 - val_accuracy: 0.5017 - val_loss: 2.3924 - learning_rate: 3.2467e-05
Epoch 150/300
657/657 - 68s - 104ms/step - accuracy: 0.4017 - loss: 3.1095 - val_accuracy: 0.5086 - val_loss: 2.3843 - learning_rate: 1.6234e-05
Epoch 151/300
657/657 - 66s - 101ms/step - accuracy: 0.3935 - loss: 3.0800 - val_accuracy: 0.5103 - val_loss: 2.3769 - learning_rate: 1.6234e-05
Epoch 152/300
657/657 - 67s - 102ms/step - accuracy: 0.3985 - loss: 3.0911 - val_accuracy: 0.5103 - val_loss: 2.3696 - learning_rate: 1.6234e-05
Epoch 153/300
657/657 - 69s - 106ms/step - accuracy: 0.3996 - loss: 3.0740 - val_accuracy: 0.5171 - val_loss: 2.3874 - learning_rate: 1.6234e-05
Epoch 154/300
657/657 - 67s - 102ms/step - accuracy: 0.3981 - loss: 3.0450 - val_accuracy: 0.4983 - val_loss: 2.3802 - learning_rate: 1.6234e-05
Epoch 155/300
657/657 - 68s - 104ms/step - accuracy: 0.4084 - loss: 3.0495 - val_accuracy: 0.5086 - val_loss: 2.3930 - learning_rate: 1.6234e-05
Epoch 156/300
657/657 - 67s - 102ms/step - accuracy: 0.3962 - loss: 3.0854 - val_accuracy: 0.5086 - val_loss: 2.3846 - learning_rate: 1.6234e-05
Epoch 157/300
657/657 - 68s - 104ms/step - accuracy: 0.3922 - loss: 3.0768 - val_accuracy: 0.5103 - val_loss: 2.3817 - learning_rate: 1.6234e-05
Epoch 158/300
657/657 - 68s - 104ms/step - accuracy: 0.4067 - loss: 3.0566 - val_accuracy: 0.5068 - val_loss: 2.3824 - learning_rate: 1.6234e-05
Epoch 159/300
657/657 - 67s - 103ms/step - accuracy: 0.3977 - loss: 3.0667 - val_accuracy: 0.5120 - val_loss: 2.3562 - learning_rate: 1.6234e-05
Epoch 160/300
657/657 - 67s - 102ms/step - accuracy: 0.3990 - loss: 3.0548 - val_accuracy: 0.5154 - val_loss: 2.3712 - learning_rate: 1.6234e-05
Epoch 161/300
657/657 - 68s - 104ms/step - accuracy: 0.4006 - loss: 3.0563 - val_accuracy: 0.5086 - val_loss: 2.3815 - learning_rate: 1.6234e-05
Epoch 162/300
657/657 - 68s - 103ms/step - accuracy: 0.3926 - loss: 3.0938 - val_accuracy: 0.5051 - val_loss: 2.3849 - learning_rate: 1.6234e-05
Epoch 163/300
657/657 - 68s - 103ms/step - accuracy: 0.4040 - loss: 3.0780 - val_accuracy: 0.5188 - val_loss: 2.3863 - learning_rate: 1.6234e-05
Epoch 164/300
657/657 - 68s - 104ms/step - accuracy: 0.4070 - loss: 3.0670 - val_accuracy: 0.5171 - val_loss: 2.3874 - learning_rate: 1.6234e-05
Epoch 165/300
657/657 - 69s - 104ms/step - accuracy: 0.4027 - loss: 3.0750 - val_accuracy: 0.5103 - val_loss: 2.3787 - learning_rate: 1.6234e-05
Epoch 166/300
657/657 - 66s - 101ms/step - accuracy: 0.4019 - loss: 3.0418 - val_accuracy: 0.5154 - val_loss: 2.3729 - learning_rate: 1.6234e-05
Epoch 167/300

Epoch 167: ReduceLROnPlateau reducing learning rate to 8.116815479297657e-06.
657/657 - 68s - 104ms/step - accuracy: 0.4040 - loss: 3.0697 - val_accuracy: 0.5154 - val_loss: 2.3842 - learning_rate: 1.6234e-05
Epoch 168/300
657/657 - 69s - 105ms/step - accuracy: 0.4027 - loss: 3.0625 - val_accuracy: 0.5154 - val_loss: 2.3772 - learning_rate: 8.1168e-06
Epoch 169/300
657/657 - 66s - 100ms/step - accuracy: 0.3933 - loss: 3.0621 - val_accuracy: 0.5137 - val_loss: 2.3689 - learning_rate: 8.1168e-06
Epoch 170/300
657/657 - 68s - 104ms/step - accuracy: 0.4044 - loss: 3.0785 - val_accuracy: 0.5137 - val_loss: 2.3708 - learning_rate: 8.1168e-06
Epoch 171/300
657/657 - 67s - 101ms/step - accuracy: 0.4088 - loss: 3.0691 - val_accuracy: 0.5137 - val_loss: 2.3774 - learning_rate: 8.1168e-06
Epoch 172/300
657/657 - 68s - 103ms/step - accuracy: 0.4042 - loss: 3.0599 - val_accuracy: 0.5137 - val_loss: 2.3752 - learning_rate: 8.1168e-06
Epoch 173/300
657/657 - 67s - 102ms/step - accuracy: 0.4038 - loss: 3.0552 - val_accuracy: 0.5068 - val_loss: 2.3739 - learning_rate: 8.1168e-06
Epoch 174/300
657/657 - 68s - 103ms/step - accuracy: 0.4179 - loss: 3.0480 - val_accuracy: 0.5171 - val_loss: 2.3727 - learning_rate: 8.1168e-06
Epoch 175/300

Epoch 175: ReduceLROnPlateau reducing learning rate to 4.058407739648828e-06.
657/657 - 68s - 103ms/step - accuracy: 0.4074 - loss: 3.0476 - val_accuracy: 0.5137 - val_loss: 2.3715 - learning_rate: 8.1168e-06
Epoch 175: early stopping
Restoring model weights from the end of the best epoch: 159.
Fold 4 Evaluation results: [2.3729729652404785, 0.5119863152503967]
              precision    recall  f1-score   support

        1820       0.66      0.77      0.71        43
        1821       0.00      0.00      0.00         1
        1822       0.00      0.00      0.00         1
        1823       0.00      0.00      0.00         2
        1824       0.00      0.00      0.00         1
        1825       0.00      0.00      0.00         1
        1826       0.00      0.00      0.00         1
        1827       0.00      0.00      0.00         8
        1828       0.25      0.50      0.33         2
        1829       0.40      0.50      0.44         4
        1830       0.56      0.84      0.67        45
        1831       0.00      0.00      0.00         1
        1832       0.84      0.77      0.80        53
        1833       1.00      0.89      0.94        19
        1834       0.56      0.83      0.67         6
        1835       0.00      0.00      0.00         2
        1836       0.00      0.00      0.00         4
        1837       0.30      0.86      0.44         7
        1838       0.00      0.00      0.00         4
        1839       0.00      0.00      0.00         0
        1840       0.52      0.53      0.53        43
        1841       0.33      0.10      0.15        10
        1842       0.14      0.20      0.17         5
        1843       0.50      0.33      0.40         6
        1844       0.00      0.00      0.00         0
        1845       0.00      0.00      0.00         1
        1846       0.00      0.00      0.00         6
        1847       0.00      0.00      0.00         2
        1848       0.38      0.50      0.43         6
        1849       0.50      0.33      0.40         6
        1850       0.41      0.64      0.50        47
        1851       0.12      0.17      0.14         6
        1852       0.22      0.29      0.25         7
        1853       0.00      0.00      0.00         6
        1854       0.00      0.00      0.00         3
        1855       0.20      0.09      0.12        11
        1856       0.70      0.58      0.64        12
        1857       0.50      0.25      0.33         8
        1858       0.00      0.00      0.00         2
        1859       0.00      0.00      0.00         2
        1860       0.40      0.46      0.43        48
        1861       0.00      0.00      0.00         1
        1862       1.00      0.14      0.25         7
        1863       0.67      0.80      0.73         5
        1864       0.75      0.50      0.60         6
        1865       0.60      0.43      0.50         7
        1866       0.25      0.20      0.22         5
        1867       0.28      0.50      0.36        10
        1868       0.00      0.00      0.00         7
        1869       0.00      0.00      0.00         5
        1870       0.49      0.57      0.52        30
        1871       0.50      0.40      0.44         5
        1872       0.18      0.29      0.22         7
        1873       0.20      0.09      0.12        11
        1874       0.50      0.20      0.29         5
        1875       0.50      0.33      0.40         6
        1876       0.90      0.90      0.90        10
        1877       0.50      0.40      0.44         5
        1878       0.50      0.67      0.57         9
        1879       0.00      0.00      0.00         1

    accuracy                           0.51       584
   macro avg       0.29      0.28      0.27       584
weighted avg       0.48      0.51      0.48       584

Matthews Correlation Coefficient: 0.485
Macro avg F1: 0.268
Weighted avg F1: 0.479
Micro avg F1: 0.512
Top-3 Accuracy: 0.755
Top-5 Accuracy: 0.848
Micro ROC AUC  = 0.97
Macro ROC AUC (present classes) = 0.96
Classification MAE (in years): 3.61

Fold 4 Misclassification Analysis:
Near misses (within 2 years): 92 out of 285 misclassifications (32.28%)
Big misses (greater than 10 years): 91
MAE with outliers: 3.61
MAE without outliers: 2.41 (improvement: 1.20)

10 Worst misclassifications:
Image: data/datasets/public/1870/1879_26wikimedia2.jpg, True: 1879, Predicted: 1820, Error: 59
Image: data/datasets/public/1820/1820_050met.jpg, True: 1820, Predicted: 1872, Error: 52
Image: data/datasets/public/1830/1832_1596vna.jpg, True: 1832, Predicted: 1870, Error: 38
Image: data/datasets/public/1870/1873_030met.jpg, True: 1873, Predicted: 1840, Error: 33
Image: data/datasets/public/1820/1820_032met.jpg, True: 1820, Predicted: 1852, Error: 32
Image: data/datasets/public/1860/1860_23wikimedia2.jpg, True: 1860, Predicted: 1830, Error: 30
Image: data/datasets/public/1860/1860_066met.jpg, True: 1860, Predicted: 1830, Error: 30
Image: data/datasets/public/1870/1870_40wikimedia2.jpg, True: 1870, Predicted: 1840, Error: 30
Image: data/datasets/public/1820/1820_039met.jpg, True: 1820, Predicted: 1850, Error: 30
Image: data/datasets/public/1870/1870_162wikimedia2.jpg, True: 1870, Predicted: 1840, Error: 30

===== Fold 5 =====
=== Running on Public Data ===

===== Fine Tuning 9 layers! =====
Epoch 1/300
657/657 - 88s - 134ms/step - accuracy: 0.1010 - loss: 4.6710 - val_accuracy: 0.2140 - val_loss: 4.7225 - learning_rate: 2.5974e-04
Epoch 2/300
657/657 - 69s - 105ms/step - accuracy: 0.1583 - loss: 4.3552 - val_accuracy: 0.2175 - val_loss: 4.0145 - learning_rate: 2.5974e-04
Epoch 3/300
657/657 - 68s - 104ms/step - accuracy: 0.1954 - loss: 4.2129 - val_accuracy: 0.2671 - val_loss: 3.8248 - learning_rate: 2.5974e-04
Epoch 4/300
657/657 - 68s - 104ms/step - accuracy: 0.2171 - loss: 4.1740 - val_accuracy: 0.3099 - val_loss: 3.8790 - learning_rate: 2.5974e-04
Epoch 5/300
657/657 - 67s - 102ms/step - accuracy: 0.2339 - loss: 4.1490 - val_accuracy: 0.2825 - val_loss: 3.6149 - learning_rate: 2.5974e-04
Epoch 6/300
657/657 - 68s - 103ms/step - accuracy: 0.2504 - loss: 4.0810 - val_accuracy: 0.2997 - val_loss: 3.6858 - learning_rate: 2.5974e-04
Epoch 7/300
657/657 - 68s - 103ms/step - accuracy: 0.2497 - loss: 4.0387 - val_accuracy: 0.3271 - val_loss: 3.5674 - learning_rate: 2.5974e-04
Epoch 8/300
657/657 - 66s - 101ms/step - accuracy: 0.2542 - loss: 4.0509 - val_accuracy: 0.3185 - val_loss: 3.4100 - learning_rate: 2.5974e-04
Epoch 9/300
657/657 - 81s - 123ms/step - accuracy: 0.2679 - loss: 3.9659 - val_accuracy: 0.3630 - val_loss: 3.5342 - learning_rate: 2.5974e-04
Epoch 10/300
657/657 - 66s - 100ms/step - accuracy: 0.2672 - loss: 3.9908 - val_accuracy: 0.3408 - val_loss: 3.3731 - learning_rate: 2.5974e-04
Epoch 11/300
657/657 - 68s - 104ms/step - accuracy: 0.2776 - loss: 3.9148 - val_accuracy: 0.3853 - val_loss: 3.3698 - learning_rate: 2.5974e-04
Epoch 12/300
657/657 - 67s - 103ms/step - accuracy: 0.2784 - loss: 3.8956 - val_accuracy: 0.4092 - val_loss: 3.2674 - learning_rate: 2.5974e-04
Epoch 13/300
657/657 - 67s - 102ms/step - accuracy: 0.2805 - loss: 3.8779 - val_accuracy: 0.3767 - val_loss: 3.2827 - learning_rate: 2.5974e-04
Epoch 14/300
657/657 - 68s - 104ms/step - accuracy: 0.2931 - loss: 3.8321 - val_accuracy: 0.3938 - val_loss: 3.1823 - learning_rate: 2.5974e-04
Epoch 15/300
657/657 - 67s - 101ms/step - accuracy: 0.2919 - loss: 3.8149 - val_accuracy: 0.3853 - val_loss: 3.1152 - learning_rate: 2.5974e-04
Epoch 16/300
657/657 - 67s - 103ms/step - accuracy: 0.2984 - loss: 3.8064 - val_accuracy: 0.3818 - val_loss: 3.2730 - learning_rate: 2.5974e-04
Epoch 17/300
657/657 - 69s - 104ms/step - accuracy: 0.2957 - loss: 3.7661 - val_accuracy: 0.3836 - val_loss: 3.0946 - learning_rate: 2.5974e-04
Epoch 18/300
657/657 - 67s - 103ms/step - accuracy: 0.3047 - loss: 3.7310 - val_accuracy: 0.3955 - val_loss: 3.1692 - learning_rate: 2.5974e-04
Epoch 19/300
657/657 - 69s - 105ms/step - accuracy: 0.3047 - loss: 3.7431 - val_accuracy: 0.3990 - val_loss: 3.0496 - learning_rate: 2.5974e-04
Epoch 20/300
657/657 - 68s - 103ms/step - accuracy: 0.3016 - loss: 3.7359 - val_accuracy: 0.4041 - val_loss: 2.9990 - learning_rate: 2.5974e-04
Epoch 21/300
657/657 - 68s - 103ms/step - accuracy: 0.3075 - loss: 3.7289 - val_accuracy: 0.4161 - val_loss: 3.0316 - learning_rate: 2.5974e-04
Epoch 22/300
657/657 - 69s - 106ms/step - accuracy: 0.3073 - loss: 3.6634 - val_accuracy: 0.4212 - val_loss: 3.0403 - learning_rate: 2.5974e-04
Epoch 23/300
657/657 - 68s - 103ms/step - accuracy: 0.3102 - loss: 3.6833 - val_accuracy: 0.4041 - val_loss: 3.0022 - learning_rate: 2.5974e-04
Epoch 24/300
657/657 - 68s - 103ms/step - accuracy: 0.3088 - loss: 3.6548 - val_accuracy: 0.4144 - val_loss: 2.9061 - learning_rate: 2.5974e-04
Epoch 25/300
657/657 - 68s - 103ms/step - accuracy: 0.3220 - loss: 3.6023 - val_accuracy: 0.4384 - val_loss: 3.0024 - learning_rate: 2.5974e-04
Epoch 26/300
657/657 - 69s - 104ms/step - accuracy: 0.3300 - loss: 3.6114 - val_accuracy: 0.4092 - val_loss: 2.9219 - learning_rate: 2.5974e-04
Epoch 27/300
657/657 - 66s - 101ms/step - accuracy: 0.3328 - loss: 3.6173 - val_accuracy: 0.4486 - val_loss: 2.9376 - learning_rate: 2.5974e-04
Epoch 28/300
657/657 - 68s - 103ms/step - accuracy: 0.3273 - loss: 3.6211 - val_accuracy: 0.4229 - val_loss: 2.8572 - learning_rate: 2.5974e-04
Epoch 29/300
657/657 - 68s - 103ms/step - accuracy: 0.3199 - loss: 3.5826 - val_accuracy: 0.4315 - val_loss: 2.9251 - learning_rate: 2.5974e-04
Epoch 30/300
657/657 - 67s - 103ms/step - accuracy: 0.3212 - loss: 3.5604 - val_accuracy: 0.4247 - val_loss: 2.9713 - learning_rate: 2.5974e-04
Epoch 31/300
657/657 - 67s - 102ms/step - accuracy: 0.3184 - loss: 3.5834 - val_accuracy: 0.4178 - val_loss: 2.8630 - learning_rate: 2.5974e-04
Epoch 32/300
657/657 - 69s - 105ms/step - accuracy: 0.3328 - loss: 3.5438 - val_accuracy: 0.4195 - val_loss: 2.8533 - learning_rate: 2.5974e-04
Epoch 33/300
657/657 - 68s - 104ms/step - accuracy: 0.3302 - loss: 3.5253 - val_accuracy: 0.4212 - val_loss: 2.8201 - learning_rate: 2.5974e-04
Epoch 34/300
657/657 - 68s - 104ms/step - accuracy: 0.3402 - loss: 3.5079 - val_accuracy: 0.4281 - val_loss: 2.8405 - learning_rate: 2.5974e-04
Epoch 35/300
657/657 - 68s - 103ms/step - accuracy: 0.3284 - loss: 3.5530 - val_accuracy: 0.4384 - val_loss: 2.8563 - learning_rate: 2.5974e-04
Epoch 36/300
657/657 - 66s - 101ms/step - accuracy: 0.3279 - loss: 3.5513 - val_accuracy: 0.4469 - val_loss: 2.8371 - learning_rate: 2.5974e-04
Epoch 37/300
657/657 - 68s - 103ms/step - accuracy: 0.3357 - loss: 3.5478 - val_accuracy: 0.4418 - val_loss: 2.8257 - learning_rate: 2.5974e-04
Epoch 38/300
657/657 - 68s - 103ms/step - accuracy: 0.3328 - loss: 3.5202 - val_accuracy: 0.4401 - val_loss: 2.7587 - learning_rate: 2.5974e-04
Epoch 39/300
657/657 - 68s - 104ms/step - accuracy: 0.3435 - loss: 3.4966 - val_accuracy: 0.4418 - val_loss: 2.7801 - learning_rate: 2.5974e-04
Epoch 40/300
657/657 - 69s - 104ms/step - accuracy: 0.3406 - loss: 3.4901 - val_accuracy: 0.4401 - val_loss: 2.7868 - learning_rate: 2.5974e-04
Epoch 41/300
657/657 - 67s - 101ms/step - accuracy: 0.3448 - loss: 3.4550 - val_accuracy: 0.4538 - val_loss: 2.7565 - learning_rate: 2.5974e-04
Epoch 42/300
657/657 - 68s - 104ms/step - accuracy: 0.3404 - loss: 3.4604 - val_accuracy: 0.4503 - val_loss: 2.7368 - learning_rate: 2.5974e-04
Epoch 43/300
657/657 - 68s - 103ms/step - accuracy: 0.3473 - loss: 3.4783 - val_accuracy: 0.4743 - val_loss: 2.8272 - learning_rate: 2.5974e-04
Epoch 44/300
657/657 - 67s - 102ms/step - accuracy: 0.3446 - loss: 3.4576 - val_accuracy: 0.4692 - val_loss: 2.7755 - learning_rate: 2.5974e-04
Epoch 45/300
657/657 - 68s - 104ms/step - accuracy: 0.3399 - loss: 3.5164 - val_accuracy: 0.4623 - val_loss: 2.7318 - learning_rate: 2.5974e-04
Epoch 46/300
657/657 - 65s - 99ms/step - accuracy: 0.3414 - loss: 3.4821 - val_accuracy: 0.4589 - val_loss: 2.7599 - learning_rate: 2.5974e-04
Epoch 47/300
657/657 - 68s - 104ms/step - accuracy: 0.3401 - loss: 3.4718 - val_accuracy: 0.4486 - val_loss: 2.7353 - learning_rate: 2.5974e-04
Epoch 48/300
657/657 - 67s - 102ms/step - accuracy: 0.3500 - loss: 3.4462 - val_accuracy: 0.4521 - val_loss: 2.6467 - learning_rate: 2.5974e-04
Epoch 49/300
657/657 - 68s - 104ms/step - accuracy: 0.3505 - loss: 3.4624 - val_accuracy: 0.4743 - val_loss: 2.6943 - learning_rate: 2.5974e-04
Epoch 50/300
657/657 - 68s - 104ms/step - accuracy: 0.3423 - loss: 3.4558 - val_accuracy: 0.4538 - val_loss: 2.6930 - learning_rate: 2.5974e-04
Epoch 51/300
657/657 - 67s - 102ms/step - accuracy: 0.3418 - loss: 3.4615 - val_accuracy: 0.4675 - val_loss: 2.7329 - learning_rate: 2.5974e-04
Epoch 52/300
657/657 - 69s - 105ms/step - accuracy: 0.3477 - loss: 3.4475 - val_accuracy: 0.4640 - val_loss: 2.6542 - learning_rate: 2.5974e-04
Epoch 53/300
657/657 - 67s - 101ms/step - accuracy: 0.3444 - loss: 3.4462 - val_accuracy: 0.4675 - val_loss: 2.6748 - learning_rate: 2.5974e-04
Epoch 54/300
657/657 - 66s - 101ms/step - accuracy: 0.3395 - loss: 3.3981 - val_accuracy: 0.4812 - val_loss: 2.6866 - learning_rate: 2.5974e-04
Epoch 55/300
657/657 - 68s - 104ms/step - accuracy: 0.3488 - loss: 3.4184 - val_accuracy: 0.4795 - val_loss: 2.6648 - learning_rate: 2.5974e-04
Epoch 56/300
657/657 - 69s - 106ms/step - accuracy: 0.3568 - loss: 3.4207 - val_accuracy: 0.4777 - val_loss: 2.6363 - learning_rate: 2.5974e-04
Epoch 57/300
657/657 - 67s - 102ms/step - accuracy: 0.3463 - loss: 3.3980 - val_accuracy: 0.4829 - val_loss: 2.6457 - learning_rate: 2.5974e-04
Epoch 58/300
657/657 - 68s - 104ms/step - accuracy: 0.3492 - loss: 3.4234 - val_accuracy: 0.4812 - val_loss: 2.6537 - learning_rate: 2.5974e-04
Epoch 59/300
657/657 - 69s - 104ms/step - accuracy: 0.3559 - loss: 3.3896 - val_accuracy: 0.4726 - val_loss: 2.6394 - learning_rate: 2.5974e-04
Epoch 60/300
657/657 - 68s - 104ms/step - accuracy: 0.3528 - loss: 3.3807 - val_accuracy: 0.4863 - val_loss: 2.6871 - learning_rate: 2.5974e-04
Epoch 61/300
657/657 - 67s - 102ms/step - accuracy: 0.3576 - loss: 3.3887 - val_accuracy: 0.4606 - val_loss: 2.6278 - learning_rate: 2.5974e-04
Epoch 62/300
657/657 - 67s - 103ms/step - accuracy: 0.3621 - loss: 3.3634 - val_accuracy: 0.4795 - val_loss: 2.6083 - learning_rate: 2.5974e-04
Epoch 63/300
657/657 - 68s - 104ms/step - accuracy: 0.3530 - loss: 3.3778 - val_accuracy: 0.4795 - val_loss: 2.6225 - learning_rate: 2.5974e-04
Epoch 64/300
657/657 - 68s - 103ms/step - accuracy: 0.3600 - loss: 3.3796 - val_accuracy: 0.5034 - val_loss: 2.6009 - learning_rate: 2.5974e-04
Epoch 65/300
657/657 - 69s - 105ms/step - accuracy: 0.3538 - loss: 3.3796 - val_accuracy: 0.4863 - val_loss: 2.6076 - learning_rate: 2.5974e-04
Epoch 66/300
657/657 - 69s - 105ms/step - accuracy: 0.3536 - loss: 3.3915 - val_accuracy: 0.4726 - val_loss: 2.6132 - learning_rate: 2.5974e-04
Epoch 67/300
657/657 - 67s - 103ms/step - accuracy: 0.3541 - loss: 3.3979 - val_accuracy: 0.4863 - val_loss: 2.6266 - learning_rate: 2.5974e-04
Epoch 68/300
657/657 - 69s - 104ms/step - accuracy: 0.3621 - loss: 3.3589 - val_accuracy: 0.4777 - val_loss: 2.6754 - learning_rate: 2.5974e-04
Epoch 69/300
657/657 - 69s - 105ms/step - accuracy: 0.3644 - loss: 3.3224 - val_accuracy: 0.4709 - val_loss: 2.5924 - learning_rate: 2.5974e-04
Epoch 70/300
657/657 - 67s - 103ms/step - accuracy: 0.3701 - loss: 3.3283 - val_accuracy: 0.4880 - val_loss: 2.5701 - learning_rate: 2.5974e-04
Epoch 71/300
657/657 - 69s - 104ms/step - accuracy: 0.3520 - loss: 3.3443 - val_accuracy: 0.4795 - val_loss: 2.5222 - learning_rate: 2.5974e-04
Epoch 72/300
657/657 - 68s - 104ms/step - accuracy: 0.3541 - loss: 3.3563 - val_accuracy: 0.4846 - val_loss: 2.5452 - learning_rate: 2.5974e-04
Epoch 73/300
657/657 - 70s - 106ms/step - accuracy: 0.3650 - loss: 3.3140 - val_accuracy: 0.5051 - val_loss: 2.5936 - learning_rate: 2.5974e-04
Epoch 74/300
657/657 - 66s - 101ms/step - accuracy: 0.3597 - loss: 3.3407 - val_accuracy: 0.4829 - val_loss: 2.5792 - learning_rate: 2.5974e-04
Epoch 75/300
657/657 - 69s - 105ms/step - accuracy: 0.3625 - loss: 3.3088 - val_accuracy: 0.4726 - val_loss: 2.5411 - learning_rate: 2.5974e-04
Epoch 76/300
657/657 - 69s - 104ms/step - accuracy: 0.3635 - loss: 3.3029 - val_accuracy: 0.4863 - val_loss: 2.5555 - learning_rate: 2.5974e-04
Epoch 77/300
657/657 - 68s - 103ms/step - accuracy: 0.3598 - loss: 3.3655 - val_accuracy: 0.4863 - val_loss: 2.5090 - learning_rate: 2.5974e-04
Epoch 78/300
657/657 - 68s - 104ms/step - accuracy: 0.3557 - loss: 3.3456 - val_accuracy: 0.4897 - val_loss: 2.5923 - learning_rate: 2.5974e-04
Epoch 79/300
657/657 - 67s - 102ms/step - accuracy: 0.3579 - loss: 3.3432 - val_accuracy: 0.4863 - val_loss: 2.5331 - learning_rate: 2.5974e-04
Epoch 80/300
657/657 - 67s - 102ms/step - accuracy: 0.3633 - loss: 3.3273 - val_accuracy: 0.4880 - val_loss: 2.5919 - learning_rate: 2.5974e-04
Epoch 81/300
657/657 - 68s - 103ms/step - accuracy: 0.3579 - loss: 3.3202 - val_accuracy: 0.4743 - val_loss: 2.5709 - learning_rate: 2.5974e-04
Epoch 82/300
657/657 - 69s - 105ms/step - accuracy: 0.3676 - loss: 3.3004 - val_accuracy: 0.4897 - val_loss: 2.5694 - learning_rate: 2.5974e-04
Epoch 83/300
657/657 - 68s - 104ms/step - accuracy: 0.3656 - loss: 3.3147 - val_accuracy: 0.5000 - val_loss: 2.5460 - learning_rate: 2.5974e-04
Epoch 84/300
657/657 - 67s - 102ms/step - accuracy: 0.3612 - loss: 3.3364 - val_accuracy: 0.4863 - val_loss: 2.5366 - learning_rate: 2.5974e-04
Epoch 85/300

Epoch 85: ReduceLROnPlateau reducing learning rate to 0.0001298690476687625.
657/657 - 68s - 104ms/step - accuracy: 0.3753 - loss: 3.3080 - val_accuracy: 0.4760 - val_loss: 2.5735 - learning_rate: 2.5974e-04
Epoch 86/300
657/657 - 68s - 104ms/step - accuracy: 0.3699 - loss: 3.2886 - val_accuracy: 0.4795 - val_loss: 2.4739 - learning_rate: 1.2987e-04
Epoch 87/300
657/657 - 69s - 105ms/step - accuracy: 0.3764 - loss: 3.2431 - val_accuracy: 0.4829 - val_loss: 2.4987 - learning_rate: 1.2987e-04
Epoch 88/300
657/657 - 66s - 101ms/step - accuracy: 0.3650 - loss: 3.2321 - val_accuracy: 0.4966 - val_loss: 2.5298 - learning_rate: 1.2987e-04
Epoch 89/300
657/657 - 84s - 128ms/step - accuracy: 0.3737 - loss: 3.2325 - val_accuracy: 0.4914 - val_loss: 2.5215 - learning_rate: 1.2987e-04
Epoch 90/300
657/657 - 67s - 102ms/step - accuracy: 0.3701 - loss: 3.2518 - val_accuracy: 0.4949 - val_loss: 2.5078 - learning_rate: 1.2987e-04
Epoch 91/300
657/657 - 69s - 105ms/step - accuracy: 0.3675 - loss: 3.2595 - val_accuracy: 0.5034 - val_loss: 2.5276 - learning_rate: 1.2987e-04
Epoch 92/300
657/657 - 68s - 104ms/step - accuracy: 0.3775 - loss: 3.2197 - val_accuracy: 0.4983 - val_loss: 2.4926 - learning_rate: 1.2987e-04
Epoch 93/300
657/657 - 69s - 104ms/step - accuracy: 0.3686 - loss: 3.2556 - val_accuracy: 0.5120 - val_loss: 2.4979 - learning_rate: 1.2987e-04
Epoch 94/300

Epoch 94: ReduceLROnPlateau reducing learning rate to 6.493452383438125e-05.
657/657 - 67s - 103ms/step - accuracy: 0.3798 - loss: 3.2050 - val_accuracy: 0.5000 - val_loss: 2.4899 - learning_rate: 1.2987e-04
Epoch 95/300
657/657 - 69s - 104ms/step - accuracy: 0.3907 - loss: 3.1673 - val_accuracy: 0.4949 - val_loss: 2.4593 - learning_rate: 6.4935e-05
Epoch 96/300
657/657 - 67s - 103ms/step - accuracy: 0.3730 - loss: 3.1959 - val_accuracy: 0.4983 - val_loss: 2.4549 - learning_rate: 6.4935e-05
Epoch 97/300
657/657 - 67s - 101ms/step - accuracy: 0.3798 - loss: 3.2007 - val_accuracy: 0.5086 - val_loss: 2.4459 - learning_rate: 6.4935e-05
Epoch 98/300
657/657 - 69s - 106ms/step - accuracy: 0.3865 - loss: 3.1681 - val_accuracy: 0.4983 - val_loss: 2.4545 - learning_rate: 6.4935e-05
Epoch 99/300
657/657 - 69s - 105ms/step - accuracy: 0.3796 - loss: 3.2116 - val_accuracy: 0.4932 - val_loss: 2.4573 - learning_rate: 6.4935e-05
Epoch 100/300
657/657 - 68s - 104ms/step - accuracy: 0.3656 - loss: 3.1873 - val_accuracy: 0.4949 - val_loss: 2.4557 - learning_rate: 6.4935e-05
Epoch 101/300
657/657 - 69s - 104ms/step - accuracy: 0.3905 - loss: 3.1437 - val_accuracy: 0.5103 - val_loss: 2.4483 - learning_rate: 6.4935e-05
Epoch 102/300
657/657 - 69s - 105ms/step - accuracy: 0.3758 - loss: 3.1954 - val_accuracy: 0.5086 - val_loss: 2.4689 - learning_rate: 6.4935e-05
Epoch 103/300
657/657 - 68s - 104ms/step - accuracy: 0.3768 - loss: 3.1826 - val_accuracy: 0.4983 - val_loss: 2.4364 - learning_rate: 6.4935e-05
Epoch 104/300
657/657 - 68s - 104ms/step - accuracy: 0.3829 - loss: 3.1667 - val_accuracy: 0.5017 - val_loss: 2.4738 - learning_rate: 6.4935e-05
Epoch 105/300
657/657 - 67s - 102ms/step - accuracy: 0.3821 - loss: 3.1895 - val_accuracy: 0.4966 - val_loss: 2.4313 - learning_rate: 6.4935e-05
Epoch 106/300
657/657 - 67s - 103ms/step - accuracy: 0.3774 - loss: 3.2042 - val_accuracy: 0.4880 - val_loss: 2.4311 - learning_rate: 6.4935e-05
Epoch 107/300
657/657 - 68s - 103ms/step - accuracy: 0.3789 - loss: 3.1958 - val_accuracy: 0.4983 - val_loss: 2.4328 - learning_rate: 6.4935e-05
Epoch 108/300
657/657 - 69s - 105ms/step - accuracy: 0.3821 - loss: 3.1818 - val_accuracy: 0.4932 - val_loss: 2.4401 - learning_rate: 6.4935e-05
Epoch 109/300
657/657 - 68s - 103ms/step - accuracy: 0.3802 - loss: 3.1994 - val_accuracy: 0.5137 - val_loss: 2.4371 - learning_rate: 6.4935e-05
Epoch 110/300
657/657 - 67s - 102ms/step - accuracy: 0.3827 - loss: 3.1734 - val_accuracy: 0.5034 - val_loss: 2.4423 - learning_rate: 6.4935e-05
Epoch 111/300
657/657 - 67s - 103ms/step - accuracy: 0.3855 - loss: 3.1833 - val_accuracy: 0.5000 - val_loss: 2.4212 - learning_rate: 6.4935e-05
Epoch 112/300
657/657 - 68s - 103ms/step - accuracy: 0.3867 - loss: 3.1642 - val_accuracy: 0.5017 - val_loss: 2.4051 - learning_rate: 6.4935e-05
Epoch 113/300
657/657 - 68s - 104ms/step - accuracy: 0.3842 - loss: 3.1639 - val_accuracy: 0.5051 - val_loss: 2.4102 - learning_rate: 6.4935e-05
Epoch 114/300
657/657 - 68s - 104ms/step - accuracy: 0.3734 - loss: 3.2158 - val_accuracy: 0.4983 - val_loss: 2.4200 - learning_rate: 6.4935e-05
Epoch 115/300
657/657 - 70s - 106ms/step - accuracy: 0.3745 - loss: 3.1994 - val_accuracy: 0.5068 - val_loss: 2.4455 - learning_rate: 6.4935e-05
Epoch 116/300
657/657 - 68s - 103ms/step - accuracy: 0.3874 - loss: 3.1482 - val_accuracy: 0.4983 - val_loss: 2.4380 - learning_rate: 6.4935e-05
Epoch 117/300
657/657 - 68s - 104ms/step - accuracy: 0.3888 - loss: 3.1416 - val_accuracy: 0.5034 - val_loss: 2.4337 - learning_rate: 6.4935e-05
Epoch 118/300
657/657 - 68s - 104ms/step - accuracy: 0.3783 - loss: 3.1790 - val_accuracy: 0.4983 - val_loss: 2.4108 - learning_rate: 6.4935e-05
Epoch 119/300
657/657 - 69s - 105ms/step - accuracy: 0.3825 - loss: 3.1298 - val_accuracy: 0.5086 - val_loss: 2.4049 - learning_rate: 6.4935e-05
Epoch 120/300
657/657 - 67s - 103ms/step - accuracy: 0.3878 - loss: 3.1530 - val_accuracy: 0.5068 - val_loss: 2.3992 - learning_rate: 6.4935e-05
Epoch 121/300
657/657 - 68s - 103ms/step - accuracy: 0.3903 - loss: 3.1545 - val_accuracy: 0.5051 - val_loss: 2.3952 - learning_rate: 6.4935e-05
Epoch 122/300
657/657 - 67s - 102ms/step - accuracy: 0.3933 - loss: 3.1287 - val_accuracy: 0.5137 - val_loss: 2.4090 - learning_rate: 6.4935e-05
Epoch 123/300
657/657 - 67s - 102ms/step - accuracy: 0.3846 - loss: 3.1615 - val_accuracy: 0.5086 - val_loss: 2.4207 - learning_rate: 6.4935e-05
Epoch 124/300
657/657 - 67s - 102ms/step - accuracy: 0.3931 - loss: 3.1281 - val_accuracy: 0.5103 - val_loss: 2.3993 - learning_rate: 6.4935e-05
Epoch 125/300
657/657 - 67s - 102ms/step - accuracy: 0.3884 - loss: 3.1553 - val_accuracy: 0.5068 - val_loss: 2.4233 - learning_rate: 6.4935e-05
Epoch 126/300
657/657 - 68s - 103ms/step - accuracy: 0.3873 - loss: 3.1424 - val_accuracy: 0.5103 - val_loss: 2.4313 - learning_rate: 6.4935e-05
Epoch 127/300
657/657 - 69s - 104ms/step - accuracy: 0.3873 - loss: 3.1654 - val_accuracy: 0.5034 - val_loss: 2.3908 - learning_rate: 6.4935e-05
Epoch 128/300
657/657 - 69s - 105ms/step - accuracy: 0.3888 - loss: 3.1464 - val_accuracy: 0.5068 - val_loss: 2.3919 - learning_rate: 6.4935e-05
Epoch 129/300
657/657 - 69s - 105ms/step - accuracy: 0.3850 - loss: 3.1573 - val_accuracy: 0.4949 - val_loss: 2.4126 - learning_rate: 6.4935e-05
Epoch 130/300
657/657 - 68s - 103ms/step - accuracy: 0.3931 - loss: 3.1415 - val_accuracy: 0.5154 - val_loss: 2.3853 - learning_rate: 6.4935e-05
Epoch 131/300
657/657 - 67s - 102ms/step - accuracy: 0.3945 - loss: 3.1108 - val_accuracy: 0.5120 - val_loss: 2.3849 - learning_rate: 6.4935e-05
Epoch 132/300
657/657 - 69s - 105ms/step - accuracy: 0.3869 - loss: 3.1420 - val_accuracy: 0.5154 - val_loss: 2.4022 - learning_rate: 6.4935e-05
Epoch 133/300
657/657 - 66s - 100ms/step - accuracy: 0.3882 - loss: 3.1608 - val_accuracy: 0.5034 - val_loss: 2.4031 - learning_rate: 6.4935e-05
Epoch 134/300
657/657 - 67s - 102ms/step - accuracy: 0.3871 - loss: 3.1669 - val_accuracy: 0.5240 - val_loss: 2.4256 - learning_rate: 6.4935e-05
Epoch 135/300
657/657 - 69s - 105ms/step - accuracy: 0.3992 - loss: 3.1198 - val_accuracy: 0.5137 - val_loss: 2.3984 - learning_rate: 6.4935e-05
Epoch 136/300
657/657 - 68s - 103ms/step - accuracy: 0.3880 - loss: 3.1234 - val_accuracy: 0.5205 - val_loss: 2.4256 - learning_rate: 6.4935e-05
Epoch 137/300
657/657 - 69s - 105ms/step - accuracy: 0.3901 - loss: 3.1414 - val_accuracy: 0.5171 - val_loss: 2.3820 - learning_rate: 6.4935e-05
Epoch 138/300
657/657 - 70s - 106ms/step - accuracy: 0.3964 - loss: 3.1130 - val_accuracy: 0.5103 - val_loss: 2.3652 - learning_rate: 6.4935e-05
Epoch 139/300
657/657 - 67s - 102ms/step - accuracy: 0.3812 - loss: 3.1875 - val_accuracy: 0.5171 - val_loss: 2.3837 - learning_rate: 6.4935e-05
Epoch 140/300
657/657 - 68s - 103ms/step - accuracy: 0.3880 - loss: 3.1434 - val_accuracy: 0.5205 - val_loss: 2.3885 - learning_rate: 6.4935e-05
Epoch 141/300
657/657 - 69s - 105ms/step - accuracy: 0.3926 - loss: 3.1252 - val_accuracy: 0.5137 - val_loss: 2.3859 - learning_rate: 6.4935e-05
Epoch 142/300
657/657 - 69s - 105ms/step - accuracy: 0.3901 - loss: 3.1510 - val_accuracy: 0.5223 - val_loss: 2.3863 - learning_rate: 6.4935e-05
Epoch 143/300
657/657 - 66s - 100ms/step - accuracy: 0.3876 - loss: 3.1412 - val_accuracy: 0.5120 - val_loss: 2.3976 - learning_rate: 6.4935e-05
Epoch 144/300
657/657 - 67s - 102ms/step - accuracy: 0.3911 - loss: 3.1000 - val_accuracy: 0.5188 - val_loss: 2.4140 - learning_rate: 6.4935e-05
Epoch 145/300
657/657 - 67s - 102ms/step - accuracy: 0.3939 - loss: 3.1125 - val_accuracy: 0.5171 - val_loss: 2.4040 - learning_rate: 6.4935e-05
Epoch 146/300

Epoch 146: ReduceLROnPlateau reducing learning rate to 3.2467261917190626e-05.
657/657 - 68s - 104ms/step - accuracy: 0.3922 - loss: 3.1517 - val_accuracy: 0.5223 - val_loss: 2.4089 - learning_rate: 6.4935e-05
Epoch 147/300
657/657 - 69s - 105ms/step - accuracy: 0.3966 - loss: 3.0903 - val_accuracy: 0.5154 - val_loss: 2.3852 - learning_rate: 3.2467e-05
Epoch 148/300
657/657 - 68s - 103ms/step - accuracy: 0.3973 - loss: 3.1014 - val_accuracy: 0.5120 - val_loss: 2.3675 - learning_rate: 3.2467e-05
Epoch 149/300
657/657 - 68s - 103ms/step - accuracy: 0.3975 - loss: 3.1172 - val_accuracy: 0.5154 - val_loss: 2.3885 - learning_rate: 3.2467e-05
Epoch 150/300
657/657 - 67s - 102ms/step - accuracy: 0.4063 - loss: 3.1024 - val_accuracy: 0.5188 - val_loss: 2.3906 - learning_rate: 3.2467e-05
Epoch 151/300
657/657 - 69s - 105ms/step - accuracy: 0.3964 - loss: 3.1374 - val_accuracy: 0.5154 - val_loss: 2.3746 - learning_rate: 3.2467e-05
Epoch 152/300
657/657 - 68s - 104ms/step - accuracy: 0.3907 - loss: 3.1482 - val_accuracy: 0.5120 - val_loss: 2.3688 - learning_rate: 3.2467e-05
Epoch 153/300
657/657 - 68s - 103ms/step - accuracy: 0.3911 - loss: 3.1494 - val_accuracy: 0.5137 - val_loss: 2.3688 - learning_rate: 3.2467e-05
Epoch 154/300

Epoch 154: ReduceLROnPlateau reducing learning rate to 1.6233630958595313e-05.
657/657 - 68s - 104ms/step - accuracy: 0.3952 - loss: 3.1131 - val_accuracy: 0.5257 - val_loss: 2.3941 - learning_rate: 3.2467e-05
Epoch 154: early stopping
Restoring model weights from the end of the best epoch: 138.
Fold 5 Evaluation results: [2.378199338912964, 0.5102739930152893]
              precision    recall  f1-score   support

        1820       0.70      0.74      0.72        43
        1821       0.00      0.00      0.00         1
        1822       0.00      0.00      0.00         1
        1823       0.00      0.00      0.00         1
        1824       0.00      0.00      0.00         1
        1825       0.00      0.00      0.00         1
        1826       0.00      0.00      0.00         2
        1827       1.00      0.14      0.25         7
        1828       0.00      0.00      0.00         2
        1829       0.67      0.50      0.57         4
        1830       0.52      0.77      0.62        44
        1831       0.00      0.00      0.00         0
        1832       0.89      0.89      0.89        53
        1833       0.95      0.95      0.95        19
        1834       0.50      0.33      0.40         6
        1835       0.00      0.00      0.00         2
        1836       1.00      0.25      0.40         4
        1837       0.46      0.86      0.60         7
        1838       0.00      0.00      0.00         4
        1839       0.00      0.00      0.00         1
        1840       0.51      0.56      0.53        43
        1841       0.50      0.20      0.29        10
        1842       1.00      0.60      0.75         5
        1843       1.00      0.33      0.50         6
        1844       0.00      0.00      0.00         0
        1845       0.00      0.00      0.00         1
        1846       0.33      0.17      0.22         6
        1847       0.00      0.00      0.00         2
        1848       0.33      0.33      0.33         6
        1849       0.00      0.00      0.00         5
        1850       0.34      0.62      0.44        48
        1851       1.00      0.17      0.29         6
        1852       0.00      0.00      0.00         7
        1853       0.00      0.00      0.00         6
        1854       0.00      0.00      0.00         3
        1855       0.38      0.27      0.32        11
        1856       0.64      0.58      0.61        12
        1857       0.12      0.12      0.12         8
        1858       0.00      0.00      0.00         2
        1859       0.00      0.00      0.00         2
        1860       0.34      0.52      0.41        48
        1861       0.00      0.00      0.00         1
        1862       0.00      0.00      0.00         7
        1863       0.33      0.40      0.36         5
        1864       0.00      0.00      0.00         5
        1865       0.00      0.00      0.00         7
        1866       1.00      0.33      0.50         6
        1867       0.50      0.36      0.42        11
        1868       0.00      0.00      0.00         7
        1869       0.00      0.00      0.00         6
        1870       0.42      0.68      0.52        31
        1871       1.00      0.20      0.33         5
        1872       0.40      0.57      0.47         7
        1873       0.00      0.00      0.00        10
        1874       0.50      0.20      0.29         5
        1875       0.50      0.60      0.55         5
        1876       1.00      0.80      0.89        10
        1877       0.33      0.50      0.40         6
        1878       0.71      0.56      0.62         9
        1879       0.00      0.00      0.00         1

    accuracy                           0.51       584
   macro avg       0.33      0.25      0.26       584
weighted avg       0.49      0.51      0.48       584

Matthews Correlation Coefficient: 0.482
Macro avg F1: 0.259
Weighted avg F1: 0.475
Micro avg F1: 0.510
Top-3 Accuracy: 0.774
Top-5 Accuracy: 0.851
Micro ROC AUC  = 0.97
Macro ROC AUC (present classes) = 0.97
Classification MAE (in years): 3.57

Fold 5 Misclassification Analysis:
Near misses (within 2 years): 79 out of 286 misclassifications (27.62%)
Big misses (greater than 10 years): 95
MAE with outliers: 3.57
MAE without outliers: 2.51 (improvement: 1.06)

10 Worst misclassifications:
Image: data/datasets/public/1870/1870_130wikimedia2.jpg, True: 1870, Predicted: 1820, Error: 50
Image: data/datasets/public/1870/1876_53washington.jpg, True: 1876, Predicted: 1832, Error: 44
Image: data/datasets/public/1870/1873_1812vna.jpg, True: 1873, Predicted: 1832, Error: 41
Image: data/datasets/public/1820/1820_040met.jpg, True: 1820, Predicted: 1860, Error: 40
Image: data/datasets/public/1870/1870_28wikimedia2.jpg, True: 1870, Predicted: 1830, Error: 40
Image: data/datasets/public/1820/1820_033met.jpg, True: 1820, Predicted: 1850, Error: 30
Image: data/datasets/public/1820/1820_034met.jpg, True: 1820, Predicted: 1850, Error: 30
Image: data/datasets/public/1870/1870_156wikimedia2.jpg, True: 1870, Predicted: 1840, Error: 30
Image: data/datasets/public/1830/1834_3056vna.jpg, True: 1834, Predicted: 1860, Error: 26
Image: data/datasets/public/1860/1865_30washington.jpg, True: 1865, Predicted: 1840, Error: 25

===== Fold 6 =====
=== Running on Public Data ===

===== Fine Tuning 9 layers! =====
Epoch 1/300
657/657 - 91s - 138ms/step - accuracy: 0.1001 - loss: 4.7213 - val_accuracy: 0.1250 - val_loss: 3.9474 - learning_rate: 2.5974e-04
Epoch 2/300
657/657 - 66s - 101ms/step - accuracy: 0.1560 - loss: 4.4650 - val_accuracy: 0.2432 - val_loss: 3.8730 - learning_rate: 2.5974e-04
Epoch 3/300
657/657 - 66s - 100ms/step - accuracy: 0.1886 - loss: 4.3181 - val_accuracy: 0.2397 - val_loss: 3.6871 - learning_rate: 2.5974e-04
Epoch 4/300
657/657 - 68s - 104ms/step - accuracy: 0.2110 - loss: 4.2625 - val_accuracy: 0.2620 - val_loss: 4.0325 - learning_rate: 2.5974e-04
Epoch 5/300
657/657 - 69s - 106ms/step - accuracy: 0.2209 - loss: 4.1864 - val_accuracy: 0.3031 - val_loss: 3.8019 - learning_rate: 2.5974e-04
Epoch 6/300
657/657 - 69s - 105ms/step - accuracy: 0.2394 - loss: 4.1145 - val_accuracy: 0.3442 - val_loss: 3.6724 - learning_rate: 2.5974e-04
Epoch 7/300
657/657 - 67s - 102ms/step - accuracy: 0.2525 - loss: 4.0910 - val_accuracy: 0.3493 - val_loss: 3.6426 - learning_rate: 2.5974e-04
Epoch 8/300
657/657 - 66s - 101ms/step - accuracy: 0.2622 - loss: 4.0303 - val_accuracy: 0.3682 - val_loss: 3.6756 - learning_rate: 2.5974e-04
Epoch 9/300
657/657 - 70s - 107ms/step - accuracy: 0.2708 - loss: 4.0074 - val_accuracy: 0.3562 - val_loss: 3.4768 - learning_rate: 2.5974e-04
Epoch 10/300
657/657 - 70s - 106ms/step - accuracy: 0.2733 - loss: 3.9803 - val_accuracy: 0.3699 - val_loss: 3.3977 - learning_rate: 2.5974e-04
Epoch 11/300
657/657 - 69s - 105ms/step - accuracy: 0.2833 - loss: 3.9134 - val_accuracy: 0.3801 - val_loss: 3.3856 - learning_rate: 2.5974e-04
Epoch 12/300
657/657 - 69s - 105ms/step - accuracy: 0.2845 - loss: 3.8558 - val_accuracy: 0.3733 - val_loss: 3.2718 - learning_rate: 2.5974e-04
Epoch 13/300
657/657 - 69s - 106ms/step - accuracy: 0.2864 - loss: 3.8374 - val_accuracy: 0.3818 - val_loss: 3.2673 - learning_rate: 2.5974e-04
Epoch 14/300
657/657 - 68s - 103ms/step - accuracy: 0.2936 - loss: 3.8330 - val_accuracy: 0.3801 - val_loss: 3.1283 - learning_rate: 2.5974e-04
Epoch 15/300
657/657 - 70s - 106ms/step - accuracy: 0.2910 - loss: 3.8614 - val_accuracy: 0.3853 - val_loss: 3.1547 - learning_rate: 2.5974e-04
Epoch 16/300
657/657 - 69s - 105ms/step - accuracy: 0.2965 - loss: 3.7906 - val_accuracy: 0.3990 - val_loss: 3.1873 - learning_rate: 2.5974e-04
Epoch 17/300
657/657 - 69s - 105ms/step - accuracy: 0.3052 - loss: 3.7280 - val_accuracy: 0.4110 - val_loss: 3.0568 - learning_rate: 2.5974e-04
Epoch 18/300
657/657 - 71s - 107ms/step - accuracy: 0.3026 - loss: 3.7458 - val_accuracy: 0.4127 - val_loss: 3.0526 - learning_rate: 2.5974e-04
Epoch 19/300
657/657 - 66s - 101ms/step - accuracy: 0.3010 - loss: 3.7338 - val_accuracy: 0.4092 - val_loss: 3.0208 - learning_rate: 2.5974e-04
Epoch 20/300
657/657 - 65s - 99ms/step - accuracy: 0.3069 - loss: 3.7207 - val_accuracy: 0.4058 - val_loss: 3.0672 - learning_rate: 2.5974e-04
Epoch 21/300
657/657 - 67s - 102ms/step - accuracy: 0.3096 - loss: 3.7037 - val_accuracy: 0.4178 - val_loss: 2.9680 - learning_rate: 2.5974e-04
Epoch 22/300
657/657 - 64s - 97ms/step - accuracy: 0.3191 - loss: 3.6704 - val_accuracy: 0.4024 - val_loss: 2.9947 - learning_rate: 2.5974e-04
Epoch 23/300
657/657 - 65s - 100ms/step - accuracy: 0.3096 - loss: 3.6625 - val_accuracy: 0.3990 - val_loss: 2.9852 - learning_rate: 2.5974e-04
Epoch 24/300
657/657 - 62s - 95ms/step - accuracy: 0.3142 - loss: 3.6299 - val_accuracy: 0.4161 - val_loss: 2.9650 - learning_rate: 2.5974e-04
Epoch 25/300
657/657 - 63s - 96ms/step - accuracy: 0.3128 - loss: 3.6626 - val_accuracy: 0.4144 - val_loss: 2.9663 - learning_rate: 2.5974e-04
Epoch 26/300
657/657 - 65s - 99ms/step - accuracy: 0.3085 - loss: 3.6427 - val_accuracy: 0.4092 - val_loss: 2.8906 - learning_rate: 2.5974e-04
Epoch 27/300
657/657 - 63s - 96ms/step - accuracy: 0.3180 - loss: 3.6245 - val_accuracy: 0.4281 - val_loss: 2.7943 - learning_rate: 2.5974e-04
Epoch 28/300
657/657 - 67s - 102ms/step - accuracy: 0.3279 - loss: 3.6028 - val_accuracy: 0.4264 - val_loss: 2.9272 - learning_rate: 2.5974e-04
Epoch 29/300
657/657 - 65s - 99ms/step - accuracy: 0.3222 - loss: 3.5922 - val_accuracy: 0.4384 - val_loss: 2.8510 - learning_rate: 2.5974e-04
Epoch 30/300
657/657 - 64s - 98ms/step - accuracy: 0.3243 - loss: 3.5908 - val_accuracy: 0.4503 - val_loss: 2.8073 - learning_rate: 2.5974e-04
Epoch 31/300
657/657 - 65s - 99ms/step - accuracy: 0.3292 - loss: 3.5737 - val_accuracy: 0.4418 - val_loss: 2.7974 - learning_rate: 2.5974e-04
Epoch 32/300
657/657 - 66s - 100ms/step - accuracy: 0.3324 - loss: 3.5649 - val_accuracy: 0.4332 - val_loss: 2.7633 - learning_rate: 2.5974e-04
Epoch 33/300
657/657 - 66s - 100ms/step - accuracy: 0.3256 - loss: 3.5857 - val_accuracy: 0.4315 - val_loss: 2.7946 - learning_rate: 2.5974e-04
Epoch 34/300
657/657 - 63s - 96ms/step - accuracy: 0.3311 - loss: 3.5398 - val_accuracy: 0.4418 - val_loss: 2.7182 - learning_rate: 2.5974e-04
Epoch 35/300
657/657 - 65s - 99ms/step - accuracy: 0.3292 - loss: 3.5470 - val_accuracy: 0.4521 - val_loss: 2.7490 - learning_rate: 2.5974e-04
Epoch 36/300
657/657 - 65s - 98ms/step - accuracy: 0.3296 - loss: 3.5744 - val_accuracy: 0.4315 - val_loss: 2.8145 - learning_rate: 2.5974e-04
Epoch 37/300
657/657 - 64s - 98ms/step - accuracy: 0.3391 - loss: 3.5328 - val_accuracy: 0.4658 - val_loss: 2.7364 - learning_rate: 2.5974e-04
Epoch 38/300
657/657 - 65s - 98ms/step - accuracy: 0.3372 - loss: 3.5377 - val_accuracy: 0.4418 - val_loss: 2.7728 - learning_rate: 2.5974e-04
Epoch 39/300
657/657 - 66s - 101ms/step - accuracy: 0.3385 - loss: 3.5287 - val_accuracy: 0.4521 - val_loss: 2.7312 - learning_rate: 2.5974e-04
Epoch 40/300
657/657 - 65s - 99ms/step - accuracy: 0.3393 - loss: 3.5087 - val_accuracy: 0.4503 - val_loss: 2.7063 - learning_rate: 2.5974e-04
Epoch 41/300
657/657 - 66s - 101ms/step - accuracy: 0.3372 - loss: 3.5063 - val_accuracy: 0.4658 - val_loss: 2.7085 - learning_rate: 2.5974e-04
Epoch 42/300
657/657 - 65s - 99ms/step - accuracy: 0.3321 - loss: 3.4924 - val_accuracy: 0.4640 - val_loss: 2.6731 - learning_rate: 2.5974e-04
Epoch 43/300
657/657 - 65s - 99ms/step - accuracy: 0.3271 - loss: 3.5094 - val_accuracy: 0.4640 - val_loss: 2.6857 - learning_rate: 2.5974e-04
Epoch 44/300
657/657 - 79s - 121ms/step - accuracy: 0.3423 - loss: 3.4863 - val_accuracy: 0.4486 - val_loss: 2.6480 - learning_rate: 2.5974e-04
Epoch 45/300
657/657 - 66s - 100ms/step - accuracy: 0.3422 - loss: 3.4840 - val_accuracy: 0.4623 - val_loss: 2.6599 - learning_rate: 2.5974e-04
Epoch 46/300
657/657 - 64s - 97ms/step - accuracy: 0.3343 - loss: 3.5193 - val_accuracy: 0.4623 - val_loss: 2.7087 - learning_rate: 2.5974e-04
Epoch 47/300
657/657 - 63s - 96ms/step - accuracy: 0.3347 - loss: 3.4768 - val_accuracy: 0.4349 - val_loss: 2.6969 - learning_rate: 2.5974e-04
Epoch 48/300
657/657 - 66s - 100ms/step - accuracy: 0.3412 - loss: 3.4784 - val_accuracy: 0.4521 - val_loss: 2.6370 - learning_rate: 2.5974e-04
Epoch 49/300
657/657 - 66s - 101ms/step - accuracy: 0.3395 - loss: 3.4885 - val_accuracy: 0.4315 - val_loss: 2.6685 - learning_rate: 2.5974e-04
Epoch 50/300
657/657 - 64s - 98ms/step - accuracy: 0.3532 - loss: 3.4070 - val_accuracy: 0.4743 - val_loss: 2.6329 - learning_rate: 2.5974e-04
Epoch 51/300
657/657 - 64s - 98ms/step - accuracy: 0.3402 - loss: 3.4828 - val_accuracy: 0.4658 - val_loss: 2.6663 - learning_rate: 2.5974e-04
Epoch 52/300
657/657 - 66s - 101ms/step - accuracy: 0.3507 - loss: 3.4213 - val_accuracy: 0.4777 - val_loss: 2.6019 - learning_rate: 2.5974e-04
Epoch 53/300
657/657 - 67s - 102ms/step - accuracy: 0.3484 - loss: 3.3987 - val_accuracy: 0.4846 - val_loss: 2.6656 - learning_rate: 2.5974e-04
Epoch 54/300
657/657 - 62s - 95ms/step - accuracy: 0.3469 - loss: 3.4077 - val_accuracy: 0.4914 - val_loss: 2.6281 - learning_rate: 2.5974e-04
Epoch 55/300
657/657 - 65s - 99ms/step - accuracy: 0.3338 - loss: 3.4598 - val_accuracy: 0.4658 - val_loss: 2.6168 - learning_rate: 2.5974e-04
Epoch 56/300
657/657 - 65s - 100ms/step - accuracy: 0.3420 - loss: 3.4365 - val_accuracy: 0.4743 - val_loss: 2.6121 - learning_rate: 2.5974e-04
Epoch 57/300
657/657 - 66s - 100ms/step - accuracy: 0.3378 - loss: 3.4651 - val_accuracy: 0.4675 - val_loss: 2.6568 - learning_rate: 2.5974e-04
Epoch 58/300
657/657 - 64s - 97ms/step - accuracy: 0.3412 - loss: 3.4063 - val_accuracy: 0.4726 - val_loss: 2.6567 - learning_rate: 2.5974e-04
Epoch 59/300
657/657 - 66s - 101ms/step - accuracy: 0.3477 - loss: 3.3863 - val_accuracy: 0.4760 - val_loss: 2.6259 - learning_rate: 2.5974e-04
Epoch 60/300
657/657 - 66s - 100ms/step - accuracy: 0.3503 - loss: 3.4023 - val_accuracy: 0.4675 - val_loss: 2.5716 - learning_rate: 2.5974e-04
Epoch 61/300
657/657 - 64s - 98ms/step - accuracy: 0.3503 - loss: 3.4211 - val_accuracy: 0.4897 - val_loss: 2.6083 - learning_rate: 2.5974e-04
Epoch 62/300
657/657 - 65s - 99ms/step - accuracy: 0.3488 - loss: 3.3729 - val_accuracy: 0.4812 - val_loss: 2.6266 - learning_rate: 2.5974e-04
Epoch 63/300
657/657 - 67s - 102ms/step - accuracy: 0.3513 - loss: 3.3932 - val_accuracy: 0.5017 - val_loss: 2.6116 - learning_rate: 2.5974e-04
Epoch 64/300
657/657 - 62s - 95ms/step - accuracy: 0.3475 - loss: 3.3551 - val_accuracy: 0.4829 - val_loss: 2.6458 - learning_rate: 2.5974e-04
Epoch 65/300
657/657 - 64s - 98ms/step - accuracy: 0.3555 - loss: 3.3870 - val_accuracy: 0.4709 - val_loss: 2.5482 - learning_rate: 2.5974e-04
Epoch 66/300
657/657 - 67s - 102ms/step - accuracy: 0.3598 - loss: 3.3616 - val_accuracy: 0.4846 - val_loss: 2.6062 - learning_rate: 2.5974e-04
Epoch 67/300
657/657 - 65s - 98ms/step - accuracy: 0.3498 - loss: 3.4002 - val_accuracy: 0.4692 - val_loss: 2.6082 - learning_rate: 2.5974e-04
Epoch 68/300
657/657 - 64s - 98ms/step - accuracy: 0.3553 - loss: 3.3675 - val_accuracy: 0.4897 - val_loss: 2.6076 - learning_rate: 2.5974e-04
Epoch 69/300
657/657 - 65s - 98ms/step - accuracy: 0.3532 - loss: 3.4033 - val_accuracy: 0.4795 - val_loss: 2.6149 - learning_rate: 2.5974e-04
Epoch 70/300
657/657 - 67s - 101ms/step - accuracy: 0.3557 - loss: 3.4014 - val_accuracy: 0.4726 - val_loss: 2.5940 - learning_rate: 2.5974e-04
Epoch 71/300
657/657 - 64s - 98ms/step - accuracy: 0.3547 - loss: 3.3450 - val_accuracy: 0.4812 - val_loss: 2.5897 - learning_rate: 2.5974e-04
Epoch 72/300
657/657 - 64s - 98ms/step - accuracy: 0.3526 - loss: 3.3750 - val_accuracy: 0.4658 - val_loss: 2.5768 - learning_rate: 2.5974e-04
Epoch 73/300

Epoch 73: ReduceLROnPlateau reducing learning rate to 0.0001298690476687625.
657/657 - 64s - 98ms/step - accuracy: 0.3562 - loss: 3.3287 - val_accuracy: 0.4829 - val_loss: 2.5531 - learning_rate: 2.5974e-04
Epoch 74/300
657/657 - 64s - 97ms/step - accuracy: 0.3640 - loss: 3.3040 - val_accuracy: 0.4966 - val_loss: 2.5182 - learning_rate: 1.2987e-04
Epoch 75/300
657/657 - 65s - 99ms/step - accuracy: 0.3671 - loss: 3.3020 - val_accuracy: 0.4897 - val_loss: 2.5585 - learning_rate: 1.2987e-04
Epoch 76/300
657/657 - 65s - 99ms/step - accuracy: 0.3768 - loss: 3.2950 - val_accuracy: 0.5086 - val_loss: 2.5282 - learning_rate: 1.2987e-04
Epoch 77/300
657/657 - 81s - 124ms/step - accuracy: 0.3716 - loss: 3.2791 - val_accuracy: 0.4983 - val_loss: 2.5267 - learning_rate: 1.2987e-04
Epoch 78/300
657/657 - 66s - 100ms/step - accuracy: 0.3621 - loss: 3.2843 - val_accuracy: 0.4880 - val_loss: 2.5204 - learning_rate: 1.2987e-04
Epoch 79/300
657/657 - 64s - 97ms/step - accuracy: 0.3642 - loss: 3.2763 - val_accuracy: 0.5017 - val_loss: 2.5080 - learning_rate: 1.2987e-04
Epoch 80/300
657/657 - 65s - 99ms/step - accuracy: 0.3585 - loss: 3.2948 - val_accuracy: 0.4932 - val_loss: 2.5101 - learning_rate: 1.2987e-04
Epoch 81/300
657/657 - 66s - 101ms/step - accuracy: 0.3618 - loss: 3.3086 - val_accuracy: 0.4983 - val_loss: 2.4934 - learning_rate: 1.2987e-04
Epoch 82/300
657/657 - 64s - 98ms/step - accuracy: 0.3692 - loss: 3.2874 - val_accuracy: 0.5120 - val_loss: 2.5532 - learning_rate: 1.2987e-04
Epoch 83/300
657/657 - 66s - 101ms/step - accuracy: 0.3627 - loss: 3.2442 - val_accuracy: 0.4983 - val_loss: 2.5296 - learning_rate: 1.2987e-04
Epoch 84/300
657/657 - 62s - 94ms/step - accuracy: 0.3718 - loss: 3.2875 - val_accuracy: 0.4880 - val_loss: 2.4678 - learning_rate: 1.2987e-04
Epoch 85/300
657/657 - 84s - 128ms/step - accuracy: 0.3724 - loss: 3.2439 - val_accuracy: 0.5034 - val_loss: 2.4407 - learning_rate: 1.2987e-04
Epoch 86/300
657/657 - 65s - 99ms/step - accuracy: 0.3707 - loss: 3.2562 - val_accuracy: 0.4897 - val_loss: 2.4673 - learning_rate: 1.2987e-04
Epoch 87/300
657/657 - 63s - 96ms/step - accuracy: 0.3688 - loss: 3.2254 - val_accuracy: 0.5103 - val_loss: 2.4588 - learning_rate: 1.2987e-04
Epoch 88/300
657/657 - 64s - 98ms/step - accuracy: 0.3678 - loss: 3.2610 - val_accuracy: 0.5051 - val_loss: 2.4990 - learning_rate: 1.2987e-04
Epoch 89/300
657/657 - 66s - 100ms/step - accuracy: 0.3675 - loss: 3.2509 - val_accuracy: 0.5051 - val_loss: 2.4547 - learning_rate: 1.2987e-04
Epoch 90/300
657/657 - 64s - 98ms/step - accuracy: 0.3715 - loss: 3.2600 - val_accuracy: 0.4863 - val_loss: 2.4639 - learning_rate: 1.2987e-04
Epoch 91/300
657/657 - 66s - 101ms/step - accuracy: 0.3781 - loss: 3.2123 - val_accuracy: 0.4914 - val_loss: 2.4353 - learning_rate: 1.2987e-04
Epoch 92/300
657/657 - 64s - 98ms/step - accuracy: 0.3720 - loss: 3.2543 - val_accuracy: 0.4829 - val_loss: 2.4536 - learning_rate: 1.2987e-04
Epoch 93/300
657/657 - 66s - 100ms/step - accuracy: 0.3741 - loss: 3.2453 - val_accuracy: 0.5205 - val_loss: 2.4558 - learning_rate: 1.2987e-04
Epoch 94/300
657/657 - 63s - 96ms/step - accuracy: 0.3783 - loss: 3.2171 - val_accuracy: 0.5223 - val_loss: 2.4954 - learning_rate: 1.2987e-04
Epoch 95/300
657/657 - 64s - 97ms/step - accuracy: 0.3751 - loss: 3.2359 - val_accuracy: 0.5171 - val_loss: 2.4659 - learning_rate: 1.2987e-04
Epoch 96/300
657/657 - 64s - 97ms/step - accuracy: 0.3762 - loss: 3.2441 - val_accuracy: 0.4897 - val_loss: 2.4602 - learning_rate: 1.2987e-04
Epoch 97/300
657/657 - 64s - 97ms/step - accuracy: 0.3680 - loss: 3.2055 - val_accuracy: 0.5000 - val_loss: 2.4584 - learning_rate: 1.2987e-04
Epoch 98/300
657/657 - 66s - 101ms/step - accuracy: 0.3777 - loss: 3.2466 - val_accuracy: 0.5017 - val_loss: 2.4411 - learning_rate: 1.2987e-04
Epoch 99/300

Epoch 99: ReduceLROnPlateau reducing learning rate to 6.493452383438125e-05.
657/657 - 65s - 100ms/step - accuracy: 0.3755 - loss: 3.2432 - val_accuracy: 0.5000 - val_loss: 2.4606 - learning_rate: 1.2987e-04
Epoch 100/300
657/657 - 65s - 99ms/step - accuracy: 0.3836 - loss: 3.1734 - val_accuracy: 0.5086 - val_loss: 2.4336 - learning_rate: 6.4935e-05
Epoch 101/300
657/657 - 66s - 100ms/step - accuracy: 0.3715 - loss: 3.2449 - val_accuracy: 0.5137 - val_loss: 2.4464 - learning_rate: 6.4935e-05
Epoch 102/300
657/657 - 65s - 99ms/step - accuracy: 0.3808 - loss: 3.1886 - val_accuracy: 0.5068 - val_loss: 2.4383 - learning_rate: 6.4935e-05
Epoch 103/300
657/657 - 65s - 99ms/step - accuracy: 0.3855 - loss: 3.1907 - val_accuracy: 0.5103 - val_loss: 2.4551 - learning_rate: 6.4935e-05
Epoch 104/300
657/657 - 62s - 94ms/step - accuracy: 0.3663 - loss: 3.2397 - val_accuracy: 0.4983 - val_loss: 2.4331 - learning_rate: 6.4935e-05
Epoch 105/300
657/657 - 66s - 101ms/step - accuracy: 0.3705 - loss: 3.1990 - val_accuracy: 0.5068 - val_loss: 2.4285 - learning_rate: 6.4935e-05
Epoch 106/300
657/657 - 64s - 98ms/step - accuracy: 0.3808 - loss: 3.2331 - val_accuracy: 0.4914 - val_loss: 2.4403 - learning_rate: 6.4935e-05
Epoch 107/300
657/657 - 64s - 98ms/step - accuracy: 0.3831 - loss: 3.1949 - val_accuracy: 0.5068 - val_loss: 2.4462 - learning_rate: 6.4935e-05
Epoch 108/300
657/657 - 66s - 101ms/step - accuracy: 0.3753 - loss: 3.2167 - val_accuracy: 0.4966 - val_loss: 2.4489 - learning_rate: 6.4935e-05
Epoch 109/300
657/657 - 67s - 102ms/step - accuracy: 0.3844 - loss: 3.1705 - val_accuracy: 0.5000 - val_loss: 2.4197 - learning_rate: 6.4935e-05
Epoch 110/300
657/657 - 64s - 98ms/step - accuracy: 0.3793 - loss: 3.2036 - val_accuracy: 0.5000 - val_loss: 2.4201 - learning_rate: 6.4935e-05
Epoch 111/300
657/657 - 62s - 94ms/step - accuracy: 0.3876 - loss: 3.1400 - val_accuracy: 0.5171 - val_loss: 2.4300 - learning_rate: 6.4935e-05
Epoch 112/300
657/657 - 68s - 104ms/step - accuracy: 0.3825 - loss: 3.2066 - val_accuracy: 0.5017 - val_loss: 2.4114 - learning_rate: 6.4935e-05
Epoch 113/300
657/657 - 64s - 98ms/step - accuracy: 0.3865 - loss: 3.1925 - val_accuracy: 0.5017 - val_loss: 2.4182 - learning_rate: 6.4935e-05
Epoch 114/300
657/657 - 63s - 97ms/step - accuracy: 0.3819 - loss: 3.1780 - val_accuracy: 0.5086 - val_loss: 2.4351 - learning_rate: 6.4935e-05
Epoch 115/300
657/657 - 65s - 100ms/step - accuracy: 0.3747 - loss: 3.2183 - val_accuracy: 0.5068 - val_loss: 2.4431 - learning_rate: 6.4935e-05
Epoch 116/300
657/657 - 65s - 98ms/step - accuracy: 0.3774 - loss: 3.1966 - val_accuracy: 0.5000 - val_loss: 2.4318 - learning_rate: 6.4935e-05
Epoch 117/300
657/657 - 65s - 99ms/step - accuracy: 0.3739 - loss: 3.2176 - val_accuracy: 0.4932 - val_loss: 2.4201 - learning_rate: 6.4935e-05
Epoch 118/300
657/657 - 65s - 98ms/step - accuracy: 0.3804 - loss: 3.1845 - val_accuracy: 0.5068 - val_loss: 2.4284 - learning_rate: 6.4935e-05
Epoch 119/300
657/657 - 66s - 101ms/step - accuracy: 0.3796 - loss: 3.1622 - val_accuracy: 0.5103 - val_loss: 2.4261 - learning_rate: 6.4935e-05
Epoch 120/300
657/657 - 65s - 99ms/step - accuracy: 0.3783 - loss: 3.1683 - val_accuracy: 0.5000 - val_loss: 2.4010 - learning_rate: 6.4935e-05
Epoch 121/300
657/657 - 65s - 99ms/step - accuracy: 0.3863 - loss: 3.1561 - val_accuracy: 0.5068 - val_loss: 2.4100 - learning_rate: 6.4935e-05
Epoch 122/300
657/657 - 65s - 99ms/step - accuracy: 0.3914 - loss: 3.1827 - val_accuracy: 0.5086 - val_loss: 2.4302 - learning_rate: 6.4935e-05
Epoch 123/300
657/657 - 68s - 103ms/step - accuracy: 0.3833 - loss: 3.1779 - val_accuracy: 0.5068 - val_loss: 2.4074 - learning_rate: 6.4935e-05
Epoch 124/300
657/657 - 62s - 95ms/step - accuracy: 0.3817 - loss: 3.1859 - val_accuracy: 0.4983 - val_loss: 2.4205 - learning_rate: 6.4935e-05
Epoch 125/300
657/657 - 66s - 100ms/step - accuracy: 0.3842 - loss: 3.1875 - val_accuracy: 0.4966 - val_loss: 2.4199 - learning_rate: 6.4935e-05
Epoch 126/300
657/657 - 64s - 98ms/step - accuracy: 0.3728 - loss: 3.1692 - val_accuracy: 0.5086 - val_loss: 2.3930 - learning_rate: 6.4935e-05
Epoch 127/300
657/657 - 65s - 99ms/step - accuracy: 0.3808 - loss: 3.1607 - val_accuracy: 0.5171 - val_loss: 2.3990 - learning_rate: 6.4935e-05
Epoch 128/300
657/657 - 68s - 103ms/step - accuracy: 0.3844 - loss: 3.1825 - val_accuracy: 0.5103 - val_loss: 2.4098 - learning_rate: 6.4935e-05
Epoch 129/300
657/657 - 64s - 97ms/step - accuracy: 0.3697 - loss: 3.1739 - val_accuracy: 0.5017 - val_loss: 2.3923 - learning_rate: 6.4935e-05
Epoch 130/300
657/657 - 67s - 102ms/step - accuracy: 0.3804 - loss: 3.1697 - val_accuracy: 0.5257 - val_loss: 2.4189 - learning_rate: 6.4935e-05
Epoch 131/300
657/657 - 62s - 95ms/step - accuracy: 0.3806 - loss: 3.1801 - val_accuracy: 0.5137 - val_loss: 2.4028 - learning_rate: 6.4935e-05
Epoch 132/300
657/657 - 64s - 98ms/step - accuracy: 0.3802 - loss: 3.1585 - val_accuracy: 0.5086 - val_loss: 2.4010 - learning_rate: 6.4935e-05
Epoch 133/300
657/657 - 66s - 100ms/step - accuracy: 0.3857 - loss: 3.1881 - val_accuracy: 0.5188 - val_loss: 2.3950 - learning_rate: 6.4935e-05
Epoch 134/300
657/657 - 63s - 96ms/step - accuracy: 0.3892 - loss: 3.1931 - val_accuracy: 0.5291 - val_loss: 2.3874 - learning_rate: 6.4935e-05
Epoch 135/300
657/657 - 65s - 99ms/step - accuracy: 0.3831 - loss: 3.1756 - val_accuracy: 0.5171 - val_loss: 2.3794 - learning_rate: 6.4935e-05
Epoch 136/300
657/657 - 64s - 98ms/step - accuracy: 0.3772 - loss: 3.1620 - val_accuracy: 0.4983 - val_loss: 2.3953 - learning_rate: 6.4935e-05
Epoch 137/300
657/657 - 66s - 101ms/step - accuracy: 0.3812 - loss: 3.1965 - val_accuracy: 0.5205 - val_loss: 2.4000 - learning_rate: 6.4935e-05
Epoch 138/300
657/657 - 63s - 96ms/step - accuracy: 0.3812 - loss: 3.1739 - val_accuracy: 0.5342 - val_loss: 2.4012 - learning_rate: 6.4935e-05
Epoch 139/300
657/657 - 65s - 99ms/step - accuracy: 0.3899 - loss: 3.1739 - val_accuracy: 0.5188 - val_loss: 2.3999 - learning_rate: 6.4935e-05
Epoch 140/300
657/657 - 64s - 97ms/step - accuracy: 0.3775 - loss: 3.1590 - val_accuracy: 0.5223 - val_loss: 2.3558 - learning_rate: 6.4935e-05
Epoch 141/300
657/657 - 63s - 96ms/step - accuracy: 0.3884 - loss: 3.1806 - val_accuracy: 0.5223 - val_loss: 2.3829 - learning_rate: 6.4935e-05
Epoch 142/300
657/657 - 66s - 100ms/step - accuracy: 0.3810 - loss: 3.1946 - val_accuracy: 0.5086 - val_loss: 2.3861 - learning_rate: 6.4935e-05
Epoch 143/300
657/657 - 64s - 98ms/step - accuracy: 0.3873 - loss: 3.1276 - val_accuracy: 0.5068 - val_loss: 2.3991 - learning_rate: 6.4935e-05
Epoch 144/300
657/657 - 66s - 101ms/step - accuracy: 0.3794 - loss: 3.1634 - val_accuracy: 0.5223 - val_loss: 2.3864 - learning_rate: 6.4935e-05
Epoch 145/300
657/657 - 64s - 98ms/step - accuracy: 0.3802 - loss: 3.2058 - val_accuracy: 0.5171 - val_loss: 2.3916 - learning_rate: 6.4935e-05
Epoch 146/300
657/657 - 65s - 99ms/step - accuracy: 0.3884 - loss: 3.1640 - val_accuracy: 0.5325 - val_loss: 2.3798 - learning_rate: 6.4935e-05
Epoch 147/300
657/657 - 66s - 100ms/step - accuracy: 0.3857 - loss: 3.1452 - val_accuracy: 0.5257 - val_loss: 2.3761 - learning_rate: 6.4935e-05
Epoch 148/300

Epoch 148: ReduceLROnPlateau reducing learning rate to 3.2467261917190626e-05.
657/657 - 62s - 95ms/step - accuracy: 0.3901 - loss: 3.1487 - val_accuracy: 0.5240 - val_loss: 2.3899 - learning_rate: 6.4935e-05
Epoch 149/300
657/657 - 65s - 99ms/step - accuracy: 0.3951 - loss: 3.1212 - val_accuracy: 0.5257 - val_loss: 2.3609 - learning_rate: 3.2467e-05
Epoch 150/300
657/657 - 64s - 97ms/step - accuracy: 0.3861 - loss: 3.1473 - val_accuracy: 0.5240 - val_loss: 2.3599 - learning_rate: 3.2467e-05
Epoch 151/300
657/657 - 64s - 98ms/step - accuracy: 0.3918 - loss: 3.1481 - val_accuracy: 0.5205 - val_loss: 2.3557 - learning_rate: 3.2467e-05
Epoch 152/300
657/657 - 64s - 98ms/step - accuracy: 0.3899 - loss: 3.0773 - val_accuracy: 0.5205 - val_loss: 2.3690 - learning_rate: 3.2467e-05
Epoch 153/300
657/657 - 66s - 100ms/step - accuracy: 0.3911 - loss: 3.1467 - val_accuracy: 0.5120 - val_loss: 2.3720 - learning_rate: 3.2467e-05
Epoch 154/300
657/657 - 67s - 101ms/step - accuracy: 0.3884 - loss: 3.1499 - val_accuracy: 0.5205 - val_loss: 2.3849 - learning_rate: 3.2467e-05
Epoch 155/300
657/657 - 61s - 93ms/step - accuracy: 0.3833 - loss: 3.1537 - val_accuracy: 0.5274 - val_loss: 2.3784 - learning_rate: 3.2467e-05
Epoch 156/300
657/657 - 69s - 105ms/step - accuracy: 0.3808 - loss: 3.1720 - val_accuracy: 0.5240 - val_loss: 2.3512 - learning_rate: 3.2467e-05
Epoch 157/300
657/657 - 63s - 97ms/step - accuracy: 0.3886 - loss: 3.1375 - val_accuracy: 0.5171 - val_loss: 2.3591 - learning_rate: 3.2467e-05
Epoch 158/300
657/657 - 65s - 99ms/step - accuracy: 0.3880 - loss: 3.1479 - val_accuracy: 0.5171 - val_loss: 2.3574 - learning_rate: 3.2467e-05
Epoch 159/300
657/657 - 63s - 96ms/step - accuracy: 0.3897 - loss: 3.1479 - val_accuracy: 0.5257 - val_loss: 2.3646 - learning_rate: 3.2467e-05
Epoch 160/300
657/657 - 63s - 96ms/step - accuracy: 0.3924 - loss: 3.1202 - val_accuracy: 0.5205 - val_loss: 2.3755 - learning_rate: 3.2467e-05
Epoch 161/300
657/657 - 66s - 100ms/step - accuracy: 0.3838 - loss: 3.1229 - val_accuracy: 0.5103 - val_loss: 2.3592 - learning_rate: 3.2467e-05
Epoch 162/300
657/657 - 65s - 99ms/step - accuracy: 0.3899 - loss: 3.1203 - val_accuracy: 0.5137 - val_loss: 2.3573 - learning_rate: 3.2467e-05
Epoch 163/300
657/657 - 64s - 98ms/step - accuracy: 0.3886 - loss: 3.1538 - val_accuracy: 0.5171 - val_loss: 2.3809 - learning_rate: 3.2467e-05
Epoch 164/300

Epoch 164: ReduceLROnPlateau reducing learning rate to 1.6233630958595313e-05.
657/657 - 64s - 98ms/step - accuracy: 0.3853 - loss: 3.1608 - val_accuracy: 0.5274 - val_loss: 2.3954 - learning_rate: 3.2467e-05
Epoch 165/300
657/657 - 66s - 101ms/step - accuracy: 0.3794 - loss: 3.1564 - val_accuracy: 0.5223 - val_loss: 2.3776 - learning_rate: 1.6234e-05
Epoch 166/300
657/657 - 65s - 98ms/step - accuracy: 0.3907 - loss: 3.1315 - val_accuracy: 0.5257 - val_loss: 2.3635 - learning_rate: 1.6234e-05
Epoch 167/300
657/657 - 65s - 99ms/step - accuracy: 0.3920 - loss: 3.0847 - val_accuracy: 0.5223 - val_loss: 2.3577 - learning_rate: 1.6234e-05
Epoch 168/300
657/657 - 66s - 100ms/step - accuracy: 0.3926 - loss: 3.1491 - val_accuracy: 0.5188 - val_loss: 2.3573 - learning_rate: 1.6234e-05
Epoch 169/300
657/657 - 64s - 98ms/step - accuracy: 0.3918 - loss: 3.1187 - val_accuracy: 0.5223 - val_loss: 2.3388 - learning_rate: 1.6234e-05
Epoch 170/300
657/657 - 63s - 96ms/step - accuracy: 0.3907 - loss: 3.1360 - val_accuracy: 0.5223 - val_loss: 2.3553 - learning_rate: 1.6234e-05
Epoch 171/300
657/657 - 65s - 99ms/step - accuracy: 0.3901 - loss: 3.1216 - val_accuracy: 0.5154 - val_loss: 2.3722 - learning_rate: 1.6234e-05
Epoch 172/300
657/657 - 65s - 99ms/step - accuracy: 0.3873 - loss: 3.1409 - val_accuracy: 0.5188 - val_loss: 2.3694 - learning_rate: 1.6234e-05
Epoch 173/300
657/657 - 64s - 98ms/step - accuracy: 0.3840 - loss: 3.1437 - val_accuracy: 0.5223 - val_loss: 2.3412 - learning_rate: 1.6234e-05
Epoch 174/300
657/657 - 65s - 99ms/step - accuracy: 0.3878 - loss: 3.1523 - val_accuracy: 0.5171 - val_loss: 2.3707 - learning_rate: 1.6234e-05
Epoch 175/300
657/657 - 65s - 99ms/step - accuracy: 0.3890 - loss: 3.1639 - val_accuracy: 0.5205 - val_loss: 2.3521 - learning_rate: 1.6234e-05
Epoch 176/300
657/657 - 64s - 97ms/step - accuracy: 0.3907 - loss: 3.1356 - val_accuracy: 0.5223 - val_loss: 2.3483 - learning_rate: 1.6234e-05
Epoch 177/300

Epoch 177: ReduceLROnPlateau reducing learning rate to 8.116815479297657e-06.
657/657 - 65s - 99ms/step - accuracy: 0.3857 - loss: 3.1252 - val_accuracy: 0.5188 - val_loss: 2.3531 - learning_rate: 1.6234e-05
Epoch 178/300
657/657 - 66s - 100ms/step - accuracy: 0.3922 - loss: 3.0995 - val_accuracy: 0.5188 - val_loss: 2.3686 - learning_rate: 8.1168e-06
Epoch 179/300
657/657 - 66s - 101ms/step - accuracy: 0.3876 - loss: 3.1239 - val_accuracy: 0.5223 - val_loss: 2.3582 - learning_rate: 8.1168e-06
Epoch 180/300
657/657 - 62s - 95ms/step - accuracy: 0.3893 - loss: 3.1294 - val_accuracy: 0.5154 - val_loss: 2.3629 - learning_rate: 8.1168e-06
Epoch 181/300
657/657 - 67s - 101ms/step - accuracy: 0.3912 - loss: 3.1188 - val_accuracy: 0.5171 - val_loss: 2.3511 - learning_rate: 8.1168e-06
Epoch 182/300
657/657 - 65s - 98ms/step - accuracy: 0.3968 - loss: 3.0794 - val_accuracy: 0.5171 - val_loss: 2.3474 - learning_rate: 8.1168e-06
Epoch 183/300
657/657 - 64s - 97ms/step - accuracy: 0.3964 - loss: 3.1086 - val_accuracy: 0.5188 - val_loss: 2.3562 - learning_rate: 8.1168e-06
Epoch 184/300
657/657 - 66s - 101ms/step - accuracy: 0.3836 - loss: 3.1430 - val_accuracy: 0.5154 - val_loss: 2.3499 - learning_rate: 8.1168e-06
Epoch 185/300

Epoch 185: ReduceLROnPlateau reducing learning rate to 4.058407739648828e-06.
657/657 - 65s - 100ms/step - accuracy: 0.3930 - loss: 3.1271 - val_accuracy: 0.5223 - val_loss: 2.3429 - learning_rate: 8.1168e-06
Epoch 185: early stopping
Restoring model weights from the end of the best epoch: 169.
Fold 6 Evaluation results: [2.3515193462371826, 0.5222602486610413]
              precision    recall  f1-score   support

        1820       0.68      0.91      0.78        43
        1821       0.00      0.00      0.00         1
        1822       0.00      0.00      0.00         1
        1823       0.00      0.00      0.00         1
        1824       0.00      0.00      0.00         1
        1825       0.00      0.00      0.00         1
        1826       0.00      0.00      0.00         2
        1827       0.00      0.00      0.00         7
        1828       1.00      1.00      1.00         2
        1829       0.62      1.00      0.77         5
        1830       0.57      0.61      0.59        44
        1831       0.00      0.00      0.00         0
        1832       0.85      0.85      0.85        53
        1833       0.95      0.95      0.95        19
        1834       0.50      0.67      0.57         6
        1835       0.00      0.00      0.00         2
        1836       0.00      0.00      0.00         4
        1837       0.33      0.86      0.48         7
        1838       0.00      0.00      0.00         3
        1839       0.00      0.00      0.00         1
        1840       0.57      0.74      0.65        43
        1841       0.83      0.50      0.62        10
        1842       0.75      0.60      0.67         5
        1843       0.00      0.00      0.00         6
        1844       0.00      0.00      0.00         0
        1845       0.00      0.00      0.00         1
        1846       1.00      0.33      0.50         6
        1847       0.00      0.00      0.00         2
        1848       0.60      0.50      0.55         6
        1849       0.50      0.20      0.29         5
        1850       0.38      0.58      0.46        48
        1851       0.00      0.00      0.00         6
        1852       0.50      0.14      0.22         7
        1853       0.20      0.17      0.18         6
        1854       0.00      0.00      0.00         3
        1855       0.31      0.45      0.37        11
        1856       0.73      0.67      0.70        12
        1857       0.00      0.00      0.00         8
        1858       0.00      0.00      0.00         2
        1859       0.00      0.00      0.00         2
        1860       0.29      0.35      0.32        48
        1861       0.00      0.00      0.00         1
        1862       0.00      0.00      0.00         6
        1863       0.45      1.00      0.62         5
        1864       0.00      0.00      0.00         5
        1865       1.00      0.29      0.44         7
        1866       0.25      0.17      0.20         6
        1867       0.27      0.27      0.27        11
        1868       0.00      0.00      0.00         7
        1869       0.00      0.00      0.00         6
        1870       0.39      0.74      0.51        31
        1871       0.00      0.00      0.00         5
        1872       0.33      0.25      0.29         8
        1873       0.00      0.00      0.00        10
        1874       0.00      0.00      0.00         5
        1875       0.00      0.00      0.00         5
        1876       0.89      0.80      0.84        10
        1877       0.67      0.67      0.67         6
        1878       0.83      0.56      0.67         9
        1879       0.00      0.00      0.00         1

    accuracy                           0.52       584
   macro avg       0.29      0.28      0.27       584
weighted avg       0.47      0.52      0.48       584

Matthews Correlation Coefficient: 0.495
Macro avg F1: 0.267
Weighted avg F1: 0.479
Micro avg F1: 0.522
Top-3 Accuracy: 0.788
Top-5 Accuracy: 0.865
Micro ROC AUC  = 0.97
Macro ROC AUC (present classes) = 0.95
Classification MAE (in years): 3.65

Fold 6 Misclassification Analysis:
Near misses (within 2 years): 83 out of 279 misclassifications (29.75%)
Big misses (greater than 10 years): 97
MAE with outliers: 3.65
MAE without outliers: 2.51 (improvement: 1.15)

10 Worst misclassifications:
Image: data/datasets/public/1870/1876_440vna.jpg, True: 1876, Predicted: 1832, Error: 44
Image: data/datasets/public/1870/1876_463vna.jpg, True: 1876, Predicted: 1832, Error: 44
Image: data/datasets/public/1860/1860_345vna.jpg, True: 1860, Predicted: 1820, Error: 40
Image: data/datasets/public/1860/1860_052met.jpg, True: 1860, Predicted: 1820, Error: 40
Image: data/datasets/public/1820/1820_033_001met.jpg, True: 1820, Predicted: 1860, Error: 40
Image: data/datasets/public/1830/1832_1602vna.jpg, True: 1832, Predicted: 1870, Error: 38
Image: data/datasets/public/1830/1839_3040vna.jpg, True: 1839, Predicted: 1870, Error: 31
Image: data/datasets/public/1860/1860_8wikimedia2.jpg, True: 1860, Predicted: 1830, Error: 30
Image: data/datasets/public/1820/1820_019met.jpg, True: 1820, Predicted: 1850, Error: 30
Image: data/datasets/public/1860/1860_044met.jpg, True: 1860, Predicted: 1830, Error: 30

===== Fold 7 =====
=== Running on Public Data ===

===== Fine Tuning 9 layers! =====
Epoch 1/300
657/657 - 86s - 131ms/step - accuracy: 0.1029 - loss: 4.7393 - val_accuracy: 0.1935 - val_loss: 3.8916 - learning_rate: 2.5974e-04
Epoch 2/300
657/657 - 66s - 100ms/step - accuracy: 0.1631 - loss: 4.4128 - val_accuracy: 0.2329 - val_loss: 3.9994 - learning_rate: 2.5974e-04
Epoch 3/300
657/657 - 64s - 98ms/step - accuracy: 0.1928 - loss: 4.2752 - val_accuracy: 0.2466 - val_loss: 3.6967 - learning_rate: 2.5974e-04
Epoch 4/300
657/657 - 62s - 95ms/step - accuracy: 0.2061 - loss: 4.1989 - val_accuracy: 0.2928 - val_loss: 3.7523 - learning_rate: 2.5974e-04
Epoch 5/300
657/657 - 66s - 100ms/step - accuracy: 0.2207 - loss: 4.1668 - val_accuracy: 0.3425 - val_loss: 3.8597 - learning_rate: 2.5974e-04
Epoch 6/300
657/657 - 67s - 103ms/step - accuracy: 0.2405 - loss: 4.1237 - val_accuracy: 0.3219 - val_loss: 3.5607 - learning_rate: 2.5974e-04
Epoch 7/300
657/657 - 66s - 100ms/step - accuracy: 0.2462 - loss: 4.0619 - val_accuracy: 0.3459 - val_loss: 3.6305 - learning_rate: 2.5974e-04
Epoch 8/300
657/657 - 65s - 99ms/step - accuracy: 0.2599 - loss: 4.0302 - val_accuracy: 0.3836 - val_loss: 3.5256 - learning_rate: 2.5974e-04
Epoch 9/300
657/657 - 67s - 102ms/step - accuracy: 0.2655 - loss: 3.9795 - val_accuracy: 0.3596 - val_loss: 3.3055 - learning_rate: 2.5974e-04
Epoch 10/300
657/657 - 64s - 97ms/step - accuracy: 0.2702 - loss: 3.9644 - val_accuracy: 0.3836 - val_loss: 3.3939 - learning_rate: 2.5974e-04
Epoch 11/300
657/657 - 63s - 95ms/step - accuracy: 0.2771 - loss: 3.9187 - val_accuracy: 0.4092 - val_loss: 3.3568 - learning_rate: 2.5974e-04
Epoch 12/300
657/657 - 67s - 101ms/step - accuracy: 0.2717 - loss: 3.9094 - val_accuracy: 0.3973 - val_loss: 3.1973 - learning_rate: 2.5974e-04
Epoch 13/300
657/657 - 66s - 100ms/step - accuracy: 0.2816 - loss: 3.8530 - val_accuracy: 0.4127 - val_loss: 3.1936 - learning_rate: 2.5974e-04
Epoch 14/300
657/657 - 64s - 97ms/step - accuracy: 0.2913 - loss: 3.8297 - val_accuracy: 0.4144 - val_loss: 3.1974 - learning_rate: 2.5974e-04
Epoch 15/300
657/657 - 65s - 100ms/step - accuracy: 0.2870 - loss: 3.8332 - val_accuracy: 0.4298 - val_loss: 3.1190 - learning_rate: 2.5974e-04
Epoch 16/300
657/657 - 68s - 103ms/step - accuracy: 0.2942 - loss: 3.7929 - val_accuracy: 0.4058 - val_loss: 3.0719 - learning_rate: 2.5974e-04
Epoch 17/300
657/657 - 64s - 98ms/step - accuracy: 0.2978 - loss: 3.7324 - val_accuracy: 0.4144 - val_loss: 3.1558 - learning_rate: 2.5974e-04
Epoch 18/300
657/657 - 65s - 99ms/step - accuracy: 0.3037 - loss: 3.7551 - val_accuracy: 0.4332 - val_loss: 3.0247 - learning_rate: 2.5974e-04
Epoch 19/300
657/657 - 65s - 99ms/step - accuracy: 0.3049 - loss: 3.7475 - val_accuracy: 0.4144 - val_loss: 3.0586 - learning_rate: 2.5974e-04
Epoch 20/300
657/657 - 67s - 102ms/step - accuracy: 0.2984 - loss: 3.7237 - val_accuracy: 0.4298 - val_loss: 3.0137 - learning_rate: 2.5974e-04
Epoch 21/300
657/657 - 63s - 96ms/step - accuracy: 0.3077 - loss: 3.7077 - val_accuracy: 0.4384 - val_loss: 3.0250 - learning_rate: 2.5974e-04
Epoch 22/300
657/657 - 65s - 98ms/step - accuracy: 0.3136 - loss: 3.6850 - val_accuracy: 0.4264 - val_loss: 2.9088 - learning_rate: 2.5974e-04
Epoch 23/300
657/657 - 66s - 101ms/step - accuracy: 0.3128 - loss: 3.6686 - val_accuracy: 0.4298 - val_loss: 2.9933 - learning_rate: 2.5974e-04
Epoch 24/300
657/657 - 64s - 97ms/step - accuracy: 0.3128 - loss: 3.6847 - val_accuracy: 0.4486 - val_loss: 2.9371 - learning_rate: 2.5974e-04
Epoch 25/300
657/657 - 64s - 98ms/step - accuracy: 0.3119 - loss: 3.6715 - val_accuracy: 0.4366 - val_loss: 2.8757 - learning_rate: 2.5974e-04
Epoch 26/300
657/657 - 65s - 99ms/step - accuracy: 0.3109 - loss: 3.6732 - val_accuracy: 0.4349 - val_loss: 2.8818 - learning_rate: 2.5974e-04
Epoch 27/300
657/657 - 67s - 102ms/step - accuracy: 0.3233 - loss: 3.6138 - val_accuracy: 0.4161 - val_loss: 2.8269 - learning_rate: 2.5974e-04
Epoch 28/300
657/657 - 64s - 98ms/step - accuracy: 0.3136 - loss: 3.6358 - val_accuracy: 0.4401 - val_loss: 2.8191 - learning_rate: 2.5974e-04
Epoch 29/300
657/657 - 65s - 98ms/step - accuracy: 0.3260 - loss: 3.5750 - val_accuracy: 0.4418 - val_loss: 2.8593 - learning_rate: 2.5974e-04
Epoch 30/300
657/657 - 66s - 100ms/step - accuracy: 0.3273 - loss: 3.5652 - val_accuracy: 0.4538 - val_loss: 2.7979 - learning_rate: 2.5974e-04
Epoch 31/300
657/657 - 62s - 95ms/step - accuracy: 0.3374 - loss: 3.5730 - val_accuracy: 0.4452 - val_loss: 2.7922 - learning_rate: 2.5974e-04
Epoch 32/300
657/657 - 65s - 99ms/step - accuracy: 0.3229 - loss: 3.5596 - val_accuracy: 0.4606 - val_loss: 2.7560 - learning_rate: 2.5974e-04
Epoch 33/300
657/657 - 65s - 99ms/step - accuracy: 0.3245 - loss: 3.5494 - val_accuracy: 0.4572 - val_loss: 2.7258 - learning_rate: 2.5974e-04
Epoch 34/300
657/657 - 80s - 122ms/step - accuracy: 0.3326 - loss: 3.5439 - val_accuracy: 0.4435 - val_loss: 2.7150 - learning_rate: 2.5974e-04
Epoch 35/300
657/657 - 65s - 100ms/step - accuracy: 0.3323 - loss: 3.5469 - val_accuracy: 0.4503 - val_loss: 2.7282 - learning_rate: 2.5974e-04
Epoch 36/300
657/657 - 66s - 100ms/step - accuracy: 0.3292 - loss: 3.5368 - val_accuracy: 0.4555 - val_loss: 2.7507 - learning_rate: 2.5974e-04
Epoch 37/300
657/657 - 65s - 99ms/step - accuracy: 0.3343 - loss: 3.5330 - val_accuracy: 0.4640 - val_loss: 2.7627 - learning_rate: 2.5974e-04
Epoch 38/300
657/657 - 65s - 99ms/step - accuracy: 0.3389 - loss: 3.4870 - val_accuracy: 0.4589 - val_loss: 2.7442 - learning_rate: 2.5974e-04
Epoch 39/300
657/657 - 65s - 99ms/step - accuracy: 0.3402 - loss: 3.5103 - val_accuracy: 0.4675 - val_loss: 2.7013 - learning_rate: 2.5974e-04
Epoch 40/300
657/657 - 66s - 100ms/step - accuracy: 0.3361 - loss: 3.4832 - val_accuracy: 0.4572 - val_loss: 2.6298 - learning_rate: 2.5974e-04
Epoch 41/300
657/657 - 64s - 97ms/step - accuracy: 0.3307 - loss: 3.4943 - val_accuracy: 0.4726 - val_loss: 2.6432 - learning_rate: 2.5974e-04
Epoch 42/300
657/657 - 65s - 99ms/step - accuracy: 0.3330 - loss: 3.5079 - val_accuracy: 0.4623 - val_loss: 2.6712 - learning_rate: 2.5974e-04
Epoch 43/300
657/657 - 65s - 98ms/step - accuracy: 0.3442 - loss: 3.4675 - val_accuracy: 0.4692 - val_loss: 2.6960 - learning_rate: 2.5974e-04
Epoch 44/300
657/657 - 63s - 97ms/step - accuracy: 0.3488 - loss: 3.4834 - val_accuracy: 0.4658 - val_loss: 2.6858 - learning_rate: 2.5974e-04
Epoch 45/300
657/657 - 66s - 100ms/step - accuracy: 0.3330 - loss: 3.5068 - val_accuracy: 0.4658 - val_loss: 2.6762 - learning_rate: 2.5974e-04
Epoch 46/300
657/657 - 65s - 98ms/step - accuracy: 0.3454 - loss: 3.4535 - val_accuracy: 0.4692 - val_loss: 2.6922 - learning_rate: 2.5974e-04
Epoch 47/300
657/657 - 65s - 99ms/step - accuracy: 0.3302 - loss: 3.4772 - val_accuracy: 0.4743 - val_loss: 2.6189 - learning_rate: 2.5974e-04
Epoch 48/300
657/657 - 65s - 99ms/step - accuracy: 0.3500 - loss: 3.4418 - val_accuracy: 0.4897 - val_loss: 2.6727 - learning_rate: 2.5974e-04
Epoch 49/300
657/657 - 65s - 99ms/step - accuracy: 0.3444 - loss: 3.4452 - val_accuracy: 0.4812 - val_loss: 2.6508 - learning_rate: 2.5974e-04
Epoch 50/300
657/657 - 65s - 99ms/step - accuracy: 0.3349 - loss: 3.4831 - val_accuracy: 0.4863 - val_loss: 2.6843 - learning_rate: 2.5974e-04
Epoch 51/300
657/657 - 63s - 95ms/step - accuracy: 0.3380 - loss: 3.4492 - val_accuracy: 0.4812 - val_loss: 2.5849 - learning_rate: 2.5974e-04
Epoch 52/300
657/657 - 66s - 100ms/step - accuracy: 0.3351 - loss: 3.4734 - val_accuracy: 0.4914 - val_loss: 2.5512 - learning_rate: 2.5974e-04
Epoch 53/300
657/657 - 66s - 100ms/step - accuracy: 0.3463 - loss: 3.4428 - val_accuracy: 0.4914 - val_loss: 2.5929 - learning_rate: 2.5974e-04
Epoch 54/300
657/657 - 65s - 100ms/step - accuracy: 0.3488 - loss: 3.4660 - val_accuracy: 0.4743 - val_loss: 2.6582 - learning_rate: 2.5974e-04
Epoch 55/300
657/657 - 64s - 97ms/step - accuracy: 0.3441 - loss: 3.4476 - val_accuracy: 0.4777 - val_loss: 2.6365 - learning_rate: 2.5974e-04
Epoch 56/300
657/657 - 64s - 98ms/step - accuracy: 0.3433 - loss: 3.4066 - val_accuracy: 0.4914 - val_loss: 2.6065 - learning_rate: 2.5974e-04
Epoch 57/300
657/657 - 64s - 98ms/step - accuracy: 0.3482 - loss: 3.4092 - val_accuracy: 0.4777 - val_loss: 2.5840 - learning_rate: 2.5974e-04
Epoch 58/300
657/657 - 66s - 100ms/step - accuracy: 0.3494 - loss: 3.4338 - val_accuracy: 0.4949 - val_loss: 2.5348 - learning_rate: 2.5974e-04
Epoch 59/300
657/657 - 65s - 99ms/step - accuracy: 0.3473 - loss: 3.4099 - val_accuracy: 0.4863 - val_loss: 2.5889 - learning_rate: 2.5974e-04
Epoch 60/300
657/657 - 65s - 99ms/step - accuracy: 0.3490 - loss: 3.4391 - val_accuracy: 0.4846 - val_loss: 2.5676 - learning_rate: 2.5974e-04
Epoch 61/300
657/657 - 63s - 96ms/step - accuracy: 0.3446 - loss: 3.4280 - val_accuracy: 0.4777 - val_loss: 2.5706 - learning_rate: 2.5974e-04
Epoch 62/300
657/657 - 66s - 100ms/step - accuracy: 0.3452 - loss: 3.4206 - val_accuracy: 0.4812 - val_loss: 2.6011 - learning_rate: 2.5974e-04
Epoch 63/300
657/657 - 64s - 98ms/step - accuracy: 0.3505 - loss: 3.4152 - val_accuracy: 0.4812 - val_loss: 2.5571 - learning_rate: 2.5974e-04
Epoch 64/300
657/657 - 66s - 100ms/step - accuracy: 0.3469 - loss: 3.3998 - val_accuracy: 0.4966 - val_loss: 2.5484 - learning_rate: 2.5974e-04
Epoch 65/300
657/657 - 65s - 100ms/step - accuracy: 0.3484 - loss: 3.4233 - val_accuracy: 0.4726 - val_loss: 2.5394 - learning_rate: 2.5974e-04
Epoch 66/300

Epoch 66: ReduceLROnPlateau reducing learning rate to 0.0001298690476687625.
657/657 - 65s - 100ms/step - accuracy: 0.3517 - loss: 3.3944 - val_accuracy: 0.5103 - val_loss: 2.6070 - learning_rate: 2.5974e-04
Epoch 67/300
657/657 - 66s - 100ms/step - accuracy: 0.3463 - loss: 3.3476 - val_accuracy: 0.5103 - val_loss: 2.4753 - learning_rate: 1.2987e-04
Epoch 68/300
657/657 - 65s - 98ms/step - accuracy: 0.3621 - loss: 3.3178 - val_accuracy: 0.4914 - val_loss: 2.4968 - learning_rate: 1.2987e-04
Epoch 69/300
657/657 - 65s - 100ms/step - accuracy: 0.3589 - loss: 3.3224 - val_accuracy: 0.5051 - val_loss: 2.4837 - learning_rate: 1.2987e-04
Epoch 70/300
657/657 - 65s - 99ms/step - accuracy: 0.3633 - loss: 3.2895 - val_accuracy: 0.4932 - val_loss: 2.4576 - learning_rate: 1.2987e-04
Epoch 71/300
657/657 - 64s - 97ms/step - accuracy: 0.3574 - loss: 3.3022 - val_accuracy: 0.5188 - val_loss: 2.4657 - learning_rate: 1.2987e-04
Epoch 72/300
657/657 - 67s - 102ms/step - accuracy: 0.3678 - loss: 3.2587 - val_accuracy: 0.5068 - val_loss: 2.4655 - learning_rate: 1.2987e-04
Epoch 73/300
657/657 - 65s - 99ms/step - accuracy: 0.3593 - loss: 3.3167 - val_accuracy: 0.4863 - val_loss: 2.4642 - learning_rate: 1.2987e-04
Epoch 74/300
657/657 - 65s - 99ms/step - accuracy: 0.3576 - loss: 3.3268 - val_accuracy: 0.5017 - val_loss: 2.4513 - learning_rate: 1.2987e-04
Epoch 75/300
657/657 - 67s - 101ms/step - accuracy: 0.3637 - loss: 3.3174 - val_accuracy: 0.5103 - val_loss: 2.4629 - learning_rate: 1.2987e-04
Epoch 76/300
657/657 - 65s - 99ms/step - accuracy: 0.3646 - loss: 3.3007 - val_accuracy: 0.5051 - val_loss: 2.4491 - learning_rate: 1.2987e-04
Epoch 77/300
657/657 - 65s - 99ms/step - accuracy: 0.3654 - loss: 3.2715 - val_accuracy: 0.5291 - val_loss: 2.4463 - learning_rate: 1.2987e-04
Epoch 78/300
657/657 - 65s - 99ms/step - accuracy: 0.3657 - loss: 3.2856 - val_accuracy: 0.4983 - val_loss: 2.4569 - learning_rate: 1.2987e-04
Epoch 79/300
657/657 - 65s - 98ms/step - accuracy: 0.3619 - loss: 3.2790 - val_accuracy: 0.5000 - val_loss: 2.4347 - learning_rate: 1.2987e-04
Epoch 80/300
657/657 - 65s - 99ms/step - accuracy: 0.3713 - loss: 3.3038 - val_accuracy: 0.4983 - val_loss: 2.4349 - learning_rate: 1.2987e-04
Epoch 81/300
657/657 - 62s - 94ms/step - accuracy: 0.3734 - loss: 3.2913 - val_accuracy: 0.5223 - val_loss: 2.4436 - learning_rate: 1.2987e-04
Epoch 82/300
657/657 - 65s - 99ms/step - accuracy: 0.3652 - loss: 3.2891 - val_accuracy: 0.5034 - val_loss: 2.4571 - learning_rate: 1.2987e-04
Epoch 83/300
657/657 - 66s - 100ms/step - accuracy: 0.3631 - loss: 3.2865 - val_accuracy: 0.5171 - val_loss: 2.4279 - learning_rate: 1.2987e-04
Epoch 84/300
657/657 - 65s - 99ms/step - accuracy: 0.3604 - loss: 3.3080 - val_accuracy: 0.5274 - val_loss: 2.4256 - learning_rate: 1.2987e-04
Epoch 85/300
657/657 - 66s - 100ms/step - accuracy: 0.3768 - loss: 3.2806 - val_accuracy: 0.5154 - val_loss: 2.4348 - learning_rate: 1.2987e-04
Epoch 86/300
657/657 - 67s - 102ms/step - accuracy: 0.3779 - loss: 3.2686 - val_accuracy: 0.5188 - val_loss: 2.4348 - learning_rate: 1.2987e-04
Epoch 87/300
657/657 - 65s - 100ms/step - accuracy: 0.3608 - loss: 3.2853 - val_accuracy: 0.4863 - val_loss: 2.4794 - learning_rate: 1.2987e-04
Epoch 88/300
657/657 - 63s - 95ms/step - accuracy: 0.3696 - loss: 3.2321 - val_accuracy: 0.5240 - val_loss: 2.4463 - learning_rate: 1.2987e-04
Epoch 89/300
657/657 - 66s - 100ms/step - accuracy: 0.3654 - loss: 3.2499 - val_accuracy: 0.5223 - val_loss: 2.4595 - learning_rate: 1.2987e-04
Epoch 90/300
657/657 - 66s - 101ms/step - accuracy: 0.3644 - loss: 3.3091 - val_accuracy: 0.5171 - val_loss: 2.4068 - learning_rate: 1.2987e-04
Epoch 91/300
657/657 - 65s - 100ms/step - accuracy: 0.3804 - loss: 3.2617 - val_accuracy: 0.5171 - val_loss: 2.4109 - learning_rate: 1.2987e-04
Epoch 92/300
657/657 - 63s - 97ms/step - accuracy: 0.3703 - loss: 3.2639 - val_accuracy: 0.5240 - val_loss: 2.4854 - learning_rate: 1.2987e-04
Epoch 93/300
657/657 - 66s - 100ms/step - accuracy: 0.3673 - loss: 3.2557 - val_accuracy: 0.5223 - val_loss: 2.4440 - learning_rate: 1.2987e-04
Epoch 94/300
657/657 - 65s - 99ms/step - accuracy: 0.3678 - loss: 3.2805 - val_accuracy: 0.5137 - val_loss: 2.4042 - learning_rate: 1.2987e-04
Epoch 95/300
657/657 - 67s - 102ms/step - accuracy: 0.3690 - loss: 3.2519 - val_accuracy: 0.5051 - val_loss: 2.3988 - learning_rate: 1.2987e-04
Epoch 96/300
657/657 - 63s - 95ms/step - accuracy: 0.3800 - loss: 3.1987 - val_accuracy: 0.5188 - val_loss: 2.4238 - learning_rate: 1.2987e-04
Epoch 97/300
657/657 - 65s - 99ms/step - accuracy: 0.3897 - loss: 3.2148 - val_accuracy: 0.5068 - val_loss: 2.4107 - learning_rate: 1.2987e-04
Epoch 98/300
657/657 - 63s - 96ms/step - accuracy: 0.3623 - loss: 3.2841 - val_accuracy: 0.5120 - val_loss: 2.3990 - learning_rate: 1.2987e-04
Epoch 99/300
657/657 - 66s - 101ms/step - accuracy: 0.3783 - loss: 3.2300 - val_accuracy: 0.5291 - val_loss: 2.3744 - learning_rate: 1.2987e-04
Epoch 100/300
657/657 - 65s - 99ms/step - accuracy: 0.3735 - loss: 3.2553 - val_accuracy: 0.4846 - val_loss: 2.4003 - learning_rate: 1.2987e-04
Epoch 101/300
657/657 - 64s - 97ms/step - accuracy: 0.3766 - loss: 3.2122 - val_accuracy: 0.5103 - val_loss: 2.3875 - learning_rate: 1.2987e-04
Epoch 102/300
657/657 - 67s - 103ms/step - accuracy: 0.3701 - loss: 3.2193 - val_accuracy: 0.5086 - val_loss: 2.3738 - learning_rate: 1.2987e-04
Epoch 103/300
657/657 - 65s - 99ms/step - accuracy: 0.3697 - loss: 3.2397 - val_accuracy: 0.5188 - val_loss: 2.3924 - learning_rate: 1.2987e-04
Epoch 104/300
657/657 - 66s - 100ms/step - accuracy: 0.3657 - loss: 3.2696 - val_accuracy: 0.5240 - val_loss: 2.3719 - learning_rate: 1.2987e-04
Epoch 105/300
657/657 - 66s - 101ms/step - accuracy: 0.3734 - loss: 3.2333 - val_accuracy: 0.5188 - val_loss: 2.3901 - learning_rate: 1.2987e-04
Epoch 106/300
657/657 - 65s - 99ms/step - accuracy: 0.3732 - loss: 3.2426 - val_accuracy: 0.5308 - val_loss: 2.3808 - learning_rate: 1.2987e-04
Epoch 107/300
657/657 - 66s - 100ms/step - accuracy: 0.3796 - loss: 3.2300 - val_accuracy: 0.5051 - val_loss: 2.3805 - learning_rate: 1.2987e-04
Epoch 108/300
657/657 - 62s - 94ms/step - accuracy: 0.3690 - loss: 3.2283 - val_accuracy: 0.5017 - val_loss: 2.3810 - learning_rate: 1.2987e-04
Epoch 109/300
657/657 - 66s - 101ms/step - accuracy: 0.3709 - loss: 3.2337 - val_accuracy: 0.5034 - val_loss: 2.3699 - learning_rate: 1.2987e-04
Epoch 110/300
657/657 - 63s - 96ms/step - accuracy: 0.3772 - loss: 3.2505 - val_accuracy: 0.5000 - val_loss: 2.3638 - learning_rate: 1.2987e-04
Epoch 111/300
657/657 - 65s - 99ms/step - accuracy: 0.3745 - loss: 3.2261 - val_accuracy: 0.5205 - val_loss: 2.3844 - learning_rate: 1.2987e-04
Epoch 112/300
657/657 - 65s - 99ms/step - accuracy: 0.3718 - loss: 3.2428 - val_accuracy: 0.5188 - val_loss: 2.3787 - learning_rate: 1.2987e-04
Epoch 113/300
657/657 - 65s - 99ms/step - accuracy: 0.3783 - loss: 3.2594 - val_accuracy: 0.5291 - val_loss: 2.4132 - learning_rate: 1.2987e-04
Epoch 114/300
657/657 - 65s - 99ms/step - accuracy: 0.3701 - loss: 3.2048 - val_accuracy: 0.5274 - val_loss: 2.3485 - learning_rate: 1.2987e-04
Epoch 115/300
657/657 - 64s - 97ms/step - accuracy: 0.3833 - loss: 3.1963 - val_accuracy: 0.5205 - val_loss: 2.4035 - learning_rate: 1.2987e-04
Epoch 116/300
657/657 - 66s - 100ms/step - accuracy: 0.3758 - loss: 3.1905 - val_accuracy: 0.5103 - val_loss: 2.4140 - learning_rate: 1.2987e-04
Epoch 117/300
657/657 - 65s - 99ms/step - accuracy: 0.3821 - loss: 3.1988 - val_accuracy: 0.5137 - val_loss: 2.3355 - learning_rate: 1.2987e-04
Epoch 118/300
657/657 - 64s - 98ms/step - accuracy: 0.3762 - loss: 3.2469 - val_accuracy: 0.5223 - val_loss: 2.3815 - learning_rate: 1.2987e-04
Epoch 119/300
657/657 - 64s - 98ms/step - accuracy: 0.3760 - loss: 3.2177 - val_accuracy: 0.5274 - val_loss: 2.3546 - learning_rate: 1.2987e-04
Epoch 120/300
657/657 - 66s - 101ms/step - accuracy: 0.3686 - loss: 3.2461 - val_accuracy: 0.5120 - val_loss: 2.3286 - learning_rate: 1.2987e-04
Epoch 121/300
657/657 - 64s - 97ms/step - accuracy: 0.3730 - loss: 3.2201 - val_accuracy: 0.5137 - val_loss: 2.3449 - learning_rate: 1.2987e-04
Epoch 122/300
657/657 - 67s - 102ms/step - accuracy: 0.3705 - loss: 3.2243 - val_accuracy: 0.5034 - val_loss: 2.3438 - learning_rate: 1.2987e-04
Epoch 123/300
657/657 - 66s - 100ms/step - accuracy: 0.3859 - loss: 3.2029 - val_accuracy: 0.5188 - val_loss: 2.3796 - learning_rate: 1.2987e-04
Epoch 124/300
657/657 - 64s - 98ms/step - accuracy: 0.3831 - loss: 3.1694 - val_accuracy: 0.5120 - val_loss: 2.3391 - learning_rate: 1.2987e-04
Epoch 125/300
657/657 - 67s - 103ms/step - accuracy: 0.3716 - loss: 3.1990 - val_accuracy: 0.5171 - val_loss: 2.3586 - learning_rate: 1.2987e-04
Epoch 126/300
657/657 - 66s - 101ms/step - accuracy: 0.3713 - loss: 3.2267 - val_accuracy: 0.5325 - val_loss: 2.3809 - learning_rate: 1.2987e-04
Epoch 127/300
657/657 - 66s - 100ms/step - accuracy: 0.3869 - loss: 3.1673 - val_accuracy: 0.5188 - val_loss: 2.3312 - learning_rate: 1.2987e-04
Epoch 128/300

Epoch 128: ReduceLROnPlateau reducing learning rate to 6.493452383438125e-05.
657/657 - 64s - 98ms/step - accuracy: 0.3785 - loss: 3.2182 - val_accuracy: 0.5137 - val_loss: 2.3305 - learning_rate: 1.2987e-04
Epoch 129/300
657/657 - 67s - 102ms/step - accuracy: 0.3850 - loss: 3.1755 - val_accuracy: 0.5240 - val_loss: 2.3151 - learning_rate: 6.4935e-05
Epoch 130/300
657/657 - 66s - 100ms/step - accuracy: 0.3836 - loss: 3.1692 - val_accuracy: 0.5291 - val_loss: 2.3136 - learning_rate: 6.4935e-05
Epoch 131/300
657/657 - 65s - 99ms/step - accuracy: 0.3848 - loss: 3.1866 - val_accuracy: 0.5274 - val_loss: 2.3346 - learning_rate: 6.4935e-05
Epoch 132/300
657/657 - 67s - 102ms/step - accuracy: 0.3800 - loss: 3.1845 - val_accuracy: 0.5291 - val_loss: 2.3152 - learning_rate: 6.4935e-05
Epoch 133/300
657/657 - 65s - 99ms/step - accuracy: 0.3812 - loss: 3.1568 - val_accuracy: 0.5171 - val_loss: 2.3002 - learning_rate: 6.4935e-05
Epoch 134/300
657/657 - 66s - 101ms/step - accuracy: 0.3871 - loss: 3.1935 - val_accuracy: 0.5342 - val_loss: 2.3196 - learning_rate: 6.4935e-05
Epoch 135/300
657/657 - 64s - 98ms/step - accuracy: 0.3867 - loss: 3.1609 - val_accuracy: 0.5188 - val_loss: 2.3220 - learning_rate: 6.4935e-05
Epoch 136/300
657/657 - 64s - 98ms/step - accuracy: 0.3793 - loss: 3.1697 - val_accuracy: 0.5325 - val_loss: 2.3227 - learning_rate: 6.4935e-05
Epoch 137/300
657/657 - 84s - 128ms/step - accuracy: 0.3804 - loss: 3.1832 - val_accuracy: 0.5205 - val_loss: 2.3271 - learning_rate: 6.4935e-05
Epoch 138/300
657/657 - 63s - 96ms/step - accuracy: 0.3884 - loss: 3.1835 - val_accuracy: 0.5154 - val_loss: 2.2998 - learning_rate: 6.4935e-05
Epoch 139/300
657/657 - 65s - 99ms/step - accuracy: 0.3793 - loss: 3.1979 - val_accuracy: 0.5291 - val_loss: 2.2804 - learning_rate: 6.4935e-05
Epoch 140/300
657/657 - 65s - 99ms/step - accuracy: 0.3789 - loss: 3.2104 - val_accuracy: 0.5308 - val_loss: 2.3173 - learning_rate: 6.4935e-05
Epoch 141/300
657/657 - 64s - 97ms/step - accuracy: 0.3844 - loss: 3.1664 - val_accuracy: 0.5308 - val_loss: 2.3484 - learning_rate: 6.4935e-05
Epoch 142/300
657/657 - 65s - 98ms/step - accuracy: 0.3869 - loss: 3.1686 - val_accuracy: 0.5342 - val_loss: 2.3087 - learning_rate: 6.4935e-05
Epoch 143/300
657/657 - 66s - 100ms/step - accuracy: 0.3842 - loss: 3.1796 - val_accuracy: 0.5360 - val_loss: 2.2978 - learning_rate: 6.4935e-05
Epoch 144/300
657/657 - 66s - 100ms/step - accuracy: 0.3977 - loss: 3.1260 - val_accuracy: 0.5205 - val_loss: 2.3008 - learning_rate: 6.4935e-05
Epoch 145/300
657/657 - 64s - 97ms/step - accuracy: 0.3947 - loss: 3.1262 - val_accuracy: 0.5291 - val_loss: 2.3071 - learning_rate: 6.4935e-05
Epoch 146/300
657/657 - 62s - 94ms/step - accuracy: 0.3753 - loss: 3.1808 - val_accuracy: 0.5257 - val_loss: 2.3230 - learning_rate: 6.4935e-05
Epoch 147/300

Epoch 147: ReduceLROnPlateau reducing learning rate to 3.2467261917190626e-05.
657/657 - 67s - 102ms/step - accuracy: 0.3949 - loss: 3.1512 - val_accuracy: 0.5325 - val_loss: 2.3217 - learning_rate: 6.4935e-05
Epoch 148/300
657/657 - 65s - 99ms/step - accuracy: 0.3907 - loss: 3.1514 - val_accuracy: 0.5462 - val_loss: 2.3040 - learning_rate: 3.2467e-05
Epoch 149/300
657/657 - 63s - 96ms/step - accuracy: 0.3897 - loss: 3.1426 - val_accuracy: 0.5291 - val_loss: 2.2804 - learning_rate: 3.2467e-05
Epoch 150/300
657/657 - 66s - 100ms/step - accuracy: 0.3859 - loss: 3.1376 - val_accuracy: 0.5257 - val_loss: 2.2958 - learning_rate: 3.2467e-05
Epoch 151/300
657/657 - 65s - 99ms/step - accuracy: 0.3926 - loss: 3.1401 - val_accuracy: 0.5342 - val_loss: 2.3006 - learning_rate: 3.2467e-05
Epoch 152/300
657/657 - 64s - 97ms/step - accuracy: 0.3981 - loss: 3.1407 - val_accuracy: 0.5154 - val_loss: 2.2943 - learning_rate: 3.2467e-05
Epoch 153/300
657/657 - 65s - 99ms/step - accuracy: 0.3878 - loss: 3.1450 - val_accuracy: 0.5188 - val_loss: 2.2818 - learning_rate: 3.2467e-05
Epoch 154/300
657/657 - 67s - 102ms/step - accuracy: 0.3893 - loss: 3.1293 - val_accuracy: 0.5394 - val_loss: 2.2921 - learning_rate: 3.2467e-05
Epoch 155/300

Epoch 155: ReduceLROnPlateau reducing learning rate to 1.6233630958595313e-05.
657/657 - 65s - 99ms/step - accuracy: 0.3880 - loss: 3.1002 - val_accuracy: 0.5154 - val_loss: 2.2823 - learning_rate: 3.2467e-05
Epoch 155: early stopping
Restoring model weights from the end of the best epoch: 139.
Fold 7 Evaluation results: [2.294278860092163, 0.5291095972061157]
              precision    recall  f1-score   support

        1820       0.66      0.88      0.76        42
        1821       0.00      0.00      0.00         1
        1822       0.00      0.00      0.00         1
        1823       1.00      1.00      1.00         1
        1824       0.00      0.00      0.00         0
        1825       0.00      0.00      0.00         1
        1826       0.00      0.00      0.00         2
        1827       0.00      0.00      0.00         7
        1828       0.00      0.00      0.00         2
        1829       1.00      0.80      0.89         5
        1830       0.67      0.73      0.70        45
        1831       0.00      0.00      0.00         1
        1832       0.91      0.91      0.91        53
        1833       0.77      0.89      0.83        19
        1834       0.00      0.00      0.00         6
        1835       0.00      0.00      0.00         2
        1836       0.00      0.00      0.00         4
        1837       0.29      0.86      0.43         7
        1838       1.00      0.33      0.50         3
        1839       0.00      0.00      0.00         1
        1840       0.47      0.51      0.49        43
        1841       0.80      0.40      0.53        10
        1842       0.67      0.80      0.73         5
        1843       0.33      0.20      0.25         5
        1844       0.00      0.00      0.00         0
        1845       0.00      0.00      0.00         1
        1846       0.00      0.00      0.00         6
        1847       0.00      0.00      0.00         2
        1848       0.33      0.33      0.33         6
        1849       0.33      0.20      0.25         5
        1850       0.37      0.60      0.46        48
        1851       0.00      0.00      0.00         6
        1852       0.00      0.00      0.00         7
        1853       0.50      0.14      0.22         7
        1854       0.00      0.00      0.00         3
        1855       0.24      0.36      0.29        11
        1856       0.78      0.58      0.67        12
        1857       1.00      0.12      0.22         8
        1858       0.00      0.00      0.00         2
        1859       0.00      0.00      0.00         2
        1860       0.42      0.56      0.48        48
        1861       0.00      0.00      0.00         1
        1862       0.00      0.00      0.00         6
        1863       0.33      0.60      0.43         5
        1864       1.00      0.40      0.57         5
        1865       0.60      0.43      0.50         7
        1866       0.25      0.33      0.29         6
        1867       0.23      0.27      0.25        11
        1868       0.00      0.00      0.00         8
        1869       0.00      0.00      0.00         6
        1870       0.40      0.74      0.52        31
        1871       1.00      0.20      0.33         5
        1872       0.00      0.00      0.00         7
        1873       0.50      0.10      0.17        10
        1874       0.50      0.20      0.29         5
        1875       0.00      0.00      0.00         5
        1876       1.00      1.00      1.00        10
        1877       0.80      0.67      0.73         6
        1878       0.60      0.67      0.63         9
        1879       0.00      0.00      0.00         1

    accuracy                           0.53       584
   macro avg       0.33      0.28      0.28       584
weighted avg       0.50      0.53      0.49       584

Matthews Correlation Coefficient: 0.503
Macro avg F1: 0.277
Weighted avg F1: 0.488
Micro avg F1: 0.529
Top-3 Accuracy: 0.786
Top-5 Accuracy: 0.848
Micro ROC AUC  = 0.98
Macro ROC AUC (present classes) = 0.97
Classification MAE (in years): 3.21

Fold 7 Misclassification Analysis:
Near misses (within 2 years): 73 out of 275 misclassifications (26.55%)
Big misses (greater than 10 years): 78
MAE with outliers: 3.21
MAE without outliers: 2.37 (improvement: 0.84)

10 Worst misclassifications:
Image: data/datasets/public/1870/1875_012met.jpg, True: 1875, Predicted: 1820, Error: 55
Image: data/datasets/public/1870/1870_75wikimedia2.jpg, True: 1870, Predicted: 1820, Error: 50
Image: data/datasets/public/1860/1868_1397vna.jpg, True: 1868, Predicted: 1820, Error: 48
Image: data/datasets/public/1860/1860_100met.jpg, True: 1860, Predicted: 1820, Error: 40
Image: data/datasets/public/1870/1870_34wikimedia2.jpg, True: 1870, Predicted: 1840, Error: 30
Image: data/datasets/public/1820/1820_026met.jpg, True: 1820, Predicted: 1850, Error: 30
Image: data/datasets/public/1820/1820_049met.jpg, True: 1820, Predicted: 1850, Error: 30
Image: data/datasets/public/1820/1820_031met.jpg, True: 1820, Predicted: 1850, Error: 30
Image: data/datasets/public/1860/1860_123wikimedia2.jpg, True: 1860, Predicted: 1830, Error: 30
Image: data/datasets/public/1870/1872_029met.jpg, True: 1872, Predicted: 1850, Error: 22

===== Fold 8 =====
=== Running on Public Data ===

===== Fine Tuning 9 layers! =====
Epoch 1/300
657/657 - 90s - 138ms/step - accuracy: 0.1010 - loss: 4.6956 - val_accuracy: 0.2055 - val_loss: 4.2760 - learning_rate: 2.5974e-04
Epoch 2/300
657/657 - 65s - 99ms/step - accuracy: 0.1688 - loss: 4.3798 - val_accuracy: 0.2380 - val_loss: 3.8335 - learning_rate: 2.5974e-04
Epoch 3/300
657/657 - 63s - 96ms/step - accuracy: 0.1966 - loss: 4.2466 - val_accuracy: 0.2534 - val_loss: 3.8908 - learning_rate: 2.5974e-04
Epoch 4/300
657/657 - 66s - 100ms/step - accuracy: 0.2167 - loss: 4.1614 - val_accuracy: 0.2705 - val_loss: 3.7077 - learning_rate: 2.5974e-04
Epoch 5/300
657/657 - 65s - 99ms/step - accuracy: 0.2390 - loss: 4.1165 - val_accuracy: 0.2962 - val_loss: 3.6693 - learning_rate: 2.5974e-04
Epoch 6/300
657/657 - 62s - 94ms/step - accuracy: 0.2514 - loss: 4.0723 - val_accuracy: 0.3236 - val_loss: 3.6981 - learning_rate: 2.5974e-04
Epoch 7/300
657/657 - 63s - 95ms/step - accuracy: 0.2556 - loss: 4.0535 - val_accuracy: 0.3373 - val_loss: 3.6504 - learning_rate: 2.5974e-04
Epoch 8/300
657/657 - 63s - 95ms/step - accuracy: 0.2613 - loss: 4.0129 - val_accuracy: 0.3630 - val_loss: 3.4730 - learning_rate: 2.5974e-04
Epoch 9/300
657/657 - 64s - 97ms/step - accuracy: 0.2636 - loss: 3.9590 - val_accuracy: 0.3459 - val_loss: 3.4093 - learning_rate: 2.5974e-04
Epoch 10/300
657/657 - 63s - 96ms/step - accuracy: 0.2733 - loss: 3.9028 - val_accuracy: 0.3510 - val_loss: 3.4067 - learning_rate: 2.5974e-04
Epoch 11/300
657/657 - 66s - 100ms/step - accuracy: 0.2818 - loss: 3.9247 - val_accuracy: 0.3699 - val_loss: 3.2763 - learning_rate: 2.5974e-04
Epoch 12/300
657/657 - 65s - 99ms/step - accuracy: 0.2839 - loss: 3.8589 - val_accuracy: 0.3818 - val_loss: 3.3071 - learning_rate: 2.5974e-04
Epoch 13/300
657/657 - 64s - 97ms/step - accuracy: 0.2980 - loss: 3.8161 - val_accuracy: 0.3442 - val_loss: 3.1723 - learning_rate: 2.5974e-04
Epoch 14/300
657/657 - 67s - 102ms/step - accuracy: 0.3028 - loss: 3.7952 - val_accuracy: 0.3990 - val_loss: 3.2162 - learning_rate: 2.5974e-04
Epoch 15/300
657/657 - 65s - 98ms/step - accuracy: 0.3049 - loss: 3.8215 - val_accuracy: 0.4024 - val_loss: 3.1623 - learning_rate: 2.5974e-04
Epoch 16/300
657/657 - 67s - 101ms/step - accuracy: 0.3012 - loss: 3.7684 - val_accuracy: 0.4007 - val_loss: 3.1894 - learning_rate: 2.5974e-04
Epoch 17/300
657/657 - 63s - 96ms/step - accuracy: 0.2942 - loss: 3.7607 - val_accuracy: 0.3921 - val_loss: 3.1935 - learning_rate: 2.5974e-04
Epoch 18/300
657/657 - 65s - 99ms/step - accuracy: 0.3108 - loss: 3.6953 - val_accuracy: 0.3938 - val_loss: 3.1464 - learning_rate: 2.5974e-04
Epoch 19/300
657/657 - 66s - 101ms/step - accuracy: 0.3172 - loss: 3.6971 - val_accuracy: 0.4058 - val_loss: 3.0534 - learning_rate: 2.5974e-04
Epoch 20/300
657/657 - 64s - 97ms/step - accuracy: 0.3180 - loss: 3.6824 - val_accuracy: 0.4092 - val_loss: 3.0393 - learning_rate: 2.5974e-04
Epoch 21/300
657/657 - 67s - 102ms/step - accuracy: 0.3155 - loss: 3.6410 - val_accuracy: 0.4178 - val_loss: 3.0384 - learning_rate: 2.5974e-04
Epoch 22/300
657/657 - 64s - 98ms/step - accuracy: 0.3203 - loss: 3.6446 - val_accuracy: 0.4195 - val_loss: 2.9667 - learning_rate: 2.5974e-04
Epoch 23/300
657/657 - 66s - 101ms/step - accuracy: 0.3262 - loss: 3.6254 - val_accuracy: 0.4281 - val_loss: 2.8841 - learning_rate: 2.5974e-04
Epoch 24/300
657/657 - 63s - 96ms/step - accuracy: 0.3237 - loss: 3.6189 - val_accuracy: 0.4144 - val_loss: 2.9608 - learning_rate: 2.5974e-04
Epoch 25/300
657/657 - 66s - 101ms/step - accuracy: 0.3250 - loss: 3.6089 - val_accuracy: 0.4229 - val_loss: 2.8823 - learning_rate: 2.5974e-04
Epoch 26/300
657/657 - 65s - 99ms/step - accuracy: 0.3269 - loss: 3.5830 - val_accuracy: 0.4092 - val_loss: 2.9101 - learning_rate: 2.5974e-04
Epoch 27/300
657/657 - 63s - 95ms/step - accuracy: 0.3359 - loss: 3.5228 - val_accuracy: 0.4110 - val_loss: 2.8947 - learning_rate: 2.5974e-04
Epoch 28/300
657/657 - 66s - 101ms/step - accuracy: 0.3243 - loss: 3.5316 - val_accuracy: 0.4247 - val_loss: 2.8457 - learning_rate: 2.5974e-04
Epoch 29/300
657/657 - 64s - 97ms/step - accuracy: 0.3292 - loss: 3.5149 - val_accuracy: 0.4486 - val_loss: 2.8500 - learning_rate: 2.5974e-04
Epoch 30/300
657/657 - 66s - 100ms/step - accuracy: 0.3271 - loss: 3.5400 - val_accuracy: 0.4127 - val_loss: 2.7952 - learning_rate: 2.5974e-04
Epoch 31/300
657/657 - 65s - 98ms/step - accuracy: 0.3338 - loss: 3.5438 - val_accuracy: 0.4384 - val_loss: 2.7641 - learning_rate: 2.5974e-04
Epoch 32/300
657/657 - 64s - 97ms/step - accuracy: 0.3383 - loss: 3.5454 - val_accuracy: 0.4281 - val_loss: 2.8364 - learning_rate: 2.5974e-04
Epoch 33/300
657/657 - 67s - 103ms/step - accuracy: 0.3336 - loss: 3.5173 - val_accuracy: 0.4264 - val_loss: 2.8099 - learning_rate: 2.5974e-04
Epoch 34/300
657/657 - 63s - 96ms/step - accuracy: 0.3387 - loss: 3.4975 - val_accuracy: 0.4503 - val_loss: 2.8279 - learning_rate: 2.5974e-04
Epoch 35/300
657/657 - 65s - 98ms/step - accuracy: 0.3345 - loss: 3.4857 - val_accuracy: 0.4418 - val_loss: 2.7320 - learning_rate: 2.5974e-04
Epoch 36/300
657/657 - 65s - 99ms/step - accuracy: 0.3517 - loss: 3.4708 - val_accuracy: 0.4435 - val_loss: 2.7350 - learning_rate: 2.5974e-04
Epoch 37/300
657/657 - 64s - 97ms/step - accuracy: 0.3357 - loss: 3.4790 - val_accuracy: 0.4401 - val_loss: 2.7669 - learning_rate: 2.5974e-04
Epoch 38/300
657/657 - 66s - 100ms/step - accuracy: 0.3511 - loss: 3.4397 - val_accuracy: 0.4521 - val_loss: 2.7139 - learning_rate: 2.5974e-04
Epoch 39/300
657/657 - 62s - 95ms/step - accuracy: 0.3463 - loss: 3.4981 - val_accuracy: 0.4332 - val_loss: 2.7744 - learning_rate: 2.5974e-04
Epoch 40/300
657/657 - 67s - 102ms/step - accuracy: 0.3458 - loss: 3.4210 - val_accuracy: 0.4247 - val_loss: 2.7054 - learning_rate: 2.5974e-04
Epoch 41/300
657/657 - 63s - 96ms/step - accuracy: 0.3482 - loss: 3.4224 - val_accuracy: 0.4366 - val_loss: 2.7132 - learning_rate: 2.5974e-04
Epoch 42/300
657/657 - 65s - 99ms/step - accuracy: 0.3479 - loss: 3.4356 - val_accuracy: 0.4418 - val_loss: 2.7009 - learning_rate: 2.5974e-04
Epoch 43/300
657/657 - 68s - 103ms/step - accuracy: 0.3460 - loss: 3.4324 - val_accuracy: 0.4298 - val_loss: 2.7029 - learning_rate: 2.5974e-04
Epoch 44/300
657/657 - 64s - 97ms/step - accuracy: 0.3490 - loss: 3.4514 - val_accuracy: 0.4281 - val_loss: 2.6839 - learning_rate: 2.5974e-04
Epoch 45/300
657/657 - 64s - 98ms/step - accuracy: 0.3492 - loss: 3.4024 - val_accuracy: 0.4521 - val_loss: 2.6948 - learning_rate: 2.5974e-04
Epoch 46/300
657/657 - 65s - 98ms/step - accuracy: 0.3479 - loss: 3.3944 - val_accuracy: 0.4777 - val_loss: 2.7112 - learning_rate: 2.5974e-04
Epoch 47/300
657/657 - 65s - 100ms/step - accuracy: 0.3520 - loss: 3.4389 - val_accuracy: 0.4401 - val_loss: 2.7197 - learning_rate: 2.5974e-04
Epoch 48/300
657/657 - 65s - 99ms/step - accuracy: 0.3475 - loss: 3.3942 - val_accuracy: 0.4469 - val_loss: 2.6591 - learning_rate: 2.5974e-04
Epoch 49/300
657/657 - 64s - 98ms/step - accuracy: 0.3500 - loss: 3.3954 - val_accuracy: 0.4658 - val_loss: 2.6946 - learning_rate: 2.5974e-04
Epoch 50/300
657/657 - 66s - 101ms/step - accuracy: 0.3505 - loss: 3.4024 - val_accuracy: 0.4435 - val_loss: 2.6218 - learning_rate: 2.5974e-04
Epoch 51/300
657/657 - 64s - 98ms/step - accuracy: 0.3519 - loss: 3.3692 - val_accuracy: 0.4777 - val_loss: 2.6930 - learning_rate: 2.5974e-04
Epoch 52/300
657/657 - 65s - 98ms/step - accuracy: 0.3568 - loss: 3.3596 - val_accuracy: 0.4640 - val_loss: 2.5855 - learning_rate: 2.5974e-04
Epoch 53/300
657/657 - 64s - 97ms/step - accuracy: 0.3539 - loss: 3.3804 - val_accuracy: 0.4623 - val_loss: 2.6241 - learning_rate: 2.5974e-04
Epoch 54/300
657/657 - 64s - 98ms/step - accuracy: 0.3551 - loss: 3.3438 - val_accuracy: 0.4555 - val_loss: 2.6646 - learning_rate: 2.5974e-04
Epoch 55/300
657/657 - 65s - 99ms/step - accuracy: 0.3520 - loss: 3.3410 - val_accuracy: 0.4897 - val_loss: 2.5967 - learning_rate: 2.5974e-04
Epoch 56/300
657/657 - 63s - 96ms/step - accuracy: 0.3509 - loss: 3.3727 - val_accuracy: 0.4555 - val_loss: 2.5934 - learning_rate: 2.5974e-04
Epoch 57/300
657/657 - 67s - 101ms/step - accuracy: 0.3688 - loss: 3.3507 - val_accuracy: 0.4760 - val_loss: 2.6388 - learning_rate: 2.5974e-04
Epoch 58/300
657/657 - 65s - 99ms/step - accuracy: 0.3616 - loss: 3.3357 - val_accuracy: 0.4760 - val_loss: 2.6083 - learning_rate: 2.5974e-04
Epoch 59/300
657/657 - 64s - 97ms/step - accuracy: 0.3618 - loss: 3.3214 - val_accuracy: 0.4863 - val_loss: 2.6023 - learning_rate: 2.5974e-04
Epoch 60/300
657/657 - 67s - 101ms/step - accuracy: 0.3616 - loss: 3.3538 - val_accuracy: 0.4589 - val_loss: 2.5643 - learning_rate: 2.5974e-04
Epoch 61/300
657/657 - 62s - 94ms/step - accuracy: 0.3625 - loss: 3.3672 - val_accuracy: 0.4846 - val_loss: 2.6219 - learning_rate: 2.5974e-04
Epoch 62/300
657/657 - 65s - 100ms/step - accuracy: 0.3587 - loss: 3.3326 - val_accuracy: 0.4623 - val_loss: 2.5783 - learning_rate: 2.5974e-04
Epoch 63/300
657/657 - 65s - 99ms/step - accuracy: 0.3619 - loss: 3.3038 - val_accuracy: 0.4692 - val_loss: 2.5720 - learning_rate: 2.5974e-04
Epoch 64/300
657/657 - 66s - 101ms/step - accuracy: 0.3591 - loss: 3.3326 - val_accuracy: 0.4692 - val_loss: 2.5478 - learning_rate: 2.5974e-04
Epoch 65/300
657/657 - 66s - 100ms/step - accuracy: 0.3623 - loss: 3.3095 - val_accuracy: 0.4914 - val_loss: 2.5100 - learning_rate: 2.5974e-04
Epoch 66/300
657/657 - 63s - 97ms/step - accuracy: 0.3568 - loss: 3.3400 - val_accuracy: 0.4675 - val_loss: 2.5069 - learning_rate: 2.5974e-04
Epoch 67/300
657/657 - 66s - 101ms/step - accuracy: 0.3726 - loss: 3.2808 - val_accuracy: 0.4606 - val_loss: 2.5375 - learning_rate: 2.5974e-04
Epoch 68/300
657/657 - 63s - 96ms/step - accuracy: 0.3646 - loss: 3.2966 - val_accuracy: 0.4623 - val_loss: 2.6017 - learning_rate: 2.5974e-04
Epoch 69/300
657/657 - 66s - 100ms/step - accuracy: 0.3564 - loss: 3.3527 - val_accuracy: 0.4932 - val_loss: 2.5148 - learning_rate: 2.5974e-04
Epoch 70/300
657/657 - 64s - 97ms/step - accuracy: 0.3579 - loss: 3.2776 - val_accuracy: 0.4743 - val_loss: 2.5542 - learning_rate: 2.5974e-04
Epoch 71/300
657/657 - 63s - 96ms/step - accuracy: 0.3638 - loss: 3.3130 - val_accuracy: 0.4829 - val_loss: 2.5263 - learning_rate: 2.5974e-04
Epoch 72/300
657/657 - 85s - 129ms/step - accuracy: 0.3732 - loss: 3.2701 - val_accuracy: 0.4743 - val_loss: 2.5310 - learning_rate: 2.5974e-04
Epoch 73/300
657/657 - 65s - 99ms/step - accuracy: 0.3564 - loss: 3.3253 - val_accuracy: 0.4829 - val_loss: 2.5174 - learning_rate: 2.5974e-04
Epoch 74/300
657/657 - 64s - 98ms/step - accuracy: 0.3690 - loss: 3.2971 - val_accuracy: 0.4880 - val_loss: 2.4976 - learning_rate: 2.5974e-04
Epoch 75/300
657/657 - 66s - 100ms/step - accuracy: 0.3675 - loss: 3.2840 - val_accuracy: 0.4932 - val_loss: 2.5370 - learning_rate: 2.5974e-04
Epoch 76/300
657/657 - 66s - 100ms/step - accuracy: 0.3775 - loss: 3.2452 - val_accuracy: 0.5137 - val_loss: 2.5124 - learning_rate: 2.5974e-04
Epoch 77/300
657/657 - 63s - 95ms/step - accuracy: 0.3686 - loss: 3.3139 - val_accuracy: 0.4692 - val_loss: 2.5421 - learning_rate: 2.5974e-04
Epoch 78/300
657/657 - 66s - 101ms/step - accuracy: 0.3644 - loss: 3.3002 - val_accuracy: 0.4897 - val_loss: 2.5426 - learning_rate: 2.5974e-04
Epoch 79/300
657/657 - 66s - 100ms/step - accuracy: 0.3676 - loss: 3.2739 - val_accuracy: 0.5017 - val_loss: 2.4799 - learning_rate: 2.5974e-04
Epoch 80/300
657/657 - 65s - 99ms/step - accuracy: 0.3787 - loss: 3.2225 - val_accuracy: 0.5017 - val_loss: 2.4806 - learning_rate: 2.5974e-04
Epoch 81/300
657/657 - 63s - 96ms/step - accuracy: 0.3703 - loss: 3.2498 - val_accuracy: 0.5000 - val_loss: 2.4399 - learning_rate: 2.5974e-04
Epoch 82/300
657/657 - 66s - 101ms/step - accuracy: 0.3648 - loss: 3.2630 - val_accuracy: 0.4966 - val_loss: 2.5368 - learning_rate: 2.5974e-04
Epoch 83/300
657/657 - 66s - 100ms/step - accuracy: 0.3701 - loss: 3.2389 - val_accuracy: 0.4692 - val_loss: 2.4734 - learning_rate: 2.5974e-04
Epoch 84/300
657/657 - 64s - 98ms/step - accuracy: 0.3728 - loss: 3.2537 - val_accuracy: 0.4983 - val_loss: 2.4420 - learning_rate: 2.5974e-04
Epoch 85/300
657/657 - 66s - 100ms/step - accuracy: 0.3699 - loss: 3.2639 - val_accuracy: 0.5086 - val_loss: 2.4625 - learning_rate: 2.5974e-04
Epoch 86/300
657/657 - 66s - 101ms/step - accuracy: 0.3749 - loss: 3.2311 - val_accuracy: 0.5137 - val_loss: 2.4791 - learning_rate: 2.5974e-04
Epoch 87/300
657/657 - 64s - 98ms/step - accuracy: 0.3718 - loss: 3.2571 - val_accuracy: 0.5171 - val_loss: 2.4303 - learning_rate: 2.5974e-04
Epoch 88/300
657/657 - 65s - 98ms/step - accuracy: 0.3688 - loss: 3.2603 - val_accuracy: 0.4949 - val_loss: 2.5276 - learning_rate: 2.5974e-04
Epoch 89/300
657/657 - 66s - 100ms/step - accuracy: 0.3699 - loss: 3.2192 - val_accuracy: 0.5188 - val_loss: 2.4515 - learning_rate: 2.5974e-04
Epoch 90/300
657/657 - 66s - 100ms/step - accuracy: 0.3720 - loss: 3.2773 - val_accuracy: 0.5034 - val_loss: 2.4580 - learning_rate: 2.5974e-04
Epoch 91/300
657/657 - 62s - 94ms/step - accuracy: 0.3779 - loss: 3.2291 - val_accuracy: 0.5171 - val_loss: 2.4666 - learning_rate: 2.5974e-04
Epoch 92/300
657/657 - 67s - 101ms/step - accuracy: 0.3753 - loss: 3.2388 - val_accuracy: 0.4966 - val_loss: 2.4884 - learning_rate: 2.5974e-04
Epoch 93/300
657/657 - 67s - 102ms/step - accuracy: 0.3661 - loss: 3.2641 - val_accuracy: 0.5034 - val_loss: 2.4103 - learning_rate: 2.5974e-04
Epoch 94/300
657/657 - 64s - 98ms/step - accuracy: 0.3815 - loss: 3.2361 - val_accuracy: 0.4983 - val_loss: 2.5092 - learning_rate: 2.5974e-04
Epoch 95/300
657/657 - 67s - 102ms/step - accuracy: 0.3732 - loss: 3.2421 - val_accuracy: 0.5103 - val_loss: 2.4404 - learning_rate: 2.5974e-04
Epoch 96/300
657/657 - 64s - 98ms/step - accuracy: 0.3747 - loss: 3.2495 - val_accuracy: 0.4932 - val_loss: 2.4704 - learning_rate: 2.5974e-04
Epoch 97/300
657/657 - 63s - 96ms/step - accuracy: 0.3728 - loss: 3.2302 - val_accuracy: 0.4914 - val_loss: 2.4860 - learning_rate: 2.5974e-04
Epoch 98/300
657/657 - 64s - 98ms/step - accuracy: 0.3737 - loss: 3.2321 - val_accuracy: 0.5103 - val_loss: 2.4557 - learning_rate: 2.5974e-04
Epoch 99/300
657/657 - 65s - 99ms/step - accuracy: 0.3779 - loss: 3.1987 - val_accuracy: 0.5068 - val_loss: 2.4577 - learning_rate: 2.5974e-04
Epoch 100/300
657/657 - 65s - 100ms/step - accuracy: 0.3705 - loss: 3.2448 - val_accuracy: 0.5154 - val_loss: 2.4118 - learning_rate: 2.5974e-04
Epoch 101/300

Epoch 101: ReduceLROnPlateau reducing learning rate to 0.0001298690476687625.
657/657 - 78s - 118ms/step - accuracy: 0.3848 - loss: 3.2073 - val_accuracy: 0.5034 - val_loss: 2.4250 - learning_rate: 2.5974e-04
Epoch 102/300
657/657 - 66s - 100ms/step - accuracy: 0.3892 - loss: 3.1633 - val_accuracy: 0.5034 - val_loss: 2.4515 - learning_rate: 1.2987e-04
Epoch 103/300
657/657 - 65s - 99ms/step - accuracy: 0.3831 - loss: 3.1727 - val_accuracy: 0.5120 - val_loss: 2.4135 - learning_rate: 1.2987e-04
Epoch 104/300
657/657 - 64s - 97ms/step - accuracy: 0.3878 - loss: 3.1357 - val_accuracy: 0.5257 - val_loss: 2.3796 - learning_rate: 1.2987e-04
Epoch 105/300
657/657 - 66s - 101ms/step - accuracy: 0.3871 - loss: 3.1522 - val_accuracy: 0.5205 - val_loss: 2.4033 - learning_rate: 1.2987e-04
Epoch 106/300
657/657 - 67s - 101ms/step - accuracy: 0.3893 - loss: 3.1376 - val_accuracy: 0.5103 - val_loss: 2.3861 - learning_rate: 1.2987e-04
Epoch 107/300
657/657 - 65s - 99ms/step - accuracy: 0.3909 - loss: 3.1334 - val_accuracy: 0.5223 - val_loss: 2.3897 - learning_rate: 1.2987e-04
Epoch 108/300
657/657 - 65s - 99ms/step - accuracy: 0.3850 - loss: 3.1364 - val_accuracy: 0.5137 - val_loss: 2.3846 - learning_rate: 1.2987e-04
Epoch 109/300
657/657 - 67s - 102ms/step - accuracy: 0.3882 - loss: 3.1405 - val_accuracy: 0.5120 - val_loss: 2.4126 - learning_rate: 1.2987e-04
Epoch 110/300
657/657 - 64s - 98ms/step - accuracy: 0.3897 - loss: 3.1561 - val_accuracy: 0.5223 - val_loss: 2.4289 - learning_rate: 1.2987e-04
Epoch 111/300
657/657 - 63s - 95ms/step - accuracy: 0.3886 - loss: 3.1629 - val_accuracy: 0.5000 - val_loss: 2.3756 - learning_rate: 1.2987e-04
Epoch 112/300
657/657 - 64s - 97ms/step - accuracy: 0.3933 - loss: 3.1349 - val_accuracy: 0.5171 - val_loss: 2.3576 - learning_rate: 1.2987e-04
Epoch 113/300
657/657 - 66s - 100ms/step - accuracy: 0.3956 - loss: 3.1126 - val_accuracy: 0.5103 - val_loss: 2.4207 - learning_rate: 1.2987e-04
Epoch 114/300
657/657 - 66s - 100ms/step - accuracy: 0.3874 - loss: 3.1544 - val_accuracy: 0.5120 - val_loss: 2.3551 - learning_rate: 1.2987e-04
Epoch 115/300
657/657 - 63s - 96ms/step - accuracy: 0.3931 - loss: 3.1104 - val_accuracy: 0.5051 - val_loss: 2.3568 - learning_rate: 1.2987e-04
Epoch 116/300
657/657 - 66s - 101ms/step - accuracy: 0.3890 - loss: 3.1213 - val_accuracy: 0.5240 - val_loss: 2.3824 - learning_rate: 1.2987e-04
Epoch 117/300
657/657 - 65s - 99ms/step - accuracy: 0.3943 - loss: 3.1099 - val_accuracy: 0.5120 - val_loss: 2.3623 - learning_rate: 1.2987e-04
Epoch 118/300
657/657 - 62s - 95ms/step - accuracy: 0.3935 - loss: 3.1396 - val_accuracy: 0.5360 - val_loss: 2.3697 - learning_rate: 1.2987e-04
Epoch 119/300
657/657 - 66s - 101ms/step - accuracy: 0.3973 - loss: 3.0902 - val_accuracy: 0.5086 - val_loss: 2.3689 - learning_rate: 1.2987e-04
Epoch 120/300
657/657 - 66s - 101ms/step - accuracy: 0.4023 - loss: 3.1018 - val_accuracy: 0.5291 - val_loss: 2.3520 - learning_rate: 1.2987e-04
Epoch 121/300
657/657 - 64s - 98ms/step - accuracy: 0.3977 - loss: 3.1067 - val_accuracy: 0.5257 - val_loss: 2.3499 - learning_rate: 1.2987e-04
Epoch 122/300
657/657 - 65s - 98ms/step - accuracy: 0.3951 - loss: 3.1221 - val_accuracy: 0.5223 - val_loss: 2.3506 - learning_rate: 1.2987e-04
Epoch 123/300
657/657 - 65s - 99ms/step - accuracy: 0.4049 - loss: 3.0974 - val_accuracy: 0.5103 - val_loss: 2.3708 - learning_rate: 1.2987e-04
Epoch 124/300
657/657 - 66s - 100ms/step - accuracy: 0.3800 - loss: 3.1409 - val_accuracy: 0.5291 - val_loss: 2.3520 - learning_rate: 1.2987e-04
Epoch 125/300
657/657 - 63s - 96ms/step - accuracy: 0.3956 - loss: 3.0983 - val_accuracy: 0.5223 - val_loss: 2.3509 - learning_rate: 1.2987e-04
Epoch 126/300
657/657 - 65s - 99ms/step - accuracy: 0.3886 - loss: 3.0806 - val_accuracy: 0.5411 - val_loss: 2.3547 - learning_rate: 1.2987e-04
Epoch 127/300
657/657 - 65s - 98ms/step - accuracy: 0.3905 - loss: 3.1049 - val_accuracy: 0.5257 - val_loss: 2.3459 - learning_rate: 1.2987e-04
Epoch 128/300
657/657 - 63s - 96ms/step - accuracy: 0.3912 - loss: 3.1078 - val_accuracy: 0.5377 - val_loss: 2.3116 - learning_rate: 1.2987e-04
Epoch 129/300
657/657 - 66s - 100ms/step - accuracy: 0.3880 - loss: 3.0991 - val_accuracy: 0.5154 - val_loss: 2.3529 - learning_rate: 1.2987e-04
Epoch 130/300
657/657 - 64s - 97ms/step - accuracy: 0.3960 - loss: 3.1143 - val_accuracy: 0.5223 - val_loss: 2.3365 - learning_rate: 1.2987e-04
Epoch 131/300
657/657 - 66s - 101ms/step - accuracy: 0.3968 - loss: 3.1215 - val_accuracy: 0.5188 - val_loss: 2.3358 - learning_rate: 1.2987e-04
Epoch 132/300
657/657 - 65s - 99ms/step - accuracy: 0.4141 - loss: 3.0513 - val_accuracy: 0.5274 - val_loss: 2.3577 - learning_rate: 1.2987e-04
Epoch 133/300
657/657 - 64s - 97ms/step - accuracy: 0.4017 - loss: 3.0655 - val_accuracy: 0.5205 - val_loss: 2.3042 - learning_rate: 1.2987e-04
Epoch 134/300
657/657 - 67s - 102ms/step - accuracy: 0.3960 - loss: 3.1164 - val_accuracy: 0.5223 - val_loss: 2.3691 - learning_rate: 1.2987e-04
Epoch 135/300
657/657 - 63s - 96ms/step - accuracy: 0.4025 - loss: 3.0923 - val_accuracy: 0.5068 - val_loss: 2.3209 - learning_rate: 1.2987e-04
Epoch 136/300
657/657 - 64s - 97ms/step - accuracy: 0.3937 - loss: 3.0999 - val_accuracy: 0.5223 - val_loss: 2.3218 - learning_rate: 1.2987e-04
Epoch 137/300
657/657 - 66s - 100ms/step - accuracy: 0.4072 - loss: 3.0557 - val_accuracy: 0.5137 - val_loss: 2.3749 - learning_rate: 1.2987e-04
Epoch 138/300
657/657 - 63s - 95ms/step - accuracy: 0.3987 - loss: 3.1013 - val_accuracy: 0.5342 - val_loss: 2.3564 - learning_rate: 1.2987e-04
Epoch 139/300
657/657 - 67s - 101ms/step - accuracy: 0.4000 - loss: 3.0829 - val_accuracy: 0.5223 - val_loss: 2.3209 - learning_rate: 1.2987e-04
Epoch 140/300
657/657 - 64s - 97ms/step - accuracy: 0.4004 - loss: 3.0756 - val_accuracy: 0.5257 - val_loss: 2.3219 - learning_rate: 1.2987e-04
Epoch 141/300

Epoch 141: ReduceLROnPlateau reducing learning rate to 6.493452383438125e-05.
657/657 - 67s - 101ms/step - accuracy: 0.3916 - loss: 3.1109 - val_accuracy: 0.5257 - val_loss: 2.3249 - learning_rate: 1.2987e-04
Epoch 142/300
657/657 - 66s - 101ms/step - accuracy: 0.3979 - loss: 3.0854 - val_accuracy: 0.5342 - val_loss: 2.3349 - learning_rate: 6.4935e-05
Epoch 143/300
657/657 - 64s - 97ms/step - accuracy: 0.4036 - loss: 3.0484 - val_accuracy: 0.5342 - val_loss: 2.2755 - learning_rate: 6.4935e-05
Epoch 144/300
657/657 - 66s - 100ms/step - accuracy: 0.4095 - loss: 3.0421 - val_accuracy: 0.5308 - val_loss: 2.3193 - learning_rate: 6.4935e-05
Epoch 145/300
657/657 - 66s - 101ms/step - accuracy: 0.4143 - loss: 3.0212 - val_accuracy: 0.5462 - val_loss: 2.3259 - learning_rate: 6.4935e-05
Epoch 146/300
657/657 - 66s - 100ms/step - accuracy: 0.4017 - loss: 3.0659 - val_accuracy: 0.5291 - val_loss: 2.3135 - learning_rate: 6.4935e-05
Epoch 147/300
657/657 - 64s - 98ms/step - accuracy: 0.4036 - loss: 3.0441 - val_accuracy: 0.5428 - val_loss: 2.3146 - learning_rate: 6.4935e-05
Epoch 148/300
657/657 - 62s - 95ms/step - accuracy: 0.4082 - loss: 2.9776 - val_accuracy: 0.5154 - val_loss: 2.3057 - learning_rate: 6.4935e-05
Epoch 149/300
657/657 - 63s - 96ms/step - accuracy: 0.4021 - loss: 3.0279 - val_accuracy: 0.5360 - val_loss: 2.2915 - learning_rate: 6.4935e-05
Epoch 150/300
657/657 - 65s - 99ms/step - accuracy: 0.4015 - loss: 3.0466 - val_accuracy: 0.5548 - val_loss: 2.3307 - learning_rate: 6.4935e-05
Epoch 151/300

Epoch 151: ReduceLROnPlateau reducing learning rate to 3.2467261917190626e-05.
657/657 - 65s - 99ms/step - accuracy: 0.4029 - loss: 3.0493 - val_accuracy: 0.5360 - val_loss: 2.2861 - learning_rate: 6.4935e-05
Epoch 152/300
657/657 - 66s - 101ms/step - accuracy: 0.4069 - loss: 3.0216 - val_accuracy: 0.5377 - val_loss: 2.2894 - learning_rate: 3.2467e-05
Epoch 153/300
657/657 - 64s - 98ms/step - accuracy: 0.4122 - loss: 2.9989 - val_accuracy: 0.5342 - val_loss: 2.2992 - learning_rate: 3.2467e-05
Epoch 154/300
657/657 - 64s - 97ms/step - accuracy: 0.4029 - loss: 3.0477 - val_accuracy: 0.5325 - val_loss: 2.2925 - learning_rate: 3.2467e-05
Epoch 155/300
657/657 - 66s - 101ms/step - accuracy: 0.4135 - loss: 3.0213 - val_accuracy: 0.5394 - val_loss: 2.3042 - learning_rate: 3.2467e-05
Epoch 156/300
657/657 - 66s - 101ms/step - accuracy: 0.4038 - loss: 3.0609 - val_accuracy: 0.5462 - val_loss: 2.3045 - learning_rate: 3.2467e-05
Epoch 157/300
657/657 - 65s - 98ms/step - accuracy: 0.4093 - loss: 3.0317 - val_accuracy: 0.5411 - val_loss: 2.2895 - learning_rate: 3.2467e-05
Epoch 158/300
657/657 - 68s - 104ms/step - accuracy: 0.4091 - loss: 3.0032 - val_accuracy: 0.5411 - val_loss: 2.3000 - learning_rate: 3.2467e-05
Epoch 159/300

Epoch 159: ReduceLROnPlateau reducing learning rate to 1.6233630958595313e-05.
657/657 - 65s - 99ms/step - accuracy: 0.4023 - loss: 3.0381 - val_accuracy: 0.5394 - val_loss: 2.2918 - learning_rate: 3.2467e-05
Epoch 159: early stopping
Restoring model weights from the end of the best epoch: 143.
Fold 8 Evaluation results: [2.286775588989258, 0.534246563911438]
              precision    recall  f1-score   support

        1820       0.64      0.76      0.70        42
        1821       0.00      0.00      0.00         1
        1822       0.00      0.00      0.00         1
        1823       0.00      0.00      0.00         1
        1824       0.00      0.00      0.00         0
        1825       0.00      0.00      0.00         1
        1826       0.00      0.00      0.00         2
        1827       1.00      0.29      0.44         7
        1828       0.00      0.00      0.00         2
        1829       1.00      1.00      1.00         5
        1830       0.61      0.67      0.64        45
        1831       0.00      0.00      0.00         1
        1832       0.98      0.85      0.91        53
        1833       0.90      1.00      0.95        19
        1834       0.64      1.00      0.78         7
        1835       0.00      0.00      0.00         2
        1836       0.00      0.00      0.00         3
        1837       0.21      0.50      0.30         6
        1838       0.00      0.00      0.00         4
        1839       0.00      0.00      0.00         1
        1840       0.62      0.60      0.61        43
        1841       0.50      0.40      0.44        10
        1842       0.50      0.20      0.29         5
        1843       0.50      0.40      0.44         5
        1844       0.00      0.00      0.00         0
        1845       0.00      0.00      0.00         1
        1846       0.33      0.17      0.22         6
        1847       0.00      0.00      0.00         2
        1848       0.25      0.17      0.20         6
        1849       0.00      0.00      0.00         5
        1850       0.36      0.65      0.46        48
        1851       0.30      0.50      0.38         6
        1852       0.00      0.00      0.00         7
        1853       0.50      0.14      0.22         7
        1854       1.00      0.50      0.67         2
        1855       0.36      0.45      0.40        11
        1856       0.62      0.67      0.64        12
        1857       0.00      0.00      0.00         8
        1858       0.00      0.00      0.00         2
        1859       0.00      0.00      0.00         3
        1860       0.51      0.58      0.54        48
        1861       0.00      0.00      0.00         1
        1862       0.00      0.00      0.00         6
        1863       0.30      0.50      0.38         6
        1864       0.40      0.40      0.40         5
        1865       1.00      0.29      0.44         7
        1866       0.33      0.33      0.33         6
        1867       0.25      0.18      0.21        11
        1868       0.00      0.00      0.00         8
        1869       0.00      0.00      0.00         5
        1870       0.43      0.71      0.54        31
        1871       0.00      0.00      0.00         5
        1872       0.17      0.14      0.15         7
        1873       0.50      0.40      0.44        10
        1874       1.00      0.20      0.33         5
        1875       0.00      0.00      0.00         5
        1876       0.90      0.90      0.90        10
        1877       0.29      0.33      0.31         6
        1878       0.64      0.78      0.70         9
        1879       0.00      0.00      0.00         1

    accuracy                           0.53       584
   macro avg       0.31      0.28      0.27       584
weighted avg       0.51      0.53      0.50       584

Matthews Correlation Coefficient: 0.509
Macro avg F1: 0.273
Weighted avg F1: 0.505
Micro avg F1: 0.534
Top-3 Accuracy: 0.764
Top-5 Accuracy: 0.860
Micro ROC AUC  = 0.98
Macro ROC AUC (present classes) = 0.97
Classification MAE (in years): 3.25

Fold 8 Misclassification Analysis:
Near misses (within 2 years): 87 out of 272 misclassifications (31.99%)
Big misses (greater than 10 years): 85
MAE with outliers: 3.25
MAE without outliers: 2.24 (improvement: 1.01)

10 Worst misclassifications:
Image: data/datasets/public/1820/1820_029met.jpg, True: 1820, Predicted: 1860, Error: 40
Image: data/datasets/public/1820/1820_047met.jpg, True: 1820, Predicted: 1860, Error: 40
Image: data/datasets/public/1870/1870_38wikimedia2.jpg, True: 1870, Predicted: 1830, Error: 40
Image: data/datasets/public/1820/1820_045met.jpg, True: 1820, Predicted: 1856, Error: 36
Image: data/datasets/public/1820/1820_030met.jpg, True: 1820, Predicted: 1850, Error: 30
Image: data/datasets/public/1820/1820_025met.jpg, True: 1820, Predicted: 1850, Error: 30
Image: data/datasets/public/1860/1860_49wikimedia2.jpg, True: 1860, Predicted: 1830, Error: 30
Image: data/datasets/public/1820/1820_036met.jpg, True: 1820, Predicted: 1850, Error: 30
Image: data/datasets/public/1860/1860_29_001wikimedia2.jpg, True: 1860, Predicted: 1830, Error: 30
Image: data/datasets/public/1840/1841_046met.jpg, True: 1841, Predicted: 1864, Error: 23

===== Fold 9 =====
=== Running on Public Data ===

===== Fine Tuning 9 layers! =====
Epoch 1/300
657/657 - 89s - 136ms/step - accuracy: 0.1027 - loss: 4.6099 - val_accuracy: 0.2144 - val_loss: 4.5828 - learning_rate: 2.5974e-04
Epoch 2/300
657/657 - 64s - 97ms/step - accuracy: 0.1480 - loss: 4.3896 - val_accuracy: 0.2624 - val_loss: 4.1535 - learning_rate: 2.5974e-04
Epoch 3/300
657/657 - 65s - 99ms/step - accuracy: 0.1920 - loss: 4.2839 - val_accuracy: 0.2573 - val_loss: 3.9027 - learning_rate: 2.5974e-04
Epoch 4/300
657/657 - 65s - 99ms/step - accuracy: 0.2108 - loss: 4.2097 - val_accuracy: 0.2813 - val_loss: 3.7585 - learning_rate: 2.5974e-04
Epoch 5/300
657/657 - 65s - 98ms/step - accuracy: 0.2260 - loss: 4.1510 - val_accuracy: 0.2985 - val_loss: 3.6233 - learning_rate: 2.5974e-04
Epoch 6/300
657/657 - 66s - 100ms/step - accuracy: 0.2382 - loss: 4.0913 - val_accuracy: 0.3087 - val_loss: 3.5562 - learning_rate: 2.5974e-04
Epoch 7/300
657/657 - 65s - 98ms/step - accuracy: 0.2588 - loss: 4.0520 - val_accuracy: 0.3328 - val_loss: 3.5613 - learning_rate: 2.5974e-04
Epoch 8/300
657/657 - 66s - 100ms/step - accuracy: 0.2570 - loss: 4.0272 - val_accuracy: 0.3293 - val_loss: 3.5984 - learning_rate: 2.5974e-04
Epoch 9/300
657/657 - 64s - 98ms/step - accuracy: 0.2639 - loss: 3.9950 - val_accuracy: 0.3499 - val_loss: 3.4397 - learning_rate: 2.5974e-04
Epoch 10/300
657/657 - 64s - 97ms/step - accuracy: 0.2717 - loss: 3.9841 - val_accuracy: 0.3585 - val_loss: 3.4745 - learning_rate: 2.5974e-04
Epoch 11/300
657/657 - 67s - 102ms/step - accuracy: 0.2783 - loss: 3.9650 - val_accuracy: 0.3877 - val_loss: 3.3146 - learning_rate: 2.5974e-04
Epoch 12/300
657/657 - 65s - 98ms/step - accuracy: 0.2761 - loss: 3.9037 - val_accuracy: 0.3928 - val_loss: 3.3014 - learning_rate: 2.5974e-04
Epoch 13/300
657/657 - 66s - 101ms/step - accuracy: 0.2850 - loss: 3.8864 - val_accuracy: 0.3962 - val_loss: 3.3296 - learning_rate: 2.5974e-04
Epoch 14/300
657/657 - 83s - 127ms/step - accuracy: 0.2922 - loss: 3.8486 - val_accuracy: 0.4168 - val_loss: 3.2061 - learning_rate: 2.5974e-04
Epoch 15/300
657/657 - 65s - 98ms/step - accuracy: 0.2869 - loss: 3.8499 - val_accuracy: 0.3962 - val_loss: 3.2003 - learning_rate: 2.5974e-04
Epoch 16/300
657/657 - 64s - 97ms/step - accuracy: 0.2983 - loss: 3.7638 - val_accuracy: 0.3894 - val_loss: 3.1808 - learning_rate: 2.5974e-04
Epoch 17/300
657/657 - 67s - 101ms/step - accuracy: 0.3021 - loss: 3.7834 - val_accuracy: 0.4014 - val_loss: 3.1679 - learning_rate: 2.5974e-04
Epoch 18/300
657/657 - 65s - 100ms/step - accuracy: 0.3067 - loss: 3.7402 - val_accuracy: 0.3928 - val_loss: 3.1065 - learning_rate: 2.5974e-04
Epoch 19/300
657/657 - 65s - 99ms/step - accuracy: 0.2915 - loss: 3.7722 - val_accuracy: 0.3962 - val_loss: 2.9878 - learning_rate: 2.5974e-04
Epoch 20/300
657/657 - 64s - 97ms/step - accuracy: 0.3019 - loss: 3.7439 - val_accuracy: 0.4185 - val_loss: 3.0080 - learning_rate: 2.5974e-04
Epoch 21/300
657/657 - 66s - 101ms/step - accuracy: 0.2979 - loss: 3.7597 - val_accuracy: 0.4117 - val_loss: 3.0212 - learning_rate: 2.5974e-04
Epoch 22/300
657/657 - 62s - 95ms/step - accuracy: 0.3042 - loss: 3.6943 - val_accuracy: 0.4065 - val_loss: 2.9335 - learning_rate: 2.5974e-04
Epoch 23/300
657/657 - 63s - 96ms/step - accuracy: 0.3113 - loss: 3.6743 - val_accuracy: 0.4391 - val_loss: 2.9391 - learning_rate: 2.5974e-04
Epoch 24/300
657/657 - 65s - 99ms/step - accuracy: 0.3156 - loss: 3.6779 - val_accuracy: 0.4408 - val_loss: 2.9827 - learning_rate: 2.5974e-04
Epoch 25/300
657/657 - 63s - 96ms/step - accuracy: 0.3113 - loss: 3.6680 - val_accuracy: 0.4408 - val_loss: 3.0116 - learning_rate: 2.5974e-04
Epoch 26/300
657/657 - 62s - 95ms/step - accuracy: 0.3179 - loss: 3.6385 - val_accuracy: 0.4425 - val_loss: 2.9368 - learning_rate: 2.5974e-04
Epoch 27/300
657/657 - 65s - 98ms/step - accuracy: 0.3153 - loss: 3.6357 - val_accuracy: 0.4408 - val_loss: 2.8706 - learning_rate: 2.5974e-04
Epoch 28/300
657/657 - 63s - 96ms/step - accuracy: 0.3185 - loss: 3.6105 - val_accuracy: 0.4460 - val_loss: 2.9025 - learning_rate: 2.5974e-04
Epoch 29/300
657/657 - 63s - 96ms/step - accuracy: 0.3202 - loss: 3.6369 - val_accuracy: 0.4477 - val_loss: 2.8517 - learning_rate: 2.5974e-04
Epoch 30/300
657/657 - 64s - 97ms/step - accuracy: 0.3158 - loss: 3.5708 - val_accuracy: 0.4391 - val_loss: 2.8492 - learning_rate: 2.5974e-04
Epoch 31/300
657/657 - 64s - 98ms/step - accuracy: 0.3179 - loss: 3.5858 - val_accuracy: 0.4648 - val_loss: 2.8145 - learning_rate: 2.5974e-04
Epoch 32/300
657/657 - 62s - 94ms/step - accuracy: 0.3293 - loss: 3.5689 - val_accuracy: 0.4580 - val_loss: 2.7743 - learning_rate: 2.5974e-04
Epoch 33/300
657/657 - 61s - 93ms/step - accuracy: 0.3303 - loss: 3.5398 - val_accuracy: 0.4511 - val_loss: 2.8029 - learning_rate: 2.5974e-04
Epoch 34/300
657/657 - 64s - 97ms/step - accuracy: 0.3295 - loss: 3.5767 - val_accuracy: 0.4477 - val_loss: 2.7754 - learning_rate: 2.5974e-04
Epoch 35/300
657/657 - 62s - 95ms/step - accuracy: 0.3280 - loss: 3.5932 - val_accuracy: 0.4734 - val_loss: 2.8258 - learning_rate: 2.5974e-04
Epoch 36/300
657/657 - 62s - 95ms/step - accuracy: 0.3272 - loss: 3.5395 - val_accuracy: 0.4648 - val_loss: 2.7616 - learning_rate: 2.5974e-04
Epoch 37/300
657/657 - 63s - 96ms/step - accuracy: 0.3253 - loss: 3.5543 - val_accuracy: 0.4580 - val_loss: 2.7627 - learning_rate: 2.5974e-04
Epoch 38/300
657/657 - 63s - 96ms/step - accuracy: 0.3196 - loss: 3.5748 - val_accuracy: 0.4460 - val_loss: 2.7677 - learning_rate: 2.5974e-04
Epoch 39/300
657/657 - 64s - 98ms/step - accuracy: 0.3253 - loss: 3.5527 - val_accuracy: 0.4734 - val_loss: 2.7896 - learning_rate: 2.5974e-04
Epoch 40/300
657/657 - 62s - 94ms/step - accuracy: 0.3364 - loss: 3.4962 - val_accuracy: 0.4391 - val_loss: 2.7184 - learning_rate: 2.5974e-04
Epoch 41/300
657/657 - 65s - 99ms/step - accuracy: 0.3301 - loss: 3.5286 - val_accuracy: 0.4854 - val_loss: 2.7727 - learning_rate: 2.5974e-04
Epoch 42/300
657/657 - 63s - 96ms/step - accuracy: 0.3238 - loss: 3.5141 - val_accuracy: 0.4820 - val_loss: 2.7624 - learning_rate: 2.5974e-04
Epoch 43/300
657/657 - 61s - 93ms/step - accuracy: 0.3375 - loss: 3.5019 - val_accuracy: 0.4734 - val_loss: 2.6598 - learning_rate: 2.5974e-04
Epoch 44/300
657/657 - 64s - 98ms/step - accuracy: 0.3303 - loss: 3.4963 - val_accuracy: 0.4460 - val_loss: 2.6918 - learning_rate: 2.5974e-04
Epoch 45/300
657/657 - 62s - 95ms/step - accuracy: 0.3392 - loss: 3.4872 - val_accuracy: 0.4648 - val_loss: 2.6884 - learning_rate: 2.5974e-04
Epoch 46/300
657/657 - 63s - 95ms/step - accuracy: 0.3390 - loss: 3.4639 - val_accuracy: 0.4751 - val_loss: 2.6628 - learning_rate: 2.5974e-04
Epoch 47/300
657/657 - 62s - 94ms/step - accuracy: 0.3417 - loss: 3.5055 - val_accuracy: 0.4734 - val_loss: 2.7656 - learning_rate: 2.5974e-04
Epoch 48/300
657/657 - 65s - 98ms/step - accuracy: 0.3392 - loss: 3.4523 - val_accuracy: 0.4648 - val_loss: 2.6180 - learning_rate: 2.5974e-04
Epoch 49/300
657/657 - 64s - 97ms/step - accuracy: 0.3432 - loss: 3.4480 - val_accuracy: 0.4768 - val_loss: 2.6925 - learning_rate: 2.5974e-04
Epoch 50/300
657/657 - 63s - 96ms/step - accuracy: 0.3506 - loss: 3.4760 - val_accuracy: 0.4597 - val_loss: 2.5812 - learning_rate: 2.5974e-04
Epoch 51/300
657/657 - 64s - 98ms/step - accuracy: 0.3455 - loss: 3.4010 - val_accuracy: 0.4631 - val_loss: 2.6597 - learning_rate: 2.5974e-04
Epoch 52/300
657/657 - 62s - 95ms/step - accuracy: 0.3423 - loss: 3.4358 - val_accuracy: 0.4889 - val_loss: 2.7615 - learning_rate: 2.5974e-04
Epoch 53/300
657/657 - 69s - 105ms/step - accuracy: 0.3428 - loss: 3.4187 - val_accuracy: 0.4768 - val_loss: 2.6452 - learning_rate: 2.5974e-04
Epoch 54/300
657/657 - 68s - 104ms/step - accuracy: 0.3343 - loss: 3.4463 - val_accuracy: 0.4854 - val_loss: 2.6676 - learning_rate: 2.5974e-04
Epoch 55/300
657/657 - 69s - 104ms/step - accuracy: 0.3451 - loss: 3.4434 - val_accuracy: 0.4820 - val_loss: 2.6423 - learning_rate: 2.5974e-04
Epoch 56/300
657/657 - 68s - 104ms/step - accuracy: 0.3440 - loss: 3.4063 - val_accuracy: 0.4889 - val_loss: 2.6886 - learning_rate: 2.5974e-04
Epoch 57/300
657/657 - 69s - 105ms/step - accuracy: 0.3434 - loss: 3.4437 - val_accuracy: 0.4974 - val_loss: 2.6089 - learning_rate: 2.5974e-04
Epoch 58/300

Epoch 58: ReduceLROnPlateau reducing learning rate to 0.0001298690476687625.
657/657 - 68s - 103ms/step - accuracy: 0.3548 - loss: 3.3882 - val_accuracy: 0.4957 - val_loss: 2.5901 - learning_rate: 2.5974e-04
Epoch 59/300
657/657 - 68s - 103ms/step - accuracy: 0.3548 - loss: 3.3607 - val_accuracy: 0.4786 - val_loss: 2.5677 - learning_rate: 1.2987e-04
Epoch 60/300
657/657 - 67s - 102ms/step - accuracy: 0.3565 - loss: 3.3675 - val_accuracy: 0.4906 - val_loss: 2.6003 - learning_rate: 1.2987e-04
Epoch 61/300
657/657 - 68s - 104ms/step - accuracy: 0.3573 - loss: 3.3400 - val_accuracy: 0.4940 - val_loss: 2.5622 - learning_rate: 1.2987e-04
Epoch 62/300
657/657 - 68s - 104ms/step - accuracy: 0.3552 - loss: 3.3218 - val_accuracy: 0.4871 - val_loss: 2.5884 - learning_rate: 1.2987e-04
Epoch 63/300
657/657 - 69s - 105ms/step - accuracy: 0.3558 - loss: 3.3535 - val_accuracy: 0.4940 - val_loss: 2.5721 - learning_rate: 1.2987e-04
Epoch 64/300
657/657 - 69s - 106ms/step - accuracy: 0.3569 - loss: 3.3703 - val_accuracy: 0.4854 - val_loss: 2.5700 - learning_rate: 1.2987e-04
Epoch 65/300
657/657 - 67s - 103ms/step - accuracy: 0.3674 - loss: 3.3431 - val_accuracy: 0.4957 - val_loss: 2.5667 - learning_rate: 1.2987e-04
Epoch 66/300
657/657 - 69s - 104ms/step - accuracy: 0.3567 - loss: 3.3537 - val_accuracy: 0.4923 - val_loss: 2.5322 - learning_rate: 1.2987e-04
Epoch 67/300
657/657 - 68s - 103ms/step - accuracy: 0.3630 - loss: 3.3387 - val_accuracy: 0.4974 - val_loss: 2.5199 - learning_rate: 1.2987e-04
Epoch 68/300
657/657 - 68s - 103ms/step - accuracy: 0.3615 - loss: 3.3298 - val_accuracy: 0.5077 - val_loss: 2.4949 - learning_rate: 1.2987e-04
Epoch 69/300
657/657 - 66s - 101ms/step - accuracy: 0.3621 - loss: 3.3274 - val_accuracy: 0.4974 - val_loss: 2.5218 - learning_rate: 1.2987e-04
Epoch 70/300
657/657 - 64s - 98ms/step - accuracy: 0.3733 - loss: 3.2957 - val_accuracy: 0.4906 - val_loss: 2.5465 - learning_rate: 1.2987e-04
Epoch 71/300
657/657 - 61s - 94ms/step - accuracy: 0.3638 - loss: 3.3448 - val_accuracy: 0.4837 - val_loss: 2.5824 - learning_rate: 1.2987e-04
Epoch 72/300
657/657 - 62s - 94ms/step - accuracy: 0.3569 - loss: 3.3309 - val_accuracy: 0.4940 - val_loss: 2.5272 - learning_rate: 1.2987e-04
Epoch 73/300
657/657 - 63s - 95ms/step - accuracy: 0.3611 - loss: 3.3294 - val_accuracy: 0.4923 - val_loss: 2.5252 - learning_rate: 1.2987e-04
Epoch 74/300
657/657 - 64s - 98ms/step - accuracy: 0.3693 - loss: 3.3094 - val_accuracy: 0.4957 - val_loss: 2.5291 - learning_rate: 1.2987e-04
Epoch 75/300
657/657 - 64s - 97ms/step - accuracy: 0.3689 - loss: 3.2769 - val_accuracy: 0.4906 - val_loss: 2.4936 - learning_rate: 1.2987e-04
Epoch 76/300
657/657 - 64s - 98ms/step - accuracy: 0.3575 - loss: 3.3406 - val_accuracy: 0.5026 - val_loss: 2.5333 - learning_rate: 1.2987e-04
Epoch 77/300
657/657 - 64s - 98ms/step - accuracy: 0.3628 - loss: 3.3067 - val_accuracy: 0.4957 - val_loss: 2.5350 - learning_rate: 1.2987e-04
Epoch 78/300
657/657 - 62s - 95ms/step - accuracy: 0.3623 - loss: 3.3254 - val_accuracy: 0.5163 - val_loss: 2.5217 - learning_rate: 1.2987e-04
Epoch 79/300
657/657 - 63s - 96ms/step - accuracy: 0.3645 - loss: 3.3117 - val_accuracy: 0.5043 - val_loss: 2.5417 - learning_rate: 1.2987e-04
Epoch 80/300
657/657 - 64s - 97ms/step - accuracy: 0.3634 - loss: 3.3053 - val_accuracy: 0.5026 - val_loss: 2.5068 - learning_rate: 1.2987e-04
Epoch 81/300
657/657 - 64s - 97ms/step - accuracy: 0.3695 - loss: 3.2814 - val_accuracy: 0.5043 - val_loss: 2.5144 - learning_rate: 1.2987e-04
Epoch 82/300
657/657 - 62s - 94ms/step - accuracy: 0.3643 - loss: 3.2824 - val_accuracy: 0.4991 - val_loss: 2.4777 - learning_rate: 1.2987e-04
Epoch 83/300
657/657 - 64s - 98ms/step - accuracy: 0.3674 - loss: 3.2568 - val_accuracy: 0.5094 - val_loss: 2.5026 - learning_rate: 1.2987e-04
Epoch 84/300
657/657 - 63s - 96ms/step - accuracy: 0.3668 - loss: 3.2969 - val_accuracy: 0.5026 - val_loss: 2.5802 - learning_rate: 1.2987e-04
Epoch 85/300
657/657 - 63s - 96ms/step - accuracy: 0.3672 - loss: 3.2777 - val_accuracy: 0.4889 - val_loss: 2.5046 - learning_rate: 1.2987e-04
Epoch 86/300
657/657 - 62s - 94ms/step - accuracy: 0.3581 - loss: 3.2835 - val_accuracy: 0.4940 - val_loss: 2.4902 - learning_rate: 1.2987e-04
Epoch 87/300
657/657 - 62s - 94ms/step - accuracy: 0.3680 - loss: 3.2848 - val_accuracy: 0.5060 - val_loss: 2.5056 - learning_rate: 1.2987e-04
Epoch 88/300
657/657 - 64s - 98ms/step - accuracy: 0.3689 - loss: 3.2774 - val_accuracy: 0.5077 - val_loss: 2.5255 - learning_rate: 1.2987e-04
Epoch 89/300
657/657 - 62s - 95ms/step - accuracy: 0.3632 - loss: 3.2760 - val_accuracy: 0.5111 - val_loss: 2.5259 - learning_rate: 1.2987e-04
Epoch 90/300

Epoch 90: ReduceLROnPlateau reducing learning rate to 6.493452383438125e-05.
657/657 - 62s - 94ms/step - accuracy: 0.3621 - loss: 3.3076 - val_accuracy: 0.5026 - val_loss: 2.5061 - learning_rate: 1.2987e-04
Epoch 91/300
657/657 - 66s - 100ms/step - accuracy: 0.3796 - loss: 3.2143 - val_accuracy: 0.5197 - val_loss: 2.4535 - learning_rate: 6.4935e-05
Epoch 92/300
657/657 - 63s - 96ms/step - accuracy: 0.3788 - loss: 3.2072 - val_accuracy: 0.5111 - val_loss: 2.4771 - learning_rate: 6.4935e-05
Epoch 93/300
657/657 - 63s - 95ms/step - accuracy: 0.3760 - loss: 3.2686 - val_accuracy: 0.5043 - val_loss: 2.4616 - learning_rate: 6.4935e-05
Epoch 94/300
657/657 - 63s - 97ms/step - accuracy: 0.3765 - loss: 3.2207 - val_accuracy: 0.5094 - val_loss: 2.4589 - learning_rate: 6.4935e-05
Epoch 95/300
657/657 - 61s - 93ms/step - accuracy: 0.3750 - loss: 3.2532 - val_accuracy: 0.5060 - val_loss: 2.4727 - learning_rate: 6.4935e-05
Epoch 96/300
657/657 - 63s - 96ms/step - accuracy: 0.3740 - loss: 3.2737 - val_accuracy: 0.5009 - val_loss: 2.4364 - learning_rate: 6.4935e-05
Epoch 97/300
657/657 - 63s - 97ms/step - accuracy: 0.3666 - loss: 3.2650 - val_accuracy: 0.5249 - val_loss: 2.4800 - learning_rate: 6.4935e-05
Epoch 98/300
657/657 - 67s - 102ms/step - accuracy: 0.3725 - loss: 3.2142 - val_accuracy: 0.5009 - val_loss: 2.4674 - learning_rate: 6.4935e-05
Epoch 99/300
657/657 - 67s - 101ms/step - accuracy: 0.3786 - loss: 3.2368 - val_accuracy: 0.5060 - val_loss: 2.4806 - learning_rate: 6.4935e-05
Epoch 100/300
657/657 - 68s - 103ms/step - accuracy: 0.3782 - loss: 3.2180 - val_accuracy: 0.5129 - val_loss: 2.4840 - learning_rate: 6.4935e-05
Epoch 101/300
657/657 - 68s - 103ms/step - accuracy: 0.3750 - loss: 3.2339 - val_accuracy: 0.5197 - val_loss: 2.4701 - learning_rate: 6.4935e-05
Epoch 102/300
657/657 - 67s - 102ms/step - accuracy: 0.3727 - loss: 3.2417 - val_accuracy: 0.5060 - val_loss: 2.4463 - learning_rate: 6.4935e-05
Epoch 103/300
657/657 - 68s - 104ms/step - accuracy: 0.3771 - loss: 3.2172 - val_accuracy: 0.5129 - val_loss: 2.4482 - learning_rate: 6.4935e-05
Epoch 104/300

Epoch 104: ReduceLROnPlateau reducing learning rate to 3.2467261917190626e-05.
657/657 - 67s - 102ms/step - accuracy: 0.3767 - loss: 3.2151 - val_accuracy: 0.5094 - val_loss: 2.4422 - learning_rate: 6.4935e-05
Epoch 105/300
657/657 - 67s - 102ms/step - accuracy: 0.3796 - loss: 3.1633 - val_accuracy: 0.5180 - val_loss: 2.4541 - learning_rate: 3.2467e-05
Epoch 106/300
657/657 - 67s - 102ms/step - accuracy: 0.3773 - loss: 3.2272 - val_accuracy: 0.5180 - val_loss: 2.4478 - learning_rate: 3.2467e-05
Epoch 107/300
657/657 - 69s - 106ms/step - accuracy: 0.3798 - loss: 3.2102 - val_accuracy: 0.5111 - val_loss: 2.4460 - learning_rate: 3.2467e-05
Epoch 108/300
657/657 - 68s - 103ms/step - accuracy: 0.3813 - loss: 3.1957 - val_accuracy: 0.5077 - val_loss: 2.4298 - learning_rate: 3.2467e-05
Epoch 109/300
657/657 - 68s - 103ms/step - accuracy: 0.3761 - loss: 3.1970 - val_accuracy: 0.5129 - val_loss: 2.4441 - learning_rate: 3.2467e-05
Epoch 110/300
657/657 - 68s - 103ms/step - accuracy: 0.3777 - loss: 3.2029 - val_accuracy: 0.5197 - val_loss: 2.4321 - learning_rate: 3.2467e-05
Epoch 111/300
657/657 - 69s - 105ms/step - accuracy: 0.3872 - loss: 3.1681 - val_accuracy: 0.5094 - val_loss: 2.4265 - learning_rate: 3.2467e-05
Epoch 112/300
657/657 - 67s - 102ms/step - accuracy: 0.3794 - loss: 3.2066 - val_accuracy: 0.5180 - val_loss: 2.4268 - learning_rate: 3.2467e-05
Epoch 113/300
657/657 - 68s - 103ms/step - accuracy: 0.3742 - loss: 3.2080 - val_accuracy: 0.5146 - val_loss: 2.4418 - learning_rate: 3.2467e-05
Epoch 114/300
657/657 - 69s - 105ms/step - accuracy: 0.3716 - loss: 3.2366 - val_accuracy: 0.5129 - val_loss: 2.4368 - learning_rate: 3.2467e-05
Epoch 115/300
657/657 - 67s - 102ms/step - accuracy: 0.3792 - loss: 3.2017 - val_accuracy: 0.5077 - val_loss: 2.4139 - learning_rate: 3.2467e-05
Epoch 116/300
657/657 - 66s - 101ms/step - accuracy: 0.3739 - loss: 3.1998 - val_accuracy: 0.5249 - val_loss: 2.4233 - learning_rate: 3.2467e-05
Epoch 117/300
657/657 - 67s - 103ms/step - accuracy: 0.3742 - loss: 3.1998 - val_accuracy: 0.5129 - val_loss: 2.4084 - learning_rate: 3.2467e-05
Epoch 118/300
657/657 - 68s - 103ms/step - accuracy: 0.3820 - loss: 3.1823 - val_accuracy: 0.5163 - val_loss: 2.4544 - learning_rate: 3.2467e-05
Epoch 119/300
657/657 - 68s - 103ms/step - accuracy: 0.3826 - loss: 3.1951 - val_accuracy: 0.5111 - val_loss: 2.4194 - learning_rate: 3.2467e-05
Epoch 120/300
657/657 - 67s - 103ms/step - accuracy: 0.3807 - loss: 3.1904 - val_accuracy: 0.5146 - val_loss: 2.4217 - learning_rate: 3.2467e-05
Epoch 121/300
657/657 - 67s - 102ms/step - accuracy: 0.3754 - loss: 3.1967 - val_accuracy: 0.5232 - val_loss: 2.4422 - learning_rate: 3.2467e-05
Epoch 122/300
657/657 - 69s - 105ms/step - accuracy: 0.3803 - loss: 3.2146 - val_accuracy: 0.5077 - val_loss: 2.4075 - learning_rate: 3.2467e-05
Epoch 123/300
657/657 - 68s - 103ms/step - accuracy: 0.3725 - loss: 3.2221 - val_accuracy: 0.5197 - val_loss: 2.4440 - learning_rate: 3.2467e-05
Epoch 124/300
657/657 - 69s - 105ms/step - accuracy: 0.3794 - loss: 3.1992 - val_accuracy: 0.5249 - val_loss: 2.4362 - learning_rate: 3.2467e-05
Epoch 125/300
657/657 - 67s - 103ms/step - accuracy: 0.3725 - loss: 3.2305 - val_accuracy: 0.5180 - val_loss: 2.4299 - learning_rate: 3.2467e-05
Epoch 126/300
657/657 - 66s - 101ms/step - accuracy: 0.3796 - loss: 3.1967 - val_accuracy: 0.5180 - val_loss: 2.4232 - learning_rate: 3.2467e-05
Epoch 127/300
657/657 - 67s - 102ms/step - accuracy: 0.3771 - loss: 3.1645 - val_accuracy: 0.5249 - val_loss: 2.4156 - learning_rate: 3.2467e-05
Epoch 128/300
657/657 - 69s - 105ms/step - accuracy: 0.3799 - loss: 3.1788 - val_accuracy: 0.5163 - val_loss: 2.4253 - learning_rate: 3.2467e-05
Epoch 129/300
657/657 - 68s - 103ms/step - accuracy: 0.3767 - loss: 3.2054 - val_accuracy: 0.5283 - val_loss: 2.4461 - learning_rate: 3.2467e-05
Epoch 130/300

Epoch 130: ReduceLROnPlateau reducing learning rate to 1.6233630958595313e-05.
657/657 - 64s - 98ms/step - accuracy: 0.3798 - loss: 3.1942 - val_accuracy: 0.5146 - val_loss: 2.4143 - learning_rate: 3.2467e-05
Epoch 131/300
657/657 - 64s - 98ms/step - accuracy: 0.3874 - loss: 3.1558 - val_accuracy: 0.5163 - val_loss: 2.4191 - learning_rate: 1.6234e-05
Epoch 132/300
657/657 - 63s - 95ms/step - accuracy: 0.3881 - loss: 3.1845 - val_accuracy: 0.5266 - val_loss: 2.4394 - learning_rate: 1.6234e-05
Epoch 133/300
657/657 - 61s - 93ms/step - accuracy: 0.3780 - loss: 3.1626 - val_accuracy: 0.5180 - val_loss: 2.4112 - learning_rate: 1.6234e-05
Epoch 134/300
657/657 - 63s - 96ms/step - accuracy: 0.3836 - loss: 3.1547 - val_accuracy: 0.5266 - val_loss: 2.4185 - learning_rate: 1.6234e-05
Epoch 135/300
657/657 - 62s - 95ms/step - accuracy: 0.3896 - loss: 3.1378 - val_accuracy: 0.5197 - val_loss: 2.4044 - learning_rate: 1.6234e-05
Epoch 136/300
657/657 - 62s - 94ms/step - accuracy: 0.3788 - loss: 3.2240 - val_accuracy: 0.5146 - val_loss: 2.4153 - learning_rate: 1.6234e-05
Epoch 137/300
657/657 - 63s - 96ms/step - accuracy: 0.3824 - loss: 3.1950 - val_accuracy: 0.5266 - val_loss: 2.4082 - learning_rate: 1.6234e-05
Epoch 138/300
657/657 - 62s - 95ms/step - accuracy: 0.3786 - loss: 3.1799 - val_accuracy: 0.5197 - val_loss: 2.4071 - learning_rate: 1.6234e-05
Epoch 139/300
657/657 - 62s - 95ms/step - accuracy: 0.3752 - loss: 3.1929 - val_accuracy: 0.5232 - val_loss: 2.4017 - learning_rate: 1.6234e-05
Epoch 140/300
657/657 - 64s - 97ms/step - accuracy: 0.3826 - loss: 3.1742 - val_accuracy: 0.5300 - val_loss: 2.3981 - learning_rate: 1.6234e-05
Epoch 141/300
657/657 - 66s - 100ms/step - accuracy: 0.3754 - loss: 3.2473 - val_accuracy: 0.5214 - val_loss: 2.4077 - learning_rate: 1.6234e-05
Epoch 142/300
657/657 - 67s - 102ms/step - accuracy: 0.3801 - loss: 3.1843 - val_accuracy: 0.5163 - val_loss: 2.4253 - learning_rate: 1.6234e-05
Epoch 143/300
657/657 - 68s - 104ms/step - accuracy: 0.3822 - loss: 3.1834 - val_accuracy: 0.5249 - val_loss: 2.4122 - learning_rate: 1.6234e-05
Epoch 144/300
657/657 - 65s - 99ms/step - accuracy: 0.3794 - loss: 3.2010 - val_accuracy: 0.5180 - val_loss: 2.4241 - learning_rate: 1.6234e-05
Epoch 145/300
657/657 - 65s - 99ms/step - accuracy: 0.3824 - loss: 3.1686 - val_accuracy: 0.5111 - val_loss: 2.4239 - learning_rate: 1.6234e-05
Epoch 146/300
657/657 - 67s - 102ms/step - accuracy: 0.3790 - loss: 3.1780 - val_accuracy: 0.5180 - val_loss: 2.4016 - learning_rate: 1.6234e-05
Epoch 147/300
657/657 - 68s - 104ms/step - accuracy: 0.3763 - loss: 3.1865 - val_accuracy: 0.5214 - val_loss: 2.4069 - learning_rate: 1.6234e-05
Epoch 148/300

Epoch 148: ReduceLROnPlateau reducing learning rate to 8.116815479297657e-06.
657/657 - 68s - 103ms/step - accuracy: 0.3836 - loss: 3.1855 - val_accuracy: 0.5249 - val_loss: 2.4352 - learning_rate: 1.6234e-05
Epoch 149/300
657/657 - 66s - 101ms/step - accuracy: 0.3834 - loss: 3.1622 - val_accuracy: 0.5283 - val_loss: 2.4135 - learning_rate: 8.1168e-06
Epoch 150/300
657/657 - 69s - 105ms/step - accuracy: 0.3927 - loss: 3.1422 - val_accuracy: 0.5232 - val_loss: 2.3913 - learning_rate: 8.1168e-06
Epoch 151/300
657/657 - 67s - 103ms/step - accuracy: 0.3857 - loss: 3.1752 - val_accuracy: 0.5266 - val_loss: 2.3995 - learning_rate: 8.1168e-06
Epoch 152/300
657/657 - 69s - 105ms/step - accuracy: 0.3868 - loss: 3.1755 - val_accuracy: 0.5197 - val_loss: 2.3962 - learning_rate: 8.1168e-06
Epoch 153/300
657/657 - 68s - 103ms/step - accuracy: 0.3820 - loss: 3.1728 - val_accuracy: 0.5197 - val_loss: 2.4102 - learning_rate: 8.1168e-06
Epoch 154/300
657/657 - 68s - 104ms/step - accuracy: 0.3845 - loss: 3.1724 - val_accuracy: 0.5197 - val_loss: 2.4043 - learning_rate: 8.1168e-06
Epoch 155/300
657/657 - 67s - 101ms/step - accuracy: 0.3788 - loss: 3.1913 - val_accuracy: 0.5180 - val_loss: 2.4072 - learning_rate: 8.1168e-06
Epoch 156/300
657/657 - 68s - 103ms/step - accuracy: 0.3801 - loss: 3.1991 - val_accuracy: 0.5197 - val_loss: 2.4021 - learning_rate: 8.1168e-06
Epoch 157/300
657/657 - 68s - 103ms/step - accuracy: 0.3839 - loss: 3.1630 - val_accuracy: 0.5180 - val_loss: 2.4057 - learning_rate: 8.1168e-06
Epoch 158/300

Epoch 158: ReduceLROnPlateau reducing learning rate to 4.058407739648828e-06.
657/657 - 66s - 101ms/step - accuracy: 0.3815 - loss: 3.1768 - val_accuracy: 0.5180 - val_loss: 2.4110 - learning_rate: 8.1168e-06
Epoch 159/300
657/657 - 68s - 103ms/step - accuracy: 0.3820 - loss: 3.1705 - val_accuracy: 0.5163 - val_loss: 2.4007 - learning_rate: 4.0584e-06
Epoch 160/300
657/657 - 66s - 101ms/step - accuracy: 0.3851 - loss: 3.1542 - val_accuracy: 0.5197 - val_loss: 2.3945 - learning_rate: 4.0584e-06
Epoch 161/300
657/657 - 69s - 105ms/step - accuracy: 0.3872 - loss: 3.1461 - val_accuracy: 0.5197 - val_loss: 2.3761 - learning_rate: 4.0584e-06
Epoch 162/300
657/657 - 68s - 103ms/step - accuracy: 0.3841 - loss: 3.1785 - val_accuracy: 0.5197 - val_loss: 2.4077 - learning_rate: 4.0584e-06
Epoch 163/300
657/657 - 68s - 103ms/step - accuracy: 0.3927 - loss: 3.1461 - val_accuracy: 0.5163 - val_loss: 2.4069 - learning_rate: 4.0584e-06
Epoch 164/300
657/657 - 68s - 103ms/step - accuracy: 0.3807 - loss: 3.1752 - val_accuracy: 0.5214 - val_loss: 2.3967 - learning_rate: 4.0584e-06
Epoch 165/300
657/657 - 68s - 103ms/step - accuracy: 0.3801 - loss: 3.1885 - val_accuracy: 0.5249 - val_loss: 2.3997 - learning_rate: 4.0584e-06
Epoch 166/300
657/657 - 68s - 104ms/step - accuracy: 0.3780 - loss: 3.1854 - val_accuracy: 0.5232 - val_loss: 2.4044 - learning_rate: 4.0584e-06
Epoch 167/300
657/657 - 67s - 101ms/step - accuracy: 0.3843 - loss: 3.1664 - val_accuracy: 0.5214 - val_loss: 2.4192 - learning_rate: 4.0584e-06
Epoch 168/300
657/657 - 69s - 105ms/step - accuracy: 0.3839 - loss: 3.1737 - val_accuracy: 0.5232 - val_loss: 2.4028 - learning_rate: 4.0584e-06
Epoch 169/300

Epoch 169: ReduceLROnPlateau reducing learning rate to 2.029203869824414e-06.
657/657 - 68s - 103ms/step - accuracy: 0.3822 - loss: 3.1904 - val_accuracy: 0.5232 - val_loss: 2.4112 - learning_rate: 4.0584e-06
Epoch 170/300
657/657 - 67s - 102ms/step - accuracy: 0.3801 - loss: 3.1982 - val_accuracy: 0.5249 - val_loss: 2.4054 - learning_rate: 2.0292e-06
Epoch 171/300
657/657 - 68s - 104ms/step - accuracy: 0.3735 - loss: 3.1678 - val_accuracy: 0.5266 - val_loss: 2.4015 - learning_rate: 2.0292e-06
Epoch 172/300
657/657 - 68s - 103ms/step - accuracy: 0.3773 - loss: 3.1579 - val_accuracy: 0.5232 - val_loss: 2.4027 - learning_rate: 2.0292e-06
Epoch 173/300
657/657 - 66s - 100ms/step - accuracy: 0.3801 - loss: 3.1861 - val_accuracy: 0.5232 - val_loss: 2.4140 - learning_rate: 2.0292e-06
Epoch 174/300
657/657 - 68s - 103ms/step - accuracy: 0.3805 - loss: 3.1552 - val_accuracy: 0.5232 - val_loss: 2.4100 - learning_rate: 2.0292e-06
Epoch 175/300
657/657 - 67s - 102ms/step - accuracy: 0.3843 - loss: 3.1534 - val_accuracy: 0.5249 - val_loss: 2.4000 - learning_rate: 2.0292e-06
Epoch 176/300
657/657 - 68s - 103ms/step - accuracy: 0.3817 - loss: 3.1642 - val_accuracy: 0.5180 - val_loss: 2.4058 - learning_rate: 2.0292e-06
Epoch 177/300

Epoch 177: ReduceLROnPlateau reducing learning rate to 1.014601934912207e-06.
657/657 - 68s - 103ms/step - accuracy: 0.3761 - loss: 3.2107 - val_accuracy: 0.5180 - val_loss: 2.3947 - learning_rate: 2.0292e-06
Epoch 177: early stopping
Restoring model weights from the end of the best epoch: 161.
Fold 9 Evaluation results: [2.391031503677368, 0.5197255611419678]
              precision    recall  f1-score   support

        1820       0.66      0.91      0.76        43
        1821       0.00      0.00      0.00         1
        1822       0.00      0.00      0.00         1
        1823       0.00      0.00      0.00         1
        1824       0.00      0.00      0.00         0
        1825       0.00      0.00      0.00         1
        1826       0.00      0.00      0.00         1
        1827       0.00      0.00      0.00         8
        1828       0.00      0.00      0.00         2
        1829       1.00      0.80      0.89         5
        1830       0.60      0.67      0.63        45
        1831       0.00      0.00      0.00         1
        1832       0.87      0.87      0.87        52
        1833       0.69      0.95      0.80        19
        1834       0.50      0.57      0.53         7
        1835       0.00      0.00      0.00         2
        1836       0.00      0.00      0.00         3
        1837       0.25      0.67      0.36         6
        1838       0.00      0.00      0.00         4
        1839       0.00      0.00      0.00         1
        1840       0.58      0.67      0.62        42
        1841       0.50      0.18      0.27        11
        1842       0.67      0.33      0.44         6
        1843       1.00      0.17      0.29         6
        1844       0.00      0.00      0.00         0
        1845       0.00      0.00      0.00         1
        1846       0.67      0.40      0.50         5
        1847       0.00      0.00      0.00         2
        1848       0.00      0.00      0.00         5
        1849       0.14      0.20      0.17         5
        1850       0.33      0.58      0.42        48
        1851       0.00      0.00      0.00         6
        1852       0.50      0.14      0.22         7
        1853       0.00      0.00      0.00         7
        1854       0.00      0.00      0.00         2
        1855       0.20      0.10      0.13        10
        1856       1.00      0.75      0.86        12
        1857       0.00      0.00      0.00         7
        1858       0.00      0.00      0.00         2
        1859       0.00      0.00      0.00         3
        1860       0.31      0.46      0.37        48
        1861       0.00      0.00      0.00         1
        1862       0.00      0.00      0.00         7
        1863       0.33      0.50      0.40         6
        1864       0.33      0.20      0.25         5
        1865       1.00      0.33      0.50         6
        1866       0.50      0.17      0.25         6
        1867       0.36      0.40      0.38        10
        1868       0.00      0.00      0.00         8
        1869       0.00      0.00      0.00         5
        1870       0.43      0.65      0.52        31
        1871       1.00      0.20      0.33         5
        1872       0.42      0.71      0.53         7
        1873       0.67      0.18      0.29        11
        1874       0.00      0.00      0.00         5
        1875       0.43      0.50      0.46         6
        1876       0.83      1.00      0.91        10
        1877       0.56      1.00      0.71         5
        1878       0.71      0.56      0.62         9
        1879       0.00      0.00      0.00         2

    accuracy                           0.52       583
   macro avg       0.30      0.26      0.25       583
weighted avg       0.48      0.52      0.48       583

Matthews Correlation Coefficient: 0.492
Macro avg F1: 0.255
Weighted avg F1: 0.475
Micro avg F1: 0.520
Top-3 Accuracy: 0.772
Top-5 Accuracy: 0.856
Micro ROC AUC  = 0.97
Macro ROC AUC (present classes) = 0.97
Classification MAE (in years): 3.44

Fold 9 Misclassification Analysis:
Near misses (within 2 years): 84 out of 280 misclassifications (30.00%)
Big misses (greater than 10 years): 85
MAE with outliers: 3.44
MAE without outliers: 2.43 (improvement: 1.01)

10 Worst misclassifications:
Image: data/datasets/public/1820/1820_12wikimedia2.jpg, True: 1820, Predicted: 1876, Error: 56
Image: data/datasets/public/1870/1878_1258vna.jpg, True: 1878, Predicted: 1832, Error: 46
Image: data/datasets/public/1830/1830_84wikimedia2.jpg, True: 1830, Predicted: 1870, Error: 40
Image: data/datasets/public/1870/1870_27wikimedia2.jpg, True: 1870, Predicted: 1832, Error: 38
Image: data/datasets/public/1860/1867_1390vna.jpg, True: 1867, Predicted: 1832, Error: 35
Image: data/datasets/public/1860/1860_830vna.jpg, True: 1860, Predicted: 1830, Error: 30
Image: data/datasets/public/1850/1850_84vna.jpg, True: 1850, Predicted: 1820, Error: 30
Image: data/datasets/public/1870/1870_16_001wikimedia2.jpg, True: 1870, Predicted: 1840, Error: 30
Image: data/datasets/public/1830/1830_98wikimedia2.jpg, True: 1830, Predicted: 1860, Error: 30
Image: data/datasets/public/1870/1870_045met.jpg, True: 1870, Predicted: 1840, Error: 30

Mean MAE over all folds: 3.5345 ± 0.2270
Mean accuracy over all folds: 0.5225 ± 0.0182
Mean Matthews Correlation Coefficient: 0.4958 ± 0.0195

=== Total running time: 31 hours, 32 minutes, 14 seconds ===

