Using model: NASNetMobile.
TensorFlow Version: 2.19.0
Num GPUs Available: 1
Using GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')
Test fold: 0
Epoch 1/100
707/707 - 200s - 284ms/step - accuracy: 0.2825 - loss: 2.5606 - val_accuracy: 0.2811 - val_loss: 2.5948 - learning_rate: 0.0100
Epoch 2/100
707/707 - 127s - 180ms/step - accuracy: 0.3511 - loss: 2.2137 - val_accuracy: 0.2803 - val_loss: 2.5538 - learning_rate: 0.0100
Epoch 3/100
707/707 - 120s - 170ms/step - accuracy: 0.3688 - loss: 2.1491 - val_accuracy: 0.3041 - val_loss: 2.5097 - learning_rate: 0.0100
Epoch 4/100
707/707 - 118s - 167ms/step - accuracy: 0.3825 - loss: 2.1079 - val_accuracy: 0.3368 - val_loss: 2.4464 - learning_rate: 0.0100
Epoch 5/100
707/707 - 118s - 167ms/step - accuracy: 0.3903 - loss: 2.0743 - val_accuracy: 0.3185 - val_loss: 2.3720 - learning_rate: 0.0100
Epoch 6/100
707/707 - 149s - 210ms/step - accuracy: 0.3932 - loss: 2.0543 - val_accuracy: 0.3312 - val_loss: 2.5019 - learning_rate: 0.0100
Epoch 7/100
707/707 - 125s - 177ms/step - accuracy: 0.3891 - loss: 2.0852 - val_accuracy: 0.3432 - val_loss: 2.3899 - learning_rate: 0.0100
Epoch 8/100
707/707 - 125s - 177ms/step - accuracy: 0.4046 - loss: 2.0351 - val_accuracy: 0.3352 - val_loss: 2.3504 - learning_rate: 0.0100
Epoch 9/100
707/707 - 122s - 172ms/step - accuracy: 0.4034 - loss: 2.0400 - val_accuracy: 0.3129 - val_loss: 2.4553 - learning_rate: 0.0100
Epoch 10/100
707/707 - 119s - 168ms/step - accuracy: 0.4018 - loss: 2.0201 - val_accuracy: 0.3153 - val_loss: 2.5638 - learning_rate: 0.0100
Epoch 11/100

Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.
707/707 - 123s - 174ms/step - accuracy: 0.3979 - loss: 2.0256 - val_accuracy: 0.2747 - val_loss: 2.6573 - learning_rate: 0.0100
Epoch 12/100
707/707 - 117s - 165ms/step - accuracy: 0.4589 - loss: 1.8224 - val_accuracy: 0.3670 - val_loss: 2.2566 - learning_rate: 1.0000e-03
Epoch 13/100
707/707 - 120s - 169ms/step - accuracy: 0.4632 - loss: 1.7897 - val_accuracy: 0.3567 - val_loss: 2.2731 - learning_rate: 1.0000e-03
Epoch 14/100
707/707 - 116s - 165ms/step - accuracy: 0.4747 - loss: 1.7573 - val_accuracy: 0.3702 - val_loss: 2.2975 - learning_rate: 1.0000e-03
Epoch 15/100

Epoch 15: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.
707/707 - 116s - 165ms/step - accuracy: 0.4743 - loss: 1.7465 - val_accuracy: 0.3678 - val_loss: 2.2595 - learning_rate: 1.0000e-03
Epoch 16/100
707/707 - 117s - 165ms/step - accuracy: 0.4799 - loss: 1.7374 - val_accuracy: 0.3830 - val_loss: 2.2457 - learning_rate: 1.0000e-04
Epoch 17/100
707/707 - 119s - 168ms/step - accuracy: 0.4659 - loss: 1.7563 - val_accuracy: 0.3830 - val_loss: 2.2179 - learning_rate: 1.0000e-04
Epoch 18/100
707/707 - 121s - 171ms/step - accuracy: 0.4798 - loss: 1.7208 - val_accuracy: 0.3790 - val_loss: 2.2177 - learning_rate: 1.0000e-04
Epoch 19/100
707/707 - 123s - 174ms/step - accuracy: 0.4766 - loss: 1.7201 - val_accuracy: 0.3814 - val_loss: 2.2099 - learning_rate: 1.0000e-04
Epoch 20/100
707/707 - 119s - 168ms/step - accuracy: 0.4715 - loss: 1.7351 - val_accuracy: 0.3806 - val_loss: 2.2205 - learning_rate: 1.0000e-04
Epoch 21/100
707/707 - 117s - 166ms/step - accuracy: 0.4750 - loss: 1.7392 - val_accuracy: 0.3822 - val_loss: 2.2158 - learning_rate: 1.0000e-04
Epoch 22/100

Epoch 22: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.
707/707 - 116s - 165ms/step - accuracy: 0.4799 - loss: 1.7299 - val_accuracy: 0.3814 - val_loss: 2.2243 - learning_rate: 1.0000e-04
Epoch 23/100
707/707 - 115s - 163ms/step - accuracy: 0.4773 - loss: 1.7245 - val_accuracy: 0.3814 - val_loss: 2.2151 - learning_rate: 1.0000e-05
Epoch 23: early stopping
Restoring model weights from the end of the best epoch: 19.
Fold 0 Evaluation results: [2.2098941802978516, 0.381369411945343]
              precision    recall  f1-score   support

        1820       0.52      0.66      0.58        62
        1821       0.71      0.68      0.70        57
        1822       0.00      0.00      0.00         1
        1823       0.00      0.00      0.00         1
        1824       0.00      0.00      0.00         1
        1825       0.00      0.00      0.00         3
        1826       0.00      0.00      0.00         2
        1827       0.33      0.08      0.13        25
        1828       0.00      0.00      0.00         1
        1829       0.00      0.00      0.00         5
        1830       0.23      0.54      0.32        56
        1831       0.80      0.79      0.80       134
        1832       0.37      0.61      0.46        67
        1833       0.57      0.21      0.31        19
        1834       0.00      0.00      0.00        29
        1835       0.00      0.00      0.00         2
        1836       0.00      0.00      0.00         4
        1837       0.00      0.00      0.00         6
        1838       0.00      0.00      0.00         3
        1839       0.00      0.00      0.00         1
        1840       0.19      0.47      0.26        43
        1841       0.53      0.47      0.50       108
        1842       0.00      0.00      0.00         6
        1843       0.00      0.00      0.00         6
        1844       0.00      0.00      0.00         1
        1845       0.00      0.00      0.00         1
        1846       0.00      0.00      0.00         6
        1847       0.00      0.00      0.00         2
        1848       0.00      0.00      0.00         5
        1849       0.00      0.00      0.00         6
        1850       0.18      0.44      0.25        48
        1851       0.61      0.48      0.54        77
        1852       0.00      0.00      0.00         7
        1853       0.00      0.00      0.00         7
        1854       0.00      0.00      0.00         3
        1855       0.25      0.04      0.07        23
        1856       0.40      0.33      0.36        12
        1857       0.27      0.20      0.23        30
        1858       0.00      0.00      0.00         2
        1859       0.00      0.00      0.00         2
        1860       0.15      0.31      0.20        65
        1861       0.60      0.25      0.35        85
        1862       0.00      0.00      0.00        19
        1863       0.22      0.11      0.14        19
        1864       0.00      0.00      0.00        17
        1865       0.00      0.00      0.00         7
        1866       0.00      0.00      0.00         5
        1867       0.00      0.00      0.00        11
        1868       0.00      0.00      0.00         7
        1869       0.00      0.00      0.00         5
        1870       0.14      0.29      0.19        31
        1871       0.47      0.41      0.43        49
        1872       0.00      0.00      0.00         7
        1873       0.00      0.00      0.00        10
        1874       0.00      0.00      0.00         5
        1875       0.31      0.29      0.30        14
        1876       0.00      0.00      0.00        10
        1877       0.00      0.00      0.00         5
        1878       0.00      0.00      0.00         9
        1879       0.00      0.00      0.00         2

    accuracy                           0.38      1256
   macro avg       0.13      0.13      0.12      1256
weighted avg       0.38      0.38      0.36      1256

Macro avg F1: 0.119
Weighted avg F1: 0.357
Micro avg F1: 0.381
Top-3 Accuracy: 0.650
Top-5 Accuracy: 0.738
Classification MAE (in years): 7.04
Micro ROC AUC  = 0.94
Macro ROC AUC (present classes) = 0.89
Metrics: {'accuracy': 0.381369411945343}
Total running time: 0 hours, 48 minutes, 51 seconds
