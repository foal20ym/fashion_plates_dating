TensorFlow Version: 2.19.0
Num GPUs Available: 1
Using GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')
Using model: InceptionV3.
RUN ID: 2025-05-07_09:53:04

=== Fold 0 ===
Fine Tuning!
707/707 - 194s - 274ms/step - accuracy: 0.3845 - loss: 6.7343 - val_accuracy: 0.3264 - val_loss: 9.4926 - learning_rate: 0.0100
Restoring model weights from the end of the best epoch: 1.
Fold 0 Evaluation results: [9.479138374328613, 0.32643312215805054]
              precision    recall  f1-score   support

        1820       0.52      0.63      0.57        62
        1821       0.89      0.14      0.24        57
        1822       0.00      0.00      0.00         1
        1823       0.00      0.00      0.00         1
        1824       0.00      0.00      0.00         1
        1825       0.00      0.00      0.00         3
        1826       0.00      0.00      0.00         2
        1827       0.79      0.44      0.56        25
        1828       0.00      0.00      0.00         1
        1829       0.00      0.00      0.00         5
        1830       0.00      0.00      0.00        56
        1831       0.84      0.62      0.71       134
        1832       0.34      0.85      0.49        67
        1833       0.89      0.42      0.57        19
        1834       0.00      0.00      0.00        29
        1835       0.00      0.00      0.00         2
        1836       0.00      0.00      0.00         4
        1837       0.00      0.00      0.00         6
        1838       0.00      0.00      0.00         3
        1839       0.00      0.00      0.00         1
        1840       0.13      0.60      0.22        43
        1841       0.53      0.23      0.32       108
        1842       0.00      0.00      0.00         6
        1843       0.00      0.00      0.00         6
        1844       0.00      0.00      0.00         1
        1845       0.00      0.00      0.00         1
        1846       0.00      0.00      0.00         6
        1847       0.00      0.00      0.00         2
        1848       0.00      0.00      0.00         5
        1849       0.00      0.00      0.00         6
        1850       0.21      0.52      0.30        48
        1851       0.82      0.18      0.30        77
        1852       0.00      0.00      0.00         7
        1853       0.00      0.00      0.00         7
        1854       0.00      0.00      0.00         3
        1855       0.00      0.00      0.00        23
        1856       0.00      0.00      0.00        12
        1857       0.39      0.23      0.29        30
        1858       0.00      0.00      0.00         2
        1859       0.00      0.00      0.00         2
        1860       0.00      0.00      0.00        65
        1861       0.46      0.76      0.57        85
        1862       0.00      0.00      0.00        19
        1863       0.00      0.00      0.00        19
        1864       0.33      0.06      0.10        17
        1865       0.00      0.00      0.00         7
        1866       0.02      0.80      0.04         5
        1867       0.00      0.00      0.00        11
        1868       0.00      0.00      0.00         7
        1869       0.00      0.00      0.00         5
        1870       0.40      0.06      0.11        31
        1871       0.65      0.53      0.58        49
        1872       0.00      0.00      0.00         7
        1873       0.00      0.00      0.00        10
        1874       0.00      0.00      0.00         5
        1875       0.00      0.00      0.00        14
        1876       0.00      0.00      0.00        10
        1877       0.00      0.00      0.00         5
        1878       0.09      1.00      0.16         9
        1879       0.00      0.00      0.00         2

    accuracy                           0.33      1256
   macro avg       0.14      0.13      0.10      1256
weighted avg       0.39      0.33      0.30      1256

Macro avg F1: 0.102
Weighted avg F1: 0.300
Micro avg F1: 0.326
Top-3 Accuracy: 0.514
Top-5 Accuracy: 0.610
Micro ROC AUC  = 0.88
Macro ROC AUC (present classes) = 0.84
Classification MAE (in years): 8.31

=== Fold 1 ===
Fine Tuning!
707/707 - 163s - 231ms/step - accuracy: 0.3839 - loss: 6.9049 - val_accuracy: 0.3217 - val_loss: 7.6273 - learning_rate: 0.0100
Restoring model weights from the end of the best epoch: 1.
Fold 1 Evaluation results: [7.606135845184326, 0.3216560482978821]
              precision    recall  f1-score   support

        1820       0.52      0.24      0.33        62
        1821       0.96      0.47      0.64        57
        1822       0.00      0.00      0.00         1
        1823       0.00      0.00      0.00         1
        1824       0.00      0.00      0.00         1
        1825       0.00      0.00      0.00         2
        1826       0.00      0.00      0.00         2
        1827       0.62      0.20      0.30        25
        1828       0.00      0.00      0.00         1
        1829       0.00      0.00      0.00         5
        1830       0.68      0.23      0.35        56
        1831       0.64      0.61      0.62       134
        1832       0.65      0.75      0.69        68
        1833       1.00      0.63      0.77        19
        1834       0.00      0.00      0.00        29
        1835       0.00      0.00      0.00         3
        1836       0.00      0.00      0.00         4
        1837       0.00      0.00      0.00         7
        1838       0.00      0.00      0.00         3
        1839       0.00      0.00      0.00         0
        1840       0.24      0.44      0.31        43
        1841       0.43      0.48      0.45       108
        1842       0.00      0.00      0.00         5
        1843       0.00      0.00      0.00         6
        1844       0.00      0.00      0.00         1
        1845       0.00      0.00      0.00         2
        1846       0.00      0.00      0.00         6
        1847       0.00      0.00      0.00         2
        1848       0.00      0.00      0.00         6
        1849       0.00      0.00      0.00         6
        1850       0.00      0.00      0.00        48
        1851       0.69      0.31      0.43        77
        1852       0.00      0.00      0.00         7
        1853       0.00      0.00      0.00         6
        1854       0.00      0.00      0.00         3
        1855       0.00      0.00      0.00        24
        1856       0.36      0.42      0.38        12
        1857       0.00      0.00      0.00        30
        1858       0.00      0.00      0.00         2
        1859       0.07      0.50      0.12         2
        1860       0.00      0.00      0.00        64
        1861       0.39      0.80      0.53        85
        1862       0.00      0.00      0.00        18
        1863       0.33      0.11      0.16        19
        1864       0.00      0.00      0.00        17
        1865       0.00      0.00      0.00         6
        1866       0.03      0.20      0.05         5
        1867       0.00      0.00      0.00        11
        1868       0.00      0.00      0.00         7
        1869       0.00      0.00      0.00         5
        1870       0.33      0.13      0.19        31
        1871       0.81      0.27      0.40        49
        1872       0.00      0.00      0.00         8
        1873       0.00      0.00      0.00        10
        1874       0.00      0.00      0.00         5
        1875       0.20      0.71      0.31        14
        1876       0.00      0.00      0.00        10
        1877       0.00      0.00      0.00         5
        1878       0.00      0.00      0.00         9
        1879       0.00      0.00      0.00         2

    accuracy                           0.32      1256
   macro avg       0.15      0.13      0.12      1256
weighted avg       0.39      0.32      0.32      1256

Macro avg F1: 0.117
Weighted avg F1: 0.324
Micro avg F1: 0.322
Top-3 Accuracy: 0.545
Top-5 Accuracy: 0.635
Micro ROC AUC  = 0.88
Macro ROC AUC (present classes) = 0.79
Classification MAE (in years): 10.65

=== Fold 2 ===
Fine Tuning!
707/707 - 163s - 230ms/step - accuracy: 0.3879 - loss: 6.7808 - val_accuracy: 0.2890 - val_loss: 7.9313 - learning_rate: 0.0100
Restoring model weights from the end of the best epoch: 1.
Fold 2 Evaluation results: [7.932079315185547, 0.28901273012161255]
              precision    recall  f1-score   support

        1820       0.00      0.00      0.00        62
        1821       1.00      0.54      0.70        57
        1822       0.00      0.00      0.00         1
        1823       0.00      0.00      0.00         2
        1824       0.00      0.00      0.00         1
        1825       0.00      0.50      0.01         2
        1826       0.00      0.00      0.00         3
        1827       0.48      0.48      0.48        25
        1828       0.00      0.00      0.00         1
        1829       0.00      0.00      0.00         5
        1830       0.13      0.88      0.22        56
        1831       0.67      0.82      0.74       134
        1832       0.79      0.46      0.58        68
        1833       1.00      0.16      0.27        19
        1834       0.00      0.00      0.00        29
        1835       0.00      0.00      0.00         2
        1836       0.00      0.00      0.00         3
        1837       0.00      0.00      0.00         7
        1838       0.00      0.00      0.00         4
        1839       0.00      0.00      0.00         0
        1840       0.28      0.40      0.33        43
        1841       0.50      0.37      0.43       108
        1842       0.00      0.00      0.00         5
        1843       0.00      0.00      0.00         6
        1844       0.00      0.00      0.00         1
        1845       0.00      0.00      0.00         1
        1846       0.00      0.00      0.00         6
        1847       0.00      0.00      0.00         2
        1848       0.00      0.00      0.00         6
        1849       0.00      0.00      0.00         5
        1850       0.17      0.25      0.20        48
        1851       0.75      0.08      0.14        77
        1852       0.00      0.00      0.00         7
        1853       0.00      0.00      0.00         6
        1854       0.00      0.00      0.00         2
        1855       0.75      0.12      0.21        24
        1856       0.00      0.00      0.00        12
        1857       0.00      0.00      0.00        31
        1858       0.00      0.00      0.00         2
        1859       0.00      0.00      0.00         3
        1860       0.21      0.09      0.13        64
        1861       0.73      0.39      0.51        85
        1862       0.00      0.00      0.00        19
        1863       1.00      0.06      0.11        18
        1864       0.00      0.00      0.00        17
        1865       0.00      0.00      0.00         6
        1866       0.00      0.00      0.00         5
        1867       0.00      0.00      0.00        11
        1868       0.00      0.00      0.00         8
        1869       0.00      0.00      0.00         5
        1870       0.00      0.00      0.00        30
        1871       0.00      0.00      0.00        49
        1872       0.17      0.14      0.15         7
        1873       0.00      0.00      0.00        10
        1874       0.12      0.60      0.20         5
        1875       0.40      0.14      0.21        14
        1876       0.00      0.00      0.00        10
        1877       0.00      0.00      0.00         6
        1878       0.50      0.22      0.31         9
        1879       0.00      0.00      0.00         2

    accuracy                           0.29      1256
   macro avg       0.16      0.11      0.10      1256
weighted avg       0.39      0.29      0.28      1256

Macro avg F1: 0.099
Weighted avg F1: 0.283
Micro avg F1: 0.289
Top-3 Accuracy: 0.485
Top-5 Accuracy: 0.593
Micro ROC AUC  = 0.88
Macro ROC AUC (present classes) = 0.85
Classification MAE (in years): 13.54

=== Fold 3 ===
Fine Tuning!
707/707 - 163s - 230ms/step - accuracy: 0.3792 - loss: 7.2096 - val_accuracy: 0.3376 - val_loss: 7.3709 - learning_rate: 0.0100
Restoring model weights from the end of the best epoch: 1.
Fold 3 Evaluation results: [7.385274887084961, 0.337579607963562]
              precision    recall  f1-score   support

        1820       0.75      0.44      0.55        62
        1821       0.32      0.93      0.48        57
        1822       0.00      0.00      0.00         1
        1823       0.00      0.00      0.00         2
        1824       0.00      0.00      0.00         1
        1825       0.00      0.00      0.00         2
        1826       0.00      0.00      0.00         3
        1827       0.80      0.16      0.27        25
        1828       0.05      1.00      0.09         2
        1829       0.00      0.00      0.00         5
        1830       0.41      0.52      0.46        56
        1831       0.73      0.56      0.63       134
        1832       0.80      0.54      0.65        68
        1833       0.00      0.00      0.00        19
        1834       0.27      0.50      0.35        30
        1835       0.00      0.00      0.00         2
        1836       0.00      0.00      0.00         3
        1837       0.20      0.43      0.27         7
        1838       0.00      0.00      0.00         4
        1839       0.00      0.00      0.00         1
        1840       1.00      0.05      0.09        43
        1841       0.51      0.36      0.42       108
        1842       1.00      0.20      0.33         5
        1843       0.00      0.00      0.00         6
        1844       0.00      0.00      0.00         0
        1845       0.00      0.00      0.00         1
        1846       0.00      0.00      0.00         5
        1847       0.00      0.00      0.00         2
        1848       0.00      0.00      0.00         6
        1849       0.00      0.00      0.00         5
        1850       0.62      0.11      0.18        47
        1851       0.79      0.19      0.31        77
        1852       0.00      0.00      0.00         7
        1853       0.00      0.00      0.00         6
        1854       0.00      0.00      0.00         2
        1855       0.00      0.00      0.00        23
        1856       1.00      0.25      0.40        12
        1857       0.00      0.00      0.00        31
        1858       0.00      0.00      0.00         2
        1859       0.00      0.00      0.00         3
        1860       0.13      0.69      0.22        64
        1861       0.53      0.55      0.54        85
        1862       0.00      0.00      0.00        19
        1863       0.33      0.11      0.17        18
        1864       0.00      0.00      0.00        17
        1865       0.00      0.00      0.00         6
        1866       0.00      0.00      0.00         6
        1867       0.00      0.00      0.00        10
        1868       0.00      0.00      0.00         8
        1869       0.00      0.00      0.00         5
        1870       0.00      0.00      0.00        30
        1871       0.91      0.20      0.33        50
        1872       0.00      0.00      0.00         7
        1873       0.10      0.36      0.15        11
        1874       0.00      0.00      0.00         5
        1875       0.18      0.29      0.22        14
        1876       0.00      0.00      0.00        10
        1877       0.00      0.00      0.00         6
        1878       1.00      0.33      0.50         9
        1879       0.00      0.00      0.00         1

    accuracy                           0.34      1256
   macro avg       0.21      0.15      0.13      1256
weighted avg       0.47      0.34      0.33      1256

Macro avg F1: 0.127
Weighted avg F1: 0.329
Micro avg F1: 0.338
Top-3 Accuracy: 0.584
Top-5 Accuracy: 0.682
Micro ROC AUC  = 0.89
Macro ROC AUC (present classes) = 0.83
Classification MAE (in years): 9.90

=== Fold 4 ===
Fine Tuning!
707/707 - 162s - 229ms/step - accuracy: 0.3896 - loss: 7.0704 - val_accuracy: 0.2540 - val_loss: 8.0073 - learning_rate: 0.0100
Restoring model weights from the end of the best epoch: 1.
Fold 4 Evaluation results: [7.956759929656982, 0.2539809048175812]
              precision    recall  f1-score   support

        1820       0.48      0.50      0.49        62
        1821       0.20      0.95      0.33        58
        1822       0.00      0.00      0.00         1
        1823       0.00      0.00      0.00         2
        1824       0.00      0.00      0.00         1
        1825       0.00      0.00      0.00         2
        1826       0.00      0.00      0.00         3
        1827       0.38      0.52      0.44        25
        1828       0.00      0.00      0.00         2
        1829       0.00      0.00      0.00         4
        1830       1.00      0.09      0.16        56
        1831       0.74      0.10      0.18       134
        1832       1.00      0.25      0.40        68
        1833       0.82      0.95      0.88        19
        1834       0.25      0.67      0.36        30
        1835       0.00      0.00      0.00         2
        1836       0.00      0.00      0.00         3
        1837       0.00      0.00      0.00         7
        1838       0.00      0.00      0.00         4
        1839       0.00      0.00      0.00         1
        1840       0.24      0.19      0.21        43
        1841       0.60      0.06      0.10       108
        1842       0.00      0.00      0.00         5
        1843       0.00      0.00      0.00         6
        1844       0.00      0.00      0.00         0
        1845       0.00      0.00      0.00         1
        1846       0.00      0.00      0.00         5
        1847       0.00      0.00      0.00         2
        1848       0.00      0.00      0.00         6
        1849       0.00      0.00      0.00         5
        1850       0.15      0.57      0.23        47
        1851       0.50      0.10      0.17        77
        1852       0.00      0.00      0.00         7
        1853       0.00      0.00      0.00         6
        1854       0.00      0.00      0.00         2
        1855       0.00      0.00      0.00        23
        1856       0.10      1.00      0.18        12
        1857       0.00      0.00      0.00        31
        1858       0.00      0.00      0.00         2
        1859       0.00      0.00      0.00         3
        1860       0.20      0.28      0.23        64
        1861       1.00      0.16      0.28        85
        1862       0.00      0.00      0.00        19
        1863       0.50      0.06      0.10        18
        1864       0.09      0.53      0.15        17
        1865       0.00      0.00      0.00         6
        1866       0.04      0.17      0.06         6
        1867       0.00      0.00      0.00        10
        1868       0.00      0.00      0.00         8
        1869       0.00      0.00      0.00         5
        1870       0.00      0.00      0.00        30
        1871       0.32      0.78      0.45        49
        1872       0.00      0.00      0.00         7
        1873       0.00      0.00      0.00        11
        1874       0.00      0.00      0.00         6
        1875       0.50      0.29      0.36        14
        1876       0.00      0.00      0.00        10
        1877       0.00      0.00      0.00         6
        1878       0.00      0.00      0.00         9
        1879       0.00      0.00      0.00         1

    accuracy                           0.25      1256
   macro avg       0.15      0.14      0.10      1256
weighted avg       0.44      0.25      0.21      1256

Macro avg F1: 0.096
Weighted avg F1: 0.212
Micro avg F1: 0.254
Top-3 Accuracy: 0.512
Top-5 Accuracy: 0.621
Micro ROC AUC  = 0.89
Macro ROC AUC (present classes) = 0.87
Classification MAE (in years): 9.38

=== Fold 5 ===
Fine Tuning!
707/707 - 163s - 231ms/step - accuracy: 0.3803 - loss: 6.9679 - val_accuracy: 0.3153 - val_loss: 6.6864 - learning_rate: 0.0100
Restoring model weights from the end of the best epoch: 1.
Fold 5 Evaluation results: [6.703065872192383, 0.31528663635253906]
              precision    recall  f1-score   support

        1820       0.60      0.49      0.54        61
        1821       0.60      0.26      0.36        58
        1822       0.00      0.00      0.00         2
        1823       0.00      0.00      0.00         1
        1824       0.00      0.00      0.00         1
        1825       0.00      0.00      0.00         2
        1826       0.50      0.50      0.50         2
        1827       0.00      0.00      0.00        25
        1828       0.00      0.00      0.00         2
        1829       1.00      0.50      0.67         4
        1830       0.14      0.77      0.24        56
        1831       0.30      0.95      0.46       135
        1832       0.76      0.51      0.61        68
        1833       0.72      0.68      0.70        19
        1834       0.50      0.03      0.06        29
        1835       0.00      0.00      0.00         2
        1836       0.33      0.33      0.33         3
        1837       0.00      0.00      0.00         6
        1838       0.00      0.00      0.00         4
        1839       0.00      0.00      0.00         1
        1840       1.00      0.05      0.09        43
        1841       0.37      0.15      0.21       107
        1842       0.00      0.00      0.00         5
        1843       0.00      0.00      0.00         6
        1844       0.00      0.00      0.00         0
        1845       0.00      0.00      0.00         1
        1846       0.00      0.00      0.00         5
        1847       0.00      0.00      0.00         2
        1848       0.00      0.00      0.00         6
        1849       0.00      0.00      0.00         5
        1850       0.00      0.00      0.00        47
        1851       0.54      0.51      0.52        77
        1852       0.00      0.00      0.00         8
        1853       0.00      0.00      0.00         6
        1854       0.00      0.00      0.00         2
        1855       0.33      0.04      0.08        23
        1856       0.58      0.58      0.58        12
        1857       0.41      0.29      0.34        31
        1858       0.00      0.00      0.00         3
        1859       0.06      0.33      0.10         3
        1860       0.00      0.00      0.00        65
        1861       1.00      0.01      0.02        85
        1862       0.00      0.00      0.00        19
        1863       0.30      0.33      0.32        18
        1864       0.00      0.00      0.00        17
        1865       0.00      0.00      0.00         7
        1866       0.09      0.33      0.14         6
        1867       0.00      0.00      0.00        10
        1868       0.00      0.00      0.00         7
        1869       0.04      0.40      0.08         5
        1870       0.21      0.48      0.29        31
        1871       0.71      0.31      0.43        49
        1872       0.00      0.00      0.00         7
        1873       1.00      0.18      0.31        11
        1874       0.00      0.00      0.00         6
        1875       0.50      0.07      0.12        14
        1876       0.36      0.80      0.50        10
        1877       0.00      0.00      0.00         6
        1878       0.00      0.00      0.00         9
        1879       0.00      0.00      0.00         1

    accuracy                           0.32      1256
   macro avg       0.22      0.17      0.14      1256
weighted avg       0.41      0.32      0.26      1256

Macro avg F1: 0.144
Weighted avg F1: 0.260
Micro avg F1: 0.315
Top-3 Accuracy: 0.546
Top-5 Accuracy: 0.646
Micro ROC AUC  = 0.90
Macro ROC AUC (present classes) = 0.88
Classification MAE (in years): 10.61

=== Fold 6 ===
Fine Tuning!
707/707 - 167s - 236ms/step - accuracy: 0.3904 - loss: 7.0030 - val_accuracy: 0.3909 - val_loss: 7.2068 - learning_rate: 0.0100
Restoring model weights from the end of the best epoch: 1.
Fold 6 Evaluation results: [7.264663219451904, 0.39092355966567993]
              precision    recall  f1-score   support

        1820       0.69      0.36      0.47        61
        1821       1.00      0.43      0.60        58
        1822       0.00      0.00      0.00         2
        1823       0.00      0.00      0.00         1
        1824       0.00      0.00      0.00         1
        1825       0.00      0.00      0.00         2
        1826       0.00      0.00      0.00         2
        1827       0.00      0.00      0.00        25
        1828       1.00      1.00      1.00         2
        1829       0.00      0.00      0.00         4
        1830       0.55      0.21      0.31        56
        1831       0.68      0.53      0.59       135
        1832       0.77      0.71      0.74        68
        1833       0.95      0.95      0.95        19
        1834       0.26      0.83      0.40        29
        1835       0.00      0.00      0.00         2
        1836       0.00      0.00      0.00         3
        1837       0.29      0.33      0.31         6
        1838       0.00      0.00      0.00         4
        1839       0.00      0.00      0.00         1
        1840       0.46      0.14      0.22        42
        1841       0.50      0.48      0.49       107
        1842       0.50      0.17      0.25         6
        1843       0.00      0.00      0.00         6
        1844       0.00      0.00      0.00         0
        1845       0.00      0.00      0.00         1
        1846       0.00      0.00      0.00         6
        1847       0.00      0.00      0.00         2
        1848       0.00      0.00      0.00         5
        1849       0.00      0.00      0.00         5
        1850       0.60      0.12      0.21        48
        1851       0.46      0.38      0.41        77
        1852       0.00      0.00      0.00         8
        1853       0.00      0.00      0.00         6
        1854       0.00      0.00      0.00         2
        1855       0.00      0.00      0.00        23
        1856       0.75      0.25      0.38        12
        1857       0.55      0.68      0.61        31
        1858       0.00      0.00      0.00         3
        1859       0.00      0.00      0.00         3
        1860       0.18      0.58      0.27        65
        1861       0.32      0.81      0.46        85
        1862       0.00      0.00      0.00        19
        1863       0.50      0.06      0.10        18
        1864       0.00      0.00      0.00        17
        1865       0.00      0.00      0.00         7
        1866       0.00      0.00      0.00         6
        1867       0.00      0.00      0.00        10
        1868       0.00      0.00      0.00         7
        1869       0.00      0.00      0.00         6
        1870       0.21      0.39      0.27        31
        1871       0.27      0.61      0.38        49
        1872       0.00      0.00      0.00         7
        1873       0.00      0.00      0.00        11
        1874       0.00      0.00      0.00         5
        1875       0.00      0.00      0.00        14
        1876       0.00      0.00      0.00        10
        1877       0.00      0.00      0.00         5
        1878       0.00      0.00      0.00         9
        1879       0.00      0.00      0.00         1

    accuracy                           0.39      1256
   macro avg       0.19      0.17      0.16      1256
weighted avg       0.43      0.39      0.36      1256

Macro avg F1: 0.157
Weighted avg F1: 0.365
Micro avg F1: 0.391
Top-3 Accuracy: 0.628
Top-5 Accuracy: 0.705
Micro ROC AUC  = 0.90
Macro ROC AUC (present classes) = 0.84
Classification MAE (in years): 7.50

=== Fold 7 ===
Fine Tuning!
707/707 - 164s - 232ms/step - accuracy: 0.3903 - loss: 6.5929 - val_accuracy: 0.3400 - val_loss: 6.9163 - learning_rate: 0.0100
Restoring model weights from the end of the best epoch: 1.
Fold 7 Evaluation results: [6.944032669067383, 0.33996814489364624]
              precision    recall  f1-score   support

        1820       0.67      0.20      0.30        61
        1821       0.51      0.79      0.62        58
        1822       0.00      0.00      0.00         2
        1823       0.00      0.00      0.00         1
        1824       0.00      0.00      0.00         1
        1825       0.00      0.00      0.00         2
        1826       0.00      0.00      0.00         2
        1827       0.32      0.80      0.45        25
        1828       0.00      0.00      0.00         2
        1829       0.00      0.00      0.00         4
        1830       0.50      0.09      0.15        56
        1831       0.88      0.21      0.35       135
        1832       0.78      0.69      0.73        68
        1833       0.78      0.95      0.86        19
        1834       0.50      0.45      0.47        29
        1835       0.00      0.00      0.00         2
        1836       0.00      0.00      0.00         4
        1837       0.00      0.00      0.00         6
        1838       0.00      0.00      0.00         4
        1839       0.00      0.00      0.00         1
        1840       0.21      0.40      0.28        42
        1841       0.36      0.70      0.47       107
        1842       0.00      0.00      0.00         6
        1843       0.00      0.00      0.00         6
        1844       0.00      0.00      0.00         0
        1845       0.00      0.00      0.00         1
        1846       0.00      0.00      0.00         6
        1847       0.00      0.00      0.00         2
        1848       0.06      0.80      0.12         5
        1849       0.06      0.20      0.09         5
        1850       0.12      0.71      0.21        48
        1851       0.52      0.51      0.51        77
        1852       0.00      0.00      0.00         8
        1853       0.00      0.00      0.00         6
        1854       0.00      0.00      0.00         2
        1855       0.00      0.00      0.00        23
        1856       0.40      0.17      0.24        12
        1857       0.33      0.06      0.11        31
        1858       0.00      0.00      0.00         3
        1859       0.00      0.00      0.00         2
        1860       0.00      0.00      0.00        65
        1861       0.78      0.21      0.33        85
        1862       0.00      0.00      0.00        19
        1863       0.00      0.00      0.00        18
        1864       0.00      0.00      0.00        17
        1865       0.00      0.00      0.00         7
        1866       0.00      0.00      0.00         6
        1867       0.00      0.00      0.00        10
        1868       0.20      0.29      0.24         7
        1869       0.00      0.00      0.00         6
        1870       0.00      0.00      0.00        31
        1871       0.25      0.73      0.37        49
        1872       0.20      0.29      0.24         7
        1873       0.00      0.00      0.00        11
        1874       0.50      0.20      0.29         5
        1875       0.00      0.00      0.00        14
        1876       0.00      0.00      0.00        10
        1877       0.50      0.40      0.44         5
        1878       1.00      0.22      0.36         9
        1879       0.00      0.00      0.00         1

    accuracy                           0.34      1256
   macro avg       0.17      0.17      0.14      1256
weighted avg       0.41      0.34      0.30      1256

Macro avg F1: 0.137
Weighted avg F1: 0.300
Micro avg F1: 0.340
Top-3 Accuracy: 0.564
Top-5 Accuracy: 0.663
Micro ROC AUC  = 0.91
Macro ROC AUC (present classes) = 0.84
Classification MAE (in years): 8.18

=== Fold 8 ===
Fine Tuning!
707/707 - 164s - 231ms/step - accuracy: 0.3927 - loss: 6.7611 - val_accuracy: 0.3519 - val_loss: 8.5599 - learning_rate: 0.0100
Restoring model weights from the end of the best epoch: 1.
Fold 8 Evaluation results: [8.64942455291748, 0.3519108295440674]
              precision    recall  f1-score   support

        1820       0.24      0.89      0.38        62
        1821       0.90      0.61      0.73        57
        1822       0.00      0.00      0.00         2
        1823       0.00      0.00      0.00         1
        1824       0.00      0.00      0.00         1
        1825       0.00      0.00      0.00         2
        1826       0.00      0.00      0.00         2
        1827       0.48      0.40      0.43        25
        1828       1.00      0.50      0.67         2
        1829       0.00      0.00      0.00         4
        1830       0.45      0.16      0.24        56
        1831       0.91      0.22      0.36       135
        1832       0.42      0.84      0.56        68
        1833       1.00      0.37      0.54        19
        1834       0.38      0.17      0.24        29
        1835       0.00      0.00      0.00         2
        1836       0.00      0.00      0.00         4
        1837       0.00      0.00      0.00         6
        1838       0.00      0.00      0.00         4
        1839       0.00      0.00      0.00         1
        1840       0.33      0.14      0.20        42
        1841       0.37      0.77      0.50       107
        1842       0.25      0.17      0.20         6
        1843       0.00      0.00      0.00         5
        1844       0.00      0.00      0.00         0
        1845       0.00      0.00      0.00         1
        1846       0.00      0.00      0.00         6
        1847       0.00      0.00      0.00         2
        1848       0.00      0.00      0.00         5
        1849       0.00      0.00      0.00         5
        1850       0.00      0.00      0.00        48
        1851       0.55      0.57      0.56        77
        1852       0.00      0.00      0.00         8
        1853       0.17      0.29      0.21         7
        1854       0.00      0.00      0.00         3
        1855       0.00      0.00      0.00        23
        1856       0.00      0.00      0.00        12
        1857       0.00      0.00      0.00        31
        1858       0.00      0.00      0.00         2
        1859       0.00      0.00      0.00         2
        1860       0.14      0.54      0.23        65
        1861       0.77      0.32      0.45        85
        1862       0.00      0.00      0.00        19
        1863       0.00      0.00      0.00        19
        1864       0.00      0.00      0.00        17
        1865       0.00      0.00      0.00         7
        1866       0.12      0.17      0.14         6
        1867       0.00      0.00      0.00        10
        1868       0.00      0.00      0.00         7
        1869       0.00      0.00      0.00         6
        1870       0.00      0.00      0.00        31
        1871       0.53      0.63      0.57        49
        1872       0.00      0.00      0.00         7
        1873       0.00      0.00      0.00        11
        1874       0.00      0.00      0.00         5
        1875       0.00      0.00      0.00        13
        1876       0.00      0.00      0.00        10
        1877       0.06      0.80      0.11         5
        1878       0.00      0.00      0.00         9
        1879       0.00      0.00      0.00         1

    accuracy                           0.35      1256
   macro avg       0.15      0.14      0.12      1256
weighted avg       0.39      0.35      0.31      1256

Macro avg F1: 0.122
Weighted avg F1: 0.306
Micro avg F1: 0.352
Top-3 Accuracy: 0.575
Top-5 Accuracy: 0.653
Micro ROC AUC  = 0.88
Macro ROC AUC (present classes) = 0.89
Classification MAE (in years): 8.80

=== Fold 9 ===
Fine Tuning!
707/707 - 165s - 233ms/step - accuracy: 0.3891 - loss: 6.9735 - val_accuracy: 0.3418 - val_loss: 8.8865 - learning_rate: 0.0100
Restoring model weights from the end of the best epoch: 1.
Fold 9 Evaluation results: [8.855918884277344, 0.3418326675891876]
              precision    recall  f1-score   support

        1820       0.56      0.50      0.53        62
        1821       0.52      0.81      0.63        57
        1822       0.00      0.00      0.00         1
        1823       0.00      0.00      0.00         1
        1824       0.00      0.00      0.00         1
        1825       0.02      1.00      0.03         2
        1826       0.00      0.00      0.00         2
        1827       1.00      0.04      0.08        25
        1828       0.00      0.00      0.00         2
        1829       0.00      0.00      0.00         4
        1830       0.25      0.54      0.34        56
        1831       0.74      0.36      0.48       134
        1832       0.36      0.62      0.46        68
        1833       1.00      0.16      0.27        19
        1834       0.16      0.21      0.18        29
        1835       0.00      0.00      0.00         2
        1836       0.00      0.00      0.00         4
        1837       0.00      0.00      0.00         6
        1838       0.00      0.00      0.00         4
        1839       0.00      0.00      0.00         1
        1840       0.22      0.28      0.25        43
        1841       1.00      0.02      0.04       107
        1842       0.00      0.00      0.00         6
        1843       0.00      0.00      0.00         5
        1844       0.00      0.00      0.00         0
        1845       0.00      0.00      0.00         1
        1846       0.00      0.00      0.00         6
        1847       0.00      0.00      0.00         2
        1848       0.00      0.00      0.00         5
        1849       0.00      0.00      0.00         6
        1850       0.33      0.54      0.41        48
        1851       0.37      0.61      0.46        77
        1852       0.00      0.00      0.00         7
        1853       0.00      0.00      0.00         7
        1854       0.00      0.00      0.00         3
        1855       0.00      0.00      0.00        23
        1856       1.00      0.17      0.29        12
        1857       0.61      0.47      0.53        30
        1858       0.00      0.00      0.00         2
        1859       0.00      0.00      0.00         2
        1860       0.28      0.34      0.31        65
        1861       0.43      0.72      0.54        85
        1862       0.00      0.00      0.00        19
        1863       0.00      0.00      0.00        19
        1864       0.00      0.00      0.00        17
        1865       0.00      0.00      0.00         7
        1866       0.00      0.00      0.00         6
        1867       0.00      0.00      0.00        11
        1868       0.00      0.00      0.00         7
        1869       0.00      0.00      0.00         5
        1870       0.50      0.03      0.06        31
        1871       0.26      0.63      0.37        49
        1872       0.00      0.00      0.00         7
        1873       0.00      0.00      0.00        10
        1874       0.00      0.00      0.00         5
        1875       0.17      0.07      0.10        14
        1876       0.00      0.00      0.00        10
        1877       0.00      0.00      0.00         5
        1878       0.33      0.11      0.17         9
        1879       0.00      0.00      0.00         2

    accuracy                           0.34      1255
   macro avg       0.17      0.14      0.11      1255
weighted avg       0.42      0.34      0.30      1255

Macro avg F1: 0.109
Weighted avg F1: 0.298
Micro avg F1: 0.342
Top-3 Accuracy: 0.559
Top-5 Accuracy: 0.646
Micro ROC AUC  = 0.88
Macro ROC AUC (present classes) = 0.83
Classification MAE (in years): 8.76

Mean accuracy over 10 folds: 0.3269
Total running time: 0 hours, 37 minutes, 52 seconds
