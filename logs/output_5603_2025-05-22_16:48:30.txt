TensorFlow Version: 2.20.0-dev20250508
Num GPUs Available: 1
Physical devices cannot be modified after being initialized

=== Using model: InceptionV3. ===
RUN ID: 2025-05-22_16:48:35
Task: Classification
Test fold: 0

===== Fine Tuning 9 layers! =====
Epoch 1/300
89/89 - 313s - 4s/step - accuracy: 0.1075 - loss: 6.4734 - val_accuracy: 0.1704 - val_loss: 5.4884 - learning_rate: 2.5974e-04
Epoch 2/300
89/89 - 122s - 1s/step - accuracy: 0.1545 - loss: 5.4050 - val_accuracy: 0.2381 - val_loss: 4.6561 - learning_rate: 2.5974e-04
Epoch 3/300
89/89 - 119s - 1s/step - accuracy: 0.1995 - loss: 5.2450 - val_accuracy: 0.2874 - val_loss: 4.7032 - learning_rate: 2.5974e-04
Epoch 4/300
89/89 - 113s - 1s/step - accuracy: 0.2299 - loss: 4.6736 - val_accuracy: 0.3519 - val_loss: 3.4795 - learning_rate: 2.5974e-04
Epoch 5/300
89/89 - 118s - 1s/step - accuracy: 0.2467 - loss: 4.5002 - val_accuracy: 0.3639 - val_loss: 3.3148 - learning_rate: 2.5974e-04
Epoch 6/300
89/89 - 114s - 1s/step - accuracy: 0.2638 - loss: 4.4830 - val_accuracy: 0.3885 - val_loss: 3.1428 - learning_rate: 2.5974e-04
Epoch 7/300
89/89 - 118s - 1s/step - accuracy: 0.2834 - loss: 4.1846 - val_accuracy: 0.4188 - val_loss: 3.5949 - learning_rate: 2.5974e-04
Epoch 8/300
89/89 - 114s - 1s/step - accuracy: 0.2930 - loss: 4.0388 - val_accuracy: 0.4443 - val_loss: 2.9559 - learning_rate: 2.5974e-04
Epoch 9/300
89/89 - 115s - 1s/step - accuracy: 0.3035 - loss: 4.1442 - val_accuracy: 0.4586 - val_loss: 3.2118 - learning_rate: 2.5974e-04
Epoch 10/300
89/89 - 116s - 1s/step - accuracy: 0.3176 - loss: 3.8173 - val_accuracy: 0.4371 - val_loss: 3.7269 - learning_rate: 2.5974e-04
Epoch 11/300
89/89 - 114s - 1s/step - accuracy: 0.3243 - loss: 3.9174 - val_accuracy: 0.4785 - val_loss: 3.6122 - learning_rate: 2.5974e-04
Epoch 12/300
89/89 - 115s - 1s/step - accuracy: 0.3328 - loss: 3.9806 - val_accuracy: 0.4896 - val_loss: 2.7184 - learning_rate: 2.5974e-04
Epoch 13/300
89/89 - 110s - 1s/step - accuracy: 0.3385 - loss: 3.8152 - val_accuracy: 0.4952 - val_loss: 2.7714 - learning_rate: 2.5974e-04
Epoch 14/300
89/89 - 116s - 1s/step - accuracy: 0.3469 - loss: 3.7763 - val_accuracy: 0.5143 - val_loss: 2.4873 - learning_rate: 2.5974e-04
Epoch 15/300
89/89 - 115s - 1s/step - accuracy: 0.3546 - loss: 3.8291 - val_accuracy: 0.5231 - val_loss: 2.4049 - learning_rate: 2.5974e-04
Epoch 16/300
89/89 - 117s - 1s/step - accuracy: 0.3653 - loss: 3.5139 - val_accuracy: 0.5255 - val_loss: 2.7982 - learning_rate: 2.5974e-04
Epoch 17/300
89/89 - 113s - 1s/step - accuracy: 0.3647 - loss: 3.5752 - val_accuracy: 0.5239 - val_loss: 2.4080 - learning_rate: 2.5974e-04
Epoch 18/300
89/89 - 111s - 1s/step - accuracy: 0.3698 - loss: 3.5006 - val_accuracy: 0.5358 - val_loss: 2.6474 - learning_rate: 2.5974e-04
Epoch 19/300
89/89 - 114s - 1s/step - accuracy: 0.3793 - loss: 3.4715 - val_accuracy: 0.5422 - val_loss: 2.9305 - learning_rate: 2.5974e-04
Epoch 20/300
89/89 - 112s - 1s/step - accuracy: 0.3788 - loss: 3.6303 - val_accuracy: 0.5263 - val_loss: 2.8329 - learning_rate: 2.5974e-04
Epoch 21/300
89/89 - 113s - 1s/step - accuracy: 0.3822 - loss: 3.4988 - val_accuracy: 0.5518 - val_loss: 2.4239 - learning_rate: 2.5974e-04
Epoch 22/300
89/89 - 116s - 1s/step - accuracy: 0.3917 - loss: 3.5542 - val_accuracy: 0.5438 - val_loss: 2.4247 - learning_rate: 2.5974e-04
Epoch 23/300

Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0001298690476687625.
89/89 - 119s - 1s/step - accuracy: 0.3953 - loss: 3.3633 - val_accuracy: 0.5462 - val_loss: 2.4449 - learning_rate: 2.5974e-04
Epoch 24/300
89/89 - 111s - 1s/step - accuracy: 0.4041 - loss: 3.2558 - val_accuracy: 0.5478 - val_loss: 2.2505 - learning_rate: 1.2987e-04
Epoch 25/300
89/89 - 107s - 1s/step - accuracy: 0.4027 - loss: 3.4430 - val_accuracy: 0.5581 - val_loss: 2.0615 - learning_rate: 1.2987e-04
Epoch 26/300
89/89 - 116s - 1s/step - accuracy: 0.4110 - loss: 3.5159 - val_accuracy: 0.5677 - val_loss: 2.5139 - learning_rate: 1.2987e-04
Epoch 27/300
89/89 - 114s - 1s/step - accuracy: 0.4045 - loss: 3.3410 - val_accuracy: 0.5693 - val_loss: 2.3099 - learning_rate: 1.2987e-04
Epoch 28/300
89/89 - 113s - 1s/step - accuracy: 0.4133 - loss: 3.3305 - val_accuracy: 0.5645 - val_loss: 2.4870 - learning_rate: 1.2987e-04
Epoch 29/300
89/89 - 120s - 1s/step - accuracy: 0.4113 - loss: 3.3664 - val_accuracy: 0.5541 - val_loss: 2.5603 - learning_rate: 1.2987e-04
Epoch 30/300
89/89 - 122s - 1s/step - accuracy: 0.4139 - loss: 3.3099 - val_accuracy: 0.5645 - val_loss: 2.2145 - learning_rate: 1.2987e-04
Epoch 31/300
89/89 - 122s - 1s/step - accuracy: 0.4073 - loss: 3.2788 - val_accuracy: 0.5669 - val_loss: 2.2744 - learning_rate: 1.2987e-04
Epoch 32/300
89/89 - 145s - 2s/step - accuracy: 0.4136 - loss: 3.1894 - val_accuracy: 0.5669 - val_loss: 2.3457 - learning_rate: 1.2987e-04
Epoch 33/300

Epoch 33: ReduceLROnPlateau reducing learning rate to 6.493452383438125e-05.
89/89 - 120s - 1s/step - accuracy: 0.4203 - loss: 3.2318 - val_accuracy: 0.5661 - val_loss: 2.6544 - learning_rate: 1.2987e-04
Epoch 34/300
89/89 - 122s - 1s/step - accuracy: 0.4196 - loss: 3.4539 - val_accuracy: 0.5725 - val_loss: 2.4473 - learning_rate: 6.4935e-05
Epoch 35/300
89/89 - 120s - 1s/step - accuracy: 0.4227 - loss: 3.2712 - val_accuracy: 0.5717 - val_loss: 2.5091 - learning_rate: 6.4935e-05
Epoch 36/300
89/89 - 122s - 1s/step - accuracy: 0.4238 - loss: 3.1412 - val_accuracy: 0.5661 - val_loss: 2.4735 - learning_rate: 6.4935e-05
Epoch 37/300
89/89 - 120s - 1s/step - accuracy: 0.4195 - loss: 3.2939 - val_accuracy: 0.5725 - val_loss: 2.4236 - learning_rate: 6.4935e-05
Epoch 38/300
89/89 - 124s - 1s/step - accuracy: 0.4269 - loss: 3.1683 - val_accuracy: 0.5748 - val_loss: 2.3511 - learning_rate: 6.4935e-05
Epoch 39/300
89/89 - 122s - 1s/step - accuracy: 0.4214 - loss: 3.2015 - val_accuracy: 0.5709 - val_loss: 2.6170 - learning_rate: 6.4935e-05
Epoch 40/300
89/89 - 123s - 1s/step - accuracy: 0.4214 - loss: 3.2727 - val_accuracy: 0.5693 - val_loss: 2.5293 - learning_rate: 6.4935e-05
Epoch 41/300

Epoch 41: ReduceLROnPlateau reducing learning rate to 3.2467261917190626e-05.
89/89 - 123s - 1s/step - accuracy: 0.4240 - loss: 3.0705 - val_accuracy: 0.5693 - val_loss: 2.4417 - learning_rate: 6.4935e-05
Epoch 41: early stopping
Restoring model weights from the end of the best epoch: 25.
Fold 0 Evaluation results: [2.5711710453033447, 0.5581210255622864]
              precision    recall  f1-score   support

        1820       0.53      0.82      0.64        62
        1821       0.91      0.91      0.91        57
        1822       0.00      0.00      0.00         1
        1823       0.00      0.00      0.00         1
        1824       0.00      0.00      0.00         1
        1825       0.00      0.00      0.00         3
        1826       0.00      0.00      0.00         2
        1827       0.73      0.64      0.68        25
        1828       0.00      0.00      0.00         1
        1829       0.00      0.00      0.00         5
        1830       0.47      0.54      0.50        56
        1831       0.81      0.96      0.88       134
        1832       0.69      0.78      0.73        67
        1833       0.57      0.84      0.68        19
        1834       0.44      0.41      0.43        29
        1835       0.00      0.00      0.00         2
        1836       0.00      0.00      0.00         4
        1837       0.00      0.00      0.00         6
        1838       0.00      0.00      0.00         3
        1839       0.00      0.00      0.00         1
        1840       0.48      0.58      0.53        43
        1841       0.65      0.56      0.60       108
        1842       0.00      0.00      0.00         6
        1843       0.00      0.00      0.00         6
        1844       0.00      0.00      0.00         1
        1845       0.00      0.00      0.00         1
        1846       0.00      0.00      0.00         6
        1847       0.00      0.00      0.00         2
        1848       0.00      0.00      0.00         5
        1849       0.00      0.00      0.00         6
        1850       0.32      0.42      0.36        48
        1851       0.75      0.62      0.68        77
        1852       0.00      0.00      0.00         7
        1853       0.00      0.00      0.00         7
        1854       0.00      0.00      0.00         3
        1855       0.00      0.00      0.00        23
        1856       0.00      0.00      0.00        12
        1857       0.29      0.67      0.40        30
        1858       0.00      0.00      0.00         2
        1859       0.00      0.00      0.00         2
        1860       0.21      0.45      0.29        65
        1861       0.78      0.79      0.78        85
        1862       0.00      0.00      0.00        19
        1863       0.55      0.32      0.40        19
        1864       0.00      0.00      0.00        17
        1865       0.00      0.00      0.00         7
        1866       0.00      0.00      0.00         5
        1867       0.00      0.00      0.00        11
        1868       0.00      0.00      0.00         7
        1869       0.00      0.00      0.00         5
        1870       0.30      0.39      0.34        31
        1871       0.57      0.80      0.66        49
        1872       0.00      0.00      0.00         7
        1873       0.00      0.00      0.00        10
        1874       0.00      0.00      0.00         5
        1875       0.33      0.71      0.45        14
        1876       0.88      0.70      0.78        10
        1877       0.00      0.00      0.00         5
        1878       1.00      0.11      0.20         9
        1879       0.00      0.00      0.00         2

    accuracy                           0.56      1256
   macro avg       0.20      0.22      0.20      1256
weighted avg       0.50      0.56      0.52      1256

Matthews Correlation Coefficient: 0.535
Macro avg F1: 0.199
Weighted avg F1: 0.517
Micro avg F1: 0.558
Top-3 Accuracy: 0.765
Top-5 Accuracy: 0.846
Micro ROC AUC  = 0.98
Macro ROC AUC (present classes) = 0.96
Classification MAE (in years): 4.25

Fold 0 Misclassification Analysis:
Near misses (within 2 years): 96 out of 555 misclassifications (17.30%)
Big misses (greater than 10 years): 246
MAE with outliers: 4.25
MAE without outliers: 3.04 (improvement: 1.21)

10 Worst misclassifications:
Image: data/datasets/public/1870/1879_1476vna.jpg, True: 1879, Predicted: 1820, Error: 59
Image: data/datasets/public/1870/1873_044met.jpg, True: 1873, Predicted: 1820, Error: 53
Image: data/datasets/public/1820/1820_23wikimedia2.jpg, True: 1820, Predicted: 1871, Error: 51
Image: data/datasets/private/1870/1871_412etsy.jpg, True: 1871, Predicted: 1821, Error: 50
Image: data/datasets/public/1870/1870_2402vna.jpg, True: 1870, Predicted: 1820, Error: 50
Image: data/datasets/private/1870/1871_398etsy.jpg, True: 1871, Predicted: 1821, Error: 50
Image: data/datasets/public/1860/1869_003met.jpg, True: 1869, Predicted: 1820, Error: 49
Image: data/datasets/public/1860/1867_027_001met.jpg, True: 1867, Predicted: 1820, Error: 47
Image: data/datasets/private/1820/1825_038_Zrzut ekranu 2022-07-26 210721.png, True: 1825, Predicted: 1871, Error: 46
Image: data/datasets/public/1870/1876_455vna.jpg, True: 1876, Predicted: 1832, Error: 44
Metrics: {'accuracy': 0.5581210255622864, 'mae_years': np.float64(4.245222929936306), 'mcc': np.float64(0.5352933340713872)}

=== Total running time: 1 hours, 24 minutes, 47 seconds ===

