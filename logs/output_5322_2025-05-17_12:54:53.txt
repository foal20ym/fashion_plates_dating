TensorFlow Version: 2.20.0-dev20250425
Num GPUs Available: 1
Physical devices cannot be modified after being initialized

=== Using model: ConvNeXtTiny. ===
RUN ID: 2025-05-17_12:55:00
Task: Classification
Test fold: 0

===== Fine Tuning 9 layers! =====
Epoch 1/300
1413/1413 - 298s - 211ms/step - accuracy: 0.1161 - loss: 4.4506 - val_accuracy: 0.1170 - val_loss: 4.3069 - learning_rate: 2.5974e-04
Epoch 2/300
1413/1413 - 224s - 159ms/step - accuracy: 0.1553 - loss: 4.1451 - val_accuracy: 0.1911 - val_loss: 4.6381 - learning_rate: 2.5974e-04
Epoch 3/300
1413/1413 - 222s - 157ms/step - accuracy: 0.1770 - loss: 3.9903 - val_accuracy: 0.1346 - val_loss: 5.1249 - learning_rate: 2.5974e-04
Epoch 4/300
1413/1413 - 221s - 157ms/step - accuracy: 0.2078 - loss: 3.8502 - val_accuracy: 0.2046 - val_loss: 4.3058 - learning_rate: 2.5974e-04
Epoch 5/300
1413/1413 - 234s - 166ms/step - accuracy: 0.2232 - loss: 3.7324 - val_accuracy: 0.2643 - val_loss: 4.7074 - learning_rate: 2.5974e-04
Epoch 6/300
1413/1413 - 238s - 168ms/step - accuracy: 0.2345 - loss: 3.6809 - val_accuracy: 0.1489 - val_loss: 6.1347 - learning_rate: 2.5974e-04
Epoch 7/300
1413/1413 - 240s - 170ms/step - accuracy: 0.2399 - loss: 3.6542 - val_accuracy: 0.1791 - val_loss: 5.9203 - learning_rate: 2.5974e-04
Epoch 8/300
1413/1413 - 242s - 172ms/step - accuracy: 0.2466 - loss: 3.6002 - val_accuracy: 0.2723 - val_loss: 3.4827 - learning_rate: 2.5974e-04
Epoch 9/300
1413/1413 - 249s - 176ms/step - accuracy: 0.2629 - loss: 3.5255 - val_accuracy: 0.2540 - val_loss: 4.0554 - learning_rate: 2.5974e-04
Epoch 10/300
1413/1413 - 252s - 178ms/step - accuracy: 0.2625 - loss: 3.5358 - val_accuracy: 0.2373 - val_loss: 4.5893 - learning_rate: 2.5974e-04
Epoch 11/300
1413/1413 - 259s - 184ms/step - accuracy: 0.2712 - loss: 3.4925 - val_accuracy: 0.3010 - val_loss: 3.6208 - learning_rate: 2.5974e-04
Epoch 12/300
1413/1413 - 252s - 179ms/step - accuracy: 0.2746 - loss: 3.4890 - val_accuracy: 0.4260 - val_loss: 3.2353 - learning_rate: 2.5974e-04
Epoch 13/300
1413/1413 - 245s - 174ms/step - accuracy: 0.2861 - loss: 3.4440 - val_accuracy: 0.4427 - val_loss: 2.6726 - learning_rate: 2.5974e-04
Epoch 14/300
1413/1413 - 241s - 170ms/step - accuracy: 0.2861 - loss: 3.4061 - val_accuracy: 0.2850 - val_loss: 7.9413 - learning_rate: 2.5974e-04
Epoch 15/300
1413/1413 - 240s - 170ms/step - accuracy: 0.2950 - loss: 3.3966 - val_accuracy: 0.4100 - val_loss: 3.0439 - learning_rate: 2.5974e-04
Epoch 16/300
1413/1413 - 239s - 169ms/step - accuracy: 0.2944 - loss: 3.3526 - val_accuracy: 0.4482 - val_loss: 3.0909 - learning_rate: 2.5974e-04
Epoch 17/300
1413/1413 - 237s - 168ms/step - accuracy: 0.2994 - loss: 3.3494 - val_accuracy: 0.2898 - val_loss: 4.5136 - learning_rate: 2.5974e-04
Epoch 18/300
1413/1413 - 239s - 169ms/step - accuracy: 0.3085 - loss: 3.3109 - val_accuracy: 0.3209 - val_loss: 3.5249 - learning_rate: 2.5974e-04
Epoch 19/300
1413/1413 - 246s - 174ms/step - accuracy: 0.3104 - loss: 3.2901 - val_accuracy: 0.3344 - val_loss: 4.1437 - learning_rate: 2.5974e-04
Epoch 20/300
1413/1413 - 258s - 182ms/step - accuracy: 0.3168 - loss: 3.2690 - val_accuracy: 0.3471 - val_loss: 3.1376 - learning_rate: 2.5974e-04
Epoch 21/300
1413/1413 - 256s - 181ms/step - accuracy: 0.3089 - loss: 3.2570 - val_accuracy: 0.4076 - val_loss: 2.6224 - learning_rate: 2.5974e-04
Epoch 22/300
1413/1413 - 259s - 183ms/step - accuracy: 0.3066 - loss: 3.2845 - val_accuracy: 0.4164 - val_loss: 3.1602 - learning_rate: 2.5974e-04
Epoch 23/300
1413/1413 - 258s - 182ms/step - accuracy: 0.3215 - loss: 3.2483 - val_accuracy: 0.4236 - val_loss: 3.0948 - learning_rate: 2.5974e-04
Epoch 24/300
1413/1413 - 256s - 181ms/step - accuracy: 0.3241 - loss: 3.2104 - val_accuracy: 0.3933 - val_loss: 4.2325 - learning_rate: 2.5974e-04
Epoch 25/300
1413/1413 - 250s - 177ms/step - accuracy: 0.3241 - loss: 3.2091 - val_accuracy: 0.3846 - val_loss: 4.0313 - learning_rate: 2.5974e-04
Epoch 26/300
1413/1413 - 255s - 181ms/step - accuracy: 0.3296 - loss: 3.1833 - val_accuracy: 0.3073 - val_loss: 3.6666 - learning_rate: 2.5974e-04
Epoch 27/300
1413/1413 - 254s - 180ms/step - accuracy: 0.3355 - loss: 3.1780 - val_accuracy: 0.4602 - val_loss: 2.6699 - learning_rate: 2.5974e-04
Epoch 28/300
1413/1413 - 253s - 179ms/step - accuracy: 0.3331 - loss: 3.1511 - val_accuracy: 0.4682 - val_loss: 2.3672 - learning_rate: 2.5974e-04
Epoch 29/300
1413/1413 - 253s - 179ms/step - accuracy: 0.3358 - loss: 3.1700 - val_accuracy: 0.4148 - val_loss: 3.4960 - learning_rate: 2.5974e-04
Epoch 30/300
1413/1413 - 253s - 179ms/step - accuracy: 0.3358 - loss: 3.1534 - val_accuracy: 0.3909 - val_loss: 3.5607 - learning_rate: 2.5974e-04
Epoch 31/300
1413/1413 - 252s - 178ms/step - accuracy: 0.3400 - loss: 3.1155 - val_accuracy: 0.4642 - val_loss: 2.8241 - learning_rate: 2.5974e-04
Epoch 32/300
1413/1413 - 251s - 178ms/step - accuracy: 0.3431 - loss: 3.1227 - val_accuracy: 0.4586 - val_loss: 2.3439 - learning_rate: 2.5974e-04
Epoch 33/300
1413/1413 - 249s - 176ms/step - accuracy: 0.3366 - loss: 3.1153 - val_accuracy: 0.4108 - val_loss: 3.1134 - learning_rate: 2.5974e-04
Epoch 34/300
1413/1413 - 242s - 172ms/step - accuracy: 0.3469 - loss: 3.0982 - val_accuracy: 0.5143 - val_loss: 2.1733 - learning_rate: 2.5974e-04
Epoch 35/300
1413/1413 - 246s - 174ms/step - accuracy: 0.3443 - loss: 3.0600 - val_accuracy: 0.4984 - val_loss: 2.4176 - learning_rate: 2.5974e-04
Epoch 36/300
1413/1413 - 237s - 168ms/step - accuracy: 0.3462 - loss: 3.0824 - val_accuracy: 0.2325 - val_loss: 6.9767 - learning_rate: 2.5974e-04
Epoch 37/300
1413/1413 - 249s - 176ms/step - accuracy: 0.3482 - loss: 3.0783 - val_accuracy: 0.3957 - val_loss: 3.1636 - learning_rate: 2.5974e-04
Epoch 38/300
1413/1413 - 238s - 168ms/step - accuracy: 0.3511 - loss: 3.0611 - val_accuracy: 0.3766 - val_loss: 3.8840 - learning_rate: 2.5974e-04
Epoch 39/300
1413/1413 - 236s - 167ms/step - accuracy: 0.3533 - loss: 3.0706 - val_accuracy: 0.4490 - val_loss: 2.6994 - learning_rate: 2.5974e-04
Epoch 40/300
1413/1413 - 241s - 171ms/step - accuracy: 0.3559 - loss: 3.0494 - val_accuracy: 0.3447 - val_loss: 3.8488 - learning_rate: 2.5974e-04
Epoch 41/300
1413/1413 - 250s - 177ms/step - accuracy: 0.3550 - loss: 3.0511 - val_accuracy: 0.3304 - val_loss: 3.4922 - learning_rate: 2.5974e-04
Epoch 42/300

Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0001298690476687625.
1413/1413 - 253s - 179ms/step - accuracy: 0.3607 - loss: 3.0298 - val_accuracy: 0.4785 - val_loss: 2.4810 - learning_rate: 2.5974e-04
Epoch 43/300
1413/1413 - 241s - 170ms/step - accuracy: 0.3723 - loss: 2.9607 - val_accuracy: 0.5247 - val_loss: 2.4062 - learning_rate: 1.2987e-04
Epoch 44/300
1413/1413 - 240s - 170ms/step - accuracy: 0.3728 - loss: 2.9492 - val_accuracy: 0.5096 - val_loss: 2.3134 - learning_rate: 1.2987e-04
Epoch 45/300
1413/1413 - 238s - 168ms/step - accuracy: 0.3761 - loss: 2.9101 - val_accuracy: 0.5685 - val_loss: 1.9904 - learning_rate: 1.2987e-04
Epoch 46/300
1413/1413 - 236s - 167ms/step - accuracy: 0.3730 - loss: 2.9402 - val_accuracy: 0.5334 - val_loss: 2.3253 - learning_rate: 1.2987e-04
Epoch 47/300
1413/1413 - 249s - 177ms/step - accuracy: 0.3724 - loss: 2.9380 - val_accuracy: 0.5175 - val_loss: 2.3075 - learning_rate: 1.2987e-04
Epoch 48/300
1413/1413 - 249s - 177ms/step - accuracy: 0.3825 - loss: 2.9000 - val_accuracy: 0.5486 - val_loss: 2.1368 - learning_rate: 1.2987e-04
Epoch 49/300
1413/1413 - 250s - 177ms/step - accuracy: 0.3831 - loss: 2.8752 - val_accuracy: 0.5828 - val_loss: 1.9811 - learning_rate: 1.2987e-04
Epoch 50/300
1413/1413 - 253s - 179ms/step - accuracy: 0.3847 - loss: 2.8904 - val_accuracy: 0.4761 - val_loss: 2.4386 - learning_rate: 1.2987e-04
Epoch 51/300
1413/1413 - 253s - 179ms/step - accuracy: 0.3832 - loss: 2.8782 - val_accuracy: 0.5406 - val_loss: 2.1069 - learning_rate: 1.2987e-04
Epoch 52/300
1413/1413 - 251s - 178ms/step - accuracy: 0.3847 - loss: 2.8791 - val_accuracy: 0.5629 - val_loss: 1.9775 - learning_rate: 1.2987e-04
Epoch 53/300
1413/1413 - 235s - 166ms/step - accuracy: 0.3836 - loss: 2.8667 - val_accuracy: 0.5629 - val_loss: 2.0722 - learning_rate: 1.2987e-04
Epoch 54/300
1413/1413 - 239s - 169ms/step - accuracy: 0.3827 - loss: 2.8732 - val_accuracy: 0.5748 - val_loss: 1.9524 - learning_rate: 1.2987e-04
Epoch 55/300
1413/1413 - 252s - 178ms/step - accuracy: 0.3903 - loss: 2.8599 - val_accuracy: 0.6146 - val_loss: 1.8625 - learning_rate: 1.2987e-04
Epoch 56/300
1413/1413 - 252s - 178ms/step - accuracy: 0.3936 - loss: 2.8632 - val_accuracy: 0.4769 - val_loss: 2.2385 - learning_rate: 1.2987e-04
Epoch 57/300
1413/1413 - 252s - 178ms/step - accuracy: 0.3910 - loss: 2.8617 - val_accuracy: 0.5398 - val_loss: 2.0126 - learning_rate: 1.2987e-04
Epoch 58/300
1413/1413 - 253s - 179ms/step - accuracy: 0.3932 - loss: 2.8343 - val_accuracy: 0.5478 - val_loss: 2.2162 - learning_rate: 1.2987e-04
Epoch 59/300
1413/1413 - 252s - 178ms/step - accuracy: 0.3912 - loss: 2.8557 - val_accuracy: 0.5191 - val_loss: 2.2945 - learning_rate: 1.2987e-04
Epoch 60/300
1413/1413 - 251s - 178ms/step - accuracy: 0.3955 - loss: 2.8235 - val_accuracy: 0.5255 - val_loss: 2.7029 - learning_rate: 1.2987e-04
Epoch 61/300
1413/1413 - 252s - 179ms/step - accuracy: 0.3971 - loss: 2.8442 - val_accuracy: 0.5836 - val_loss: 2.0142 - learning_rate: 1.2987e-04
Epoch 62/300
1413/1413 - 253s - 179ms/step - accuracy: 0.3996 - loss: 2.8227 - val_accuracy: 0.5565 - val_loss: 1.9609 - learning_rate: 1.2987e-04
Epoch 63/300

Epoch 63: ReduceLROnPlateau reducing learning rate to 6.493452383438125e-05.
1413/1413 - 251s - 177ms/step - accuracy: 0.3908 - loss: 2.8371 - val_accuracy: 0.4506 - val_loss: 3.0931 - learning_rate: 1.2987e-04
Epoch 64/300
1413/1413 - 252s - 178ms/step - accuracy: 0.4033 - loss: 2.7857 - val_accuracy: 0.6282 - val_loss: 1.6895 - learning_rate: 6.4935e-05
Epoch 65/300
1413/1413 - 251s - 178ms/step - accuracy: 0.4031 - loss: 2.7893 - val_accuracy: 0.6282 - val_loss: 1.7546 - learning_rate: 6.4935e-05
Epoch 66/300
1413/1413 - 253s - 179ms/step - accuracy: 0.4082 - loss: 2.7686 - val_accuracy: 0.6059 - val_loss: 2.0099 - learning_rate: 6.4935e-05
Epoch 67/300
1413/1413 - 251s - 178ms/step - accuracy: 0.4126 - loss: 2.7365 - val_accuracy: 0.5621 - val_loss: 2.3057 - learning_rate: 6.4935e-05
Epoch 68/300
1413/1413 - 252s - 178ms/step - accuracy: 0.4111 - loss: 2.7781 - val_accuracy: 0.6186 - val_loss: 1.7631 - learning_rate: 6.4935e-05
Epoch 69/300
1413/1413 - 252s - 179ms/step - accuracy: 0.4048 - loss: 2.7692 - val_accuracy: 0.6131 - val_loss: 1.7620 - learning_rate: 6.4935e-05
Epoch 70/300
1413/1413 - 252s - 178ms/step - accuracy: 0.4146 - loss: 2.7457 - val_accuracy: 0.6075 - val_loss: 1.7711 - learning_rate: 6.4935e-05
Epoch 71/300
1413/1413 - 250s - 177ms/step - accuracy: 0.4078 - loss: 2.7345 - val_accuracy: 0.6258 - val_loss: 1.7455 - learning_rate: 6.4935e-05
Epoch 72/300

Epoch 72: ReduceLROnPlateau reducing learning rate to 3.2467261917190626e-05.
1413/1413 - 249s - 176ms/step - accuracy: 0.4171 - loss: 2.7369 - val_accuracy: 0.6242 - val_loss: 1.7140 - learning_rate: 6.4935e-05
Epoch 73/300
1413/1413 - 249s - 176ms/step - accuracy: 0.4211 - loss: 2.7111 - val_accuracy: 0.6441 - val_loss: 1.6360 - learning_rate: 3.2467e-05
Epoch 74/300
1413/1413 - 249s - 176ms/step - accuracy: 0.4157 - loss: 2.7263 - val_accuracy: 0.6369 - val_loss: 1.7042 - learning_rate: 3.2467e-05
Epoch 75/300
1413/1413 - 248s - 176ms/step - accuracy: 0.4153 - loss: 2.7262 - val_accuracy: 0.6250 - val_loss: 1.7128 - learning_rate: 3.2467e-05
Epoch 76/300
1413/1413 - 248s - 175ms/step - accuracy: 0.4259 - loss: 2.6960 - val_accuracy: 0.6489 - val_loss: 1.6597 - learning_rate: 3.2467e-05
Epoch 77/300
1413/1413 - 241s - 171ms/step - accuracy: 0.4229 - loss: 2.6949 - val_accuracy: 0.6266 - val_loss: 1.7496 - learning_rate: 3.2467e-05
Epoch 78/300
1413/1413 - 242s - 172ms/step - accuracy: 0.4155 - loss: 2.7137 - val_accuracy: 0.6409 - val_loss: 1.6515 - learning_rate: 3.2467e-05
Epoch 79/300
1413/1413 - 244s - 173ms/step - accuracy: 0.4256 - loss: 2.6815 - val_accuracy: 0.6425 - val_loss: 1.6542 - learning_rate: 3.2467e-05
Epoch 80/300
1413/1413 - 244s - 173ms/step - accuracy: 0.4221 - loss: 2.7020 - val_accuracy: 0.6322 - val_loss: 1.7087 - learning_rate: 3.2467e-05
Epoch 81/300

Epoch 81: ReduceLROnPlateau reducing learning rate to 1.6233630958595313e-05.
1413/1413 - 243s - 172ms/step - accuracy: 0.4255 - loss: 2.6833 - val_accuracy: 0.6266 - val_loss: 1.7073 - learning_rate: 3.2467e-05
Epoch 82/300
1413/1413 - 247s - 175ms/step - accuracy: 0.4270 - loss: 2.6789 - val_accuracy: 0.6505 - val_loss: 1.5846 - learning_rate: 1.6234e-05
Epoch 83/300
1413/1413 - 245s - 174ms/step - accuracy: 0.4269 - loss: 2.6957 - val_accuracy: 0.6513 - val_loss: 1.6054 - learning_rate: 1.6234e-05
Epoch 84/300
1413/1413 - 246s - 174ms/step - accuracy: 0.4260 - loss: 2.6675 - val_accuracy: 0.6449 - val_loss: 1.6072 - learning_rate: 1.6234e-05
Epoch 85/300
1413/1413 - 245s - 174ms/step - accuracy: 0.4382 - loss: 2.6578 - val_accuracy: 0.6521 - val_loss: 1.6095 - learning_rate: 1.6234e-05
Epoch 86/300
1413/1413 - 247s - 175ms/step - accuracy: 0.4274 - loss: 2.6829 - val_accuracy: 0.6561 - val_loss: 1.6104 - learning_rate: 1.6234e-05
Epoch 87/300
1413/1413 - 246s - 174ms/step - accuracy: 0.4330 - loss: 2.6737 - val_accuracy: 0.6513 - val_loss: 1.5894 - learning_rate: 1.6234e-05
Epoch 88/300
1413/1413 - 246s - 174ms/step - accuracy: 0.4294 - loss: 2.6529 - val_accuracy: 0.6489 - val_loss: 1.6085 - learning_rate: 1.6234e-05
Epoch 89/300
1413/1413 - 247s - 175ms/step - accuracy: 0.4247 - loss: 2.6512 - val_accuracy: 0.6561 - val_loss: 1.5813 - learning_rate: 1.6234e-05
Epoch 90/300
1413/1413 - 247s - 175ms/step - accuracy: 0.4228 - loss: 2.6848 - val_accuracy: 0.6616 - val_loss: 1.5784 - learning_rate: 1.6234e-05
Epoch 91/300
1413/1413 - 249s - 176ms/step - accuracy: 0.4358 - loss: 2.6441 - val_accuracy: 0.6584 - val_loss: 1.5905 - learning_rate: 1.6234e-05
Epoch 92/300
1413/1413 - 238s - 168ms/step - accuracy: 0.4289 - loss: 2.6322 - val_accuracy: 0.6513 - val_loss: 1.5819 - learning_rate: 1.6234e-05
Epoch 93/300
1413/1413 - 242s - 171ms/step - accuracy: 0.4318 - loss: 2.6679 - val_accuracy: 0.6545 - val_loss: 1.5783 - learning_rate: 1.6234e-05
Epoch 94/300
1413/1413 - 239s - 169ms/step - accuracy: 0.4323 - loss: 2.6719 - val_accuracy: 0.6545 - val_loss: 1.5822 - learning_rate: 1.6234e-05
Epoch 95/300
1413/1413 - 248s - 175ms/step - accuracy: 0.4361 - loss: 2.6579 - val_accuracy: 0.6553 - val_loss: 1.6137 - learning_rate: 1.6234e-05
Epoch 96/300
1413/1413 - 246s - 174ms/step - accuracy: 0.4349 - loss: 2.6470 - val_accuracy: 0.6584 - val_loss: 1.6059 - learning_rate: 1.6234e-05
Epoch 97/300
1413/1413 - 247s - 175ms/step - accuracy: 0.4279 - loss: 2.6878 - val_accuracy: 0.6624 - val_loss: 1.5613 - learning_rate: 1.6234e-05
Epoch 98/300
1413/1413 - 248s - 175ms/step - accuracy: 0.4336 - loss: 2.6776 - val_accuracy: 0.6576 - val_loss: 1.5751 - learning_rate: 1.6234e-05
Epoch 99/300
1413/1413 - 247s - 175ms/step - accuracy: 0.4312 - loss: 2.6475 - val_accuracy: 0.6600 - val_loss: 1.5991 - learning_rate: 1.6234e-05
Epoch 100/300
1413/1413 - 247s - 175ms/step - accuracy: 0.4284 - loss: 2.6803 - val_accuracy: 0.6529 - val_loss: 1.6023 - learning_rate: 1.6234e-05
Epoch 101/300
1413/1413 - 247s - 175ms/step - accuracy: 0.4342 - loss: 2.6354 - val_accuracy: 0.6640 - val_loss: 1.5892 - learning_rate: 1.6234e-05
Epoch 102/300
1413/1413 - 247s - 175ms/step - accuracy: 0.4307 - loss: 2.6490 - val_accuracy: 0.6561 - val_loss: 1.5825 - learning_rate: 1.6234e-05
Epoch 103/300
1413/1413 - 246s - 174ms/step - accuracy: 0.4355 - loss: 2.6286 - val_accuracy: 0.6600 - val_loss: 1.6106 - learning_rate: 1.6234e-05
Epoch 104/300
1413/1413 - 243s - 172ms/step - accuracy: 0.4300 - loss: 2.6496 - val_accuracy: 0.6632 - val_loss: 1.5921 - learning_rate: 1.6234e-05
Epoch 105/300

Epoch 105: ReduceLROnPlateau reducing learning rate to 8.116815479297657e-06.
1413/1413 - 243s - 172ms/step - accuracy: 0.4302 - loss: 2.6671 - val_accuracy: 0.6521 - val_loss: 1.5824 - learning_rate: 1.6234e-05
Epoch 106/300
1413/1413 - 246s - 174ms/step - accuracy: 0.4289 - loss: 2.6700 - val_accuracy: 0.6608 - val_loss: 1.5569 - learning_rate: 8.1168e-06
Epoch 107/300
1413/1413 - 242s - 171ms/step - accuracy: 0.4374 - loss: 2.6306 - val_accuracy: 0.6624 - val_loss: 1.5634 - learning_rate: 8.1168e-06
Epoch 108/300
1413/1413 - 245s - 174ms/step - accuracy: 0.4304 - loss: 2.6678 - val_accuracy: 0.6672 - val_loss: 1.5800 - learning_rate: 8.1168e-06
Epoch 109/300
1413/1413 - 249s - 176ms/step - accuracy: 0.4355 - loss: 2.6409 - val_accuracy: 0.6576 - val_loss: 1.5802 - learning_rate: 8.1168e-06
Epoch 110/300
1413/1413 - 246s - 174ms/step - accuracy: 0.4330 - loss: 2.6453 - val_accuracy: 0.6600 - val_loss: 1.5684 - learning_rate: 8.1168e-06
Epoch 111/300
1413/1413 - 240s - 170ms/step - accuracy: 0.4316 - loss: 2.6347 - val_accuracy: 0.6616 - val_loss: 1.5688 - learning_rate: 8.1168e-06
Epoch 112/300
1413/1413 - 245s - 173ms/step - accuracy: 0.4370 - loss: 2.6423 - val_accuracy: 0.6592 - val_loss: 1.5729 - learning_rate: 8.1168e-06
Epoch 113/300
1413/1413 - 242s - 171ms/step - accuracy: 0.4398 - loss: 2.6276 - val_accuracy: 0.6656 - val_loss: 1.5604 - learning_rate: 8.1168e-06
Epoch 114/300
1413/1413 - 242s - 171ms/step - accuracy: 0.4321 - loss: 2.6224 - val_accuracy: 0.6672 - val_loss: 1.5560 - learning_rate: 8.1168e-06
Epoch 115/300
1413/1413 - 247s - 174ms/step - accuracy: 0.4326 - loss: 2.6472 - val_accuracy: 0.6632 - val_loss: 1.5621 - learning_rate: 8.1168e-06
Epoch 116/300
1413/1413 - 242s - 171ms/step - accuracy: 0.4318 - loss: 2.6333 - val_accuracy: 0.6672 - val_loss: 1.5641 - learning_rate: 8.1168e-06
Epoch 117/300
1413/1413 - 243s - 172ms/step - accuracy: 0.4353 - loss: 2.6256 - val_accuracy: 0.6648 - val_loss: 1.5843 - learning_rate: 8.1168e-06
Epoch 118/300
1413/1413 - 246s - 174ms/step - accuracy: 0.4350 - loss: 2.6238 - val_accuracy: 0.6760 - val_loss: 1.5491 - learning_rate: 8.1168e-06
Epoch 119/300
1413/1413 - 243s - 172ms/step - accuracy: 0.4413 - loss: 2.6261 - val_accuracy: 0.6672 - val_loss: 1.5601 - learning_rate: 8.1168e-06
Epoch 120/300
1413/1413 - 244s - 173ms/step - accuracy: 0.4315 - loss: 2.6324 - val_accuracy: 0.6696 - val_loss: 1.5472 - learning_rate: 8.1168e-06
Epoch 121/300
1413/1413 - 245s - 173ms/step - accuracy: 0.4374 - loss: 2.6269 - val_accuracy: 0.6712 - val_loss: 1.5436 - learning_rate: 8.1168e-06
Epoch 122/300
1413/1413 - 240s - 170ms/step - accuracy: 0.4322 - loss: 2.6527 - val_accuracy: 0.6688 - val_loss: 1.5743 - learning_rate: 8.1168e-06
Epoch 123/300
1413/1413 - 244s - 173ms/step - accuracy: 0.4324 - loss: 2.6401 - val_accuracy: 0.6720 - val_loss: 1.5648 - learning_rate: 8.1168e-06
Epoch 124/300
1413/1413 - 246s - 174ms/step - accuracy: 0.4384 - loss: 2.6399 - val_accuracy: 0.6728 - val_loss: 1.5593 - learning_rate: 8.1168e-06
Epoch 125/300
1413/1413 - 242s - 171ms/step - accuracy: 0.4355 - loss: 2.6297 - val_accuracy: 0.6736 - val_loss: 1.5313 - learning_rate: 8.1168e-06
Epoch 126/300
1413/1413 - 243s - 172ms/step - accuracy: 0.4345 - loss: 2.6458 - val_accuracy: 0.6728 - val_loss: 1.5456 - learning_rate: 8.1168e-06
Epoch 127/300
1413/1413 - 244s - 173ms/step - accuracy: 0.4363 - loss: 2.6299 - val_accuracy: 0.6736 - val_loss: 1.5543 - learning_rate: 8.1168e-06
Epoch 128/300
1413/1413 - 240s - 170ms/step - accuracy: 0.4379 - loss: 2.6229 - val_accuracy: 0.6688 - val_loss: 1.5506 - learning_rate: 8.1168e-06
Epoch 129/300
1413/1413 - 241s - 171ms/step - accuracy: 0.4336 - loss: 2.6309 - val_accuracy: 0.6600 - val_loss: 1.5965 - learning_rate: 8.1168e-06
Epoch 130/300
1413/1413 - 242s - 171ms/step - accuracy: 0.4356 - loss: 2.6194 - val_accuracy: 0.6616 - val_loss: 1.5435 - learning_rate: 8.1168e-06
Epoch 131/300
1413/1413 - 236s - 167ms/step - accuracy: 0.4386 - loss: 2.6563 - val_accuracy: 0.6632 - val_loss: 1.5625 - learning_rate: 8.1168e-06
Epoch 132/300
1413/1413 - 241s - 171ms/step - accuracy: 0.4387 - loss: 2.6564 - val_accuracy: 0.6680 - val_loss: 1.5873 - learning_rate: 8.1168e-06
Epoch 133/300

Epoch 133: ReduceLROnPlateau reducing learning rate to 4.058407739648828e-06.
1413/1413 - 240s - 170ms/step - accuracy: 0.4339 - loss: 2.6280 - val_accuracy: 0.6640 - val_loss: 1.5747 - learning_rate: 8.1168e-06
Epoch 134/300
1413/1413 - 237s - 168ms/step - accuracy: 0.4380 - loss: 2.6306 - val_accuracy: 0.6624 - val_loss: 1.5558 - learning_rate: 4.0584e-06
Epoch 135/300
1413/1413 - 241s - 171ms/step - accuracy: 0.4336 - loss: 2.6206 - val_accuracy: 0.6696 - val_loss: 1.5505 - learning_rate: 4.0584e-06
Epoch 136/300
1413/1413 - 240s - 170ms/step - accuracy: 0.4380 - loss: 2.6193 - val_accuracy: 0.6664 - val_loss: 1.5570 - learning_rate: 4.0584e-06
Epoch 137/300
1413/1413 - 230s - 163ms/step - accuracy: 0.4380 - loss: 2.6225 - val_accuracy: 0.6688 - val_loss: 1.5541 - learning_rate: 4.0584e-06
Epoch 138/300
1413/1413 - 236s - 167ms/step - accuracy: 0.4317 - loss: 2.6384 - val_accuracy: 0.6688 - val_loss: 1.5566 - learning_rate: 4.0584e-06
Epoch 139/300
1413/1413 - 236s - 167ms/step - accuracy: 0.4454 - loss: 2.5994 - val_accuracy: 0.6680 - val_loss: 1.5467 - learning_rate: 4.0584e-06
Epoch 140/300
1413/1413 - 233s - 165ms/step - accuracy: 0.4407 - loss: 2.6202 - val_accuracy: 0.6696 - val_loss: 1.5431 - learning_rate: 4.0584e-06
Epoch 141/300

Epoch 141: ReduceLROnPlateau reducing learning rate to 2.029203869824414e-06.
1413/1413 - 241s - 171ms/step - accuracy: 0.4368 - loss: 2.6020 - val_accuracy: 0.6720 - val_loss: 1.5526 - learning_rate: 4.0584e-06
Epoch 141: early stopping
Restoring model weights from the end of the best epoch: 125.
Fold 0 Evaluation results: [1.535260558128357, 0.6735668778419495]
              precision    recall  f1-score   support

        1820       0.91      0.81      0.85        62
        1821       0.90      0.91      0.90        57
        1822       0.00      0.00      0.00         1
        1823       0.25      1.00      0.40         1
        1824       0.00      0.00      0.00         1
        1825       0.00      0.00      0.00         3
        1826       0.00      0.00      0.00         2
        1827       0.92      0.88      0.90        25
        1828       0.00      0.00      0.00         1
        1829       0.62      1.00      0.77         5
        1830       0.85      0.61      0.71        56
        1831       0.86      0.90      0.88       134
        1832       0.71      0.79      0.75        67
        1833       1.00      0.89      0.94        19
        1834       0.55      0.76      0.64        29
        1835       0.00      0.00      0.00         2
        1836       0.00      0.00      0.00         4
        1837       0.28      0.83      0.42         6
        1838       0.50      0.33      0.40         3
        1839       0.00      0.00      0.00         1
        1840       0.71      0.74      0.73        43
        1841       0.83      0.70      0.76       108
        1842       0.62      0.83      0.71         6
        1843       1.00      0.50      0.67         6
        1844       0.00      0.00      0.00         1
        1845       0.00      0.00      0.00         1
        1846       0.27      0.50      0.35         6
        1847       0.00      0.00      0.00         2
        1848       1.00      0.20      0.33         5
        1849       0.22      0.33      0.27         6
        1850       0.51      0.50      0.51        48
        1851       0.79      0.78      0.78        77
        1852       0.00      0.00      0.00         7
        1853       0.40      0.29      0.33         7
        1854       0.25      0.33      0.29         3
        1855       0.54      0.61      0.57        23
        1856       0.53      0.67      0.59        12
        1857       0.43      0.63      0.51        30
        1858       0.00      0.00      0.00         2
        1859       0.00      0.00      0.00         2
        1860       0.30      0.37      0.33        65
        1861       0.88      0.81      0.85        85
        1862       0.31      0.21      0.25        19
        1863       0.65      0.58      0.61        19
        1864       0.50      0.65      0.56        17
        1865       0.40      0.86      0.55         7
        1866       0.25      0.20      0.22         5
        1867       0.54      0.64      0.58        11
        1868       0.00      0.00      0.00         7
        1869       0.00      0.00      0.00         5
        1870       0.43      0.58      0.49        31
        1871       0.84      0.84      0.84        49
        1872       0.60      0.43      0.50         7
        1873       0.12      0.10      0.11        10
        1874       0.25      0.20      0.22         5
        1875       0.50      0.14      0.22        14
        1876       0.62      0.80      0.70        10
        1877       0.33      0.60      0.43         5
        1878       0.38      0.33      0.35         9
        1879       0.00      0.00      0.00         2

    accuracy                           0.67      1256
   macro avg       0.41      0.43      0.40      1256
weighted avg       0.68      0.67      0.67      1256

Matthews Correlation Coefficient: 0.658
Macro avg F1: 0.396
Weighted avg F1: 0.667
Micro avg F1: 0.674
Top-3 Accuracy: 0.864
Top-5 Accuracy: 0.911
Micro ROC AUC  = 0.99
Macro ROC AUC (present classes) = 0.98
Classification MAE (in years): 2.67

Fold 0 Misclassification Analysis:
Near misses (within 2 years): 111 out of 410 misclassifications (27.07%)
Big misses (greater than 10 years): 171
MAE with outliers: 2.67
MAE without outliers: 1.86 (improvement: 0.81)

10 Worst misclassifications:
Image: data/datasets/public/1820/1820_030met.jpg, True: 1820, Predicted: 1873, Error: 53
Image: data/datasets/public/1820/1820_036met.jpg, True: 1820, Predicted: 1873, Error: 53
Image: data/datasets/public/1820/1826_44washington.jpg, True: 1826, Predicted: 1876, Error: 50
Image: data/datasets/private/1820/1820_102etsy.jpg, True: 1820, Predicted: 1863, Error: 43
Image: data/datasets/public/1820/1820_026met.jpg, True: 1820, Predicted: 1861, Error: 41
Image: data/datasets/public/1870/1873_014met.jpg, True: 1873, Predicted: 1832, Error: 41
Image: data/datasets/public/1820/1820_046met.jpg, True: 1820, Predicted: 1860, Error: 40
Image: data/datasets/public/1820/1820_050met.jpg, True: 1820, Predicted: 1857, Error: 37
Image: data/datasets/public/1820/1820_042met.jpg, True: 1820, Predicted: 1856, Error: 36
Image: data/datasets/public/1820/1825_819vna.jpg, True: 1825, Predicted: 1860, Error: 35
Metrics: {'accuracy': 0.6735668778419495, 'mae_years': np.float64(2.6687898089171975), 'mcc': np.float64(0.6578111391622576)}

=== Total running time: 9 hours, 38 minutes, 35 seconds ===

