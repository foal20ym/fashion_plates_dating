TensorFlow Version: 2.20.0-dev20250508
Num GPUs Available: 1
Using GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')

=== Using model: ConvNeXtTiny. ===
RUN ID: 2025-05-13_17:59:58
Test fold: 0

===== Fine Tuning 7 layers! =====
Epoch 1/300
1413/1413 - 184s - 130ms/step - accuracy: 0.1410 - loss: 4.4029 - val_accuracy: 0.2150 - val_loss: 4.3771 - learning_rate: 2.0479e-04
Epoch 2/300
1413/1413 - 101s - 71ms/step - accuracy: 0.1866 - loss: 4.0414 - val_accuracy: 0.3201 - val_loss: 3.8131 - learning_rate: 2.0479e-04
Epoch 3/300
1413/1413 - 99s - 70ms/step - accuracy: 0.2008 - loss: 3.9334 - val_accuracy: 0.2930 - val_loss: 3.8146 - learning_rate: 2.0479e-04
Epoch 4/300
1413/1413 - 98s - 70ms/step - accuracy: 0.2200 - loss: 3.8439 - val_accuracy: 0.3368 - val_loss: 3.2560 - learning_rate: 2.0479e-04
Epoch 5/300
1413/1413 - 98s - 69ms/step - accuracy: 0.2263 - loss: 3.7635 - val_accuracy: 0.3527 - val_loss: 3.3677 - learning_rate: 2.0479e-04
Epoch 6/300
1413/1413 - 98s - 69ms/step - accuracy: 0.2392 - loss: 3.7020 - val_accuracy: 0.3543 - val_loss: 3.4089 - learning_rate: 2.0479e-04
Epoch 7/300
1413/1413 - 97s - 69ms/step - accuracy: 0.2449 - loss: 3.6995 - val_accuracy: 0.3487 - val_loss: 3.4042 - learning_rate: 2.0479e-04
Epoch 8/300
1413/1413 - 99s - 70ms/step - accuracy: 0.2429 - loss: 3.6604 - val_accuracy: 0.3742 - val_loss: 3.3536 - learning_rate: 2.0479e-04
Epoch 9/300
1413/1413 - 99s - 70ms/step - accuracy: 0.2568 - loss: 3.6009 - val_accuracy: 0.3296 - val_loss: 3.2010 - learning_rate: 2.0479e-04
Epoch 10/300
1413/1413 - 100s - 71ms/step - accuracy: 0.2605 - loss: 3.5850 - val_accuracy: 0.3702 - val_loss: 3.0313 - learning_rate: 2.0479e-04
Epoch 11/300
1413/1413 - 97s - 69ms/step - accuracy: 0.2655 - loss: 3.5605 - val_accuracy: 0.3997 - val_loss: 2.8805 - learning_rate: 2.0479e-04
Epoch 12/300
1413/1413 - 97s - 69ms/step - accuracy: 0.2705 - loss: 3.5254 - val_accuracy: 0.3201 - val_loss: 3.0768 - learning_rate: 2.0479e-04
Epoch 13/300
1413/1413 - 100s - 71ms/step - accuracy: 0.2705 - loss: 3.5174 - val_accuracy: 0.3471 - val_loss: 3.2315 - learning_rate: 2.0479e-04
Epoch 14/300
1413/1413 - 99s - 70ms/step - accuracy: 0.2732 - loss: 3.4920 - val_accuracy: 0.4029 - val_loss: 3.0236 - learning_rate: 2.0479e-04
Epoch 15/300
1413/1413 - 98s - 69ms/step - accuracy: 0.2827 - loss: 3.4915 - val_accuracy: 0.3328 - val_loss: 3.2038 - learning_rate: 2.0479e-04
Epoch 16/300
1413/1413 - 98s - 70ms/step - accuracy: 0.2793 - loss: 3.4608 - val_accuracy: 0.3798 - val_loss: 3.0853 - learning_rate: 2.0479e-04
Epoch 17/300
1413/1413 - 98s - 69ms/step - accuracy: 0.2752 - loss: 3.4702 - val_accuracy: 0.4021 - val_loss: 3.2323 - learning_rate: 2.0479e-04
Epoch 18/300
1413/1413 - 98s - 70ms/step - accuracy: 0.2842 - loss: 3.4162 - val_accuracy: 0.4061 - val_loss: 3.1237 - learning_rate: 2.0479e-04
Epoch 19/300
1413/1413 - 99s - 70ms/step - accuracy: 0.2927 - loss: 3.4171 - val_accuracy: 0.4164 - val_loss: 2.8516 - learning_rate: 2.0479e-04
Epoch 20/300
1413/1413 - 99s - 70ms/step - accuracy: 0.2885 - loss: 3.3877 - val_accuracy: 0.4395 - val_loss: 2.8802 - learning_rate: 2.0479e-04
Epoch 21/300
1413/1413 - 99s - 70ms/step - accuracy: 0.2964 - loss: 3.3778 - val_accuracy: 0.3121 - val_loss: 3.7078 - learning_rate: 2.0479e-04
Epoch 22/300
1413/1413 - 99s - 70ms/step - accuracy: 0.2897 - loss: 3.4148 - val_accuracy: 0.3790 - val_loss: 3.2217 - learning_rate: 2.0479e-04
Epoch 23/300
1413/1413 - 98s - 69ms/step - accuracy: 0.2959 - loss: 3.3726 - val_accuracy: 0.3424 - val_loss: 3.4163 - learning_rate: 2.0479e-04
Epoch 24/300
1413/1413 - 99s - 70ms/step - accuracy: 0.2941 - loss: 3.3650 - val_accuracy: 0.4053 - val_loss: 2.9106 - learning_rate: 2.0479e-04
Epoch 25/300
1413/1413 - 98s - 69ms/step - accuracy: 0.2979 - loss: 3.3520 - val_accuracy: 0.3854 - val_loss: 2.9856 - learning_rate: 2.0479e-04
Epoch 26/300
1413/1413 - 98s - 70ms/step - accuracy: 0.2993 - loss: 3.3564 - val_accuracy: 0.3352 - val_loss: 3.6962 - learning_rate: 2.0479e-04
Epoch 27/300

Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00010239420953439549.
1413/1413 - 98s - 70ms/step - accuracy: 0.3066 - loss: 3.3154 - val_accuracy: 0.3702 - val_loss: 4.0753 - learning_rate: 2.0479e-04
Epoch 28/300
1413/1413 - 98s - 69ms/step - accuracy: 0.3166 - loss: 3.2720 - val_accuracy: 0.4387 - val_loss: 2.6615 - learning_rate: 1.0239e-04
Epoch 29/300
1413/1413 - 99s - 70ms/step - accuracy: 0.3128 - loss: 3.2662 - val_accuracy: 0.4546 - val_loss: 2.6757 - learning_rate: 1.0239e-04
Epoch 30/300
1413/1413 - 99s - 70ms/step - accuracy: 0.3181 - loss: 3.2603 - val_accuracy: 0.4737 - val_loss: 2.4804 - learning_rate: 1.0239e-04
Epoch 31/300
1413/1413 - 99s - 70ms/step - accuracy: 0.3215 - loss: 3.2144 - val_accuracy: 0.4674 - val_loss: 2.4367 - learning_rate: 1.0239e-04
Epoch 32/300
1413/1413 - 99s - 70ms/step - accuracy: 0.3235 - loss: 3.2253 - val_accuracy: 0.4793 - val_loss: 2.5180 - learning_rate: 1.0239e-04
Epoch 33/300
1413/1413 - 98s - 69ms/step - accuracy: 0.3260 - loss: 3.2232 - val_accuracy: 0.4833 - val_loss: 2.4588 - learning_rate: 1.0239e-04
Epoch 34/300
1413/1413 - 97s - 69ms/step - accuracy: 0.3257 - loss: 3.2208 - val_accuracy: 0.4817 - val_loss: 2.5105 - learning_rate: 1.0239e-04
Epoch 35/300
1413/1413 - 99s - 70ms/step - accuracy: 0.3249 - loss: 3.1973 - val_accuracy: 0.4666 - val_loss: 2.6020 - learning_rate: 1.0239e-04
Epoch 36/300
1413/1413 - 99s - 70ms/step - accuracy: 0.3279 - loss: 3.2164 - val_accuracy: 0.4618 - val_loss: 2.5795 - learning_rate: 1.0239e-04
Epoch 37/300
1413/1413 - 98s - 69ms/step - accuracy: 0.3276 - loss: 3.1885 - val_accuracy: 0.4323 - val_loss: 3.0057 - learning_rate: 1.0239e-04
Epoch 38/300
1413/1413 - 99s - 70ms/step - accuracy: 0.3373 - loss: 3.1708 - val_accuracy: 0.4801 - val_loss: 2.4814 - learning_rate: 1.0239e-04
Epoch 39/300

Epoch 39: ReduceLROnPlateau reducing learning rate to 5.119710476719774e-05.
1413/1413 - 98s - 69ms/step - accuracy: 0.3311 - loss: 3.1704 - val_accuracy: 0.4291 - val_loss: 2.8411 - learning_rate: 1.0239e-04
Epoch 40/300
1413/1413 - 98s - 69ms/step - accuracy: 0.3381 - loss: 3.1395 - val_accuracy: 0.5279 - val_loss: 2.3450 - learning_rate: 5.1197e-05
Epoch 41/300
1413/1413 - 99s - 70ms/step - accuracy: 0.3289 - loss: 3.1692 - val_accuracy: 0.4849 - val_loss: 2.3743 - learning_rate: 5.1197e-05
Epoch 42/300
1413/1413 - 98s - 69ms/step - accuracy: 0.3501 - loss: 3.0770 - val_accuracy: 0.4936 - val_loss: 2.2934 - learning_rate: 5.1197e-05
Epoch 43/300
1413/1413 - 99s - 70ms/step - accuracy: 0.3468 - loss: 3.1082 - val_accuracy: 0.4968 - val_loss: 2.5035 - learning_rate: 5.1197e-05
Epoch 44/300
1413/1413 - 98s - 70ms/step - accuracy: 0.3499 - loss: 3.1096 - val_accuracy: 0.5056 - val_loss: 2.2628 - learning_rate: 5.1197e-05
Epoch 45/300
1413/1413 - 98s - 69ms/step - accuracy: 0.3388 - loss: 3.1256 - val_accuracy: 0.4928 - val_loss: 2.5935 - learning_rate: 5.1197e-05
Epoch 46/300
1413/1413 - 98s - 69ms/step - accuracy: 0.3452 - loss: 3.1074 - val_accuracy: 0.5008 - val_loss: 2.3978 - learning_rate: 5.1197e-05
Epoch 47/300
1413/1413 - 96s - 68ms/step - accuracy: 0.3482 - loss: 3.0887 - val_accuracy: 0.4976 - val_loss: 2.3899 - learning_rate: 5.1197e-05
Epoch 48/300
1413/1413 - 96s - 68ms/step - accuracy: 0.3388 - loss: 3.1214 - val_accuracy: 0.5056 - val_loss: 2.3016 - learning_rate: 5.1197e-05
Epoch 49/300
1413/1413 - 97s - 69ms/step - accuracy: 0.3470 - loss: 3.0968 - val_accuracy: 0.4817 - val_loss: 2.8283 - learning_rate: 5.1197e-05
Epoch 50/300
1413/1413 - 96s - 68ms/step - accuracy: 0.3459 - loss: 3.1036 - val_accuracy: 0.5199 - val_loss: 2.3328 - learning_rate: 5.1197e-05
Epoch 51/300
1413/1413 - 100s - 71ms/step - accuracy: 0.3412 - loss: 3.1096 - val_accuracy: 0.5096 - val_loss: 2.4960 - learning_rate: 5.1197e-05
Epoch 52/300
1413/1413 - 101s - 71ms/step - accuracy: 0.3431 - loss: 3.0871 - val_accuracy: 0.5366 - val_loss: 2.2573 - learning_rate: 5.1197e-05
Epoch 53/300
1413/1413 - 100s - 71ms/step - accuracy: 0.3501 - loss: 3.0708 - val_accuracy: 0.5191 - val_loss: 2.2665 - learning_rate: 5.1197e-05
Epoch 54/300
1413/1413 - 99s - 70ms/step - accuracy: 0.3461 - loss: 3.0770 - val_accuracy: 0.5040 - val_loss: 2.3746 - learning_rate: 5.1197e-05
Epoch 55/300
1413/1413 - 100s - 71ms/step - accuracy: 0.3519 - loss: 3.0689 - val_accuracy: 0.5143 - val_loss: 2.3284 - learning_rate: 5.1197e-05
Epoch 56/300
1413/1413 - 99s - 70ms/step - accuracy: 0.3455 - loss: 3.0738 - val_accuracy: 0.5183 - val_loss: 2.3984 - learning_rate: 5.1197e-05
Epoch 57/300
1413/1413 - 99s - 70ms/step - accuracy: 0.3566 - loss: 3.0668 - val_accuracy: 0.4920 - val_loss: 2.4856 - learning_rate: 5.1197e-05
Epoch 58/300
1413/1413 - 99s - 70ms/step - accuracy: 0.3490 - loss: 3.0732 - val_accuracy: 0.5438 - val_loss: 2.2965 - learning_rate: 5.1197e-05
Epoch 59/300
1413/1413 - 99s - 70ms/step - accuracy: 0.3520 - loss: 3.0762 - val_accuracy: 0.5096 - val_loss: 2.3315 - learning_rate: 5.1197e-05
Epoch 60/300

Epoch 60: ReduceLROnPlateau reducing learning rate to 2.559855238359887e-05.
1413/1413 - 100s - 71ms/step - accuracy: 0.3536 - loss: 3.0661 - val_accuracy: 0.5311 - val_loss: 2.3195 - learning_rate: 5.1197e-05
Epoch 61/300
1413/1413 - 99s - 70ms/step - accuracy: 0.3584 - loss: 3.0430 - val_accuracy: 0.5199 - val_loss: 2.3581 - learning_rate: 2.5599e-05
Epoch 62/300
1413/1413 - 99s - 70ms/step - accuracy: 0.3565 - loss: 3.0562 - val_accuracy: 0.5438 - val_loss: 2.1779 - learning_rate: 2.5599e-05
Epoch 63/300
1413/1413 - 98s - 69ms/step - accuracy: 0.3607 - loss: 3.0570 - val_accuracy: 0.5159 - val_loss: 2.4324 - learning_rate: 2.5599e-05
Epoch 64/300
1413/1413 - 95s - 67ms/step - accuracy: 0.3555 - loss: 3.0461 - val_accuracy: 0.5199 - val_loss: 2.3501 - learning_rate: 2.5599e-05
Epoch 65/300
1413/1413 - 98s - 69ms/step - accuracy: 0.3587 - loss: 3.0368 - val_accuracy: 0.5287 - val_loss: 2.1690 - learning_rate: 2.5599e-05
Epoch 66/300
1413/1413 - 97s - 69ms/step - accuracy: 0.3589 - loss: 3.0356 - val_accuracy: 0.5406 - val_loss: 2.2090 - learning_rate: 2.5599e-05
Epoch 67/300
1413/1413 - 97s - 69ms/step - accuracy: 0.3572 - loss: 3.0520 - val_accuracy: 0.5342 - val_loss: 2.1742 - learning_rate: 2.5599e-05
Epoch 68/300
1413/1413 - 96s - 68ms/step - accuracy: 0.3555 - loss: 3.0416 - val_accuracy: 0.5255 - val_loss: 2.3018 - learning_rate: 2.5599e-05
Epoch 69/300
1413/1413 - 97s - 69ms/step - accuracy: 0.3599 - loss: 3.0483 - val_accuracy: 0.5573 - val_loss: 2.2375 - learning_rate: 2.5599e-05
Epoch 70/300
1413/1413 - 98s - 69ms/step - accuracy: 0.3656 - loss: 3.0138 - val_accuracy: 0.5446 - val_loss: 2.2650 - learning_rate: 2.5599e-05
Epoch 71/300
1413/1413 - 97s - 69ms/step - accuracy: 0.3652 - loss: 3.0281 - val_accuracy: 0.5398 - val_loss: 2.2638 - learning_rate: 2.5599e-05
Epoch 72/300
1413/1413 - 97s - 69ms/step - accuracy: 0.3634 - loss: 3.0354 - val_accuracy: 0.5446 - val_loss: 2.1475 - learning_rate: 2.5599e-05
Epoch 73/300
1413/1413 - 97s - 68ms/step - accuracy: 0.3638 - loss: 3.0202 - val_accuracy: 0.5398 - val_loss: 2.2132 - learning_rate: 2.5599e-05
Epoch 74/300
1413/1413 - 97s - 69ms/step - accuracy: 0.3695 - loss: 3.0083 - val_accuracy: 0.5350 - val_loss: 2.2107 - learning_rate: 2.5599e-05
Epoch 75/300
1413/1413 - 99s - 70ms/step - accuracy: 0.3661 - loss: 3.0183 - val_accuracy: 0.5454 - val_loss: 2.2025 - learning_rate: 2.5599e-05
Epoch 76/300
1413/1413 - 99s - 70ms/step - accuracy: 0.3695 - loss: 3.0029 - val_accuracy: 0.5318 - val_loss: 2.2448 - learning_rate: 2.5599e-05
Epoch 77/300
1413/1413 - 98s - 69ms/step - accuracy: 0.3624 - loss: 3.0200 - val_accuracy: 0.5414 - val_loss: 2.2009 - learning_rate: 2.5599e-05
Epoch 78/300
1413/1413 - 98s - 69ms/step - accuracy: 0.3699 - loss: 2.9980 - val_accuracy: 0.5414 - val_loss: 2.1674 - learning_rate: 2.5599e-05
Epoch 79/300
1413/1413 - 97s - 69ms/step - accuracy: 0.3657 - loss: 3.0027 - val_accuracy: 0.5207 - val_loss: 2.2088 - learning_rate: 2.5599e-05
Epoch 80/300
1413/1413 - 97s - 69ms/step - accuracy: 0.3630 - loss: 3.0008 - val_accuracy: 0.5478 - val_loss: 2.1342 - learning_rate: 2.5599e-05
Epoch 81/300
1413/1413 - 97s - 69ms/step - accuracy: 0.3632 - loss: 3.0115 - val_accuracy: 0.5414 - val_loss: 2.1875 - learning_rate: 2.5599e-05
Epoch 82/300
1413/1413 - 97s - 68ms/step - accuracy: 0.3689 - loss: 2.9982 - val_accuracy: 0.5279 - val_loss: 2.2760 - learning_rate: 2.5599e-05
Epoch 83/300
1413/1413 - 97s - 69ms/step - accuracy: 0.3723 - loss: 2.9929 - val_accuracy: 0.5525 - val_loss: 2.1857 - learning_rate: 2.5599e-05
Epoch 84/300
1413/1413 - 97s - 68ms/step - accuracy: 0.3657 - loss: 2.9992 - val_accuracy: 0.5350 - val_loss: 2.2293 - learning_rate: 2.5599e-05
Epoch 85/300
1413/1413 - 96s - 68ms/step - accuracy: 0.3676 - loss: 3.0114 - val_accuracy: 0.5382 - val_loss: 2.3443 - learning_rate: 2.5599e-05
Epoch 86/300
1413/1413 - 97s - 69ms/step - accuracy: 0.3711 - loss: 2.9790 - val_accuracy: 0.5295 - val_loss: 2.2305 - learning_rate: 2.5599e-05
Epoch 87/300
1413/1413 - 96s - 68ms/step - accuracy: 0.3719 - loss: 2.9853 - val_accuracy: 0.5597 - val_loss: 2.0743 - learning_rate: 2.5599e-05
Epoch 88/300
1413/1413 - 101s - 72ms/step - accuracy: 0.3767 - loss: 2.9717 - val_accuracy: 0.5446 - val_loss: 2.1733 - learning_rate: 2.5599e-05
Epoch 89/300
1413/1413 - 107s - 76ms/step - accuracy: 0.3684 - loss: 2.9756 - val_accuracy: 0.5430 - val_loss: 2.1223 - learning_rate: 2.5599e-05
Epoch 90/300
1413/1413 - 109s - 77ms/step - accuracy: 0.3694 - loss: 2.9872 - val_accuracy: 0.5462 - val_loss: 2.2276 - learning_rate: 2.5599e-05
Epoch 91/300
1413/1413 - 108s - 76ms/step - accuracy: 0.3634 - loss: 2.9934 - val_accuracy: 0.5510 - val_loss: 2.1409 - learning_rate: 2.5599e-05
Epoch 92/300
1413/1413 - 108s - 76ms/step - accuracy: 0.3686 - loss: 2.9843 - val_accuracy: 0.5605 - val_loss: 2.1216 - learning_rate: 2.5599e-05
Epoch 93/300
1413/1413 - 107s - 76ms/step - accuracy: 0.3691 - loss: 3.0088 - val_accuracy: 0.5557 - val_loss: 2.1650 - learning_rate: 2.5599e-05
Epoch 94/300
1413/1413 - 108s - 76ms/step - accuracy: 0.3763 - loss: 2.9603 - val_accuracy: 0.5438 - val_loss: 2.1538 - learning_rate: 2.5599e-05
Epoch 95/300

Epoch 95: ReduceLROnPlateau reducing learning rate to 1.2799276191799436e-05.
1413/1413 - 108s - 77ms/step - accuracy: 0.3667 - loss: 3.0072 - val_accuracy: 0.5533 - val_loss: 2.0983 - learning_rate: 2.5599e-05
Epoch 96/300
1413/1413 - 107s - 76ms/step - accuracy: 0.3735 - loss: 2.9795 - val_accuracy: 0.5478 - val_loss: 2.1634 - learning_rate: 1.2799e-05
Epoch 97/300
1413/1413 - 111s - 78ms/step - accuracy: 0.3802 - loss: 2.9499 - val_accuracy: 0.5621 - val_loss: 2.1073 - learning_rate: 1.2799e-05
Epoch 98/300
1413/1413 - 109s - 77ms/step - accuracy: 0.3764 - loss: 2.9497 - val_accuracy: 0.5669 - val_loss: 2.0929 - learning_rate: 1.2799e-05
Epoch 99/300
1413/1413 - 100s - 71ms/step - accuracy: 0.3722 - loss: 2.9770 - val_accuracy: 0.5573 - val_loss: 2.1440 - learning_rate: 1.2799e-05
Epoch 100/300
1413/1413 - 96s - 68ms/step - accuracy: 0.3748 - loss: 2.9639 - val_accuracy: 0.5533 - val_loss: 2.1690 - learning_rate: 1.2799e-05
Epoch 101/300
1413/1413 - 97s - 68ms/step - accuracy: 0.3809 - loss: 2.9477 - val_accuracy: 0.5494 - val_loss: 2.1166 - learning_rate: 1.2799e-05
Epoch 102/300
1413/1413 - 97s - 69ms/step - accuracy: 0.3680 - loss: 2.9724 - val_accuracy: 0.5621 - val_loss: 2.0871 - learning_rate: 1.2799e-05
Epoch 103/300

Epoch 103: ReduceLROnPlateau reducing learning rate to 6.399638095899718e-06.
1413/1413 - 98s - 69ms/step - accuracy: 0.3720 - loss: 2.9657 - val_accuracy: 0.5518 - val_loss: 2.1142 - learning_rate: 1.2799e-05
Epoch 103: early stopping
Restoring model weights from the end of the best epoch: 87.
Fold 0 Evaluation results: [2.0777652263641357, 0.5597133636474609]
              precision    recall  f1-score   support

        1820       0.78      0.65      0.71        62
        1821       0.73      0.72      0.73        57
        1822       0.00      0.00      0.00         1
        1823       0.00      0.00      0.00         1
        1824       0.00      0.00      0.00         1
        1825       0.00      0.00      0.00         3
        1826       0.00      0.00      0.00         2
        1827       0.81      0.88      0.85        25
        1828       0.00      0.00      0.00         1
        1829       0.29      0.80      0.42         5
        1830       0.50      0.43      0.46        56
        1831       0.70      0.89      0.78       134
        1832       0.61      0.69      0.64        67
        1833       0.76      0.68      0.72        19
        1834       0.46      0.55      0.50        29
        1835       0.00      0.00      0.00         2
        1836       0.00      0.00      0.00         4
        1837       0.18      0.33      0.24         6
        1838       1.00      0.67      0.80         3
        1839       0.00      0.00      0.00         1
        1840       0.56      0.53      0.55        43
        1841       0.57      0.60      0.59       108
        1842       0.50      0.33      0.40         6
        1843       0.00      0.00      0.00         6
        1844       0.00      0.00      0.00         1
        1845       0.00      0.00      0.00         1
        1846       0.29      0.33      0.31         6
        1847       0.00      0.00      0.00         2
        1848       0.00      0.00      0.00         5
        1849       0.10      0.17      0.12         6
        1850       0.36      0.44      0.39        48
        1851       0.65      0.66      0.65        77
        1852       0.00      0.00      0.00         7
        1853       0.00      0.00      0.00         7
        1854       0.00      0.00      0.00         3
        1855       0.62      0.35      0.44        23
        1856       0.40      0.17      0.24        12
        1857       0.40      0.53      0.46        30
        1858       0.00      0.00      0.00         2
        1859       0.00      0.00      0.00         2
        1860       0.41      0.35      0.38        65
        1861       0.59      0.73      0.65        85
        1862       0.50      0.37      0.42        19
        1863       0.38      0.42      0.40        19
        1864       0.45      0.53      0.49        17
        1865       0.50      0.29      0.36         7
        1866       0.33      0.20      0.25         5
        1867       0.29      0.36      0.32        11
        1868       0.00      0.00      0.00         7
        1869       0.00      0.00      0.00         5
        1870       0.42      0.35      0.39        31
        1871       0.59      0.84      0.69        49
        1872       0.50      0.14      0.22         7
        1873       0.00      0.00      0.00        10
        1874       0.00      0.00      0.00         5
        1875       0.45      0.36      0.40        14
        1876       0.67      0.60      0.63        10
        1877       0.33      0.20      0.25         5
        1878       0.25      0.22      0.24         9
        1879       0.00      0.00      0.00         2

    accuracy                           0.56      1256
   macro avg       0.30      0.29      0.28      1256
weighted avg       0.53      0.56      0.54      1256

Matthews Correlation Coefficient: 0.536
Macro avg F1: 0.285
Weighted avg F1: 0.538
Micro avg F1: 0.560
Top-3 Accuracy: 0.792
Top-5 Accuracy: 0.861
Micro ROC AUC  = 0.98
Macro ROC AUC (present classes) = 0.96
Classification MAE (in years): 3.97

Fold 0 Misclassification Analysis:
Near misses (within 2 years): 139 out of 553 misclassifications (25.14%)
MAE with outliers: 3.97
MAE without outliers: 2.64 (improvement: 1.33)

5 Worst misclassifications:
Image: data/datasets/public/1820/1820_036met.jpg, True: 1820, Predicted: 1867, Error: 47
Image: data/datasets/public/1870/1879_1476vna.jpg, True: 1879, Predicted: 1832, Error: 47
Image: data/datasets/public/1870/1876_447vna.jpg, True: 1876, Predicted: 1832, Error: 44
Image: data/datasets/public/1870/1873_014met.jpg, True: 1873, Predicted: 1832, Error: 41
Image: data/datasets/public/1820/1820_026met.jpg, True: 1820, Predicted: 1860, Error: 40
Image: data/datasets/public/1830/1830_141wikimedia2.jpg, True: 1830, Predicted: 1870, Error: 40
Image: data/datasets/private/1870/1871_412etsy.jpg, True: 1871, Predicted: 1832, Error: 39
Image: data/datasets/public/1870/1872_1407vna.jpg, True: 1872, Predicted: 1834, Error: 38
Image: data/datasets/public/1870/1872_1405vna.jpg, True: 1872, Predicted: 1834, Error: 38
Image: data/datasets/public/1830/1832_310vna.jpg, True: 1832, Predicted: 1870, Error: 38
Metrics: {'accuracy': 0.5597133636474609, 'mae_years': np.float64(3.968949044585987), 'mcc': np.float64(0.5361571771433393)}

=== Total running time: 2 hours, 52 minutes, 36 seconds ===

