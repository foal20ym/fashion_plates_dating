TensorFlow Version: 2.20.0-dev20250508
Num GPUs Available: 1
Using GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')

=== Using model: InceptionV3. ===
RUN ID: 2025-05-12_06:37:28
Test fold: 0

===== Fine Tuning 7 layers! =====
Epoch 1/300
1413/1413 - 163s - 115ms/step - accuracy: 0.1913 - loss: 4.0284 - val_accuracy: 0.3336 - val_loss: 3.3307 - learning_rate: 6.8751e-04
Epoch 2/300
1413/1413 - 99s - 70ms/step - accuracy: 0.2790 - loss: 3.5488 - val_accuracy: 0.3965 - val_loss: 2.8205 - learning_rate: 6.8751e-04
Epoch 3/300
1413/1413 - 96s - 68ms/step - accuracy: 0.3104 - loss: 3.3396 - val_accuracy: 0.4260 - val_loss: 2.6388 - learning_rate: 6.8751e-04
Epoch 4/300
1413/1413 - 96s - 68ms/step - accuracy: 0.3335 - loss: 3.2134 - val_accuracy: 0.4275 - val_loss: 2.6684 - learning_rate: 6.8751e-04
Epoch 5/300
1413/1413 - 93s - 66ms/step - accuracy: 0.3373 - loss: 3.1875 - val_accuracy: 0.4713 - val_loss: 2.5582 - learning_rate: 6.8751e-04
Epoch 6/300
1413/1413 - 94s - 66ms/step - accuracy: 0.3551 - loss: 3.0948 - val_accuracy: 0.4753 - val_loss: 2.4558 - learning_rate: 6.8751e-04
Epoch 7/300
1413/1413 - 93s - 66ms/step - accuracy: 0.3548 - loss: 3.0663 - val_accuracy: 0.4793 - val_loss: 2.4233 - learning_rate: 6.8751e-04
Epoch 8/300
1413/1413 - 94s - 67ms/step - accuracy: 0.3678 - loss: 3.0199 - val_accuracy: 0.4952 - val_loss: 2.4623 - learning_rate: 6.8751e-04
Epoch 9/300
1413/1413 - 96s - 68ms/step - accuracy: 0.3623 - loss: 3.0188 - val_accuracy: 0.5127 - val_loss: 2.3322 - learning_rate: 6.8751e-04
Epoch 10/300
1413/1413 - 95s - 68ms/step - accuracy: 0.3728 - loss: 2.9772 - val_accuracy: 0.5032 - val_loss: 2.2825 - learning_rate: 6.8751e-04
Epoch 11/300
1413/1413 - 93s - 66ms/step - accuracy: 0.3855 - loss: 2.9222 - val_accuracy: 0.5159 - val_loss: 2.2499 - learning_rate: 6.8751e-04
Epoch 12/300
1413/1413 - 92s - 65ms/step - accuracy: 0.3788 - loss: 2.9295 - val_accuracy: 0.5119 - val_loss: 2.3405 - learning_rate: 6.8751e-04
Epoch 13/300
1413/1413 - 93s - 66ms/step - accuracy: 0.3859 - loss: 2.9096 - val_accuracy: 0.5199 - val_loss: 2.1701 - learning_rate: 6.8751e-04
Epoch 14/300
1413/1413 - 93s - 66ms/step - accuracy: 0.3901 - loss: 2.9153 - val_accuracy: 0.5183 - val_loss: 2.2165 - learning_rate: 6.8751e-04
Epoch 15/300
1413/1413 - 94s - 67ms/step - accuracy: 0.3857 - loss: 2.9238 - val_accuracy: 0.5390 - val_loss: 2.0973 - learning_rate: 6.8751e-04
Epoch 16/300
1413/1413 - 94s - 66ms/step - accuracy: 0.3944 - loss: 2.8797 - val_accuracy: 0.5287 - val_loss: 2.3751 - learning_rate: 6.8751e-04
Epoch 17/300
1413/1413 - 93s - 66ms/step - accuracy: 0.3920 - loss: 2.8769 - val_accuracy: 0.5318 - val_loss: 2.1201 - learning_rate: 6.8751e-04
Epoch 18/300
1413/1413 - 93s - 66ms/step - accuracy: 0.3964 - loss: 2.8468 - val_accuracy: 0.5414 - val_loss: 2.1341 - learning_rate: 6.8751e-04
Epoch 19/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4019 - loss: 2.8133 - val_accuracy: 0.5573 - val_loss: 2.1970 - learning_rate: 6.8751e-04
Epoch 20/300
1413/1413 - 93s - 66ms/step - accuracy: 0.3942 - loss: 2.8437 - val_accuracy: 0.5518 - val_loss: 2.1222 - learning_rate: 6.8751e-04
Epoch 21/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4033 - loss: 2.8168 - val_accuracy: 0.5255 - val_loss: 2.2030 - learning_rate: 6.8751e-04
Epoch 22/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4095 - loss: 2.8033 - val_accuracy: 0.5287 - val_loss: 2.2244 - learning_rate: 6.8751e-04
Epoch 23/300

Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0003437538689468056.
1413/1413 - 94s - 67ms/step - accuracy: 0.4061 - loss: 2.8011 - val_accuracy: 0.5478 - val_loss: 2.1368 - learning_rate: 6.8751e-04
Epoch 24/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4279 - loss: 2.7027 - val_accuracy: 0.5804 - val_loss: 2.0049 - learning_rate: 3.4375e-04
Epoch 25/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4328 - loss: 2.6618 - val_accuracy: 0.5804 - val_loss: 1.9175 - learning_rate: 3.4375e-04
Epoch 26/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4284 - loss: 2.6505 - val_accuracy: 0.5764 - val_loss: 1.9695 - learning_rate: 3.4375e-04
Epoch 27/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4380 - loss: 2.6565 - val_accuracy: 0.5780 - val_loss: 1.9264 - learning_rate: 3.4375e-04
Epoch 28/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4398 - loss: 2.6310 - val_accuracy: 0.5796 - val_loss: 1.9676 - learning_rate: 3.4375e-04
Epoch 29/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4352 - loss: 2.6484 - val_accuracy: 0.5756 - val_loss: 1.9557 - learning_rate: 3.4375e-04
Epoch 30/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4420 - loss: 2.6223 - val_accuracy: 0.6003 - val_loss: 1.9575 - learning_rate: 3.4375e-04
Epoch 31/300
1413/1413 - 91s - 65ms/step - accuracy: 0.4417 - loss: 2.6138 - val_accuracy: 0.5884 - val_loss: 1.9041 - learning_rate: 3.4375e-04
Epoch 32/300
1413/1413 - 89s - 63ms/step - accuracy: 0.4365 - loss: 2.6248 - val_accuracy: 0.5876 - val_loss: 1.9119 - learning_rate: 3.4375e-04
Epoch 33/300
1413/1413 - 90s - 64ms/step - accuracy: 0.4427 - loss: 2.5919 - val_accuracy: 0.5876 - val_loss: 1.9171 - learning_rate: 3.4375e-04
Epoch 34/300
1413/1413 - 89s - 63ms/step - accuracy: 0.4510 - loss: 2.5813 - val_accuracy: 0.5860 - val_loss: 1.9281 - learning_rate: 3.4375e-04
Epoch 35/300
1413/1413 - 90s - 64ms/step - accuracy: 0.4444 - loss: 2.6031 - val_accuracy: 0.5868 - val_loss: 1.9116 - learning_rate: 3.4375e-04
Epoch 36/300
1413/1413 - 91s - 65ms/step - accuracy: 0.4415 - loss: 2.6057 - val_accuracy: 0.5732 - val_loss: 1.9863 - learning_rate: 3.4375e-04
Epoch 37/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4433 - loss: 2.5920 - val_accuracy: 0.5892 - val_loss: 1.8965 - learning_rate: 3.4375e-04
Epoch 38/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4384 - loss: 2.6067 - val_accuracy: 0.5828 - val_loss: 1.8958 - learning_rate: 3.4375e-04
Epoch 39/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4438 - loss: 2.5946 - val_accuracy: 0.5860 - val_loss: 1.8774 - learning_rate: 3.4375e-04
Epoch 40/300
1413/1413 - 91s - 64ms/step - accuracy: 0.4429 - loss: 2.6150 - val_accuracy: 0.6003 - val_loss: 1.8986 - learning_rate: 3.4375e-04
Epoch 41/300
1413/1413 - 89s - 63ms/step - accuracy: 0.4423 - loss: 2.5844 - val_accuracy: 0.6011 - val_loss: 1.8863 - learning_rate: 3.4375e-04
Epoch 42/300
1413/1413 - 88s - 62ms/step - accuracy: 0.4480 - loss: 2.5832 - val_accuracy: 0.5836 - val_loss: 1.8779 - learning_rate: 3.4375e-04
Epoch 43/300
1413/1413 - 90s - 63ms/step - accuracy: 0.4483 - loss: 2.5633 - val_accuracy: 0.6051 - val_loss: 1.8113 - learning_rate: 3.4375e-04
Epoch 44/300
1413/1413 - 90s - 63ms/step - accuracy: 0.4495 - loss: 2.5747 - val_accuracy: 0.6115 - val_loss: 1.8610 - learning_rate: 3.4375e-04
Epoch 45/300
1413/1413 - 145s - 103ms/step - accuracy: 0.4453 - loss: 2.5927 - val_accuracy: 0.5987 - val_loss: 1.8367 - learning_rate: 3.4375e-04
Epoch 46/300
1413/1413 - 91s - 64ms/step - accuracy: 0.4471 - loss: 2.5644 - val_accuracy: 0.6051 - val_loss: 1.8438 - learning_rate: 3.4375e-04
Epoch 47/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4590 - loss: 2.5430 - val_accuracy: 0.6091 - val_loss: 1.8726 - learning_rate: 3.4375e-04
Epoch 48/300
1413/1413 - 94s - 66ms/step - accuracy: 0.4448 - loss: 2.5796 - val_accuracy: 0.5995 - val_loss: 1.8769 - learning_rate: 3.4375e-04
Epoch 49/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4491 - loss: 2.5593 - val_accuracy: 0.5971 - val_loss: 1.8226 - learning_rate: 3.4375e-04
Epoch 50/300
1413/1413 - 91s - 65ms/step - accuracy: 0.4502 - loss: 2.5517 - val_accuracy: 0.6035 - val_loss: 1.8826 - learning_rate: 3.4375e-04
Epoch 51/300

Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0001718769344734028.
1413/1413 - 91s - 65ms/step - accuracy: 0.4506 - loss: 2.5504 - val_accuracy: 0.6091 - val_loss: 1.8526 - learning_rate: 3.4375e-04
Epoch 52/300
1413/1413 - 89s - 63ms/step - accuracy: 0.4649 - loss: 2.5058 - val_accuracy: 0.6131 - val_loss: 1.8401 - learning_rate: 1.7188e-04
Epoch 53/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4624 - loss: 2.4911 - val_accuracy: 0.6067 - val_loss: 1.7915 - learning_rate: 1.7188e-04
Epoch 54/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4626 - loss: 2.4663 - val_accuracy: 0.6154 - val_loss: 1.7902 - learning_rate: 1.7188e-04
Epoch 55/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4586 - loss: 2.4909 - val_accuracy: 0.6170 - val_loss: 1.8063 - learning_rate: 1.7188e-04
Epoch 56/300
1413/1413 - 91s - 65ms/step - accuracy: 0.4694 - loss: 2.4660 - val_accuracy: 0.6107 - val_loss: 1.7715 - learning_rate: 1.7188e-04
Epoch 57/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4701 - loss: 2.4802 - val_accuracy: 0.6202 - val_loss: 1.7876 - learning_rate: 1.7188e-04
Epoch 58/300
1413/1413 - 91s - 64ms/step - accuracy: 0.4662 - loss: 2.4628 - val_accuracy: 0.6194 - val_loss: 1.7711 - learning_rate: 1.7188e-04
Epoch 59/300
1413/1413 - 90s - 64ms/step - accuracy: 0.4639 - loss: 2.4767 - val_accuracy: 0.6218 - val_loss: 1.7612 - learning_rate: 1.7188e-04
Epoch 60/300
1413/1413 - 90s - 64ms/step - accuracy: 0.4712 - loss: 2.4668 - val_accuracy: 0.6194 - val_loss: 1.7820 - learning_rate: 1.7188e-04
Epoch 61/300
1413/1413 - 91s - 65ms/step - accuracy: 0.4741 - loss: 2.4484 - val_accuracy: 0.6067 - val_loss: 1.7519 - learning_rate: 1.7188e-04
Epoch 62/300
1413/1413 - 91s - 65ms/step - accuracy: 0.4777 - loss: 2.4435 - val_accuracy: 0.6202 - val_loss: 1.7639 - learning_rate: 1.7188e-04
Epoch 63/300
1413/1413 - 94s - 66ms/step - accuracy: 0.4692 - loss: 2.4650 - val_accuracy: 0.6274 - val_loss: 1.7458 - learning_rate: 1.7188e-04
Epoch 64/300
1413/1413 - 94s - 66ms/step - accuracy: 0.4675 - loss: 2.4764 - val_accuracy: 0.6306 - val_loss: 1.7444 - learning_rate: 1.7188e-04
Epoch 65/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4684 - loss: 2.4653 - val_accuracy: 0.6290 - val_loss: 1.7502 - learning_rate: 1.7188e-04
Epoch 66/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4698 - loss: 2.4363 - val_accuracy: 0.6258 - val_loss: 1.7516 - learning_rate: 1.7188e-04
Epoch 67/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4754 - loss: 2.4303 - val_accuracy: 0.6210 - val_loss: 1.7655 - learning_rate: 1.7188e-04
Epoch 68/300
1413/1413 - 91s - 65ms/step - accuracy: 0.4681 - loss: 2.4510 - val_accuracy: 0.6162 - val_loss: 1.7617 - learning_rate: 1.7188e-04
Epoch 69/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4642 - loss: 2.4591 - val_accuracy: 0.6242 - val_loss: 1.7397 - learning_rate: 1.7188e-04
Epoch 70/300
1413/1413 - 94s - 66ms/step - accuracy: 0.4785 - loss: 2.4270 - val_accuracy: 0.6218 - val_loss: 1.7672 - learning_rate: 1.7188e-04
Epoch 71/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4729 - loss: 2.4207 - val_accuracy: 0.6170 - val_loss: 1.7815 - learning_rate: 1.7188e-04
Epoch 72/300
1413/1413 - 93s - 65ms/step - accuracy: 0.4704 - loss: 2.4705 - val_accuracy: 0.6091 - val_loss: 1.8081 - learning_rate: 1.7188e-04
Epoch 73/300
1413/1413 - 91s - 65ms/step - accuracy: 0.4810 - loss: 2.4419 - val_accuracy: 0.6107 - val_loss: 1.8154 - learning_rate: 1.7188e-04
Epoch 74/300
1413/1413 - 90s - 64ms/step - accuracy: 0.4736 - loss: 2.4427 - val_accuracy: 0.6202 - val_loss: 1.7559 - learning_rate: 1.7188e-04
Epoch 75/300
1413/1413 - 89s - 63ms/step - accuracy: 0.4764 - loss: 2.4100 - val_accuracy: 0.6178 - val_loss: 1.7658 - learning_rate: 1.7188e-04
Epoch 76/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4711 - loss: 2.4328 - val_accuracy: 0.6210 - val_loss: 1.7909 - learning_rate: 1.7188e-04
Epoch 77/300

Epoch 77: ReduceLROnPlateau reducing learning rate to 8.59384672367014e-05.
1413/1413 - 92s - 65ms/step - accuracy: 0.4749 - loss: 2.4221 - val_accuracy: 0.6274 - val_loss: 1.7893 - learning_rate: 1.7188e-04
Epoch 78/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4839 - loss: 2.3999 - val_accuracy: 0.6354 - val_loss: 1.7084 - learning_rate: 8.5938e-05
Epoch 79/300
1413/1413 - 93s - 66ms/step - accuracy: 0.4807 - loss: 2.3809 - val_accuracy: 0.6226 - val_loss: 1.7428 - learning_rate: 8.5938e-05
Epoch 80/300
1413/1413 - 93s - 65ms/step - accuracy: 0.4814 - loss: 2.4028 - val_accuracy: 0.6385 - val_loss: 1.6959 - learning_rate: 8.5938e-05
Epoch 81/300
1413/1413 - 91s - 64ms/step - accuracy: 0.4799 - loss: 2.3820 - val_accuracy: 0.6322 - val_loss: 1.7186 - learning_rate: 8.5938e-05
Epoch 82/300
1413/1413 - 91s - 64ms/step - accuracy: 0.4840 - loss: 2.3747 - val_accuracy: 0.6330 - val_loss: 1.7319 - learning_rate: 8.5938e-05
Epoch 83/300
1413/1413 - 91s - 64ms/step - accuracy: 0.4830 - loss: 2.3772 - val_accuracy: 0.6306 - val_loss: 1.7364 - learning_rate: 8.5938e-05
Epoch 84/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4844 - loss: 2.3693 - val_accuracy: 0.6322 - val_loss: 1.7165 - learning_rate: 8.5938e-05
Epoch 85/300
1413/1413 - 92s - 65ms/step - accuracy: 0.4796 - loss: 2.3784 - val_accuracy: 0.6298 - val_loss: 1.7269 - learning_rate: 8.5938e-05
Epoch 86/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4868 - loss: 2.3931 - val_accuracy: 0.6282 - val_loss: 1.7023 - learning_rate: 8.5938e-05
Epoch 87/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4804 - loss: 2.3882 - val_accuracy: 0.6338 - val_loss: 1.7069 - learning_rate: 8.5938e-05
Epoch 88/300

Epoch 88: ReduceLROnPlateau reducing learning rate to 4.29692336183507e-05.
1413/1413 - 95s - 67ms/step - accuracy: 0.4819 - loss: 2.3859 - val_accuracy: 0.6202 - val_loss: 1.7574 - learning_rate: 8.5938e-05
Epoch 89/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4908 - loss: 2.3653 - val_accuracy: 0.6274 - val_loss: 1.7205 - learning_rate: 4.2969e-05
Epoch 90/300
1413/1413 - 95s - 68ms/step - accuracy: 0.4848 - loss: 2.3693 - val_accuracy: 0.6314 - val_loss: 1.6974 - learning_rate: 4.2969e-05
Epoch 91/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4844 - loss: 2.3671 - val_accuracy: 0.6330 - val_loss: 1.6789 - learning_rate: 4.2969e-05
Epoch 92/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4795 - loss: 2.3768 - val_accuracy: 0.6354 - val_loss: 1.6769 - learning_rate: 4.2969e-05
Epoch 93/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4839 - loss: 2.3607 - val_accuracy: 0.6361 - val_loss: 1.6668 - learning_rate: 4.2969e-05
Epoch 94/300
1413/1413 - 95s - 68ms/step - accuracy: 0.4843 - loss: 2.3637 - val_accuracy: 0.6298 - val_loss: 1.7009 - learning_rate: 4.2969e-05
Epoch 95/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4863 - loss: 2.3701 - val_accuracy: 0.6250 - val_loss: 1.6840 - learning_rate: 4.2969e-05
Epoch 96/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4901 - loss: 2.3408 - val_accuracy: 0.6346 - val_loss: 1.6918 - learning_rate: 4.2969e-05
Epoch 97/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4885 - loss: 2.3690 - val_accuracy: 0.6377 - val_loss: 1.6627 - learning_rate: 4.2969e-05
Epoch 98/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4797 - loss: 2.3680 - val_accuracy: 0.6322 - val_loss: 1.6841 - learning_rate: 4.2969e-05
Epoch 99/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4854 - loss: 2.3509 - val_accuracy: 0.6361 - val_loss: 1.6792 - learning_rate: 4.2969e-05
Epoch 100/300
1413/1413 - 97s - 68ms/step - accuracy: 0.4823 - loss: 2.3783 - val_accuracy: 0.6377 - val_loss: 1.6861 - learning_rate: 4.2969e-05
Epoch 101/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4884 - loss: 2.3655 - val_accuracy: 0.6322 - val_loss: 1.6848 - learning_rate: 4.2969e-05
Epoch 102/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4878 - loss: 2.3413 - val_accuracy: 0.6354 - val_loss: 1.6881 - learning_rate: 4.2969e-05
Epoch 103/300
1413/1413 - 94s - 67ms/step - accuracy: 0.4864 - loss: 2.3468 - val_accuracy: 0.6346 - val_loss: 1.6678 - learning_rate: 4.2969e-05
Epoch 104/300
1413/1413 - 95s - 67ms/step - accuracy: 0.4867 - loss: 2.3612 - val_accuracy: 0.6361 - val_loss: 1.6728 - learning_rate: 4.2969e-05
Epoch 105/300

Epoch 105: ReduceLROnPlateau reducing learning rate to 2.148461680917535e-05.
1413/1413 - 95s - 67ms/step - accuracy: 0.4830 - loss: 2.3653 - val_accuracy: 0.6377 - val_loss: 1.6771 - learning_rate: 4.2969e-05
Epoch 106/300
1413/1413 - 95s - 68ms/step - accuracy: 0.4969 - loss: 2.3221 - val_accuracy: 0.6361 - val_loss: 1.6669 - learning_rate: 2.1485e-05
Epoch 107/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4945 - loss: 2.3379 - val_accuracy: 0.6338 - val_loss: 1.6742 - learning_rate: 2.1485e-05
Epoch 108/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4908 - loss: 2.3632 - val_accuracy: 0.6385 - val_loss: 1.6690 - learning_rate: 2.1485e-05
Epoch 109/300
1413/1413 - 97s - 68ms/step - accuracy: 0.4881 - loss: 2.3395 - val_accuracy: 0.6354 - val_loss: 1.6875 - learning_rate: 2.1485e-05
Epoch 110/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4857 - loss: 2.3697 - val_accuracy: 0.6393 - val_loss: 1.6788 - learning_rate: 2.1485e-05
Epoch 111/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4946 - loss: 2.3353 - val_accuracy: 0.6385 - val_loss: 1.6689 - learning_rate: 2.1485e-05
Epoch 112/300
1413/1413 - 96s - 68ms/step - accuracy: 0.4877 - loss: 2.3460 - val_accuracy: 0.6425 - val_loss: 1.6628 - learning_rate: 2.1485e-05
Epoch 113/300

Epoch 113: ReduceLROnPlateau reducing learning rate to 1.0742308404587675e-05.
1413/1413 - 95s - 68ms/step - accuracy: 0.4922 - loss: 2.3410 - val_accuracy: 0.6385 - val_loss: 1.6768 - learning_rate: 2.1485e-05
Epoch 113: early stopping
Restoring model weights from the end of the best epoch: 97.
Fold 0 Evaluation results: [1.662737250328064, 0.637738823890686]
              precision    recall  f1-score   support

        1820       0.84      0.79      0.82        62
        1821       0.88      0.79      0.83        57
        1822       0.00      0.00      0.00         1
        1823       0.00      0.00      0.00         1
        1824       0.00      0.00      0.00         1
        1825       1.00      0.33      0.50         3
        1826       0.00      0.00      0.00         2
        1827       0.70      0.84      0.76        25
        1828       0.33      1.00      0.50         1
        1829       0.80      0.80      0.80         5
        1830       0.64      0.77      0.70        56
        1831       0.82      0.89      0.85       134
        1832       0.87      0.81      0.84        67
        1833       1.00      0.84      0.91        19
        1834       0.56      0.69      0.62        29
        1835       0.00      0.00      0.00         2
        1836       0.00      0.00      0.00         4
        1837       0.38      0.83      0.53         6
        1838       0.67      0.67      0.67         3
        1839       0.00      0.00      0.00         1
        1840       0.57      0.58      0.57        43
        1841       0.76      0.67      0.71       108
        1842       1.00      0.67      0.80         6
        1843       0.40      0.33      0.36         6
        1844       0.00      0.00      0.00         1
        1845       0.00      0.00      0.00         1
        1846       1.00      0.33      0.50         6
        1847       0.00      0.00      0.00         2
        1848       0.00      0.00      0.00         5
        1849       0.00      0.00      0.00         6
        1850       0.25      0.35      0.29        48
        1851       0.72      0.71      0.72        77
        1852       0.33      0.14      0.20         7
        1853       0.25      0.14      0.18         7
        1854       0.00      0.00      0.00         3
        1855       0.50      0.30      0.38        23
        1856       0.90      0.75      0.82        12
        1857       0.40      0.60      0.48        30
        1858       0.00      0.00      0.00         2
        1859       0.00      0.00      0.00         2
        1860       0.37      0.40      0.38        65
        1861       0.75      0.84      0.79        85
        1862       0.27      0.32      0.29        19
        1863       0.54      0.37      0.44        19
        1864       0.50      0.41      0.45        17
        1865       0.67      0.29      0.40         7
        1866       0.25      0.40      0.31         5
        1867       0.43      0.27      0.33        11
        1868       0.00      0.00      0.00         7
        1869       0.00      0.00      0.00         5
        1870       0.47      0.65      0.54        31
        1871       0.82      0.76      0.79        49
        1872       0.44      0.57      0.50         7
        1873       0.12      0.10      0.11        10
        1874       0.50      0.20      0.29         5
        1875       0.50      0.36      0.42        14
        1876       1.00      0.90      0.95        10
        1877       0.50      0.40      0.44         5
        1878       0.56      0.56      0.56         9
        1879       0.00      0.00      0.00         2

    accuracy                           0.64      1256
   macro avg       0.42      0.39      0.39      1256
weighted avg       0.64      0.64      0.63      1256

Matthews Correlation Coefficient: 0.619
Macro avg F1: 0.389
Weighted avg F1: 0.633
Micro avg F1: 0.638
Top-3 Accuracy: 0.857
Top-5 Accuracy: 0.914
Micro ROC AUC  = 0.99
Macro ROC AUC (present classes) = 0.98
Classification MAE (in years): 3.18
Metrics: {'accuracy': 0.637738823890686, 'mae_years': np.float64(3.1815286624203822), 'mcc': np.float64(0.6194839170605421)}

=== Total running time: 2 hours, 58 minutes, 26 seconds ===

