TensorFlow Version: 2.20.0-dev20250508
Num GPUs Available: 1
Physical devices cannot be modified after being initialized

=== Using model: InceptionV3. ===
RUN ID: 2025-05-16_23:32:10
Task: Regression
Test fold: 0
DEBUG: Test file (data/datasets/fold0.csv) year range: 1820 to 1879
DEBUG: Test file columns: ['year', 'file']
DEBUG: Sample from test file:
   year                                               file
0  1844         datasets/public/1840/1844_33washington.jpg
1  1839              datasets/public/1830/1839_2663vna.jpg
2  1824  datasets/private/1820/1824_034_Zrzut ekranu 20...
3  1845              datasets/public/1840/1845_2691vna.jpg
4  1823              datasets/public/1820/1823_2530vna.jpg

===== Fine Tuning 9 layers! =====
Epoch 1/300
1413/1413 - 206s - 146ms/step - loss: 1.1959 - mae: 0.5986 - mse: 0.5972 - val_loss: 0.3117 - val_mae: 0.2376 - val_mse: 0.0741 - learning_rate: 2.5974e-04
Epoch 2/300
1413/1413 - 137s - 97ms/step - loss: 0.5853 - mae: 0.3703 - mse: 0.2150 - val_loss: 0.3352 - val_mae: 0.2505 - val_mse: 0.0846 - learning_rate: 2.5974e-04
Epoch 3/300
1413/1413 - 136s - 96ms/step - loss: 0.4388 - mae: 0.3022 - mse: 0.1366 - val_loss: 0.3090 - val_mae: 0.2367 - val_mse: 0.0723 - learning_rate: 2.5974e-04
Epoch 4/300
1413/1413 - 145s - 102ms/step - loss: 0.3705 - mae: 0.2673 - mse: 0.1031 - val_loss: 0.3170 - val_mae: 0.2404 - val_mse: 0.0765 - learning_rate: 2.5974e-04
Epoch 5/300
1413/1413 - 142s - 100ms/step - loss: 0.3469 - mae: 0.2559 - mse: 0.0910 - val_loss: 0.3028 - val_mae: 0.2302 - val_mse: 0.0726 - learning_rate: 2.5974e-04
Epoch 6/300
1413/1413 - 140s - 99ms/step - loss: 0.3138 - mae: 0.2354 - mse: 0.0784 - val_loss: 0.2180 - val_mae: 0.1703 - val_mse: 0.0478 - learning_rate: 2.5974e-04
Epoch 7/300
1413/1413 - 140s - 99ms/step - loss: 0.2658 - mae: 0.2027 - mse: 0.0632 - val_loss: 0.1714 - val_mae: 0.1387 - val_mse: 0.0326 - learning_rate: 2.5974e-04
Epoch 8/300
1413/1413 - 138s - 97ms/step - loss: 0.2408 - mae: 0.1854 - mse: 0.0554 - val_loss: 0.1599 - val_mae: 0.1289 - val_mse: 0.0310 - learning_rate: 2.5974e-04
Epoch 9/300
1413/1413 - 139s - 98ms/step - loss: 0.2276 - mae: 0.1765 - mse: 0.0512 - val_loss: 0.1503 - val_mae: 0.1222 - val_mse: 0.0282 - learning_rate: 2.5974e-04
Epoch 10/300
1413/1413 - 140s - 99ms/step - loss: 0.2213 - mae: 0.1720 - mse: 0.0493 - val_loss: 0.1519 - val_mae: 0.1242 - val_mse: 0.0277 - learning_rate: 2.5974e-04
Epoch 11/300
1413/1413 - 137s - 97ms/step - loss: 0.2169 - mae: 0.1689 - mse: 0.0480 - val_loss: 0.1498 - val_mae: 0.1220 - val_mse: 0.0278 - learning_rate: 2.5974e-04
Epoch 12/300
1413/1413 - 153s - 108ms/step - loss: 0.2118 - mae: 0.1655 - mse: 0.0463 - val_loss: 0.1484 - val_mae: 0.1216 - val_mse: 0.0268 - learning_rate: 2.5974e-04
Epoch 13/300
1413/1413 - 150s - 106ms/step - loss: 0.2098 - mae: 0.1638 - mse: 0.0461 - val_loss: 0.1369 - val_mae: 0.1127 - val_mse: 0.0242 - learning_rate: 2.5974e-04
Epoch 14/300
1413/1413 - 155s - 109ms/step - loss: 0.2085 - mae: 0.1631 - mse: 0.0454 - val_loss: 0.1407 - val_mae: 0.1150 - val_mse: 0.0256 - learning_rate: 2.5974e-04
Epoch 15/300
1413/1413 - 163s - 116ms/step - loss: 0.2089 - mae: 0.1634 - mse: 0.0455 - val_loss: 0.1534 - val_mae: 0.1264 - val_mse: 0.0270 - learning_rate: 2.5974e-04
Epoch 16/300
1413/1413 - 167s - 118ms/step - loss: 0.2062 - mae: 0.1612 - mse: 0.0450 - val_loss: 0.1359 - val_mae: 0.1118 - val_mse: 0.0241 - learning_rate: 2.5974e-04
Epoch 17/300
1413/1413 - 161s - 114ms/step - loss: 0.2058 - mae: 0.1611 - mse: 0.0447 - val_loss: 0.1568 - val_mae: 0.1267 - val_mse: 0.0301 - learning_rate: 2.5974e-04
Epoch 18/300
1413/1413 - 161s - 114ms/step - loss: 0.2043 - mae: 0.1600 - mse: 0.0442 - val_loss: 0.1397 - val_mae: 0.1153 - val_mse: 0.0244 - learning_rate: 2.5974e-04
Epoch 19/300
1413/1413 - 162s - 115ms/step - loss: 0.2043 - mae: 0.1600 - mse: 0.0443 - val_loss: 0.1351 - val_mae: 0.1106 - val_mse: 0.0244 - learning_rate: 2.5974e-04
Epoch 20/300
1413/1413 - 165s - 116ms/step - loss: 0.2017 - mae: 0.1580 - mse: 0.0437 - val_loss: 0.1264 - val_mae: 0.1055 - val_mse: 0.0209 - learning_rate: 2.5974e-04
Epoch 21/300
1413/1413 - 160s - 113ms/step - loss: 0.2030 - mae: 0.1591 - mse: 0.0439 - val_loss: 0.1506 - val_mae: 0.1239 - val_mse: 0.0267 - learning_rate: 2.5974e-04
Epoch 22/300
1413/1413 - 167s - 118ms/step - loss: 0.2023 - mae: 0.1585 - mse: 0.0438 - val_loss: 0.1334 - val_mae: 0.1102 - val_mse: 0.0233 - learning_rate: 2.5974e-04
Epoch 23/300
1413/1413 - 166s - 118ms/step - loss: 0.1980 - mae: 0.1557 - mse: 0.0424 - val_loss: 0.1257 - val_mae: 0.1047 - val_mse: 0.0210 - learning_rate: 2.5974e-04
Epoch 24/300
1413/1413 - 163s - 115ms/step - loss: 0.1977 - mae: 0.1554 - mse: 0.0423 - val_loss: 0.1214 - val_mae: 0.1014 - val_mse: 0.0201 - learning_rate: 2.5974e-04
Epoch 25/300
1413/1413 - 161s - 114ms/step - loss: 0.1953 - mae: 0.1536 - mse: 0.0417 - val_loss: 0.1201 - val_mae: 0.1006 - val_mse: 0.0195 - learning_rate: 2.5974e-04
Epoch 26/300
1413/1413 - 154s - 109ms/step - loss: 0.1985 - mae: 0.1559 - mse: 0.0426 - val_loss: 0.1193 - val_mae: 0.1004 - val_mse: 0.0190 - learning_rate: 2.5974e-04
Epoch 27/300
1413/1413 - 157s - 111ms/step - loss: 0.1973 - mae: 0.1551 - mse: 0.0422 - val_loss: 0.1429 - val_mae: 0.1192 - val_mse: 0.0237 - learning_rate: 2.5974e-04
Epoch 28/300
1413/1413 - 161s - 114ms/step - loss: 0.1969 - mae: 0.1546 - mse: 0.0423 - val_loss: 0.1643 - val_mae: 0.1314 - val_mse: 0.0330 - learning_rate: 2.5974e-04
Epoch 29/300
1413/1413 - 156s - 110ms/step - loss: 0.1926 - mae: 0.1519 - mse: 0.0408 - val_loss: 0.1194 - val_mae: 0.1009 - val_mse: 0.0185 - learning_rate: 2.5974e-04
Epoch 30/300
1413/1413 - 154s - 109ms/step - loss: 0.1954 - mae: 0.1537 - mse: 0.0417 - val_loss: 0.1359 - val_mae: 0.1137 - val_mse: 0.0222 - learning_rate: 2.5974e-04
Epoch 31/300
1413/1413 - 159s - 113ms/step - loss: 0.1915 - mae: 0.1509 - mse: 0.0406 - val_loss: 0.1228 - val_mae: 0.1035 - val_mse: 0.0193 - learning_rate: 2.5974e-04
Epoch 32/300
1413/1413 - 158s - 112ms/step - loss: 0.1957 - mae: 0.1537 - mse: 0.0421 - val_loss: 0.1201 - val_mae: 0.1015 - val_mse: 0.0185 - learning_rate: 2.5974e-04
Epoch 33/300
1413/1413 - 159s - 113ms/step - loss: 0.1931 - mae: 0.1517 - mse: 0.0414 - val_loss: 0.1195 - val_mae: 0.1010 - val_mse: 0.0185 - learning_rate: 2.5974e-04
Epoch 34/300
1413/1413 - 159s - 112ms/step - loss: 0.1910 - mae: 0.1504 - mse: 0.0406 - val_loss: 0.1102 - val_mae: 0.0934 - val_mse: 0.0168 - learning_rate: 2.5974e-04
Epoch 35/300
1413/1413 - 160s - 113ms/step - loss: 0.1899 - mae: 0.1495 - mse: 0.0404 - val_loss: 0.1104 - val_mae: 0.0937 - val_mse: 0.0166 - learning_rate: 2.5974e-04
Epoch 36/300
1413/1413 - 161s - 114ms/step - loss: 0.1894 - mae: 0.1493 - mse: 0.0401 - val_loss: 0.1115 - val_mae: 0.0946 - val_mse: 0.0169 - learning_rate: 2.5974e-04
Epoch 37/300
1413/1413 - 157s - 111ms/step - loss: 0.1923 - mae: 0.1514 - mse: 0.0408 - val_loss: 0.1195 - val_mae: 0.1013 - val_mse: 0.0182 - learning_rate: 2.5974e-04
Epoch 38/300
1413/1413 - 158s - 112ms/step - loss: 0.1919 - mae: 0.1510 - mse: 0.0409 - val_loss: 0.1187 - val_mae: 0.1005 - val_mse: 0.0183 - learning_rate: 2.5974e-04
Epoch 39/300
1413/1413 - 160s - 113ms/step - loss: 0.1905 - mae: 0.1499 - mse: 0.0406 - val_loss: 0.1135 - val_mae: 0.0964 - val_mse: 0.0171 - learning_rate: 2.5974e-04
Epoch 40/300
1413/1413 - 161s - 114ms/step - loss: 0.1896 - mae: 0.1492 - mse: 0.0404 - val_loss: 0.1103 - val_mae: 0.0931 - val_mse: 0.0172 - learning_rate: 2.5974e-04
Epoch 41/300
1413/1413 - 159s - 112ms/step - loss: 0.1905 - mae: 0.1500 - mse: 0.0405 - val_loss: 0.1106 - val_mae: 0.0934 - val_mse: 0.0172 - learning_rate: 2.5974e-04
Epoch 42/300

Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0001298690476687625.
1413/1413 - 163s - 116ms/step - loss: 0.1870 - mae: 0.1474 - mse: 0.0396 - val_loss: 0.1111 - val_mae: 0.0941 - val_mse: 0.0170 - learning_rate: 2.5974e-04
Epoch 43/300
1413/1413 - 157s - 111ms/step - loss: 0.1838 - mae: 0.1451 - mse: 0.0387 - val_loss: 0.1141 - val_mae: 0.0959 - val_mse: 0.0183 - learning_rate: 1.2987e-04
Epoch 44/300
1413/1413 - 162s - 115ms/step - loss: 0.1834 - mae: 0.1450 - mse: 0.0384 - val_loss: 0.1095 - val_mae: 0.0930 - val_mse: 0.0165 - learning_rate: 1.2987e-04
Epoch 45/300
1413/1413 - 163s - 116ms/step - loss: 0.1828 - mae: 0.1440 - mse: 0.0387 - val_loss: 0.1109 - val_mae: 0.0945 - val_mse: 0.0165 - learning_rate: 1.2987e-04
Epoch 46/300
1413/1413 - 159s - 113ms/step - loss: 0.1816 - mae: 0.1435 - mse: 0.0380 - val_loss: 0.1210 - val_mae: 0.1023 - val_mse: 0.0187 - learning_rate: 1.2987e-04
Epoch 47/300
1413/1413 - 161s - 114ms/step - loss: 0.1849 - mae: 0.1459 - mse: 0.0390 - val_loss: 0.1150 - val_mae: 0.0973 - val_mse: 0.0177 - learning_rate: 1.2987e-04
Epoch 48/300
1413/1413 - 162s - 114ms/step - loss: 0.1812 - mae: 0.1434 - mse: 0.0378 - val_loss: 0.1108 - val_mae: 0.0939 - val_mse: 0.0169 - learning_rate: 1.2987e-04
Epoch 49/300
1413/1413 - 162s - 115ms/step - loss: 0.1844 - mae: 0.1458 - mse: 0.0386 - val_loss: 0.1081 - val_mae: 0.0925 - val_mse: 0.0156 - learning_rate: 1.2987e-04
Epoch 50/300
1413/1413 - 161s - 114ms/step - loss: 0.1806 - mae: 0.1431 - mse: 0.0375 - val_loss: 0.1083 - val_mae: 0.0925 - val_mse: 0.0157 - learning_rate: 1.2987e-04
Epoch 51/300
1413/1413 - 161s - 114ms/step - loss: 0.1831 - mae: 0.1448 - mse: 0.0384 - val_loss: 0.1074 - val_mae: 0.0915 - val_mse: 0.0159 - learning_rate: 1.2987e-04
Epoch 52/300
1413/1413 - 163s - 115ms/step - loss: 0.1776 - mae: 0.1408 - mse: 0.0368 - val_loss: 0.1147 - val_mae: 0.0975 - val_mse: 0.0172 - learning_rate: 1.2987e-04
Epoch 53/300
1413/1413 - 159s - 112ms/step - loss: 0.1794 - mae: 0.1419 - mse: 0.0375 - val_loss: 0.1176 - val_mae: 0.0999 - val_mse: 0.0177 - learning_rate: 1.2987e-04
Epoch 54/300
1413/1413 - 164s - 116ms/step - loss: 0.1794 - mae: 0.1420 - mse: 0.0374 - val_loss: 0.1156 - val_mae: 0.0984 - val_mse: 0.0172 - learning_rate: 1.2987e-04
Epoch 55/300
1413/1413 - 159s - 112ms/step - loss: 0.1807 - mae: 0.1429 - mse: 0.0378 - val_loss: 0.1092 - val_mae: 0.0930 - val_mse: 0.0162 - learning_rate: 1.2987e-04
Epoch 56/300
1413/1413 - 162s - 114ms/step - loss: 0.1844 - mae: 0.1456 - mse: 0.0388 - val_loss: 0.1092 - val_mae: 0.0930 - val_mse: 0.0162 - learning_rate: 1.2987e-04
Epoch 57/300
1413/1413 - 156s - 111ms/step - loss: 0.1800 - mae: 0.1425 - mse: 0.0375 - val_loss: 0.1123 - val_mae: 0.0952 - val_mse: 0.0171 - learning_rate: 1.2987e-04
Epoch 58/300
1413/1413 - 162s - 114ms/step - loss: 0.1812 - mae: 0.1433 - mse: 0.0379 - val_loss: 0.1131 - val_mae: 0.0958 - val_mse: 0.0173 - learning_rate: 1.2987e-04
Epoch 59/300

Epoch 59: ReduceLROnPlateau reducing learning rate to 6.493452383438125e-05.
1413/1413 - 162s - 115ms/step - loss: 0.1780 - mae: 0.1410 - mse: 0.0370 - val_loss: 0.1148 - val_mae: 0.0979 - val_mse: 0.0169 - learning_rate: 1.2987e-04
Epoch 60/300
1413/1413 - 163s - 115ms/step - loss: 0.1767 - mae: 0.1401 - mse: 0.0366 - val_loss: 0.1125 - val_mae: 0.0963 - val_mse: 0.0162 - learning_rate: 6.4935e-05
Epoch 61/300
1413/1413 - 153s - 108ms/step - loss: 0.1753 - mae: 0.1394 - mse: 0.0359 - val_loss: 0.1135 - val_mae: 0.0968 - val_mse: 0.0167 - learning_rate: 6.4935e-05
Epoch 62/300
1413/1413 - 162s - 115ms/step - loss: 0.1779 - mae: 0.1411 - mse: 0.0368 - val_loss: 0.1048 - val_mae: 0.0895 - val_mse: 0.0153 - learning_rate: 6.4935e-05
Epoch 63/300
1413/1413 - 161s - 114ms/step - loss: 0.1770 - mae: 0.1405 - mse: 0.0366 - val_loss: 0.1096 - val_mae: 0.0934 - val_mse: 0.0162 - learning_rate: 6.4935e-05
Epoch 64/300
1413/1413 - 161s - 114ms/step - loss: 0.1770 - mae: 0.1405 - mse: 0.0365 - val_loss: 0.1061 - val_mae: 0.0905 - val_mse: 0.0156 - learning_rate: 6.4935e-05
Epoch 65/300
1413/1413 - 160s - 113ms/step - loss: 0.1802 - mae: 0.1421 - mse: 0.0381 - val_loss: 0.1095 - val_mae: 0.0932 - val_mse: 0.0163 - learning_rate: 6.4935e-05
Epoch 66/300
1413/1413 - 165s - 117ms/step - loss: 0.1763 - mae: 0.1399 - mse: 0.0364 - val_loss: 0.1089 - val_mae: 0.0924 - val_mse: 0.0165 - learning_rate: 6.4935e-05
Epoch 67/300
1413/1413 - 163s - 116ms/step - loss: 0.1773 - mae: 0.1404 - mse: 0.0368 - val_loss: 0.1127 - val_mae: 0.0958 - val_mse: 0.0170 - learning_rate: 6.4935e-05
Epoch 68/300
1413/1413 - 161s - 114ms/step - loss: 0.1727 - mae: 0.1373 - mse: 0.0354 - val_loss: 0.1054 - val_mae: 0.0896 - val_mse: 0.0158 - learning_rate: 6.4935e-05
Epoch 69/300
1413/1413 - 160s - 113ms/step - loss: 0.1782 - mae: 0.1411 - mse: 0.0371 - val_loss: 0.1078 - val_mae: 0.0917 - val_mse: 0.0161 - learning_rate: 6.4935e-05
Epoch 70/300

Epoch 70: ReduceLROnPlateau reducing learning rate to 3.2467261917190626e-05.
1413/1413 - 164s - 116ms/step - loss: 0.1761 - mae: 0.1396 - mse: 0.0364 - val_loss: 0.1092 - val_mae: 0.0935 - val_mse: 0.0158 - learning_rate: 6.4935e-05
Epoch 71/300
1413/1413 - 162s - 115ms/step - loss: 0.1722 - mae: 0.1374 - mse: 0.0349 - val_loss: 0.1030 - val_mae: 0.0883 - val_mse: 0.0147 - learning_rate: 3.2467e-05
Epoch 72/300
1413/1413 - 161s - 114ms/step - loss: 0.1698 - mae: 0.1354 - mse: 0.0344 - val_loss: 0.1060 - val_mae: 0.0908 - val_mse: 0.0152 - learning_rate: 3.2467e-05
Epoch 73/300
1413/1413 - 158s - 112ms/step - loss: 0.1762 - mae: 0.1396 - mse: 0.0366 - val_loss: 0.1037 - val_mae: 0.0890 - val_mse: 0.0147 - learning_rate: 3.2467e-05
Epoch 74/300
1413/1413 - 160s - 113ms/step - loss: 0.1719 - mae: 0.1367 - mse: 0.0352 - val_loss: 0.1066 - val_mae: 0.0913 - val_mse: 0.0153 - learning_rate: 3.2467e-05
Epoch 75/300
1413/1413 - 162s - 115ms/step - loss: 0.1748 - mae: 0.1386 - mse: 0.0362 - val_loss: 0.1068 - val_mae: 0.0915 - val_mse: 0.0153 - learning_rate: 3.2467e-05
Epoch 76/300
1413/1413 - 160s - 113ms/step - loss: 0.1726 - mae: 0.1371 - mse: 0.0355 - val_loss: 0.1064 - val_mae: 0.0910 - val_mse: 0.0155 - learning_rate: 3.2467e-05
Epoch 77/300
1413/1413 - 161s - 114ms/step - loss: 0.1727 - mae: 0.1374 - mse: 0.0353 - val_loss: 0.1060 - val_mae: 0.0904 - val_mse: 0.0156 - learning_rate: 3.2467e-05
Epoch 78/300
1413/1413 - 159s - 113ms/step - loss: 0.1751 - mae: 0.1389 - mse: 0.0363 - val_loss: 0.1050 - val_mae: 0.0897 - val_mse: 0.0153 - learning_rate: 3.2467e-05
Epoch 79/300

Epoch 79: ReduceLROnPlateau reducing learning rate to 1.6233630958595313e-05.
1413/1413 - 158s - 112ms/step - loss: 0.1734 - mae: 0.1377 - mse: 0.0357 - val_loss: 0.1038 - val_mae: 0.0888 - val_mse: 0.0150 - learning_rate: 3.2467e-05
Epoch 80/300
1413/1413 - 162s - 115ms/step - loss: 0.1742 - mae: 0.1382 - mse: 0.0360 - val_loss: 0.1090 - val_mae: 0.0935 - val_mse: 0.0155 - learning_rate: 1.6234e-05
Epoch 81/300
1413/1413 - 157s - 111ms/step - loss: 0.1710 - mae: 0.1364 - mse: 0.0346 - val_loss: 0.1054 - val_mae: 0.0902 - val_mse: 0.0152 - learning_rate: 1.6234e-05
Epoch 82/300
1413/1413 - 163s - 115ms/step - loss: 0.1728 - mae: 0.1372 - mse: 0.0356 - val_loss: 0.1082 - val_mae: 0.0927 - val_mse: 0.0155 - learning_rate: 1.6234e-05
Epoch 83/300
1413/1413 - 156s - 111ms/step - loss: 0.1719 - mae: 0.1367 - mse: 0.0352 - val_loss: 0.1069 - val_mae: 0.0915 - val_mse: 0.0153 - learning_rate: 1.6234e-05
Epoch 84/300
1413/1413 - 164s - 116ms/step - loss: 0.1708 - mae: 0.1359 - mse: 0.0348 - val_loss: 0.1024 - val_mae: 0.0878 - val_mse: 0.0146 - learning_rate: 1.6234e-05
Epoch 85/300
1413/1413 - 161s - 114ms/step - loss: 0.1706 - mae: 0.1360 - mse: 0.0346 - val_loss: 0.1050 - val_mae: 0.0902 - val_mse: 0.0148 - learning_rate: 1.6234e-05
Epoch 86/300
1413/1413 - 161s - 114ms/step - loss: 0.1736 - mae: 0.1379 - mse: 0.0358 - val_loss: 0.1049 - val_mae: 0.0899 - val_mse: 0.0150 - learning_rate: 1.6234e-05
Epoch 87/300
1413/1413 - 159s - 113ms/step - loss: 0.1694 - mae: 0.1352 - mse: 0.0343 - val_loss: 0.1027 - val_mae: 0.0881 - val_mse: 0.0146 - learning_rate: 1.6234e-05
Epoch 88/300
1413/1413 - 161s - 114ms/step - loss: 0.1756 - mae: 0.1394 - mse: 0.0362 - val_loss: 0.1045 - val_mae: 0.0897 - val_mse: 0.0149 - learning_rate: 1.6234e-05
Epoch 89/300
1413/1413 - 159s - 113ms/step - loss: 0.1745 - mae: 0.1385 - mse: 0.0359 - val_loss: 0.1079 - val_mae: 0.0924 - val_mse: 0.0154 - learning_rate: 1.6234e-05
Epoch 90/300
1413/1413 - 159s - 112ms/step - loss: 0.1717 - mae: 0.1366 - mse: 0.0351 - val_loss: 0.1027 - val_mae: 0.0881 - val_mse: 0.0146 - learning_rate: 1.6234e-05
Epoch 91/300
1413/1413 - 157s - 111ms/step - loss: 0.1725 - mae: 0.1371 - mse: 0.0354 - val_loss: 0.1074 - val_mae: 0.0921 - val_mse: 0.0153 - learning_rate: 1.6234e-05
Epoch 92/300

Epoch 92: ReduceLROnPlateau reducing learning rate to 8.116815479297657e-06.
1413/1413 - 160s - 113ms/step - loss: 0.1723 - mae: 0.1370 - mse: 0.0352 - val_loss: 0.1067 - val_mae: 0.0913 - val_mse: 0.0154 - learning_rate: 1.6234e-05
Epoch 93/300
1413/1413 - 162s - 115ms/step - loss: 0.1718 - mae: 0.1369 - mse: 0.0349 - val_loss: 0.1075 - val_mae: 0.0920 - val_mse: 0.0155 - learning_rate: 8.1168e-06
Epoch 94/300
1413/1413 - 158s - 112ms/step - loss: 0.1710 - mae: 0.1360 - mse: 0.0350 - val_loss: 0.1079 - val_mae: 0.0923 - val_mse: 0.0156 - learning_rate: 8.1168e-06
Epoch 95/300
1413/1413 - 156s - 111ms/step - loss: 0.1743 - mae: 0.1382 - mse: 0.0361 - val_loss: 0.1075 - val_mae: 0.0919 - val_mse: 0.0156 - learning_rate: 8.1168e-06
Epoch 96/300
1413/1413 - 161s - 114ms/step - loss: 0.1720 - mae: 0.1370 - mse: 0.0350 - val_loss: 0.1069 - val_mae: 0.0914 - val_mse: 0.0155 - learning_rate: 8.1168e-06
Epoch 97/300
1413/1413 - 163s - 115ms/step - loss: 0.1716 - mae: 0.1366 - mse: 0.0350 - val_loss: 0.1098 - val_mae: 0.0942 - val_mse: 0.0156 - learning_rate: 8.1168e-06
Epoch 98/300
1413/1413 - 159s - 113ms/step - loss: 0.1738 - mae: 0.1379 - mse: 0.0359 - val_loss: 0.1061 - val_mae: 0.0911 - val_mse: 0.0150 - learning_rate: 8.1168e-06
Epoch 99/300
1413/1413 - 159s - 113ms/step - loss: 0.1715 - mae: 0.1364 - mse: 0.0351 - val_loss: 0.1083 - val_mae: 0.0925 - val_mse: 0.0157 - learning_rate: 8.1168e-06
Epoch 100/300

Epoch 100: ReduceLROnPlateau reducing learning rate to 4.058407739648828e-06.
1413/1413 - 160s - 113ms/step - loss: 0.1723 - mae: 0.1372 - mse: 0.0351 - val_loss: 0.1088 - val_mae: 0.0933 - val_mse: 0.0154 - learning_rate: 8.1168e-06
Epoch 100: early stopping
Restoring model weights from the end of the best epoch: 84.
Fold 0 Evaluation results: [0.10236990451812744, 0.0878077894449234, 0.014561804942786694]
Debug - Year range: 1820 to 1879
Debug - Sample years from training: [1871, 1862, 1863, 1848, 1855]
Debug - Sample normalized values: [0.864406779661017, 0.711864406779661, 0.7288135593220338, 0.4745762711864407, 0.5932203389830508]
Debug - min_year: 1820, max_year: 1879
Debug - predictions range: -0.0231 to 1.0012
Debug - true normalized values range: 0.0000 to 1.0000
Warning: 4 predictions were outside [0,1] range and had to be clipped
Debug - Sample true years (first 5): [1844 1839 1824 1845 1823]
Debug - Sample predicted years (first 5): [1844 1838 1841 1850 1825]
Fold 0 Exactly correct year predictions: 86 out of 1256
Fold 0 Final MAE (rounded to years): 5.18

Fold 0 Misclassification Analysis:
Near misses (within 2 years): 309 out of 1170 misclassifications (26.41%)
Big misses (greater than 10 years): 158
MAE with outliers: 5.18
MAE without outliers: 4.40 (improvement: 0.78)

10 Worst misclassifications:
Image: data/datasets/public/1820/1820_050met.jpg, True: 1820, Predicted: 1859, Error: 39
Image: data/datasets/private/1870/1871_412etsy.jpg, True: 1871, Predicted: 1834, Error: 37
Image: data/datasets/public/1820/1820_030met.jpg, True: 1820, Predicted: 1857, Error: 37
Image: data/datasets/private/1870/1871_398etsy.jpg, True: 1871, Predicted: 1838, Error: 33
Image: data/datasets/private/1820/1820_037_Zrzut ekranu 2022-07-26 210308.png, True: 1820, Predicted: 1853, Error: 33
Image: data/datasets/public/1820/1820_046met.jpg, True: 1820, Predicted: 1852, Error: 32
Image: data/datasets/public/1820/1820_036met.jpg, True: 1820, Predicted: 1850, Error: 30
Image: data/datasets/public/1820/1820_042met.jpg, True: 1820, Predicted: 1849, Error: 29
Image: data/datasets/private/1830/1834_110etsy.jpg, True: 1834, Predicted: 1863, Error: 29
Image: data/datasets/public/1820/1820_026met.jpg, True: 1820, Predicted: 1848, Error: 28
Metrics: {'mae': np.float64(5.181528662420382), 'exact': np.int64(86), 'total': 1256}

=== Total running time: 4 hours, 25 minutes, 32 seconds ===

